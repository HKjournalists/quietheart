这里的内容可能以后需要整理。
整理计划：1）题目要改2）图片处理


本文对有问题的方，已经做了标记，秩序搜索"???"就会到达有问题的地方。
是比较关键的知识点
*关于系统调用和库函数
*关于进程时间
*关于文件操作
*关于文件系统
*关于标准输入输出库
*关于系统数据和信息
*关于进程及环境
*关于进程控制
*关于进程间关系
*关于信号
*关于线程
*线程控制
*守护进程
*高级输入输出
*进程内部通信
*网络通信
*高级进程通信
*终端输入输出
*伪终端
*其他不太确定的(或者待整理的)

*问题

*关于系统调用和库函数
==========================

               UNIX体系结构

             +------------------------+
             |   applications        a|
             | +-------------------x p|
             | |s   shell         /  p|
             | |h+---------------/   l|
             | |e|  system calls |   i|
             | |l| +-----------+ |   c|
             | |l| |  Kernel   | |   a|
             | | | +-----------+ |   t|
             | | |  system calls |   i|
             | | /---------------\   o|
             | |/library routines \  n|
             | x-------------------x s|
             +------------------------+

参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch01lev1sec11.html
	1)系统调用是用户和内核交互的接口，用来请求内核提供相应服务。
	原来的系统调用接口是用汇编声明，现在用c语言函数方式声明了，其具体的实现方式就不一定是什么了。这样使得用户只需要像用c语言函数一样地使用系统调用就行了，而不用关心是怎么实现的。
	2）c语言的库函数是用c语言实现的，它一般是需要调用系统调用来实现的。
	系统调用一般和一些c语言的库函数名称一样，用户可以像使用库函数一样使用系统调用，但是两者不同，可以自己定义库函数来取代原来的库函数，而系统调用是无法取代的。例如malloc库函数就是用sbrk系统调用实现的。system库函数就是用fork和exec系统调用实现的。
	3)系统调用接口简洁，并且提供了所有的功能，但是不如库函数友好。
	库函数是对系统调用的“封装”。
	注意，一般man手册里面，第2节的内容是系统调用，第3节的内容是库函数。

"/usr/include/syscall.h"

*关于进程时间
==========================
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch01lev1sec10.html
	为了衡量一个进程的执行时间，unix使用三个值：
	1)Clock time
	运行这个进程所花费的时间，这个时间还依赖于系统上执行的其他进程的数量。一般我们假设系统上没有其他进程运行。
	2)User CPU time
	运行这个进程所花费的用户cpu时间。也就是执行用户（和内核相对）指令所花费的时间。
	3)System CPU time
	运行这个进程所花费的系统（内核）cpu时间。也就是进程在核心态下所消耗的时间，例如调用系统调用。

	用户cpu时间和系统cpu时间统称进程的cpu时间。进程时间可以使用clock tick来衡量，例如一秒钟50个clock tick.测量一个程序的占用时间可以使用time命令。
	(总结一下，Clock time应该是我们看到的程序运行到结束的总时间，包括实际运行时间，以及由于调度产生的等待时间；而User+System为cpu时间，也就是除了进程调度和等待等因素后，纯粹的执行时间，也就是占用cpu的时间；user表示在用户空间占用的cpu时间，system表示在内核空间占用的cpu时间例如系统调用)。

*关于文件操作
==========================
	1)关于缓存
	系统调用的read和write没有缓存，库函数的可能缓存了，缓存的大小设置为和磁盘块大小一样最省时间。也就是说，一次read的数据如果是在磁盘块大小之内的话，时间是差不多的，所以最好把缓存设置为和磁盘块一样大小。
参考：
http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch01lev1sec5.html
http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec1.html
http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec9.html#ch03lev1sec9
	一般读写文件的时候，操作系统会自动尝试把文件缓存到内核中，这样下次操作同样文件的时候会比较快一些，所以测试文件操作时间的时候使用不同的文件会比较准确。这也是coredump的来源。使用sync可以将缓存的数据刷新到磁盘上面。有许多类型的sync，有的只刷新文件数据，有的连文件属性也刷新了。
参考网址：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec9.html

	2)内核用于维护进程打开的文件的相关数据结构：
	大致是，有三个数据结构：
	a）每个进程的进程表中有一个包含所有打开的文件描述符号信息的表，这个表中每一项主要包含：一个文件描述符号的标记以及一个文件符号描述表指针。
	b）文件符号描述表，由前面的进程表中指针来指向它，主要包含：一个状态标记，一个偏移，以及一个文件虚拟节点地址。如果多个进程打开同样文件，也会导致有多个这样的表，但是虚拟节点只有一个,这样是保证每个进程有自己正确的文件读取偏移量。
	c）文件虚拟节点：描述文件大小，虚拟节点信息和索引信息等。用于在计算机上支持不同的文件系统。对于虚拟节点和索引，linux类似使用的是一个依赖文件系统的i-node和不依赖文件系统的i-node.
	注意，上面的文件描述符号标记和状态标记是不一样的。文件描述符号标记例如close-on-exec,意思是使用exec的时候是否关闭之前的文件符号；状态标记有例如：读写属性，追加，同步写属性，阻塞等;
	如果打开多个文件想要使用一个文件符号描述表，那么用dup.使用fork好像就是达到这个效果的。如果一个进程打开多个文件呢？
	使用dup的时候，会使得进程中多个文件描述符号信息的表项指向一个文件符号描述表项。使用fcntl一样，不过fcntl有可能不是原子的，之前需要别的操作才行，而dup只需要一个函数，是原子的。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec10.html

                           打开文件的内核数据结构
                                                                         v-node table
      process table entry                   file table           -->+------------------+
      +------------------+  --------->+-------------------+     /   |     v-node       |
      |      fd    file  | /          |file status flags  |    /    |  information     |
      |     flags pointer|/           +-------------------|   /     +------------------+
      |     +----+-----+ /            |current file offset|  /      |     i-node       |
      | fd0 |    |     |/|            +-------------------+ /       |  information     |
      |     +----+-----+ |            | v-node pointer    |/        + - - - - - - - - -+
      | fd1 |    |     |----------\   +-------------------+         | current file size|
      |     +----+-----+ |         \                                +------------------+
      | fd2 |    |     | |          ->+-------------------+
      |     +----+-----+ |            |file status flags  |    ---->+------------------+
      |     |          | |            +-------------------|   /     |     v-node       |
      |     |  ......  | |            |current file offset|  /      |  information     |
      |     |          | |            +-------------------+ /       +------------------+
      |     +----------+ |            | v-node pointer    |/        |     i-node       |
      |                  |            +-------------------+         |  information     |
      +------------------+                                          + - - - - - - - - -+
                                                                    | current file size|
                                                                    +------------------+


                           两个独立的进程打开同样的文件

      process table entry
      +------------------+
      |      fd    file  |
      |     flags pointer|
      |     +----+-----+ |
      | fd0 |    |     | |
      |     +----+-----+ |
      | fd..|  ......  |
      |     +----+-----+ |                  file table
      | fd3 |    |     |------------->+-------------------+             v-node table
      |     +----+-----+ |            |file status flags  |    ---->+------------------+
      |     |          | |            +-------------------|   /  +->|     v-node       |
      |     |  ......  | |            |current file offset|  /   |  |  information     |
      |     |          | |            +-------------------+ /    |  +------------------+
      |     +----------+ |            | v-node pointer    |/     |  |     i-node       |
      |                  |            +-------------------+      |  |  information     |
      +------------------+                                       |  + - - - - - - - - -+
                                                                 |  | current file size|
                                                                 |  +------------------+
      process table entry        ---->+-------------------+     /
      +------------------+      /     |file status flags  |    /
      |      fd    file  |     /      +-------------------|   /
      |     flags pointer|    /       |current file offset|  /
      |     +----+-----+ |   /        +-------------------+ /
      | fd0 |    |     | |  /         | v-node pointer    |/
      |     +----+-----+ | /          +-------------------+
      | fd..|  ......  | |/
      |     +----+-----+ /
      | fd4 |    |     |/|
      |     +----+-----+ |
      |     |          | |
      |     |  ......  | |
      |     |          | |
      |     +----------+ |
      |                  |
      +------------------+


                                    dup之后的内核数据结构

      process table entry                                               v-node table
      +------------------+                                      +-->+------------------+
      |      fd    file  |                                      |   |     v-node       |
      |     flags pointer|                                      |   |  information     |
      |     +----+-----+ |                                      |   +------------------+
      | fd0 |    |     | |                                      |   |     i-node       |
      |     +----+-----+ |                                      |   |  information     |
      | fd1 |    |     |----------\                             |   + - - - - - - - - -+
      |     +---+------+ |         \                            |   | current file size|
      | fd2 |  ......  | |         -->+-------------------+     |   +------------------+
      |     +----+-----+ |        /   |file status flags  |    /
      | fd3 |    |     |---------/    +-------------------|   /
      |     +----+-----+ |            |current file offset|  /
      |     |          | |            +-------------------+ /
      |     +----------+ |            | v-node pointer    |/
      |                  |            +-------------------+
      +------------------+






	3)关于文件操作中的同步写：
	这里通过两个例子，说明，在使用O_SYNC标记的时候，会在write同时等待写到磁盘上才返回，这样明显占用了系统时间，但是在ext2系统上不认这个标记。在正常没有O_SYNC的write会写到磁盘缓存上面，所以占用时间少，正常没有O_SYNC的write后面接着一个fsync的话并不是和O_SYNC的write一样了，而是也占用很少的时间，因为在下次新write的时候会刷新之前的缓存，所以在fsync的时候，实际只把很少的一部分数据写到磁盘中了。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec14.html

	4)一些文件相关的操作
	关于open的append:
	当用append标记打开文件的时候，还是可以用lseek定位到任何地方来读取文件内容的，但是如果写的话，文件的offset会自动地定位到文件的结尾并且写。也就是说，用append的话，写操作不会写到除了结尾之外的地方(即使是用lseek定位也不会)。
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec13.html
以及练习3.6：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec18.html

	关于文件关闭：
	进程结束的时候会自动关闭它打开的所有文件；关闭文件的时候，会自动释放当前进程持有的所有在那个被关闭文件上面的锁。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec5.html

	关于lseek:
	pipe, FIFO, socket等这样不能lseek的文件当被lseek的时候，会返回1并且置errno为ESPIPE.
	检测方法具体见：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec6.html
	lseek返回值对于设备文件等特殊的文件可能为负数，对于正规文件非负，所以检测时候要小心。
	当lseek的位置大于文件的大小，然后在写入数据，会扩展文件大小，并且在原来的结尾和lseek处创建文件“空洞”。文件空洞并不会消耗磁盘空间，查看文件空洞可以用od。具体还是参见上面的网址。后面会继续说道文件“空洞”。大致是ls -l的size和du的size不是一样的，似乎前者包含了hole的,而du是不包含空洞的。cat就会把hole用空字符打印出来，所以一个包含了hole的文件core,用
	cat core>core.copy
	之后，
	du -s core.copy会比du -s core大了。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec12.html#ch04lev1sec12

	关于原子性的操作：
	参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec11.html
	原子性的操作就是在操作过程中不会被打断的操作，适用于多线程。例如：
	在文件结尾写入数据需要：1）使用lseek定位到文件结尾2）使用write写。但是这就不是原子操作了，在两步之间可能会被别的线程打断。所以要想原子操作，可以用带有append标志的open打开文件之后再write。
	还有例如：向一个指定的位置读写数据也类似，使用pread和pwrite函数指定偏移量的读写，是原子性的。

	fcntl函数和ioctl函数：
	fcntl函数可以在文件打开的时候修改文件的一些属性。例如读写属性，以及是否同步写。
	int fcntl(int filedes, int cmd, ... /* int arg */ );
	filedes是文件描述符号，cmd是要进行的操作，arg是操作的参数,不多说了。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch03lev1sec14.html

	ioctl函数可以支持任何的io操作而不仅仅是读和写。
	int ioctl(int filedes, int request, ...);
	一般在特殊文件如设备文件的驱动中等地方需要实现这个函数，不说了。

*关于文件系统
==========================
	1)对于进程对文件操作权限相关：
	*进程有六个ID：
	real user ID
	real group ID
	表示当前真正的用户究竟是谁，这个字段例如real user ID从passwd中取得。

	effective user ID
	effective group ID
	supplementary group IDs
	利用这个ID来决定进程访问文件的权限。

	saved set-user-ID
	saved set-group-ID
	这个ID在进程运行的时候，会保留一份effective ID的副本,在旧版本的posix中可选.
	另外，
	在文件的stat结构中的st_mode描述了文件的类型和权限，st_uid描述了文件的属主。

	具体来说：
	一般effective ID等于real ID.文件中的stat中的uid和gid是文件的属主相关信息，使用它和effective比较，如果一样就可以执行文件。
	如果文件设置了set-user-ID（在stat中的s_mode中设置），那么程序运行的时候，effectiveID就和文件的属主ID一样，这样就有特殊的权限了。
	set-group-ID类似。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec4.html

	*关于文件的权限，分为三个组：
	user,group,other,每个组有r,w,x三种权限，具体参见:
	http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec5.html

	*判断进程访问文件权限的过程：
	1.如果进程的effective user ID是0，那么访问被无条件允许。
	2.如果进程的effective user ID等于文件的owner ID（也就是进程拥有这个文件），那么访问权限依照文件的user访问权限而定。也就是说，如果user是可读的，那么进程能够读取，如果user可写的那么进程可以写，等等，如果设置user权限不可读写，那么即使进程effective user ID和owner ID(也就是user ID)一样，也是无法进行相应的访问的。
	3.如果进程的effective group ID或者supplementary group ID和文件的group ID一样，那么访问权限会依照文件组权限的设定而定。
	4.如果文件的other组的指定的访问权限被指定了，那么相应权限的访问会被允许。

	以上过程是依照次序进行的，如果在1－4步骤中，进入了某一步骤的判断，并且确定了权限，那么下一个步骤会被忽略的。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec5.html

	*对于一个新创建的文件：
	文件的userID将被设置为进程的effective user ID.
	文件的groupID可以是进程的effective group ID，也可以是文件父目录的group ID.
	具体如下：
	如果文件所在的目录设置了set-group-ID，那么就是父目录的groupID，否则就是进程的effective groupID.这是Linux2.4和solaris的特性。ext2,ext3可以在mount的时候指定这两种方式。
	FreeBSD 5.2.1 和 Mac OS X 10.3却一直是所在父目录的group ID.
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec6.html

	*使用real id判断的函数：access
	一般都是用effective id来判断使用的权限的，有时候需要使用real id来进行判断。例如尽管有的进程在set-user-id的情况下具有了root权限可以访问，我们还是需要知道这个进程的real id.access函数根据进程的real userid 和real group id来进行判断权限(判断的过程是把前面的四步的effective id换成real id)。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec7.html

	*创建文件之前，指定需要忽略（屏蔽）的位。
	使用create或者open创建文件的时候，指定权限，但是如果之前有一个umask设置了相应的位之后，那么open/create指定的权限相应于umask位的那些地方不会被设置。
	例如umask是002,open创建的时候是222,那么最终是220.最后一个被umask屏蔽了。查看umask有一个umask命令。
	例如$umask
	输出0022表示，8进制的022,在创建的时候被屏蔽了.
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec8.html

	如果创建一个已经存在的文件，那么这个文件的权限不会被改变，但是这个文件的内容有可能被truncate.
参见:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/app03lev1sec4.html#app03qa1q17a17

	*关于文件的stickybit:
	也就是S_ISVTX bit,在早于请求页的unix系统的时候，如果可执行文件设置了这个位，那么，第一次运行可执行文件的时候，会在进程退出的时候将可执行文件的text段（包含机器指令的部分）拷贝一份保存到swap分区。因为swap分区连续存储，这样下次运行的时候会更快。由于现在有了虚拟内存和更快的文件系统，所以这个位就不那么需要了。
	在当前的系统，对这个位进行了扩展，unix标准允许这个位设置目录，如果目录设置了这个位，那么目录中的文件可以在如下的情况下被重新命名或者删除：
	用户具有目录的写权限，并且满足下面的条件之一：
	a）用户拥有这个文件
	b）用户拥有这个目录
	c）用户是超级用户
	/tmp 和 /var/spool/uucppublic就是一个典型的应用，任何用户可以在这个目录里面创建和删除文件，但是只能删除属于自己的文件。
	saved-text bit不是POSIX标准，它是XSI扩展。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec10.html
	2)unlink一个文件的时候，如果文件link数大于0，则不删除，如果link数等于0则删除。
	另外，如果link数等于0了，还有进程再打开这个文件，那么内容先不删除（尽管这时候在目录看不见那个目录了），等关闭文件的时候，内核会检查link数目为0了才删除。
	如果被unlink的pathname是symbolic link,那么仅仅将symbolic link移除，并没有方法来移除对应的文件。
	rename用来重新命名一个文件或者目录，其执行有如下情况：
	a.如果oldname是一个文件，不是目录，那么我们会把相应的文件或者符号链接重新命名。这时候，如果newname存在，那么它不能是一个目录的引用。如果newname存在，并且不是一个目录，那么会先将newname删除，然后把oldname重新命名为newname.我们必须具有包含oldname以及newname的目录的写权限。
	b.如果oldname是一个目录，那么将会给一个目录重新命名。如果newname存在，它必须是一个目录的引用，并且这个目录必须为空。如果newname存在，并且是一个空目录，那么会被移除，然后将oldname重新命名为newname.另外，当我们重新命名一个目录的时候，newname不能包含具有oldname前缀的目录。例如，我们不能重新命名/usr/foo为/usr/foo/testdir.
	c.如果一个oldname或者newname是一个符号链接的引用，那么这些链接会被处理，而不是相应的文件。
	d.对于一特殊的情况，若oldname和newname引用相同的文件，那么函数返回成功，并且不会改变任何东西。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec15.html

	3)文件的三种时间：
	atime:访问时间。记录最后一次，例如执行exec,或者read,或者创建文件(非截断创建)的时候的时间。
	mtime:内容改变时间。记录最后一次文件内容改变的时间。
	ctime:状态改变时间。记录最后一次文件索引信息改变的时间，例如:文件名称，大小，链接数目，等一般在stat中的信息的改变。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec18.html

	一般ls -l只显示文件内容改变的时间，而chmod修改的是i-node的最近更改时间。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec9.html

	4)因为当前工作目录是进程的属性，所以子进程调用chdir不会影响父进程，这也是为什么cd命令是shell的内建命令而不是一个独立的程序的原因。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec22.html

	5)关于文件的大小：
	stat结构的st_size成员包含了文件的大小，这个成员仅对正规文件，目录，链接文件有意义。
更多参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec12.html

	6)关于链接：
	硬链接的局限是：
	a硬链接和文件必须在同一个文件系统之下。
	b只有超级用户才能够创建目录的硬链接。

	一个目录的软链接是不能用rmdir来删除的，因为软链接是一个文件，不是目录。用rm -r 也是只删除了这个软链接本身。

	这里同时也列出了如果传递的路径是一个符号链接，哪些函数会沿着符号链接跟踪到相应的文件或者不跟踪。
	例如open会follow一个symbolic link.如果一个symbolic指向一个不存在的文件，那么open的时候会提示没有这样的文件，如果大家不清楚symbolic link的工作原理，可能会被这种现象所困惑，举例如下：
	$ ln -s /no/such/file myfile            create a symbolic link
	$ ls myfile
	myfile                                  ls says it's there
	$ cat myfile                            so we try to look at it
	cat: myfile: No such file or directory
	$ ls -l myfile                          try -l option
	lrwxrwxrwx 1 sar        13 Jan 22 00:26 myfile -> /no/such/file
	我们好像看到了一个myfile的文件，但是ls的时候却提示没有这个文件。实际上，myfile是一个符号链接。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec16.html

	7)关于设备文件：
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch04lev1sec23.html
	相关的stat成员是dev_t st_dev;和dev_t st_rdev;
	*每个文件系统通过主从设备号被获知，这两者属于基本系统类型dev_t(一般是一个整数类型的typedef).major号标志驱动或者有时候标志和哪个外设板子相通信；minor用来标志特定的从设备。例如一个磁盘通常有多个文件系统，那么在这个磁盘上面的文件系统具有共同的major号，但是具有不同的minor号。
	*为了访问major号和minor号，一般都有两个宏来达到这个目的：major和minor.我们不用考虑major号和minor号是怎么存放在dev_t中的。在不同系统中dev_t的位是不同的，那位存放什么也不同，具体参见文档。
	*在系统中一个文件的st_dev值是包含这个文件的文件系统的device number.
	*只有字符设备文件和块设备文件具有s_rdev值，这个值包含device number和实际的设备。
	举例：
	*对于一个文件，其st_dev的major和minor是这个文件所在的文件系统的major和minor.
	*对于一个字符文件，会有st_dev和st_rdev.其中st_dev是这个字符设备特殊文件的文件节点所在的文件系统的major和minor(虚拟文件系统)，而st_rdev是这个字符设备文件的实际设备的major和minor号码。


*关于标准输入输出库
==========================
1)关于库函数和流：
流和文件描述符号
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec2.html
	我们使用系统调用来操作文件的时候，是通过文件描述符号来标识这个文件，如果我们使用标准库函数来进行文件操作的我们通常是把一个stream和这个文件相关联了，然后通过这个stream对这个流进行操作。
	当我们使用库函数fopen打开一个文件的时候，会返回一个指向FILE对象的指针，这个对象包含了I／O库管理stream的所有信息，例如被操作的文件的描述符号，指向这个stream的缓存的指针，以及缓存的大小，错误标志等等。我们把这个FILE对象做为参数传递给标准输入输出库函数，就可以实现相应的操作了（使用库函数操作，也不用费心去关心输入输出缓存设置为多大才好了）.
	通常，有单字节和多字节字符。stream的orientation用于决定读写的是单字节字符还是多字节字符。在最开始一个stream创建的时候，它是没有orientation的，这时候，如果使用了一个多字节I／O函数对这个stream进行操作(例如<wchar.h>中的)，那么这个stream就被设置为wide-oriented的；如果用单字节的I/O函数对这个stream进行操作，那么这个stream就被设置为byte-oriented的。一旦设置了stream的方向，除非被关闭，否则就不能改变了。当一个stream被set的时候，只有两个函数可以改变这个stream的orientation。它们是：fwide和freopen.
	freopen原型如下：
	FILE *freopen(const char *path, const char *mode, FILE *stream);
	它会把stream的orientation给clear.把原来的stream给关掉，然后把参数指定的新的stream和这个文件相互关联。

	fwide原型如下：
	#include <stdio.h>
	#include <wchar.h>
	int fwide(FILE *fp, int mode);
	这里，如果mode是负数，那么设置成byte-oriented;如mode是正数，那么设置成wide-oriented;如果mode是0那么不会做设置，但也返回当前流的orientation值。
	需要注意的是fwide不会改变已经被oriented的stream,也不会返回error。


参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec3.html
	有三个重要的流：stdin,stdout,stderr表示标准输入，输出和错误流，它们对应的文件描述符号是：STDIN_FILENO,STDOUT_FILENO,和STDERR_FILENO.

2)关于库函数和buffer
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec4.html
	使用标准输入输出库函数进行操作的目的就是为了使用最小数目的的read和write系统调用(通过自动管理设置多大的缓存等等)。
	standard i/o一般选择合适的大小来分配缓存。可能是BUFSIZ常量的值(在<stdio.h>中定义)，也可能是stat结构中的st_blksize成员。
有三种类型的缓存：
	a)Fully Buffered.在这种情况下当stand i/o的缓存被填满的时候才会发生i/o.一般使用standard i/o操作磁盘上面的文件的时候使用的是这种类型的buffer.
	b)Line Buffered.在这种情况下，当输入或者输出的时候遇到了一个换行符号的时候才会发生i/o.一般终端的标准输入和标准输出会用到这种类型的缓存。
	对于这种Line Buffered,需要注意的是：Line Buffer的缓存大小是固定的，当遇到换行符号之前缓存被填满了的时候，也会发生i/o.还有一个就是：(1)当请求输入是从一个unbuffer的方式进行的时候(2)当请求输入是从Line Buffered的时候。这两种情况下都会刷新(flushed)输出的缓存。
	c)Unbuffered.standard i/o不会缓存字符。一般标准错误流会使用这种类型的缓存，这样可以保证信息尽可能快地出现。

	ISO C规定：
	（1）standard input /output 当引用的不是交互式的设备的时候，是fully buffered.
	（2）standard error一定不能是fully buffered.
	但是，上面的规定却不是非常确定的，一般而言：
	(1)standard error是unbuffered.
	(2)其他的stream如果它们引用的是terminal设备，那么就是line Buffered；否则是fully buffered.

3)设置缓存：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec4.html
	有两个可以设置缓存的函数：
	#include <stdio.h>
	void setbuf(FILE *restrict fp, char *restrict buf);
	int setvbuf(FILE *restrict fp, char *restrict buf, int mode, size_t size);
	这两个函数必须在stream被open之后，并且任何i/o操作之前，被调用。

	使用setbuf我们可以设置和取消buffer.如果设置buffer,指向buf的指针的数据的大小必须是BUFSIZ,一般这样stream就是fully buffered.但是如果stream是和terminal相关联的也有些系统会把buffered设置为line buffered的。如果取消buffer,那么buf参数是NULL的。

	使用setvbuf,我们可以精确地指定我们想要的buffer类型。我们通过modde参数来进行指定：
	_IOFBF:表示fully buffered.
	_IOLBF:表示line buffered.
	_IONBF:表示unbuffered.
	如果我们指定为unbuffered,那么buf和size参数会被忽略.
	如果指定了fully buffered或者line buffered那么:我们可以通过buf和size来设置缓存和大小。如果这时候的buf参数是NULL那么standio 会自动分配一个合适的大小，例如BUFSIZ.
	注意，你需要保证在stream closed的时候，buf是存在的。如果我们自行指定分配的buffer是一个函数内部的局部变量，我们需要在这个函数返回之前把这个stream给closed了，另外，因为某些实现使用这个buffer的一部分做为记录的空间，所以我们存放在这个buffer中的数据应该小于它的实际大小。一般我们应该让系统自己选择分配合适的缓存和大小。
	fflush会导致在stream中没有被written的数据被提交到kernel中去。

参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec12.html
	注意：如果我们想查看一个流对应的buffer的信息的时候，我们首先对这个流进行一次I/O操作，因为一般情况下，第一次的I/O操作会为对应的流分配相应的缓存。

4)打开和关闭流：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec5.html
	三种打开流的方式：
	fopen
	freopen
	fdopen
	原型如下：
	FILE *fopen(const char *path, const char *mode);
	FILE *fdopen(int fd, const char *mode);
	FILE *freopen(const char *path, const char *mode, FILE *stream);
	其中，fdopen可以接受一个已经打开的文件描述符号，这样可以实现对除了磁盘normal文件之外的其他特殊文件进行流的操作。

5)关于流的读写：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec6.html
	当打开一个stream的时候，我们可以有三种方式读写其中的内容.例如：fgetc,fputc.
	a)字符方式。一次读写一个字符，如果stream有缓存那么由标准输入输出函数自己管理缓存。
	b)行方式。一次读写一行。例如fputs,fgets.
	c)直接方式／Binary方式/指定大小的方式。每次读写指定的大小。例如fread,fwrite.

参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec9.html
	注意：fread和fwrite的一个问题是：fread的数据必须是fwrite从同一个系统上面写的。大致因为：
	1）不同系统上面，编译环境有可能不同，结构的字节对齐因素等也不同。
	2）不同的系统，二进制文件格式可能不同，可能还包含了平台相关的信息。

参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec12.html
	想要查看流对应的文件描述符号，使用如下函数：
	#include <stdio.h>
	int fileno(FILE *fp);
	这样就可使用dup和fcntl了。

6)关于使用标准输入输出和直接使用系统调用进行输入输出的对比：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec8.html
	这里对
	char的std I/O
	line的std I/O
	以及系统调用设置最优缓存的I/O
	以及系统调用没有设置缓存的I/O
	进行了对比，发现：
	直接使用库函数，并不比最优缓存的系统调用I/O差很多。使用库函数，我们不用考虑系统最优缓存了，有时候只是考虑buffer大小就行了,这比系统调用考虑最优缓存方便多了。如果line的std I/O使用char的std I/O实现的话，其消耗的时间要比char的std I/O要大，但是由于line的std I/O是用高效率的memccopy实现的，所以快。
	使用char的std I/O比没有缓存的系统调用I/O要快，尽管循环次数差不多，而且char的还额外增加了一点sys的循环，但是一次系统调用的代价，比一次函数调用的代价大很多，所以，char的std I/O比纯粹没有缓存系统调用的I/O代价要小。
	使用std I/O需要增加一些system time用来拷贝。一般重要的程序，I/O应该占用user time更多。

7)关于流的定位：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec10.html
	有三组方法在I/O流中进行定位：
	1)ftell和fseek:在大约version7时开始，它们把位置存放在一个长整型中去。
	2)ftello和fseeko:在Single UNIX Specification是里面被引入，允许文件的偏移是off_t类型的。
	3)fgetpos和fsetpos:由ISO C引入，它使用一个fpos_t类型来存放文件的位置，这个类型可以记载需要的文件大小。
	需要移植到非Unix的程序，最好用fgetpos和fsetpos。

8)关于创建临时文件
	#include <stdio.h>
	char *tmpnam(char *ptr);
	FILE *tmpfile(void);

9)其他输入输出库：
	除了标准输入输出库(stdio)之外，还有其他的可选的输入输出库用于特定的目的。
	标准输入输出库并不是完美的，例如在我们使用line的buffer流进行标准输入输出时候，需要拷贝两次数据：一次是从内核到标准输入输出流的buffer,另外一次是从流buffer拷贝到我们的linebuffer。fast i/o(fio)库解决了这个问题。
	sfio库的速度类似fio库，通常都比stdio快。还有适合嵌入式占用内存较少的uClibc和newLibc等。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch05lev1sec14.html

*关于系统数据和信息
==========================
1)关于passwd文件
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec2.html
	Unix的用户数据库文件，描述的数据项包含许多字段，具体参考前面给出的参考网址。
	从前用户数据库文件就存放在/etc/passwd中,文件的每一行就表示了一个数据项，包含各种字段，例如用户名，用户id,等等。
	对于数据项的字段需要注意几点：
	a)一般都有一个名称为root用户，这个用户的ID是0，这个用户是超级用户。
	b)密码域只是一个单个的字母(x)，只是为了占位用的。以前是密码但是有安全隐患，现在把密码存放在了其他的地方。
	c)有些域可以为空，如果密码域为空则表示这个用户没有密码。
	d)shell字段（通常是最后一个字段），指明了用户登录的时候执行的shell程序，一般为/bin/sh,这里需要注意的是squid把/dev/null作为登录的shell,这样显然是无法登录的，目的就是为了防止以用户squid来登录。
	有许多服务程序它们的守护进程都有各自的用户id,以帮助执行服务，squid用户就是用于执行squid 代理缓冲的进程而设置的。除了使用/dev/null之外，也可以指定其他的东西来防止用户登录系统，例如/bin/false,/bin/true,等等。
	e)nobody用户用于允许用户以一个用户id（例如UId=65534,Gid=65534）来登录系统，但是没有权限。它们可以访问的文件应该是全世界都可以读写的文件，一般来说没有这样的文件。
	f)有些系统提供了一个finger命令来读取passwd中的comment域，这个域的每项内容用','来分割。
	有些系统提供了vipw命令，这个命令的作用是编辑passwd，group等相关文件。并且在编辑的时候可以保持与它们相关的其他文件的内容的一致，这和使用一些类似的图形工具来进行编辑的效果是一样的。

	posix.1定义了两个可以从passwd文件中获取数据项的函数:
	struct passwd *getpwuid(uid_t uid);
	struct passwd *getpwnam(const char *name);
	getpwuid在在ls将文件索引节点中的user id映射成为登录的用户名称的时候会被用到。getpwnam在我们输入用户名称时候login程序会用到。
	两个函数,如果运行失败了，返回NULL;成功之后都返回一个指向passwd结构的指针，这个指针内容是一个函数内部的静态变量，所以我们每次调用这两个函数的时候都会导致这个指针中的内容被后来的调用所覆盖。

	如果想要遍历passwd文件中的所有内容，那么使用如下的函数：
	#include <pwd.h>
	struct passwd *getpwent(void);

	void setpwent(void);
	void endpwent(void);
	这三个函数不是posix中的，而是Single Unix Specification中的XSI定义的，一般的系统都支持这个功能。
	函数getpwent如果运行失败了，返回NULL;成功之后返回一个passwd指针。返回的指针指向的是一个静态变量，每次调用其值都会被修改，每次调用getpwent都会返回下一条passwd记录。这个函数在第一次调用的时候会自动打开passwd文件，但是使用完了之后我们需要使用endpwent来关闭相应的文件。
	函数setpwent实现的是回滚功能，使用它之后，会回滚到第一个记录。getpwent会返回第一记录了。
	函数endpwent用来在使用完passwd之后关闭相应的文件。
	如果想要从最开始遍历passwd的化，例如如果实现getpwname，这三个函数的调用次序一般大致如下：
	struct passwd *
	getpwnam(const char *name)
	{
		struct passwd  *ptr;
		setpwent();
		while ((ptr = getpwent()) != NULL)
		{
			if (strcmp(name, ptr->pw_name) == 0)
			{
				break;
			}
		}
		endpwent();

	}

2)关于加密密码：
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec3.html
passwd中的密码域的真正密码被加密，之后存放来了另外的文件中,一般是shadow文件。这个文件至少要包含用户名和加密之后的密码信息。其他的信息可选，具体参见参考网址。
	很少有程序需要访问加密之后的密码，login和passwd可能会用到加密之后的密码，这样的程序一般是set-user-id的。shadow对外是不可读的，而passwd可以对外可读。

	linux2.4和solaris有用来访问shadow有一组函数：
	#include <shadow.h>
	struct spwd *getspnam(const char *name);
	struct spwd *getspent(void);
	这两个函数如果运行正常则返回指针，出错返回NULL.

	void setspent(void);
	void endspent(void);
	这几个函数类似访问passwd的函数。

3)关于Unix的组数据库文件：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec4.html
	组信息的数据库文件存储在/etc/group文件中，其中存放了组的相关结构信息。
	我们可以通过下面函数获取组数据项信息：
	#include <grp.h>
	struct group *getgrgid(gid_t gid);
	struct group *getgrnam(const char *name);
	如果运行正常返回相应的组数据项结构的指针，如果错误返回NULL.
	函数和访问passwd的相关函数类似，也是posix.1的。

	类似passwd相关函数，也有如下遍历组数据项的函数:
	#include <grp.h>
	struct group *getgrent(void);
	这个函数如果运行正常则返回指针，出错或者到达文件结尾返回NULL.
	void setgrent(void);
	void endgrent(void);
	这三个函数类似passwd的相关函数，setgrent如果在文件没有打开的时候会打开文件，然后rewinds。getgrent获取下一个组项。endgrent关闭组文件，这三个函数不是posix.1而是single unix的xsi扩展。

4)关于额外的组信息：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec5.html
	从前都是登录之后用户被指定了一个组，然后运行需要别的组的时候可以通过newgrp命令来修改和恢复用户所属的组。现在一个用户可以属于多个组了，所以不用newgrp来显式修改用户所属的组了。
	用来设置额外组的函数是：
	#include <unistd.h>
	int getgroups(int gidsetsize, gid_t grouplist[]);
	getgroups函数用来获取用户所属的组id，并将其存放在一个数组里面。gidsetsize指明存放在数组里面的元素数目，grouplist是存放组id的数组，函数返回获取到grouplist中的元素数目。如果gidsetsize是0那么函数返回属于的所有组的组的数目。grouplist不会被修改，这里允许用户自行分配grouplist的空间。

	#include <grp.h>     /* on Linux */
	#include <unistd.h>  /* on FreeBSD, Mac OS X, and Solaris */
	int setgroups(int ngroups, const gid_t grouplist[]);
	setgroups函数用来设置调用进程的额外组id。grouplist就是要设置的id数组，ngroups指明要存放在数组的元素的数目。一般只有initgroups才会调用setgroups.

	#include <grp.h>     /* on Linux and Solaris */
	#include <unistd.h>  /* on FreeBSD and Mac OS X */
	int initgroups(const char *username, gid_t basegid);
	initgroups使用getgrent,setgrent,endgrent来读取整个group文件以便决定username所属的组。然后这个函数调用setgroups来为用户初始化所属的组成员。除了groups文件中的组，initgroups也会把basegid中的组包含到额外组中，basegid为了passwd中的user的group id来设置的。一般来说initgroups由login来调用。

	5)不同系统的实现有所不同：
	不同系统的密码文件，前面说的密码加密文件名称和位置有所不同：
	具体参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec6.html

6)其他的系统数据文件：
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec6.html
	前面只说了两种数据文件，实际上还有许多其他的数据文件,例如/etc/services,/etc/protocols,/etc/networks
	所幸访问这些文件都有和前面的passwd等文件有类似的接口函数，这些函数分别是：
	a)一个get函数用来获取下一条记录,如果必要的话会打开文件。这些函数一般会返回一个指向结构的指针。如果到达了文件的结尾，那么大多数函数会返回null.大多数的get函数返回一个指向静态结构的指针，所以如果我们要保存其值，我们需要自己拷贝一份。
	b)一个set函数，如果文件没有打开，那么这个函数会首先打开文件。这个函数会对文件进行rewinds.这个函数在我们想要从头遍历文件的时候会被使用到。
	c)一个end函数，这个函数用来关闭文件。如同我们前面提到的那要，我们经常需要在访问之后调用这个函数来关闭所有的文件。

7)登录登记：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec8.html
	大多数unix系统都提供了两个文件utmp和wtmp.utmp只记录当前登录的所有用户，wtmp记录所有的登录和登出记录。两者中的数据是用struct utmp保存的。
	在登录的时候，login程序会向utmp写入一个用struct utmp结构表示的数据项。
	在登出的时候，utmp相应数据项会被init清空为null比特;然后一个新的条目会被追加到wtmp文件中,wtmp中logout相关条目中的ut_name会自动变成零。
	特殊的条目会被追加到wtmp文件中用来标记系统什么时候重启，以及系统时间变化的前后(???什么意思???).who命令会读取utmp文件，并且打印这个文件的内容。稍后版本的UNIX系统提供了last命令，这个命令会读取wtmp文件，并且打印选定的条目的相关信息。
	solaris的utmpx(4) man手册给出了记录格式的描述信息，FreeBSD 5.2.1, Linux 2.4.22, 和 Mac OS X 10.3的记录格式描述信息在man手册utmp(5)中。

8)关于系统信息：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec9.html
	获取当前主机和操作系统信息的函数：
	#include <sys/utsname.h>
	int uname(struct utsname *name);
	这个函数会返回一个结构，我们也可以通过命令uname来获得这个结构的信息。成功返回0，失败返回1。

	获取主机名称的信息，由于历史原因在BSD系列中有所提供，现在被放入了POSIX.1中:
	#include <unistd.h>
	int gethostname(char *name, int namelen);
	成功返回0，失败返回1。
	namelen指定name缓存的长度，如果长度足够，那么字符串以NULL结束，否则字符串是否以NULL结束是没有定义的。
	有一个hostname命令，用来设置和获取主机名称信息(主机名称的设置需要用超级用户，函数是类似sethostname之类的),主机名称一般是在系统启动脚本中被设置的。

9)系统时间相关：
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec10.html
	这个比较多，有待整理。
	内核提供的时间相关的服务记录了从Epoch即1970年1月1日也就是UTC,开始的秒数。秒数用time_t来表示，我们也把他们叫做calendar time.
	Unix表示时间和其他操作系统不同的地方是:a)使用UTC而不是本地时间。b)自动转换，例如夏日.c)只使用一个数字来表示时间和日期。
	获得当前时间的函数：
	#include <time.h>
	time_t time(time_t *calptr);
	更精确的函数(达到micro second)：
	#include <sys/time.h>
	int gettimeofday(struct timeval *restrict tp, void *restrict tzp);
	这个函数被作为single unix的XSI扩展，tzp的值一直是NULL的，如果非NULL那么行为是没有指定的。有些实现会把时区相关的信息存放在tzp中，但是这个和实现紧密相关。
	这个函数会把从Epoch开始的时间当前的时间存放在tp中，这个tp所对应的结构含有微秒的信息，其定义是：
   struct timeval {
           time_t tv_sec;    /* seconds */
           long   tv_usec;   /* microseconds */
   };
	当我们获得了从Epoch开始的秒数表示的时间(叫做calendar time)的时候，我们就可以调用其他的函数把这个时间转换成便于阅读的时间格式了.
	另外，结构struct tm包含了用年月日表示的时间格式（叫做broken-time）。

	#include <time.h>
	struct tm *gmtime(const time_t *calptr);
	struct tm *localtime(const time_t *calptr);
	localtime和gmtime的不同之处是，
	localtime把calendar time（就是从Epoch开始到现在的秒数）转换成local time,同时考虑本地时间的区域，和日光节约时间（夏令时）,所以它的执行结果也和本地的一些环境变量TZ有关系;
	gmttime是把calendar time转换成用UTC表示的broken-down time(就是struct tm结构).

	#include <time.h>
	time_t mktime(struct tm *tmptr);
	这个函数把用localtime（本地时间）表达的broken-down time(就是struct tm结构)转换成time_t表示的值(calendar time),所以它的执行结果也和环境变量TZ有关系。

	#include <time.h>
	char *asctime(const struct tm *tmptr);
	char *ctime(const time_t *calptr);
	这两个函数把时间转换成字符串输出，输出的格式类似于date命令的默认格式。两者不同的是：
	asctime是把broken-down 的time转换。
	ctime是把calendar的time转换(它的执行还和环境变量有关系)。


	#include <time.h>
	size_t strftime(char *restrict buf, size_t maxsize,
	                const char *restrict format,
	                const struct tm *restrict tmptr);
	这个函数很复杂类似printf，是把时间用自己指定的格式给格式化并且存放在tmptr中,格式由format指定，被格式化的时间变量是tmptr.
	有一个类似的输入函数使用方法是：
	strptime(argv[1],"%Y-%m-%d-%H:%M",new);//for example,argv[1] is:"2002-09-08-22:02"
	具体参考资料吧。

	以上的时间函数，只有gettimeofday不是ISO C定义的。

*关于进程及环境
==========================
1)关于可执行程序中的main函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec2.html
	当一个c程序通过exec被执行的时候，会在main函数之前首先调用一个start-up routine.根据编译时候链接阶段的设置，可执行文件会把这个start-up routine作为程序的起始地址。这个start-up routine会从内核中获取命令参数(应该对应main函数的参数)以及环境变量然后调用main函数。

2)关于程序结束的方式：
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec3.html
	有8种结束进程的方式，
	其中正常结束的方式有5种:
	1.从main函数中return
	2.调用exit函数
	3.调用_exit 或者 _Exit
	4.最后一个线程中的start routine中return。
	5.从最后一个线程中调用pthread_exit.

	非正常结束的方式有3种:
	6.调用abort.
	7.接收到一个信号(signal).
	8.响应最后一个线程的cancellation请求。
	这里，我们只考虑和线程无关的方法。

	当main函数return的时候会调用到exit函数。效果类似在start-up routine中执行了exit(main(argc,argv));
	实际真正正常结束程序的只有三个函数：exit,_exit和_Exit.
	_exit和_Exit会直接立即返回到内核，而exit会首先做一些清理工作(例如关闭打开的stream)然后返回到内核(例如可通过调用其他的两个exit函数)。
	三种exit声明如下：
	#include <stdlib.h>
	void exit(int status);
	void _Exit(int status);

	#include <unistd.h>
	void _exit(int status);
	这三种函数都返回一个整数表示进程的状态，大多数unix系统都有处理这个返回状态的方式。如果a)这三种函数没有指定status而被调用b)main函数调用了return却没有在后面指定其返回值c)main函数没有指定要返回一个整数进程的exit状态是不确定的。如果main函数被指定返回的是整数，但是是隐式退出的（没有调用return而是自然地到达了函数的结尾）,那么返回值是0(这个特性是c99新加的特性，以前返回是不确定的)。在main函数中调用exit(0)和return 0的效果是等价的。

3)进程结束前调用用户注册的指定函数：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec3.html
	#include <stdlib.h>
	int atexit(void (*func)(void));

	我们把自己定义的函数的地址传递到这个函数中去，就会将我们自定的函数注册到进程退出过程中去。当调用exit函数退出进程的时候，会按照我们注册的反顺序一次调用我们注册的自定义函数。一个函数被注册了几次，那么exit的时候就会被调用几次。ISO C允许注册至少32个函数(sysconf函数可以用来确定一个系统最多可以注册多少个退出函数)。
	这些退出函数（exit注册的函数）在1989 ANSI之前的系统中(例如SVR3和4.3BSD)是没有的。

	ISO C和POSIX.1首先调用注册的exit退出函数，然后（通过fclose）关闭所有的stream.POSIX.1扩展了ISO C的一个地方是：当调用exec函数的时候会清除所有的退出注册函数。

	总结：程序大致退出的情况是：
	用户函数最终会返回到main,main返回到start-routine,start-routine最后会调用exit函数。
	main函数和用户函数都能够调用exit或_exit或_Exit直接退出程序。
	exit最终会调用_exit或_Exit退出程序.

4)程序的命令行参数：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec4.html
	程序的命令行参数是main的参数argc,argv指定的。具体不说了。
	ISO C和POSIX.1可以保证argv[argc]是空指针。

5)程序的环境变量列表：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec5.html
	类似参数列表，每个程序都有一个环境变量列表，不过不通过参数指定,而是通过全局变量来指定。这个变量是:
	extern char **environ;
	其元素是一系列以NULL结束的字符串(形式是:name=value)。
	原来环境变量列表是通过为main指定第3个参数来传递的，不过现在看来对于一个全局变量来说没有必要这么做了，又因为ISO C的规定所以main就只有两个参数了。有专门的接口访问指定的环境变量，但是如果想要遍历整个环境变量列表那么就需要通过这个environ全局变量了。

6)c程序的内存布局：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec6.html
	一般来说c程序具有如下的几个部分：
	文本段：这里包含cpu执行的机器指令。一般来说这个段是可以共享的对于经常运行的程序来说，它在内存中只有一个拷贝,这个段也是只读的区域。
	初始化的数据段:一般简称为数据段,包含了在程序中指定初始化的数据。像类似int a =99;这样在所有函数之外定义的变量就被初始化成为这样的数据段。
	未初始化的数据段：一般称作bss段。这样的数据段在程序运行之前被内核初始化成为0或者null指针。例如int a[100];这样在所有函数之外定义的变量就被存储在这个数据段中。
	栈区：这个区域存放自动变量,用来保存函数调用的信息。
	堆区：运行时动态分配内存的时候会在这里申请，一般它在非初始化数据和栈区之间。
	参考资料里面给出了一个典型的内存布局图示。

7)共享库：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec7.html
	大多数unix系统支持共享库，共享库把一些公共的函数从可执行文件中提取出来了，这样保证在运行的时候内存中只有一个库函数的拷贝。这样会减少可执行文件的大小，同时也带来了一些运行时间开销（在第一次启动可执行文件的时候以及第一次使用库函数的时候。）另外一个共享库优点就是如果库函数被修改了只需要替换库文件就行了不用重新链接程序（当然前提是那些被修改的函数的参数类型和数目是不变的）
	程序可以要求使用或者不用共享库。例如可以通过cc或者ld的编译选项进行指定。
	如：cc -static hello1.c
	这样会导致程序在编译的时候不使用共享库。

8)内存分配：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec8.html
	ISO C指定了三种内存分配的方式：
	#include <stdlib.h>
	void *malloc(size_t size);
	void *calloc(size_t nobj, size_t size);
	void *realloc(void *ptr, size_t newsize);
	这三种函数如果返回的指针是非空的表示分配成功，如果出错了那么返回的是null.
	void free(void *ptr);
	malloc分配指定字节大小的内存，内存里面的数据是不确定的。
	calloc分配nobj个特定大小（size）的对象，内存里面的数据被初始化为0。
	realloc用来增加或者减小之前分配的内存区域。如果是增加的话，可能会把原先的分配的区域移动到别的地方然后在后面增加多出来的内存，增加的内存的内容不确定并返回新内存块的指针，如果原来的区域后面有足够的空间来增加额外的内存的话就不需要移动内存了。参数是最终内存的总大小。如果ptr为空那么realloc的行为和malloc的行为是一样的。
	三种分配函数返回的指针的对齐方式保证适合任何的数据类型。因为函数返回的是void*所以如果我们包含了stdlib.h那么我们不用强制将这个函数返回的指针转换成为我们想要的类型。
	free使用来释放之前分配的内存的。
	分配函数是使用sbrk系统来进行实现的。实际上分配的空间要比指定的空间大一些，因为需要存放空间大小等信息让free正确地执行。如果只分配不释放会导致内存泄露，如果释放了没有分配的内存，那么会导致致命的错误。
	由于这些函数导致的内存错误很难跟踪，所以有些系统提供了这些函数的可以进行一些额外检测的版本（当alloc或者free时）。可以通过包含一些库文件或者有时候也可以通过特定的编译选项来打开这些额外检查的特性。

	一些其他的内存分配函数：
	除了前面提到的malloc,free等标准分配函数，还有一些替代的内存分配函数。有些系统只提供了标准的分配函数，开发者可以自己选择下载其他的替代分配函数来使用。
	libmalloc
	SVR4-based的系统，例如solaris,包含libmalloc库，这个库提供了一系列的和ISO C内存分配函数相匹配的接口。libmalloc库包括mallopt函数，这个函数允许进程设置特定的变量来控制存储的分配（？）。还有一个函数叫做mallinfo，可以用来提供内存分配器的统计信息。

	vmalloc
	这是一种允许进程对不同的内存区域使用不同的技术分配内存的内存分配器。出了vmalloc之外，这个库也提供了ISO C内存分配函数的模拟版本。

	quick-fit
	以前标准的分配算法使用的是最佳适配或者最先适配分配策略。Quick-fit比这两种方法都快，但是它会消耗更多的内存。这个算法基于把内存分成不同大小的缓存块，然后基于缓存的大小，在free list上面维护没有使用的缓存。在一些ftp站点上面有基于quick-fit实现的malloc和free。

	alloca Function
	还有一个值得一提的函数就是alloca.这个函数和malloc具有一样的调用次序，然而它不是从heap上面分配内存而是从当前函数所处堆栈上面分配内存的。这样的有时就是我们不用释放空间了，当函数结束的时候内存的空间会自动地被释放掉。alloca函数导致堆栈桢的大小增加。这样的缺点是有些系统不支持alloca函数，因为对于它们而言不可能在调用函数之后再增加堆栈桢的大小。然而许多的软件包还是使用了它，因为这个函数在许多系统上都有实现。

9)再谈环境变量
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec9.html
	我们前面说了环境变量一般的形式是："name=value"
	unix内核从来不会检查这些字符串，对于这些字符串的解释让程序自己来做。shell中就维护了大量的内部变量例如：HOME,USER,MAILPATH等等。
	ISO C定义了一些可以获取环境变量值的函数，但是标准说值的内容是由实现定义的。
	#include <stdlib.h>
	char *getenv(const char *name);
	返回和name相关的环境变量的值的指针，如果没有这个环境变量那么返回NULL.需要注意的是这个函数返回"name=value"字符串。我们一般调用getenv来获得特定的值,而不是直接访问environ.有些环境变量是特定的标准(例如XSI)才有的,而不是所有的标准才有这样的环境变量。

	有时候我们想要修改一个环境变量或者添加一个环境变量，但是并不是所有的系统都支持这样的功能。下面的函数就和这个相关：
	#include <stdlib.h>
	int putenv(char *str);
	int setenv(const char *name, const char *value,int rewrite);
	int unsetenv(const char *name);

	putenv函数以一个"name=value"字符串做为输入，把这个字符串放到环境列表中去。如果name已经存在了，那么旧的定义会被移除。

	setenv函数设置name为value,如果name已经存在了，那么a)如果重写的值非0，会先把已经定义的name给移除;b)如果重写的值为0，那么已经存在的name定义不会被移除，name也不会设置为被设置为心值也不会有任何错误发生。

	unsetenv函数会把任何定义的name给移除。如果没有相应的定义也不会出现错误。

	注意putenv和setenv的不同之处。setenv必须分配一块memory来创建name=value来根据参数创建字符串，putenv直接把传递给它的字符串自由地传递到environment.在linux和solaris中，putenv的实现会把我们传递给它的地址直接放到environment list中去。这时候，如果传递一个在stack上面的字符串将会出现错误。

	修改环境变量列表的操作实际很复杂。前面已经说过，环境变量列表是指针数组，指针元素指向了实际的"name=value"字符串。环境变量字符串一般都存放在进程内存空间的顶部，在对阵的上面。如果删除一个字符串很简单，我们只需要找到该字符串在环境变量列表中相应的指针，然后把所有后面的指针向下移动一个单元就行了。但是如果添加一个字符串或者修改已经存在的字符串就很困难了。堆栈顶部的空间是不能被扩展的，因为它一直在进程地址空间的顶部，并且不能向上扩展；它也不能向下扩展，因为下面的stack不能被move.

	*如果我们修改一个已经存在的名字：
	a)如果新value的size比原来的小或者等于原来的value，那么我们可以把新的字符串拷贝替换旧的字符串。
	b)如果新value比旧大，我们必须为新的字符串分配空间，把新的字符串拷贝到相应的空间，然后把环境变量列表中相应的指针修改成指向新分配的空间。
	*如果我们想要增加一个环境变量，那么情况更为复杂.首先，我们的调用malloc为"name=value"分配空间，然后把字符串拷贝到这个空间。
	a)然后，如果是我们第一次添加新的变量，我们需要调用malloc分配一个新的指针列表。我们把旧的环境变量指针列表内容拷贝到这个新的列表里面，然后把我们定义的新的环境变量的地址放到这个列表指针的最后。注意，如果原来的环境变量列表是在堆栈的顶部，我们需要把指针列表移动到heap中去。但是大多数在这个堆栈上面的列表的指针还是指向了name=value字符串。
	b)如果我们不是第一次将新的环境变量添加到环境变量列表中去，那么我们需要知道我们已经在heap中为这个列表分配了空间，所以我们只需要调用realloc来分配可以容纳更多指针的空间。这个指向新定义环境变量的指针存放在列表的结尾，其后是null指针。
实际我们修改环境变量的时候，只能影响当前进程以及当前进程的子进程的环境变量。

10)关于跳转函数：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec10.html
	在c语言中，我们不能够使用goto跳转到另外一个函数的标签中去,如果我们想要实现这样的功能，我们需要使用setjmp和longjmp。

	#include <setjmp.h>
	int setjmp(jmp_buf env);
	void longjmp(jmp_buf env, int val);

	我们需要在跳转的地方调用setjmp,其参数保存了跳转时候的各种信息，并且因为是从不同函数的跳转所以一般是全局变量。
	setjmp的返回值，直接调用它返回的是0，通过longjmp返回的，是非0。
	我们在需要跳转的时候，调用longjmp函数，这个函数有两个参数，一个是先前设置setjmp的变量，一个是用来设置跳转之后setjmp的返回值。
	一个使用这两个函数的例子:
	#include <setjmp.h>
	jmp_buf jmpbuffer;
	int
	main(void)
	{
		...
		if (setjmp(jmpbuffer) != 0)
			printf("error");
		while (fgets(line, MAXLINE, stdin) != NULL)
			do_line(line);
		exit(0);
	}

	 ...

	void
	cmd_add(void)
	{
	    int     token;
		...
	    if (token < 0)    /* an error has occurred */
	        longjmp(jmpbuffer, 1);
	    /* rest of processing for this command */
	}
	当main函数执行的时候，我们调用setjmp,这个函数记录跳转时候需要保存的信息，之后返回0。当我们调用do_line的时候，do_line会调用cmd_add,然后cmd_add调用logjmp,调用logjmp导致跳转到了main调用setjmp的地方，并且setjmp返回值变为longjmp的第2个参数指定的1.

	跳转的时候哪些变量保存？哪些变量不保存？
	假设setjmp之前定义了变量并且赋值，再setjmp，之后再修改变量值；
	之后，调用某些函数导致longjmp。这时候，longjmp将返回setjmp的位置，
	我们这里假设关注的变量有5个种类：全局变量，静态变量，寄存器变量，自动变量，volatile变量，
	一般来说，具体会保存那些变量，以来于具体情况。多数的实现不会将自动变量和寄存器变量恢复，但是标准说他们的值是不确定的。如果你有一个自动变量，并且你不想让它在跳转的时候被回滚，那么应该把它定义成为volatile属性。全局变量和静态变量的值在进行longjmp的时候不会回滚。具体参见参考资料里面的例子。从例子中看，跳转之后确定不被恢复的是全局，静态和volatile变量。

11)资源的限制：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch07lev1sec11.html
	每个进程都有各种资源的限制，使用下列函数可以获得当前进程的各种资源的限制：
	#include <sys/resource.h>
	int getrlimit(int resource, struct rlimit *rlptr);
	int setrlimit(int resource, const struct rlimit *rlptr);
	这两个函数属于XSI扩展以及Single Unix标准。进程资源的限制是在系统初始化的时候被进程0来建立起来的。每种实现的资源种类可能会有所不同。
	资源的结构有两个成员：软资源限制；硬资源限制。修改资源的限制遵循如下的规则：
	a)进程可以在小于等于硬资源限制的前提下修改软资源限制。
	b)进程可以减少它的硬资源限制，硬资源限制不能小于软资源限制，普通用户减少硬资源限制之后不能够反向修改了（也就是增加了）.
	c)只有超级用户可以提高硬资源的限制。
	资源限制影响当前的进程以及它的子进程。这也就是说设置资源的应该编译到shell中去以便影响我们的所有进程。例如命令：ulimit或者c shell的limit命令。

*关于进程控制
==========================
1)关于进程标识：
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec2.html
	每一个进程用非负数字来唯一标识（即pid），由于进程pid具有唯一性，所以也常用做其他需要确保唯一性的标识的一部分。例如一些特殊的文件名称中就含有进程pid。
	尽管进程pid是唯一的，但是它可以在进程结束之后再度被重新利用。大多数系统会在进程结束之后延迟其pid的重复利用，防止随后的进程很快采用先前结束进程的pid，导致一些错误。
	另外有一些特殊的进程：pid为0的进程是调度进程(swapper)，磁盘中没有这个进程对应的可执行文件，因为它是内核的一部分作为系统进程;pid为1的进程一般就是init程序，它在内核加载的最后阶段被调用。其对应的可执行文件在早期的版本中是/etc/init后来的版本中是/sbin/init，这个进程用来在系统内核启动之后运行一些操作系统必须的脚本，它会读取一些例如/etc/rc*或者/etc/inittab,/etc/init.d/*系统无关的脚本,然后系统将进入特定状态，例如多用户状态等。init进程不会死掉，它是一个一般用户进程，不像swapper这样是内核里面的系统进程，init用supersuser的权限运行,后面会提到init也是所有孤儿进程的父亲进程。
	每个系统的实现也有一些自己的核心进程集合，用来提供一些服务。例如在一些unix系统中pid为2的进程是 pagedaemon，支持虚拟内存系统的页机制。
	除了PID,还有进程还有其他的标识属性，如下是获取这些属性的相关函数：
	#include <unistd.h>
	pid_t getpid(void);
	返回:调用进程的PID.

	pid_t getppid(void);
	返回：调用进程的父进程PID.

	uid_t getuid(void);
	返回：调用进程的真实用户ID。

	uid_t geteuid(void);
	返回：调用进程的有效用户ID.

	gid_t getgid(void);
	返回：调用进程的真实ID组。

	gid_t getegid(void);
	返回：调用进程的有效ID组。

	注意:这些函数都不会返回错误。

2)关于fork：
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec3.html
	创建进程使用fork来实现，fork函数如下：
	#include <unistd.h>
	pid_t fork(void);
	返回：在子进程中返回为0；父进程中返回为子进程PID,如果出错返回1。
	通过fork创建的新进程叫做子进程。这个fork函数调用了一次（在父进程中），但是返回了两次（在父进程中，以及新出现的子进程中）。通过返回值可知是父还是子进程。因为没有获得一个进程子进程PID的函数，所以在父进程的fork返回中会返回子进程PID,以做记录和判断等用。因为所有子进程只可能有一个父进程，所以在子进程中fork返回0，子进程可以通过getppid来获得父进程的进程ID.(进程PID为0的进程是内核中的swapper所以它不可能是某个进程的子进程).
	在调用fork之后，产生的子进程和父进程会继续在代码中fork调用的后面继续执行。子进程是父进程的一个拷贝，它拷贝了父进程的数据空间，堆和栈空间，一定要注意这是一份拷贝，父子进程不会共享这部分内存的内容。父子进程共享的部分是代码段部分。
	由于fork一般会接着一个exec函数,当前的系统实现一般不会立即执行父进程数据，堆，栈的拷贝。一般会使用一种copy-on-write(COW)的技术，也就是说，这些区域起初是父子进程共享的，一旦有进程进行了修改这些区域的操作，内核才会创建相应区域内存的一份拷贝（一般是虚拟内存的页）。
实际上有不同种类的fork函数。本文中的四种系统都支持vfork函数，这个函数在后面会提到。

    Linux 2.4.22 提供使用clone系统调用来创建新进程。这个系统调用是一个fork的通用形式，允许调用者控制在父子进程中共享哪部分数据。
    FreeBSD 5.2.1 提供rfork系统调用，和Linux中的clone系统调用类似，rfork是从Plan 9操作系统中继承过来的。
    Solaris 9 提供两个线程库,一个是POSIX的,一个是Solaris threads.两种fork的动作有所不同。对于POSIX，fork创建一个只包含调用线程的进程，但是Solaris的fork创建的进程包含调用线程的进程中的所有线程的拷贝。为了提供和posix类似的fork，solaris提供了一个fork1函数，它可以创建一个只拷贝调用线程的进程。

	例子http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec3.html#ch08fig01
	这个例子，给出了一个使用fork的例子，并且通过这个例子我们应该知道，
	a)如果fork之后，是parent先运行还是children这是不确定的，取决于内核的调度算法。
	b)子进程是父进程的拷贝，包括文件缓存等都是一个副本,所以子进程修改不会影响父进程。
	c)由于子进程拷贝了父进程的数据空间，如果使用库函数打印，重定向时可能同一个打印语句在文件中出现两次，因为缓存也拷贝了。

	父子进程之间共享文件偏移量，这样在父子进程同时写一个文件的时候容易控制它们之间的配合；如果不共享的话，有些定位之类的操作很难配合进行或者很麻烦。当然如果父子不同步的话，两者对文件的输出可能会相互干扰。
	一般fork之后，有两种操作文件描述符号的情况：
	a)父进程等待子进程结束。这时候父进程不需要对文件描述符号做任何事情，在子进程结束之后子进程读写的文件描述符号的偏移会自动更新。
	b)父子进程进行它们各自的操作。这时候，父子进程需要关闭它们不需要的文件描述符号,防止两者之间互相干扰。这在网络服务的环境下面经常会用到。
	除了打开的文件之外，还有许多父子进程共享的内容，具体参见参考资料给出列表。
	父子进程不同的地方是：
	a)fork返回值不同。
	b)进程PID不同。
	c)进程的父进程PID不同，子进程的父进程PID设置为父进程，父进程的父进程PID不变。
	d)子进程的tms_utime, tms_stime, tms_cutime, 和 tms_cstime取值设置为0.
	e)父进程设置的文件锁不会被子进程继承。
	f)在子进程中会把申请的警钟清空。
	g)子进程会把申请的信号集合清空。
	fork失败的原因有两个：
	a)系统中进程数目太多（一般这是因为出现了什么问题而导致的）
	b)当前用户 UID的进程数目超过了系统的限制。可以通过CHILD_MAX指定每个用户UID同时可以运行的进程的数目。
	fork 一般有两种使用的方法：
	a)进程想要复制自己，并且在同时执行另外的代码。这在网络中很常见：服务器端监听，接收到一个客户请求，之后它fork一个子进程来处理客户请求，然后父进程继续监听其他的请求。
	b)进程想要执行一个不同的程序：一般都是fork之后调用exec来做的。
	有些系统把b)的fork紧接这exec合并成了一个操作spawn.unix 把操作分成了两个部分，因为许多时候fork不需紧接着exec或者fork和exec之间需要做一些修改进程属性的操作等等。
	Single UNIX Specification 在高级的real-time选项组包含了spawn接口。这些接口不是fork和exec的替代。他们用来支持很难高效地执行fork的系统，尤其是那些没有内存管理硬件支持的系统。

3)关于vfork:
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec4.html
	vfork函数源于2.9BSD.有些人认为这个函数是多余的，但是本文讨论的系统都支持这个函数。实际上，BSD把这个函数从4.4BSD中删除了，但是所有从4.4BSD继承过来的开源BSD，又在它们的release中把这个函数添加进来了。vfork函数在Single UNIX Specification的version3中被标记成将被废弃的接口。
	函数vfork和fork一样，返回值也一样，但是这两个函数有所不同。
	vfork函数一般用于创建一个子进程，并且这个子进程的目的是进行exec(关于exec参见后面).
	vfork和fork一样，创建新的进程，并且它不会复制父进程的地址空间的内容到子进程中，因为子进程是将要调用exec的而不是引用父进程地址空间的数据。子进程会一直在父进程的地址空间运行，直到它调用了exit或者exec.这样的优化是为了提高一些用虚拟内存页实现的unix系统的效率。（通过前面对fork的解释我们可以发现，实际上fork现在已经使用了copy-on-write技术来提高效率，但是没有拷贝始终是要比有一些拷贝的快一些）
	fork和vfork另一个不同的地方是vfork保证了子进程先运行，直至子进程调用了exec或者exit.当子进程调用了exec或者exit的时候，父进程才重开始执行（如果子进程在调用这两个函数之前需要父进程的一些操作的话，这里可能会导致死锁）。
	总之，就两点不同：
	a)vfork的子进程不拷贝父进程空间数据而是直接运行在父进程空间内（直到调用了exec或exit）。fork的子进程拷贝一份父进程的数据。
	b）vfork之后，子进程会先继续运行，直到子进程调用exec或者exit父进程才开始运行。fork的子进程不能确定谁先继续运行。
	例子参见：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec4.html
	从例子可以知道，子进程修改了变量，也反应到父进程中了，因为两者共享进程空间而不是拷贝关系；另外子进程会先于父进程运行。需要注意的地方是：
	我们结束子进程调用的是_exit而不是exit.因为，_exit不会做任何刷新标准输入/输出库的刷新操作。如果我们调用了exit那么，输出结果是不确定的，这依赖标准I/O库的实现，我们可能会看到和使用_exit没有什么区别，或者看到父进程printf的内容没有了。
	如果子进程调用了exit，这样会对标准I/O流进行flush操作。如果这是标准I/O库的唯一动作，那么我们不会看到和_exit有什么不同。但是如果也关闭了标准I/O流，那么内存中表示标准输出的FILE对象会被清空，由于子进程和父进程共享空间，所以当父进程再次继续运行并执行printf的时候，将会不输出任何东西，同时printf会返回-1.注意，这时候父进程的STDOUT_FILENO还是合法的，就像子进程获得了父进程的文件描述符的副本。
	大多数现代对exit的实现都不会自找麻烦地去关闭streams.因为如果进程将要退出的时候，内核会关闭所有在进程中打开的文件描述符号。如果在库中关闭他们，会增加额外的开销,没有一点好处。

4)关于进程exit
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec5.html

	前面已经说过，进程正常终止有五种方式：
	a)在main函数中执行return,这实际和调用exit是一样的。
	b)调用exit函数。这个函数由ISO C来定义，它会调用所有注册的“退出回调函数”，以及关闭所有的标准I/O流。因为ISO C没有处理文件描述符号，多进程，和作业控制，所以这个函数对于unix系统来说是不完整的。
	c)调用_exit或者_Exit函数。ISO C定义了_Exit来为进程提供一种不运行“退出回调函数”以及信号处理的结束的方式，标准I/O流是否被flushed这取决于实现。在UNIX系统上，_Exit和_exit是同义的,它不会刷新标准I/O流。_exit函数被exit调用，并且会处理一些和UNIX系统相关的细节；_exit在POSIX.1中被定义。
	在大多数UNIX系统的实现中，exit(3)是一个标准C库函数，然而_exit(2)是一个系统调用。
	d)在进程的最后一个线程中执行return.但是，线程return的值不会作为进程的return值。当最后一个线程return的时候，进程会以0来表示它的termination status.
	e)在进程的最后一个线程中调用pthread_exit函数。和前面的情况类似，进程的exit status始终是0，而不考虑pthread_exit的参数值。

	三种非正常终止的形式：
	a)调用abort.实际上这是下一个形式的特殊情况，调用abork会发送SIGABRT信号。
	b)当进程接收到特定的信号的时候。信号可以被进程自己来产生（例如调用abort函数），可以由其他进程产生，或者由内核产生（例如进程引用了一个非法的内存地址空间，或者尝试除以0）。
	c)最后一个线程响应取消请求。默认来说，取消会延迟发生：一个线程请求其他线程被取消，然后过一会目标线程才会终止。

	不管进程是怎么终止的，在内核中执行的代码都是一样的。内核会关闭被终止进程的所有打开的文件描述符号，释放它使用的内存以及其他类似。

	对于前面，我们一般会系统被终止进程通知父进程它是如何终止的。对于三种exit(exit,_Exit,_exit),这是通过传入exit的参数来表示的。对于非正常终止的方式，是内核而不是进程产生一个termination status来表示非正常终止的原因。无论怎样，被终止进程的父进程都是通过wait或者waitpid函数来获得终止状态的。
	这里我们需要区分一下两种终止状态，如果是通过三种exit终止的（正常终止），那么终止状态叫做exit status，是exit函数的参数；如果非正常终止，叫做termination status.在调用_exit的时候，exit status会被内核转换成为termination status.如果进程正常结束了，那么父进程会获得子进程的exit status.

	wait或者waitpid会把它们等待的在子进程退出时候得到的status返回并存储起来，然后用下面的宏来判断其含义：
	*WIFEXITED(status):
	如果是子进程正常终止的时候产生的status，那么该宏返回True.这时候我们可以通过WEXITSTATUS(status)来获取子进程退出时，调用的三种exit函数参数的低八位。
	*WIFSIGNALED (status):
	如果是子进程是由于接收到它没有捕获的信号而非正常终止的时候产生的status，该宏返回True.我们可以使用WTERMSIG (status)来获得导致子进程终止的signal number.另外一些系统定义了WCOREDUMP (status)，如果终止进程会产生core file，该宏返回true.
	*WIFSTOPPED (status):
	如果是发送信号导致当前子进程被stop的时候返回的status（此时子进程是终止还是stop状态???），那么该宏返回true。这是后我们可以使用WSTOPSIG (status)来获得导致子进程stop的信号。
	*WIFCONTINUED (status):
	如果子进程在从job stop之后被continued导致返回了status,那么会返回True(对POSIX.1的XSI扩展,只对waitpid而言).

	如果一个父进程在子进程结束之前结束了会怎样？实际上，如果发生这种情况，那么init进程会变成终止进程的所有子进程的父进程。我们已经说了，init是进程的父进程。一般来说当一个进程终止的时候，内核会遍历所有活动的进程，查看被终止的进程是否是其他还存在的某进程的父进程。如果存在被终止进程的子进程，那么存在的子进程的父进程id(ppid)被设置为1（也就是init进程的进程号）.这样我们可以保证所有的进程都有父进程。

	还有一个我们需要注意的地方，就是如果一个子进程先于父进程终止。如果子进程完全地消失了，如果当父进程最后想要检查子进程是否terminated的时候，父进程不能获得它的termination status.内核会保存每一个终止进程的少量信息，这样当终止的进程的父进程调用wait或者waitpid的时候会用到它们。至少，这些信息里要包含PID以及进程的termination status,以及进程占用的CPU time.内核能够丢弃进程使用过的所有内存以及关闭它打开的文件。在UNIX 系统的属于中，进程如果terminated了，但是它的父进程没有wait它，那么这个进程就会被叫做zombie(僵尸进程)。使用ps(1)命令可以打印进程的状态，僵尸进程的状态是Z.如果我们些一个很长的程序，fork了许多的子进程，那么除非我们调用wait等它们来获取他们的termination status,否则它们会变成zombies.
	有些系统提供可以阻止创建僵尸进程的方法。

	最后我们还需要考虑的是：如果一个进程是init的子进程，那么如果它terminate的话会怎样？它会成为一个zombie吗？答案是“不”，因为init本身必然会调用wait函数来获得termination status,它就是那么设计的。通过这样，init可以防止系统被过多的僵尸进程占用资源。当我们说一个init的子进程的时候，我们的意思是这个进程要么就是直接从init那里继承的，要么就是它的父亲在它之前终止了，它被设置成从init继承。

5)关于wait和waitpid
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec6.html
	当一个进程结束的时候，无论是正常的还是非正常的，内核都会通过发送SIGCHLD信号来通知其父进程。因为child的终止是一个异步事件，所以它能够在父进程运行的任何时候发生，这个SIGCHLD信号是内核到父进程的异步通知。父进程可以选择忽略这个信号，或者提供一个函数来定义发生这个信号时候的处理动作。默认这个信号会被忽略。我们现在需要注意的是当我们调用wait或者waitpid的时候，调用的进程会：
	*阻塞:如果进程的所有子进程正在运行的话。
	*立即返回：这时候如果有一个子进程终止了并且它等待自己的终止状态被获取，那么会立即返回这个子进程的终止状态。
	*立即返回并且设置错误码：这时候进程没有子进程会出现这种情况。

	如果我们由于收到了SIGCHLD信号而调用wait,那么我们可以期望wait函数会立即返回，但是如果我们在一个任意的时间调用wait，那么这会导致阻塞。
	#include <sys/wait.h>
	pid_t wait(int *statloc);
	pid_t waitpid(pid_t pid, int *statloc, int options);
	两者在成功的时候都会返回进程ID,0或者在错误的时候返回1。
	两者的区别是：
	a)wait函数会导致阻塞直到有一个子进程结束，waitpid有一个选项可以防止阻塞。
	b)waitpid函数不是等待第一个结束的进程，它有一系列的选项可以指定等待哪些进程。
	如果子进程已经结束并且成为了僵尸进程，那么wait函数会立即以那个子进程的状态返回。否则它会阻塞，直到一个子进程终止。 如果调用者阻塞了并且它有多个子进程，那么wait会在一个子进程终止的时候返回。我们是能够判断那个子进程结束的，因为wait函数的返回值就是结束进程的进程pid。
	对于这两个函数，statloc参数是一个指向整数类型的参数，这个参数不是空，那么会返回结束进程的进程状态；如果我们不关心结束进程的状态，那么可以设置这个参数是空。
	一般来说整数的状态值由实现来定义其含义。例如一些位代表正常的exit状态，另外一些位代表信号数（对于非正常退出的情况），有一个位代表是否生成core file.等等。POSIX.1指定退出状态可由<sys/wait.h>中定义的一些宏来进行查看。 四个互斥的宏可以告诉我们进程是如何结束的，它们都以WIF来开始，基于是从这四个宏中返回true的那个宏，其它的宏可以用来获取退出码，信号，以及其它的信息。这四个互斥的宏我们可以参见：
	前面的"4)关于进程exit"中说明的四个宏。
	我们在后面的作业控制中将会讨论如何stop进程。下面的例子就给出了如何使用这些宏：
	#include <sys/wait.h>

	void my_func()
	{
	...
		if (wait(&status) != pid)       /* wait for child */
		{
			...
		}
	    pr_exit(status);
	}

	void pr_exit(int status)
	{
		if (WIFEXITED(status))
			printf("normal termination, exit status = %d\n",
					WEXITSTATUS(status));
		else if (WIFSIGNALED(status))
			printf("abnormal termination, signal number = %d%s\n",
					WTERMSIG(status),
	#ifdef  WCOREDUMP
					WCOREDUMP(status) ? " (core file generated)" : "");
	#else
		"");
	#endif
		else if (WIFSTOPPED(status))
			printf("child stopped, signal number = %d\n",
					WSTOPSIG(status));
	}

	以前我们使用wait来等待一个指定的进程的时候，需要根据wait的返回来判断是否是目标pid，如果不是那么我们就把这个返回的pid保存起来然后继续wait，这样重复直到指定的进程结束；然后我们再次等待指定的进程结束之前需要首先遍历之前wait的时候保存的已经结束的pid列表。这很麻烦，而且缺点很多。现在我们可以利用POSIX.1中的waitpid来实现这个功能。
	waitpid中pid参数的含义如下:
	pid==1	:等待任何子进程，这时候waitpid和wait的含义是一样的。
	pid>0	:等待pid值为参数pid的子进程。
	pid==0	:等待进程组id和调用进程一样的任何子进程。
	pid<0	:等待进程组id和参数pid的绝对值一样的任何子进程。
	waitpid返回结束的子进程的pid并且将子进程结束状态存放在参数statloc所指的地址中。对于wait来说，出现错误的情况是调用进程没有子进程（也可能这个wait函数调用被信号所打断）。对于waitpid来说，可能出现错误的情况是指定的进程pid或者指定组id不存在，或者相应的进程pid不是调用进程的子进程。(这里的进程组在后面进程关系中有所会详细提及)
	options参数可以额外控制watipid的行为,这个参数的值要么是0要么是以下这些值的按位或：

	WCONTINUED
	如果实现支持作业控制，那么pid指定的任何子进程（这个子进程在stop之后被continue但是它的状态没有被报告）的状态会被返回。

	WNOHANG
	如果指定的pid的子进程不是立即可用的，那么waitpid函数不会阻塞，这时候，返回值是0。

	WUNTRACED
	如果实现支持作业控制,那么任何指定pid的子进程（这个子进程被stopped了，并且它的状态在它被stopped的时候没有被报告）的状态被返回。WIFSTOPPED宏可以确定返回值是否和一个停止的子进程相关。

	另外，Solaris 支持一个额外的不是很标准的选项常量。WNOWAIT会使得系统进程（这个进程的终止状态通过waitpid被返回）进入一个wait的状态，这样这个进程可以再次被waited.

	The waitpid function provides three features that aren't provided by the wait function.
	函数waitpid提供了三个wait没有的特性：
	a)waitpid函数使我们等待一个特定的进程，而wait却返回任何终止进程的终止状态。
	b)waitpid函数提供了一个非阻塞的wait版本，有时候我们想要获取一个子进程的状态，但是我们不需要阻塞。
	c)waitpid函数提供了对作业控制的支持，这是通过WUNTRACED和WCONTINUED选项来做到的。

	举例：
	在前面说过如果子进程结束了，父进程没有对它进行wait，那么子进程会变成僵尸进程。如果我们不想wait子进程，也不想让子进程变成僵尸进程，那么我们有一个手段：在父进程中fork两次。
	具体为调用fork产生子进程，子进程再调用fork产生孙进程，然后在孙子进程执行子进程想要的动作，而子进程仅仅是创建孙子进程之后就退出，父进程仅仅wait子进程，不管孙进程，因为孙进程最后父进程变成了init.大概如下：
	if( fork() == 0)
	{
		if(fork()> 0)
		{
			exit(0);
		}
		sleep(5);
		...do child things...
	}
	wait(...);

6)waitid
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec7.html
	Single UNIX Specification 的XSI extension包含了一个额外的函数用来取回进程的退出状态。waitid函数和waitpid类似但是更为灵活。

	#include <sys/wait.h>
	int waitid(idtype_t idtype, id_t id, siginfo_t *infop, int options);

	类似waitpid,waitid允许进程指定等待那个子进程。但是waitid不是把指定的信息（例如子进程id，id组）都集中到一个参数里而是利用两个参数来进行指定。参数id的解释方式取决于idtype的值。如下列出了idtype各种取值时候id的解释方式：
	P_PID	idtype取这个值的时候，id表示等待一个指定的子进程id。
	P_PGID	idtype取这个值的时候,表示等待任何在指定进程组的子进程，而id就包含了要等待的子进程的进程组id。
	P_ALL	idtype取这个值的时候，表示等待任何子进程，此时id参数被忽略。

	options参数是一些标志的比特位，表示调用者关心哪些状态的变化。如下所示：
	WCONTINUED	表示等待一个进程，这个进程之前被stopped了并且被continued了，并且它的status没有被报告。
	WEXITED	表示等待已经exited的进程。
	WNOHANG	表示如果没有可用的子进程退出状态，那么就立即返回而不是阻塞。
	WNOWAIT	表示不会破坏子进程的退出状态码。子进程的退出状态可以在后来的wait,waitid,或者waitpid调用中取到.
	WSTOPPED	表示等待一个被stopped的子进程，这个子进程的状态没有被报告。

	参数infop是个结构指针。这个结构包含导致子进程变化的发生的信号的详细信息，后面会讨论这个结构。
	在本书讨论的四个系统中，只有solaris支持这个waitid。

7)wait3和wait4函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec8.html
	大多数unix系统的实现提供了wait3和wait4函数，这两个函数本来是从Unix中的BSD分支中继承过来的。这两个函数提供的wait,waitid,waitpid所没有的特性是它多了一个额外的参数允许内核返回结束进程和它所有的子进程所消耗的资源统计。
	#include <sys/types.h>
	#include <sys/wait.h>
	#include <sys/time.h>
	#include <sys/resource.h>
	pid_t wait3(int *statloc, int options, struct rusage *rusage);
	pid_t wait4(pid_t pid, int *statloc, int options, struct rusage *rusage);
	所谓资源信息，包含了诸如用户CPU时间数量的统计，系统CPU时间数量的统计，接受的信号数量，页相关的统计信息等等。可以参照geTRusage的man手册来获取更多的信息。
	参考网址里还列出了5个wait函数的参数对比情况。
	wait3函数是在早期的Single UNIX Specification版本中包含的，在第2个版本中wait3就被归类为遗留类的函数了在版本3中wait3就被去掉了。

8)竞争条件
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec9.html
	在多个进程访问共享资源的时候可能会导致竞争（例如多个进程都向标准输出输出内容）,fork的时候很可能导致竞争条件。fork之后产生竞争条件，其结果和父子进程执行的次序有很大的关系。我们无法预测是父进程还是子进程先运行，这取决于系统的负载和内核的调度算法。实际前面的例子中已经存在了竞争条件.实际上我们用sleep等待来实现子进程比父进程后运行，这样是无法保证一定这样的，如果系统负载很高的话，即使我们sleep了很长时间，也有可能最后sleep的进程比没有sleep的进程先调用。可以用类似如下的轮询方式:
	while (getppid() != 1)
		sleep(1);
	但是这也浪费cpu的时间为了避免竞争条件和轮询，我们可以使用信号机制，后面会讲到。另外有许多的进程通信机制也提供了一些手段后面也会讲到。具体例子这里不说了，可以参照给出的参考网址。

9)exec函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec10.html
	当调用exec函数的时候，进程会完全被exec所执行的可执行文件所对应的新的程序所替代，从新程序的main函数开始执行(exec后面的语句已经无法再执行到了).注意使用exec并没有创建进程，所以进程的PID并没有改变，exec仅仅替换了当前进程的text,data,heap,和stack段为磁盘中新程序相应的段。
	有6中exec函数，这些函数构成进程控制的基本要素，我们一般就把这些exec函数统称为exec函数。使用fork，我们可以创建一个进程；使用exec，我们可以初始化一个程序；使用exit和wait，我们可以指定和获取退出进程的退出码（以及同步等）。这是我们进行进程控制的基本函数，使用这些函数我们可以构造出一些其他的函数，例如popen，system等。
	#include <unistd.h>
	int execl(const char *pathname, const char *arg0,... /* (char *)0 */ );
	int execv(const char *pathname, char *const argv []);
	int execle(const char *pathname, const char *arg0, .../* (char *)0,  char *const envp[] */ );
	int execve(const char *pathname, char *const argv[], char *const envp []);
	int execlp(const char *filename, const char *arg0, ... /* (char *)0 */ );
	int execvp(const char *filename, char *const argv []);

	这些函数的第一个不同的地方就是，前四个函数将pathname作为参数，后两个函数把filename作为参数。当指定filename的参数的时候，
	a)如果filename包含了一个slash,那么就把它当作pathname.
	b)否则，会在PATH回敬变量中指定的目录搜索filename对应的可执行文件。
	PATH环境变量包含一系列以冒号分割的目录，也就是路径前缀。例如，
	PATH=/bin:/usr/bin:/usr/local/bin/:.
	这个name=value形式的环境变量name是PATH，value指定了四个搜索目录，最后一个"."代表当前目录（实际一个0长度的前缀也表示当前目录，指定的时候可以使用一个冒号在value的开始，或者两个冒号构成一列，或者一个在value结尾的冒号。）
	一般不要包含当前目录，因为这样会有安全隐患。
	如果execlp或者execvp使用路径前缀找到了一个可执行文件，但是这个文件和机器链接的时候的可执行文件格式不一样，那么这个函数假设文件是一个shell脚本，然后尝试调用/bin/sh，一这个文件名作为参数，来运行这个脚本。

	另外一个不同的地方是参数列表的传递方式（l表示list，v表示vector）。函数execl,execlp,和execle要求每个传递到这个程序的命令行参数是一个独立的参数，我们把这些参数的结尾添加一个null指针。对于其他的三个函数(execv,execvp,execve)，我们需要建立一个指针数组，其指针指向相应参数，然后这个数组的地址作为这三个函数的参数。
	在使用ISO C声明之前，正常对函数execl,execle,和execlp展示的命令行参数形式是：
	char *arg0, char *arg1, ..., char *argn, (char *)0
	这个标准要求命令行的最后一个参数是一个null 指针。如果值是0那么我们要把它显示地转换成char*类型的，否则会被当做一个int参数来看代。如果整数的大小和char*这个标准要求命令行的最后一个参数是一个null 指针。如果int变量的大小和char的大小不一样，那么实际传递给exec函数的参数会发生错误。

	最后一个不同的地方就是对新程序的环境变量的传递。execle和execve函数允许我们传递一个指向环境变量字符串的一个指针数组。另外的四个函数，使用调用进程的environ变量来为新程序拷贝一份已经存在的环境变量(回顾前面的关于环境变量的内容可知，如果我们系统支持setenv和putenv函数，那么我们可以在不影响父进程的情况下来修改子进程的环境变量)。一般来说，一个进程允许它的环境变量被传播到它的子进程，但是在一个时候，进程需要对一个子进程指定特定的环境变量，例如login程序初始化login shell的时候。一般，login创建一个指定的仅定义了几个变量环境变量列表然后让我们通过shell的启动文件在我们登录的时候添加环境变量。
	在使用ISO C声明之前，对execle的相应（环境变量列表）参数的展示形式是：
	char *pathname, char *arg0, ..., char *argn, (char *)0, char *envp[]
	由这个标准可知最后一个参数是环境变量指针列表的数组地址。 ISO C的声明就没有这样来表示，因为所有的命令行参数，空指针，以及环境变量列表指针使用(...)来进行表示了。

	这六个exec函数的参数很难记忆，但是考虑一下函数名字可以帮助我们记忆。字母p表示函数会使用PATH来接受一个filename参数，进而寻找可执行文件;字母l表示函数会接受一个参数列表，它和字母v相对；字母v表示一个argv[]（元素为参数指针的指针数组）;字母e表示函数接受一个envp[]数组（是指向环境变量列表的指针数组），和使用当前的环境变量相对。参考资料通过一个表格列出了所有exec函数的区别。

	每个系统的参数列表和环境变量列表的长度是有限制的，在第2章已经说明，限制由ARG_MAX给出。在POSIX.1中，这个值必须至少是4096字节。有时候我们在敲入文件名的时候会遇到这个限制，例如：
	grep getrlimit /usr/share/man/*/*
	可能会提示shell错误，说是参数过长.
	以前，在System V上面这个参数限制是5120字节。旧版本的BSD系统的限制是20480字节，当前系统的限制更高。
	为了避免遇到参数列表大小的限制，我们使用xargs命令把长的参数列表分割，例如上面的命令就可以写成：
	find /usr/share/man -type f -print | xargs grep getrlimit
	如果我们系统上面的man pages是压缩的,我们可以运行：
	find /usr/share/man -type f -print | xargs bzgrep getrlimit
	这里，使用了type -f选项是为了限定查找的文件类型是正常文件，因为grep无法在命令中进行搜索，我们需要避免一些不必要的错误。

	除了exec调用进程的进程ID不会改变之外，新程序还有一些其他的属性也会被继承过来，具体参见参考资料。
	新程序对打开的文件的处理取决于相应文件描述番号的close-on-exec标志。每个打开的文件描述符号有一个close-on-exec标志，如果标志被设置了，那么文件描述符在调用exec的时候会被关闭，否则执行exec的时候也会保持打开的状态。默认这个标志是没有设置的也就是说文件描述符号在执行exec的时候是打开的状态，除非我们使用了fcntl来设置这个close-on-exec标志。

	POSIX.1规定打开的目录流(参见opendir)在执行exec的时候被关闭。这一点是通过opendir函数调用fcntl设置打开的目录流中的相应文件描述符号的close-on-exec标志来做到的.

	需要注意的是调用exec之后，real user ID和real group ID是保持不变的，但是effective ID却是变化的，这取决于相应的要执行的文件的set-user-ID和set-group-ID位。如果这个位被设置了，那么effective user ID就变成了这个程序文件相应的属主ID了。否则，effective 就不变（不会设置成real user ID）.group ID的情况处理类似。

	六个exec函数之间的关系：
	在许多unix系统中，这6个函数中只有一个(execve)，是内核中的系统调用。其他的5个都是库函数，是调用这个系统调用来实现的。我们在参考资料中给出了这些函数的调用关系。
	大概的情况就是：
	execlp--(build argv)-->execvp--(尝试每一个path前缀)-->execv--(使用环境变量，执行系统调用)-->execve.
	execl--(build argv)-->execv--(使用环境变量，执行系统调用)-->execve.
	exece--(build argv,执行系统调用)-->execve.
	上面的规律是:
	先l变v(如果有的话，通过build argv)
	再去p(如果有的话，通过尝试PATH前缀)
	再用e(如果有的话，通过使用环境变量)

	举例：
	书中给出例子如下：
	...
	if (execle("/home/sar/bin/echoall", "echoall", "myarg1",
	   "MY ARG2", (char *)0, env_init) < 0)
	...
	if (execlp("echoall", "echoall", "only 1 arg", (char *)0) < 0)
	这里，我们先使用execle,它需要被传递一个路径名称以及一个环境变量数组指针;然后我们第二个方法是execlp,它只需要被传递一个文件名称，因为它会在PATH环境变量里面寻找这个文件名称的路径前缀。
	需要注意的是，这里我们设置的arg0的地方，它实际上可以是任何字符串（例如可以是程序名称，也可以是路径名称），有些shell执行可执行程序的时候，把这个args[0]设置成为了全路径.login会将args[0]前面加上一个破折号前缀，表示是登陆的shell。我这ps之后看到login如下，不知道是不是说的这个:
	root      2683  0.0  0.2   2984  1156 tty1     Ss+  08:30   0:00 /bin/login --

10)关于修改用户id(UID)和组id(GID)：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec11.html
	在unix中，特权以及访问控制是基于UID和GID的。我们设计程序一般要使用最少的特权来完成我们的工作。
	我们可以使用如下函数设置用户的real user ID和effective user ID:
	#include <unistd.h>
	int setuid(uid_t uid);
	int setgid(gid_t gid);

	修改这些ID有一套规则，我们以 UID为例(GID是一样的):
	a)如果进程有superuser特权，那么setuid函数会设置real user ID,effective user ID和saved set-user-ID为uid.
	b)如果进程没有superuser特权，但是设置的uid和real user ID或者saved set-user-ID相等，那么setuid仅仅将effective user ID设置为uid,real user ID和saved set-user-ID不变.
	c)如果以上两个条件都不满足，那么会返回1，并设置errno为EPERM.
	(这里设置的是进程的相应uid不是文件的，进程的三种uid:real uid, effective uid,saved set-user-id.核心是进程的effective uid)
	这里，我们假设_POSIX_SAVED_IDS是true.如果这个特性没有被提供，那么就删除前面所有和saved set-user-ID相关的内容。
	saved IDs是2001版本POSIX.1的必有特性。以前版本的POSIX它们是可选的。如果想要查看当前系统实现是否支持这个特性，我们可以在编译的时候测试_POSIX_SAVED_IDS宏开关，或者在运行的时候调用传递了_SC_SAVED_IDS的sysconf函数。

	我们简单描述一下内核是如何来维护这三种UID的：
	a)只有superuser进程可以改变real user ID.一般来说，real user ID是由login程序在我们登陆之时来设置，之后就不会改变了。因为login是一个superuser process,当它调用setuid的时候，它会设置所有三种user ID.
	b)effective user ID是exec函数在程序文件的set-user-ID位被置位的时候设置的(设置成程序文件的UID)。如果set-user-ID位没有被设置，那么exec函数保持当前的effective user ID值不变。我们可以在任何时候调用setuid设置effective user ID为real user ID或者saved set-user-ID.一般来说，我们不能把effective user ID设置成任何值。
	c)saved set-user-ID是exec从effective user ID拷贝来的。如果文件的set-user-ID位被设置，那么这个拷贝(saved set-user-ID)会在exec从文件的user ID存储到effective user ID之后被保存。
	这个参考资料中有个表格简单列出了这三种进程ID改变的情况。
	注意，我们通过getuid和geteuid只能获得当前的real user ID和effective user ID.我们无法获得当前saved set-user-ID的值。

	例子：
	我们用一个例子来说明这个saved set-user-ID特性的使用。这个例子就是man程序。man程序可以用来显示在线帮助手册，man程序可以被安装指定set-user-ID或者set-group-ID为一个指定的用户或者组。man程序可以读取或者覆盖某些位置的文件，这一般由一个配置文件(通常是/etc/man.config或者/etc/manpath.config)或者命令行选项来进行配置。

	man程序可能会执行一些其它的命令来处理包含显示的man手册页的文件。为防止处理出错，man会从两个特权至今进行切换：运行man命令的用户特权，以及man程序的拥有者的特权。大致过程如下：

	a,假设man程序文件被用户man所拥有，并且已经被设置了它的set-user-ID位，当我们exec 它的时候，我们有如下情况：
	real user ID = 我们的用户UID
	effective user ID = man用户UID
	saved set-user-ID = man用户UID

	b.man 程序会访问需要的配置文件和man手册页。这些文件由man用户所拥有，但是由于effective user ID是man,文件的访问就被允许了。

	c,在man为我们运行任何命令的时候，它会调用setuid(getuid())).因为我们不是superuser进程，这个变化只能改变effective user ID. 我们会有如下情况：
	real user ID = 我们的用户UID(不会被改变)
	effective user ID = 我们的用户UID
	saved set-user-ID = man 的用户UID(不会被改变)
	现在man进程运行的时候把我们得UID作为它的effective user ID.这也就是说，我们只能访问我们拥有自己权限的文件。也就是说，它能够代表我们安全地执行任何filter.

	d.当filter做完了的时候，man会调用setuid(euid).这里，euid是man用户的UID.(这个ID是通过man调用geteuid来保存的)这个调用是可以的，因为setuid的参数和saved set-user-ID是相等的。(这也就是为什么我们需要saved set-user-ID).这时候我们会有如下情况：
	real user ID = 我们的用户UID(不会被改变)
	effective user ID = man的UID
	saved set-user-ID = man 的用户UID(不会被改变)

	e.由于effective user ID是man,现在man程序可以操作它自己的文件了。

	通过这样使用saved set-user-ID,我们可以在进程开始和结束的时候通过程序文件的set-user-ID来使用额外的权限。然而，期间我们却是以我们自己的权限运行的。如果我们无法在最后切换回saved set-user-ID,我们就可能会在我们运行的时候保留额外的权限。
	我们来看看如果man启动一个shell的时候会发生什么.(shell是使用fork和exec来启动的)因为real user ID和effective user ID都是我们的普通用户UID(参见step3).shell 没有其它额外的权限.shell无法访问saved set-user-ID(man),因为shell的saved set-user-ID是由exec从effective user ID拷贝过来的。所以，在执行exec的子进程中，所有的user ID都是我们的普通用户ID.
	实际上，我们描述man使用setuid函数的方法不是特别正确，因为程序可能会set-user-ID为root.这时候，setuid会把所有三种uid都变成你设置的id，但是我们只需要设置effective user ID.

	*关于setreuid和setregid函数
	以前,BSD支持用seteuid进行real user ID和effective user ID的切换。
	#include <unistd.h>
	int setreuid(uid_t ruid, uid_t euid);
	int setregid(gid_t rgid, gid_t egid);
	两个函数如果成功则返回0,如果错误则返回1.
	如果任何一个参数设置为1，那么表示相应得ID保持不变。
	这个函数执行的规则很简单：未授权的用户可以切换real user ID和effective user ID.这允许一个set-user-ID程序切换到普通用户权限，然后又切换回set-user-ID权限。当saved set-user-ID特性从POSIX.1中引入的时候，这条规则变成了也允许一个非授权用户把它的effective user ID设置成saved set-user-ID.
	/*seteuid和setregid都是Single UNIX Specification中的XSI扩展。这样，所有UNIX系统都应该支持它们。*/
	4.3BSD没有saved set-user-ID特性，它使用setreuid和setregid来替代。这允许一个非授权用户在两个值之间来回切换。然而，当程序启动一个shell的时候，它需要在exec之前把real user ID设置成为normal user ID.如果不这样作，那么real user ID将会被授权了（从setreuid）,然后shell进程可以调用seteuid来切换到更高用户权限。为了防止这种情况发生，需要在子进程中调用exec之前把real user ID和effective user ID设置成normal user ID.

	*关于seteuid 和 setegid函数
	POSIX.1包含两个函数：seteuid和setegid.这些函数和setuid与setgid类似，但是只有effective user ID或者effective group ID被改变了。
	#include <unistd.h>
	int seteuid(uid_t uid);
	int setegid(gid_t gid);
	如果成功返回0,如果出错返回1.
	一个非授权用户可以设置它的effective user ID为real user ID或者它的saved set-user-ID.对于授权用户，只有effective user ID被设置成为了uid(这一点和setuid函数不同,setuid会把所有三个user ID改变).
	参考资料最后有个图，给出了这些修改user ID函数的动作情况。
	大致是，
	对于superuser,
	setreuid会修改real user ID和effective user ID为其参数所指定的。
	setuid会修改real user ID和effective user ID以及saved set-user-ID三者为其指定的参数。
	seteuid仅修改effective user ID为其参数所指定的。
	对于非特权用户，
	setreuid
	setuid会修改effective user ID的值，这个值可以为real userID或者saved set-user-ID.
	seteuid会修改effective user ID的值，这个值可以为real userID或者saved set-user-ID.
	另外，如果文件具有set-uid设置(也就是ls文件时候的rwx权限中的x变成s)，那么exec的时候会把effectived user ID变成设置为文件属主,否则effectived user ID保持不变;saved set-user-ID是被exec从effectived user ID拷贝过来的，如果文件的set-user-ID被设置，那么在exec把effectived user ID设置成文件属主之后，再将effectived user ID拷贝一份存到saved set-user-ID中去。

	对于组gid来说，遵循的规则和上面用户uid的规则一样，但是"额外组"不受这些组id函数设置的影响。

11)解释器文件（类似脚本文件的东西）
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec12.html
	当前所有的unix文件系统支持解释器文件(interpreter file),这种文件是一种文本文件，一般以如下形式开头：
	#! pathname [ optional-argument ]
	这里，'!'后面的空格是可选择的。最常见的解释器文件就是这样开头的：
	#!/bin/sh
	这也就是shell脚本，这里，解释器文件的pathname一般是一个绝对路径，因为没有对这个路径的特殊处理（例如不会使用PATH环境变量来处理这个路径）。这些文件在系统调用exec的时候，在内核中被处理，实际在内核中被执行的文件不是这个解释器文件而是通过解释器文件中第一行的pathname中指定的可执行文件（也就是解释器）.所以需要注意区分解释器文件（一个以#!pathname开头的文本文件）与解释器(解释器文件开头pathname所指定的文件)。
	注意，系统对解释器文件第一行有个长度的限制，这个限制包括所有的空格、回车、参数、#!字符等等任何字符。
	在 FreeBSD 5.2.1, 这个限制是 128 字节. Mac OS X 10.3 把这个限制提高到512字节.Linux2.4.22支持127字节，solaris9是1023字节。
	例子说明1：
	如下运行命令序列：
	   $ cat /home/sar/bin/testinterp
	   #!/home/sar/bin/echoarg foo
	   $ ./a.out
	   argv[0]: /home/sar/bin/echoarg
	   argv[1]: foo
	   argv[2]: /home/sar/bin/testinterp
	   argv[3]: myarg1
	   argv[4]: MY ARG2
	这里，testinterp文件内容从命令中已知，
	程序echoarg是把它所有参数打印出来，有另外一个程序通过exec调用这个testinterp文件，如下：
	execl("/home/sar/bin/testinterp","testinterp", "myarg1", "MY ARG2", (char *)0) < 0)
	从这个例子可以看出，解释器(echoarg)把这个pathname解释成arg[0],arg[1]就是解释器文件中pathname后面的选项foo,
	而解释器的arg[2]参数就是这个解释器文件，执行解释器文件的参数myarg1,MY ARG2后排到了arg[3],arg[4].也就是内核中把execl第一个参数testinterp替换成了解释器文件中的pathname因为内核认为这样会包含更多的执行动作指定选项等信息。

	有些特殊程序运行脚本文件需要用-f选项，这时候，我们需要在前面的#!处相应添加-f,例如awk脚本，前面需要有：
	#!/bin/awk -f
	因为awk用-f选项来指定文件名称。
	执行其他非shell脚本，实际解释文件是不必要的，但是解释文件效率确实比较高效，它使得
	a)我们可以用"<脚本名> <选项>"方式执行，而不必知道是什么程序然后再用"<程序名> [-f] <脚本名> <选项>"方式执行.
	b)如果我们前面不加#!/bin/<程序名> [-f]那么也行，需要修改脚本内容，成了shell脚本。但是这样效率会很低，因为会先启动shell,然后shell启动<程序>.
	c)一般如果不用#!那么系统会自动选择一个shell做为执行shell，一般为/bin/sh,实际这样让系统自己选择会降低一些效率。
	上述解释文件，如果shell不是使用'#'做为注释的话就不好用了。

12)关于system接口
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec13.html
	system函数是一个POSIX接口，它可以从程序中启动一个系统的命令。
	如下：
	#include <stdlib.h>
	int system(const char *cmdstring);
	这里，如果cmdstring参数为空，那么当命令支持处理则system返回非0，根据这一点，我们可以确定在一个操作系统上面是否支持这个system函数。
	system函数会调用fork,exec,和waitpid函数，它的返回值如下：
	a)如果fork失败或者waitpid返回错误但是错误不是EINTR,那么system返回1，并且设置errno。
	b)如果exec失败，以表示shell无法执行，那么返回就像shell执行了exit(127).
	c)如果fork,exec,waitpid成功执行，那么会返回shell的终止状态（waitpid的格式）.
	原来system返回errno(EINTR)表示收到信号中断了,因为无法从这样的状态恢复。后来POSIX添加了这样不会返回错误码的特性。
	在本节有一个简易的system实现（没有考虑信号处理）.
	使用system的优点是它会做信号处理以及错误处理。
	system后面使用了一个类似while (waitpid(pid, &status, 0) < 0) {...}的语句来等待指定子进程（system出来的）结束。以前没有waitpid的时候使用的是类似while ((lastpid = wait(&status)) != pid && lastpid != -1);这会忽略system调用之前的子进程。
	最好不要在一个有set-user-id的程序中调用system，因为这样会有安全漏洞，让任何一个程序可能以root身份运行。尽管新版本的bash shell会在与real uid不匹配的时候重置执行程序的effective uid。如果必须要这样作，那么用fork和exec这样保证程序能够在fork之后恢复原来的权限，一定不要用system.因为system会启动一个shell，而shell使用IFS(分割符号)做为输入域的分割符号，旧版本的shell不会重置这个变量，所以会为一些人创造可乘之机。

13)进程记帐
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec14.html
	大多数的unix操作系统提供了一种进程记帐的手段，用来统计每个进程的资源使用情况.如果使能了这个功能，那么每次进程结束的时候，操作系统内核就会记录一条信息。信息记录的就是一些二进制的数据，包括命令名称，cpu占用时间，userID,group ID,启动时间等等。
	这个功能并不是标准化的。因此所有系统的这个功能不是很统一。具体参见参考文档，这里不再举例了。
	每种系统实现有它自己处理记帐原始数据的命令。例如solaris提供runacct(lm)和acctcom(l),而FreeBSD提供sa(8)来处理和列出原始记帐数据。
	一个我们没有描述过的函数acct可以禁止和使能进程记帐。这个函数唯一的使用是accton命令（这个命令在不同平台上面竟然很类似）。超级用户执行带有一个路径参数的accton来使能记帐。记帐记录被写入到一个指定的文件，一般这个文件是/var/account/acct（FreeBSD和Mac OS X）或者/var/account/pacct(Linux)，或者/var/adm/pacct(Solaris).如果运行没有参数的accton那么记帐功能被禁止。
	<sys/acct.h> 文件定义了记帐数据的结构体acct。其中ac_flag记录了在进程执行过程中发生的事件。
	fork的时候会初始化一条记录但是exec的时候不会，但是exec的时候AFORK标志被清除（当然名字会更新）。每当进程结束的时候才会写入记帐记录所以记帐记录文件中记录了进程的结束次序而不是启动次序。尽管其中有start时间的记录，但是其单位是秒，无法精确记录启动次序；另外虽然cpu耗费时间比较精确，但是我们无法知道进程结束的时间；综上，我们实际上无法获得进程精确启动次序。
	参考文献给出了一个具体的例子来展示如何在程序中获取和分析记帐数据,这里不详细说了。

14)用户标识
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec15.html
	任何进程都能够得到它的real uid和effective uid以及gid.有时候，我们想要获得运行程序的用户的login name.也许我们会想要使用getpwuid但是，如果一个用户具有多个登陆名字就不行了。（一个用户可能在password文件中拥有多个用户名，这些用户名对应一个uid，这样可以对不同的用户名使用不同得shell进行登陆）。系统一般会保留login名称（参见6章8节网址为：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch06lev1sec8.html#ch06lev1sec8）.getlogin函数提供获得login name的功能。
	#include <unistd.h>
	char *getlogin(void);
	正确返回指向登陆名称的字符串指针，错误返回NULL.
	如果用户登陆的终端没有和进程相关联，那么这个函数会返回错误。我们把这样得进程称为daemon,后面会有所涉及。
	给定login name我们就可以通过搜索password文件来确定登陆的shell了(例如使用getpwnam)。
	不同系统获取loginname有不同的方式，例如unix以前使用ttyname搜索utmp文件，FreeBSD和Mac Os在进程表中存放相关信息，更多的其他系统不多说了。
	另外需要注意的是：环境变量LOGNAME一般会被login程序初始化成用户登陆的名称，然后被登陆shell所继承。但是由于环境变量是可以修改的所以我们不使用LOGNAME而是使用getlogin函数。

15)进程时间：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec16.html
	前面我们说了进程时间：clock time, user cpu time, system cpu time.任何进程可以通过times函数获得它自己或者结束的子进程的这些值。
	#include <sys/times.h>
	clock_t times(struct tms *buf);
	函数填充参数中tms结构体，并且返回clocktime。
	结构体定义如下：
	struct tms
	{
	  clock_t  tms_utime;  /* user CPU time */
	  clock_t  tms_stime;  /* system CPU time */
	  clock_t  tms_cutime; /* user CPU time, terminated children */
	  clock_t  tms_cstime; /* system CPU time, terminated children */
	};
	这些值是从一个从前的某个起点开始计算的，所以一般我们用不上它们的绝对值，我们需要使用相对值来计算时间的长短。例如计时开始记录当前时间，计时结束记录一个时间，然后两者相减计算时间消耗。
	这里，用于子进程的两个成员的时间值只是我们调用wait,waitid,或者waitpid等到的子进程时间。
	函数返回的clock_t值使用clock tick per second转换成秒，这个clock tick per sceond由sysconf返回的_SC_CLK_TCK 来决定。
	大多数系统有geTRusage函数，这个函数返回cpu time和其他14种资源值，BSD系列系统一般比其它实现支持更多的信息。

*关于进程间关系
==========================
1)登陆终端:
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec2.html
	从前的Unix用户都是通过接线连接的哑终端来进行登陆系统的。这些要么是来自本地要么来自远程，但都来自内核中的终端设备的登陆.同时由于主机中终端设备的数目是固定的，所以可以同时登陆的用户数目也是固定的。后来随着图形终端的流行，窗口系统为用户提供了终端窗口来模拟基于字符的终端。
	现在，有些平台允许你在登陆之后可以启动窗口系统，或者有些平台自动就为你启动了一个窗口系统但你还是需要登陆的，这取决于你的窗口系统是如何配置的。下面将要描述使用terminal登陆unix的过程,无论是图形终端还是什么，这些过程都是类似的。
	*BSD系统上面的终端登陆：
	这种登陆已经30多年没有什么变化了.系统管理员首先创建一个文件(一般是/etc/ttys),这个文件的每一行描述每种字符终端设备。每一行给出了设备名称，以及其它一些传入getty程序的参数,例如终端的波特率。当内核启动的时候，创建进程ID为1的init进程，这个进程会把系统引导成多用户系统。对于每一个可以登陆的终端设备，init进程读取/etc/ttys,然后进行fork再exec执行getty程序,参考文献中有相应的图形表示。这里简单用文字来描述一下：
	a)init调用fork,fork出多个init
	b)每个init调用exec,exec的是getty程序。
	上述所有进程的real uid和effective uid都是0，init在exec程序getty的时候的环境变量为空。
	getty程序对终端设备调用open,open的终端用来reading和writing.如果设备是一个modem,那么open可能会在设备驱动中延迟，直到modem拨号成功调用得到回复。
	终端被open之后，文件描述符号0,1,2就会被设置成这个终端设备，然后getty会打印出login:并且等待我们输入用户名。如果终端支持多种速率，那么getty可以检测到特殊字符，并且告诉它来修改终端的波特率。
	我们可以查看getty的man手册来了解更多的信息。当我们输入完用户名之后，getty的任务就完成了，它会调用类似如下的语句来启动login程序:"execle("/bin/login", "login", "-p", username, (char *)0, envp);"

	可以在gettytab中有其他的选项来启动其他的程序，但是默认来说启动得就是login程序。init调用getty的时候环境变量是空的，getty会为login创建环境变量(envp参数).环境变量的名字有终端的名称（例如TERM=foo,这里终端foo的类型从gettytap文件中获取）,以及其它在gettytab中指定的环境变量字符串.login的-p标志告诉它保存传递给它的环境变量并且追加新的环境变量，而不是替代。参考资料中有个图说明了这个过程,大致描述如下：
	a)init读取/etc/ttys文件，对每一个termimal进行fork，并且设置空的环境变量。
	b)fork出来的每一个init进行exec，exec的程序是getty.
	c)getty打开termial设备，读取用户名称，初始化环境变量，然后调用exec,exec的程序是login.
	以上，因为最开始的init具有superuser权限，所以后面所有的进程都有superuser权限，由于调用了exec，所有exec之后进程的pid不会发生变化，因此除了最开始的init之外，所有进程的父进程都是pid为1的init。
	login程序做的事情不少。它根据我们给它的用户名称，调用getpwnam从我们的passwd中获取一个entry,然后login调用getpass来显示"Passwork:"提示符号，我们开始输入密码（这是后，输入的显示被屏蔽），然后它调用crypt来对我们输入的密码进行加密，然后将shadow中的entry的pw_passwd域和加密之后的结果相比较,如果login由于密码非法而失败，那么login会调用exit(1)返回，并且将终止通知给父进程（init),然后对这个terminal调用另外一个fork和exec生成getty,和前面说的过程一样。
	前面叙述的是unix系统上面传统的认证过程，现在的unix系统支持多种认证过程。例如FreeBSD,Linux,Mac OS X,和Solaris都支持PAM(pluggable Authentication Modules)这种更灵活的方案。PAM允许管理员配置认证的方法，这些方法用来访问使用PAM库写的服务。
	如果我们的应用程序需要确认一个用户是否有合适的权限来执行一个任务，那么我们可以再这个应用程序中进行硬编码实现认证机制，也可以使用PAM库。使用PAM的优点是，管理员可以基于本地站点的策略，针对不同的任务配置不同的途径，给用户授权。

	如果我们登陆正确了,那么login程序会：
	a)切换到我们的主目录
	b)更改终端设备的属主(chown)，这样我们可以拥有这个终端设备
	c)更改终端设备的访问权限，这样我们可以有相应的读写权限
	d)通过调用setgid和initgroups来设置我们的组id
	e)使用login程序已知信息来初始化环境变量(HOME,SHELL,USER,LOGNAME,PATH).
	f)切换成我们的uid然后采用如下形式调用loginshell："execl("/bin/sh", "-sh", (char *)0);"
	这里，argv[0]前面的"-"表示这个sh是一个登陆发起的sh，这样shell可以根据这个字符来对启动做相应的调整。
	login程序还会作许多其它的事情，例如检查email，打印时间等信息等等，我们这里只专注我们指出的那些动作。
	如前面所述，setuid被superuser调用会改变readl user id,effective uid,saved uid三种uid.login 会更早地调用setgid,并且其效果和setuid类似。
	这时候，我们的login shell的父进程id是init的进程id，所以当我们的login shell结束的时候，init进程会被通知到（SIGCHLD），然后会对当前的terminal重复前面的过程。参考资料给出了相应的图示。描述大致如下：
	a)init程序经过前面的过程，将login shell启动起来
	b)将文件描述符号0,1,2设置到terminal device,并且与terminal device driver交互
	c)再往后是终端的用户使用终端

	之后，login shell读取startup文件（bourne shell和korn shell是.profile;GNU bourne again shell是.bash_profile,.bash_login或者.profile;c shell是.cshrc,.login）,它们通常会设置一些额外的环境变量，然后我们就可以在提示符号下面键入命令了。

	*Mac OS X上的终端登陆：
	由于是基于Free BSD的，所以过程一样。然而我们可以图形显示login 启动。

	*Linux 上的终端登陆：
	Linux上面的登陆过程和BSD系统差不多，实际Linux的login命令就是从BSD继承过来的，两者主要不同的地方就是终端配置的指定方式。
	在Linux上，/etc/inittab包含了用来指定终端驱动的配置信息，init需要为这个终端驱动启动一个getty进程，其中的过程和systemV类似。根据使用的getty版本不同，终端的特性可以由命令行指定（agetty程序），或者由文件/etc/gettydefs指定(mgetty程序)

	*Solaris上面的终端登陆：
	Solaris支持两种类型的登陆：a)getty类型b)ttymon类型.一般用不上，这里就不浪费时间了，具体参照参考资料。

2)关于使用网络登陆终端:
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec3.html
	使用网络和串口终端登陆系统的主要区别是：电脑和终端之间连接的方式不是点到点的。在这种情况下，login只是一个可以使用的服务，就像类似ftp和smtp这样的网络服务一样。
	有了我们之前叙述过的终端登陆，init知道哪些终端设备对于login来说是可以使用的，然后它会启动一个为每一个设备启动一个getty进程。然而，在网络登陆的情况下，所有的login来自内核的网络接口驱动(例如以太网卡驱动)，我们无法提前知道这些发生的时间。我们需要使用等待网络连接请求的方式来替代用每一个进程等待每一个可能的请求login的方式。
	为了使用同样的软件来处理网络连接和终端连接，使用一个被称作pseudo terminal(伪终端)来模拟串口终端并把终端操作映射成为网络操作，反之亦然。(关于pseudo terminal我们后面会详细介绍)

	*BSD下面的网络登陆：
	在BSD下面，有一个单一的进程用来等待大多数的网络连接，这个进程是inetd进程，有时候也被称作"internet super server".这里我们将要看看在BSD系统中网络方式登陆时启动进程的顺序和过程。
	在系统启动的时候，init会启动一个shell来运行/etc/rc脚本，通过这个脚本启动的守护进程中，其中有一个就是inetd进程。当shell脚本结束的时候，inetd的父进程变成了init; inetd会等待到达主机的TCP/IP连接请求。当一个连接请求到达的时候，inetd会fork并exec一个合适的程序。
	假设tcp请求来自telnet的server(telnet是一个使用tcp协议的远程登陆程序)，在其他主机（以某种网络连接的形式连接到本地服务主机）的用户,或者在本地服务主机发起一个telnet client:
	telnet hostname
	client从"hostname"主机打开一个tcp连接，在hostname上面启动的程序叫做telnet server.client和server通过tcp连接，使用telnet协议互相传送数据。这样，启动client端的user就会登陆到server的host上面。参考资料中给出了启动telnet server(telnetd)的过程。简单叙述如下：
	a)最初的init进程调用fork创建子进程,然后子进程exec执行一个sh脚本(/etc/rc)
	b)通过前面的脚本，启动inetd守护进程，这个守护进程开始等待telnet客户端发起的TCP连接请求。
	c)当收到一个telnet请求的时候，inetd调用fork创建子进程，子进程再调用exec执行telnetd
	从这之后，telnetd进程会打开一个伪终端设备，然后调用fork得到两个进程。父进程处理来自网络连接的通信；子进程调用exec执行login程序;父进程和子进程通过伪终端联系起来。在执行exec之前，子进程设置文件描述符号0，1，2到伪终端.如果我们正确登陆了，login之后的过程就和我们之前叙述的一样了:它会切换到我们的home目录，设置gid,uid和初始环境变量，然后login调用exec把它自己替换成我们的login shell。
	参考资料给出了login之后简略的过程，大致如下：
	a)init经过前面的过程,进入loginshell
	b)这时候0,1,2文件描述符号和伪终端设备驱动联系上了。
	c)设备驱动通过telnetd和telnet client之间的网络连接和用户终端交互。

	这里，在设备驱动和用户终端之间有许多复杂的过程，后面会详细叙述。现在先总结一下这个整体的过程如下：
	a)最初的init进程调用fork创建子进程,然后子进程exec执行一个sh脚本(/etc/rc)
	b)通过前面的脚本，启动inetd守护进程，这个守护进程开始等待telnet客户端发起的TCP连接请求。
	c)当收到一个telnet请求的时候，inetd调用fork创建子进程，子进程再调用exec执行telnetd
	d)telnetd再fork，fork之后其中一个进程（telnetd）负责在网络上和伪终端之间收发数据;另外一个进程调用exec执行login,login将切换到我们的home目录，设置gid,uid和初始环境变量，然后login调用exec把它自己替换成我们的login shell,然后通过虚拟终端和用户交互。
	e)telnetd fork的两个进程(这里姑且叫做telnetd,login shell)之间是通过如下方式进行交互：
	...network messages....<->telnetd<->pseudo terminal device <->login shell<->......

	这里比较重要的一点是，我们登陆的时候是通过terminal(终端)，还是network;我们的login shell的标准输入标准输出和标准错误输出是连接到终端设备或者虚拟终端设备.后面我们将会知道，login shell是posix.1的部分，终端或者伪终端是session的control terminal.

	*MacOs X 的网络登陆
	由于是基于Free BSD的，所以过程一样。

	*Linux上的网络登陆
	Linux上面的网络登陆和BSD上面一样，不同的地方是使用了不同的inetd进程，叫做xinetd.xinetd进程比inetd的控制层次好。

	*Solaris上的网络登陆
	目前本人还没用到，不说了,具体参考参考资料。

3)关于进程组ID:
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec4.html
	除了进程ID,进程还有组ID.进程组是一个或者多个进程的集合，通常和相同的job相互关联,job从同样的终端接收信号。每个进程有唯一的进程组id,进程组id类似进程id是一个正数可以存放在pid_t中。
	函数getpgrp返回调用进程的进程组id。如下：
	#include <unistd.h>
	pid_t getpgrp(void);

	原来BSD体系的系统getpgrd函数有一个pid参数，会返回对应那个pid进程id的进程所在的组。Single UNIX Specification定义了getpgid函数作为extension,用来模拟这个函数。
	#include <unistd.h>
	pid_t getpgid(pid_t pid);
	如果传入的参数是0,那么返回调用进程的组id.(这和没有参数的getpgid调用一样)

	进程组leader可以创建一个进程组，可以在组内创建一个进程，然后终止退出。只要进程组内有进程，无论进程组leader是否存在，进程组也都会存在。组内最后一个进程可以终止，也可以加入一个其它的进程组。
	通过调用如下函数创建或者加入一个已经存在的进程组：
	#include <unistd.h>
	int setpgid(pid_t pid, pid_t pgid);
	函数正确运行的时候，返回0；错误的时候返回1。
	函数会将进程id等于pid的进程的进程组id设置成pgid.如果两个参数相等，那么进程pid就变成了一个进程组leader.如果pid等于0，那么进程id假设就是调用该函数进程的进程id.当然，如果pgid为0，那么就使用pid进程的进程组id。
	一个进程只能设置它自己或者它的子进程的进程组id。另外，如果它的子进程调用了exec，那么这个进程就不能够改变它这个子进程的进程组id了。
	在大多数的作业控制shell中，这个函数在执行fork之后会被调用，一般都是在父进程中设置一下子进程的进程组id，然后再在子进程中设置一下它自己的进程组id；这里实际上有一个调用是冗余的，但是通过这样做（也就是在父子进程中都调用setpgid）我们可以保证子进程被放在了它自己的进程组中（在父子两进程做这样的假设之前），如果我们没有这样做，那么我们可能会碰到一些竞争条件，这个竞争条件会导致子进程的进程组成员关系取决于哪个进程被首先执行。
	当我们后面说到信号的时候，我们将会看到我们是如何发送一个信号到某个单个的进程（通过进程pid进行标识），或者某个进程组（通过进程组id进行标识）的。类似地，在前面的waitpid函数中我们已经看到，我们可以等待某个特定的进程或者进程组。

4)关于Session:
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec5.html
	一个session是一个或者多个进程组的集合。参考资料中给出了一个简单的图来表示这个意思。
	这里没有图，所以叙述一下图中描述的情况：
	有一个session，session中有三个进程组。第一个进程组中有一个login shell进程；第二个进程组中有两个进程：proc1,proc2；第三个进程组中有三个进程：proc3,proc4,proc5.
	在个进程组中的进程，一般都是通过shell管道的方式来产生的，上面叙述的图中的后两个进程组是通过如下的命令产生的:
	proc1 | proc2 &
	proc3 | proc4 | proc5

	一个进程是通过调用函数setsid来建立一个会话(session)的。这个函数如下：
	#include <unistd.h>
	pid_t setsid(void);
	这个函数正确的时候返回进程组id，错误的时候返回1.
	如果调用这个函数的进程不是一个进程组leader,那么这个函数创建一个新的session,这时候有如下三个事情发生：
	1.进程变成这个新session的session leader(一个session leader就是创建这个session的进程)，并且这个进程成为这个新的session中的唯一的进程。
	2.进程变成一个新的进程组的leader。这个新的进程组id就是这个调用setsid函数的进程的进程id。
	3.进程没有controlling terminal(控制终端)。我们将在下一节讨论控制终端。如果再进程调用setsid函数之前这个进程具有了一个控制终端，那么和那个控制终端的联系会被断开。
	如果调用进程已经是一个进程组的leader了，那么这个函数这个函数会返回一个错误。为了确保不会发生这种情况，一般的方法是调用fork创建一个子进程，然后让父进程终止，子进程继续；这样我们可以保证子进程不是一个进程组leader，因为子进程会自动继承父进程的进程组id，但是子进程的进程号却是新产生的（和父进程不同）(所以子进程的pid就不等于父进程的pid，所以也不等于其进程组的组id了，因为组id和组leader的pid相等).

	Single UNIX Specification只说了"session leader",并没有和进程ID和进程组ID类似的"session ID"的说法。很显然，一个session leader就是一个单个的进程，所以我们说到 session ID的时候，就认为那是这个session的session leader的进程pid。session ID的概念是在SVR4中引入的。BSD体系的系统没有支持这个概念，但是已经被更新包含了这个相关的东西。 getsid函数返回一个进程的session leader的的进程组id。getsid函数在Single UNIX Specification中被作为XSI扩展包含进去了。

	Solaris和Single UNIX Specification差不多，它尽量避免使用"session id"的概念,它采用的说法是"process group ID of the session leader".这两种说法是相等的，一个session 的leader一直都是一个process group的leader。
	获取session id的函数:
	#include <unistd.h>
	pid_t getsid(pid_t pid);
	如果正确会返回session leader的process group ID,错误的时候返回1.
	如果pid是0，那么getsid返回调用进程的session的进程组id。由于某些安全性的因素，有些实现可能会在pid参数和进程id不属于同一个session的情况下限制调用进程获取相应的"session id".

5)关于控制终端
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec6.html
	会话和进程组有一些其它的特性:
	*会话可以有一个单个的控制终端。这个控制终端一般都是我们登陆时候的终端设备（在终端登陆的情况下），或者是一个伪终端设备（在网络登陆的情况下）。
	*建立到控制终端连接的会话leader被称作控制进程。
	*在一个会话中的进程组可以被分成一个单一的前台进程组，以及一个或者多个后台进程组。
	*如果一个session有一个控制终端，那么它有一个单一的前台进程组，这个session（session就是会话）其他的进程组是后台进程组。
	*当我们键入终端的中断键（一般都是DELETE或者Control-C）的时候，会发送给所有在前台进程组中的进程一个中断信号。
	*当我们敲入终端的quit键（一般是Control-backslash）的时候,这会导致一个quit信号发送给所有前台进程组的进程。
	*如果一个modem(或者网络)的连接断开被终端的接口检测到了，那么会给控制进程（session leader）发送一个hang-up信号。
	参考资料的图描述了这个叙述。简单总结该图的意思就是：
	a)controlling terminal在检测到modem disconnect之类的情况的时候会给login shell(也是后台进程组中的进程，也是session leader，也是控制进程)发送hang-up信号。
	b)终端输入或者终端发起的信号会发送给session中的前台进程组。
	c)另外，一个session中还有可能存在其他的后台进程组。

	一般来说，我们不用担心控制终端，因为在我们登陆进去的时候它会自动被建立。
	POSIX.1把分配控制终端机制留给了各自实现。
	从UNIX System V继承过来的系统，会在session leader打开第一个没有和session建立联系的终端设备的时候分配一个控制终端.当然这假设session leader调用的open没有指定O_NOCTTY标志。
	基于BSD的系统会在session leader调用ioctl(有一个TIOCSCTTY请求参数，第三个参数是空指针)的时候给一个session分配一个控制终端。在调用之前，session不能已经有了controlling terminal(否则调用不成功).一般来说，这个ioctl调用后面需要接着一个setsid调用，这个调用保证进程是一个没有控制终端的session leader.在BSD系列的系统中，POSIX.1中open的O_NOCTTY标记并没有使用，除非是要和其他系统相互兼容的时候。

	有时候一个程序想要和controlling terminal进行交互，并且不考虑标准输入输出是否被重新定向了。程序用来确保自己是要和controlling terminal进行交互的方法是通过打开/dev/tty文件.这个特殊文件在内核中和controlling terminal是同义的。一般来说，如果程序没有controlling terminal,那么打开这个设备文件会失败。

	一个经典的例子是getpass函数，这个函数读取密码（这时候terminal 的echo是关闭的）.这个函数被crypt程序调用，可以在管道中使用。例如：
	crypt < salaries | lpr

	解密salaries文件然后通过管道输出到打印池。因为crypt从标准输入读取输入文件，不用使用标准输入输入密码。并且，crypt程序每次运行的时候，需要输入加密的密码，这样我们就不用将密码保存在文件中了(保存在文件中有安全隐患)。
	有一些已知的方法将crypt使用的encoding给break,这里不说了。

6)关于tcgetpgrp, tcsetpgrp, 和 tcgetsid 函数:
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec7.html
	我们需要一种方法来告诉内核哪个进程组是前台的，这个终端设备驱动知道向哪里发送终端输入以及终端产生的信号
	#include <unistd.h>
	pid_t tcgetpgrp(int filedes);
	如果成功返回前台的进程组id，否则出错并返回1.

	int tcsetpgrp(int filedes, pid_t pgrpid);
	如果成功返回0，否则出错并返回1.

	tcgetpgrp函数返回和参数filedes相关的打开的终端的前台进程组id.
	如果进程有一个控制终端,那么函数tcsetpgrp会设置前台进程组id为pgrpid.pgrpid的值必须是当前同一个会话中的进程组id的值，filedes必须是session的控制终端的引用。
	大多数应用程序不会直接调用这两个函数，它们一般是被作业控制的shell来进行调用的。
	Single UNIX Specification定义了一个XSI扩展，叫做tcgetsid允许应用程序通过一个给定的控制tty的描述符号获得session leader的进程组id。

	#include <termios.h>
	pid_t tcgetsid(int filedes);
	如果成功返回session leader的进程组id，否则出错并返回1。
	需要管理控制终端的应用程序可以使用tcgetsid函数来辨别控制终端session leader的session id(这个和session leader所在的进程组一样).

7)关于作业控制
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec8.html
	作业控制是大概1980年的时候引入BSD的一个特性，这个特性允许我们从一个单个的终端启动多个作业(许多进程组),并且可以控制哪些作业可以访问终端以及哪些作业在后台运行。
	作业控制需要三种形式的支持：
	a)需要shell来支持作业控制.
	b)内核中的终端驱动需要支持作业控制.
	c)内核必须支持特定的作业控制信号.
	SVR3提供了一种不同形式的作业控制，叫做shell层.然而这里讨论的是被POSIX.1选中的BSD形式的作业控制。以前的标准作业控制的支持是可选的，但是POSIX.1现在要求平台来支持这个特性。

	在我们看来，从shell中使用作业控制，我们可以在前台或者后台启动一个作业，一个作业就是一些进程的集合,一般来说是用管道连接起来的进程。例如：
	vi main.c
	这会在前台启动一个只有一个进程的作业。命令：
	pr *.c | lpr &
	make all &
	会在后台启动两个作业,这两个后台作业中的进程也是在后台运行的。
	正如前面所说，为了使用作业控制的特性，我们需要使用一个支持作业控制的shell。在以前的系统中，很容易辨别出哪些shell支持作业控制哪些不支持。C Shell支持，Bourne Shell不支持,Korn Shell可选,这取决于主机是否支持作业控制。但是C Shell已经移植到了不支持作业控制的主机上面，还有SVR4 Bourne Shell如果是用jsh而不是用sh来启动的话也支持作业控制,Korn Shell在主机支持的情况下仍旧支持作业控制,Bourne-again Shell也支持作业控制,我们后面只讨论具有作业控制的shell，而且不关心这些shell之间的不同。当我们启动一个后台作业的时候，shell会给这个后台作业赋予一个作业号,并且打印出一个或者多个进程ID.下面的例子给处了Korn Shell如何处理这些：
	$ make all > Make.out &
	[1]     1475
	$ pr *.c | lpr &
	[2]     1490
	$                          just press RETURN
	[2] +  Done                 pr *.c | lpr &
	[1] +  Done                 make all > Make.out &
	这里，make对应作业号是1，启动的进程是1475;下一个管道的作业的作业号是2，打印的pid是第一个进程的1490.当作业完成，并且我们输入了RETURN的时候，shell会告诉我们作业已经完成。我们需要键入回车才能得到shell打印的提示的原因是shell不会在任意的时间来打印其中的后台作业的状态变化，shell只有在要打印它的提示符号前的时候才会打印这些，这样我们可以键入新的命令。如果shell不这样做，那么会在我们正在输入某一行的过程中打印提示，这样很容易出现显示错乱。

	可以通过一些特殊字符来和terminal driver进行交互，影响前台运行的作业。例如[Ctrl]z按键，会导致terminal driver给前台进程组的所有进程发送SIGTSTP信号，而后台进程组的进程不会受到影响。terminal driver会监视如下三个字符，用来给前台的进程组发送信号：
	*中断字符(DELETE或者Control-C),发送信号SIGINT.
	*退出字符(Control-backslash)，产生信号SIGQUIT.
	*挂起字符(Control-Z)产生信号SIGTSTP.
	后面我们会讲到如何把这些字符更改成其他字符以及如何让terminal driver忽略处理这些字符。

	terminal driver还有必须处理的另外一种作业控制的情况。由于我们可以有一个前台作业以及多个或者一个后台作业，那么哪些作业接受我们在终端键入的字符呢？答案是只有前台作业接受终端输入。但是，后台作业尝试读取终端的输入也是没有错误的，这时候，terminal driver 检测到这个情况发生，然后会给后台作业发送一个SIGTTIN信号，通过shell，这个信号一般都会停止后台的作业，我们会被通知到有这个情况发生，然后把作业凋到前台，这样就可以从终端读取输入了。
	例如如下:
	$ cat > temp.foo &          start in background, but it'll read from standard input
	   [1]     1681
	$                           we press RETURN
	   [1] + Stopped (SIGTTIN)     cat > temp.foo &
	$ fg %1                     bring job number 1 into the foreground
	   cat > temp.foo              the shell tells us which job is now in the foreground

	   hello, world                enter one line

	   ^D                          type the end-of-file character
	$ cat temp.foo              check that the one line was put into the file
	   hello, world
	在这个例子中，shell从后台启动一个cat进程，这个cat程序尝试从标准输入(controlling terminal)读取输入，terminal driver检测到这个情况之后，发现cat是一个后台作业，所以发送SIGTTIN信号给后台作业。shell检测到这个子进程的状态变化（通过wait和waitpid），然后就告诉我们那个作业stopped了。之后我们可以通过fg命令把这个作业调到前台来。这会导致shell把作业放到前台进程组中（通过tcsetpgrp）,然后发送SIGCONT信号给进程组。因为进程已经跑到前台了，所以可以从controlling terminal来读取输入信息。

	如果后台作业输出到控制终端会如何？这个问题我们可以自行选择允许或者不允许。一般来说，我们通过stty命令来进行选择。后面我们可以看到我们如何可以从程序设置这个选项。下面展示了这是如何工作的:
	$ cat temp.foo &             后台执行命令
	   [1]     1719
	   $ hello, world            提示符号后面出现后台作业的输出
	$                             输入回车
	   [1] + Done              cat temp.foo &
	$ stty tostop             禁止后台作业进行输出
	$ cat temp.foo &           再次运行
	   [1]     1721
	$                             输入回车
	   [1] + Stopped(SIGTTOU)               cat temp.foo &
	$ fg %1                      把作业重新调到前台
	   cat temp.foo
	   hello, world             开始打印输出
	在这个例子中，当我们禁止后台作业向控制终端输出的时候，cat将在尝试输出到标准输出的时候阻塞，因为终端驱动可以辨别来自后台进程的输出，然后给后台作业发送一个SIGTTOU信号，然后我们使用fg将作业调到前台的时候，作业就会自然完成了。

	参考资料中有一个图说明了login shell,前台和后台进程，以及terminal driver之间的关系,大致描述如下：
	a)getty 或telnetd调用exec,setsid然后创建controlling terminal进入b)
	b)启动login，再执行exec进入c）
	c)使用exec启动login shell,调用tcsetpgrp为controlling terminal设置进程组.
	前台进程:login shell可以给它调用setpgid,它可以通知login shell的子进程状态;它可以和terminal driver相互读取数据以及写入数据，terminal driver可以给它相应发送信号。
	后台进程:login shell可以给它调用setpgid,它可以通知login shell的子进程状态;它可以从terminal driver读取数据以及写入数据，在读写数据的时候terminal driver可以给它相应发送信号。
	d)terminal driver
	e)在终端前面的用户

	作业控制是POSIX.1的一个特性。

8)关于用shell执行程序：
参考资料：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec9.html
	我们这里看看shell是如何执行程序的，以及这些如何与进程组，控制终端，以及会话联系起来,我们使用ps命令为例。

	首先我们在solaris使用经典的不支持作业控制的bourne shell来运行ps如下：
	ps -o pid,ppid,pgid,sid,comm
	这个命令的输出如下：
	     PID  PPID  PGID  SID  COMMAND
	     949   947   949  949  sh
	    1774   949   949  949  ps
	ps的父进程(ppid)是shell(sh),shell和ps在同一个session中，以及同一个前台进程组中(949).

	有一些平台的ps命令支持一些特殊的选项，例如打印session的controlling terinal相关联的进程组id。这个值会在TPGID列的下方显示。可是，不同版本的unix系统中ps命令的输出可能有所不同。例如，solaris9不支持这个选项，在FreeBSD5.2.1和MacOsX10.3中,如下命令：
	    ps -o pid,ppid,pgid,sess,tpgid,command
	以及在Linux2.4.22中，如下命令：
	    ps -o pid,ppid,pgrp,session,tpgid,comm
	会打印出我们想要的信息。

	有一点需要注意的地方就是，把一个进程和terminal 进程组ID(即TPGID列)相互关联是有一点误导人的。 一个进程并没有终端进程控制组，一个进程属于某个进程组，而这个进程组又属于某个session，这个session可能有控制终端(controlling terminal)，也可能没有。如果session有控制终端，那么终端设备会知道前台进程的进程组ID.这个值可以使用tcsetpgrp函数在终端驱动中被杯设置,我们在前面的图中有对这一点的描述。前台进程组的ID是终端的一个属性，而不是进程的属性。终端设备驱动中获取的这个值就是ps打印的TPGID.如果一个session没有控制终端，那么ps会把这个值打印为1。

	如果我们如下在后台执行这个命令：
		ps -o pid,ppid,pgid,sid,comm &
	输出如下：
	        PID  PPID  PGID  SID COMMAND
	        949   947   949  949 sh
	       1812   949   949  949 ps
	这里，唯一改变的是进程PID.shell不知道作业控制，所以后台作业不会被放到它自己的进程组中，控制终端也不会被从后台作业中拿出。

	下面我们看看管道方式执行的情况：
	   ps -o pid,ppid,pgid,sid,comm | cat1
	输出如下：
	    PID  PPID  PGID  SID COMMAND
	    949   947   949  949 sh
	   1823   949   949  949 cat1
	   1824  1823   949  949 ps
	需要注意的是：管道中的最后一个进程是shell的子进程，管道中第一个进程是其中最后一个进程的子进程。这个现象看起来好象是这样的：shell调用fork得到一个它自己的拷贝，然后这个拷贝再调用fork执行管道中其它前面的进程。

	如果我们在后台执行管道，如下：
	   ps -o pid,ppid,pgid,sid,comm | cat1 &
	那么输出性质不变，变化的仅仅是一些pid。由于shell不处理作业控制，这样输出的后台进程组id和session进程组id都是949。

	如果一个后台进程尝试从它的控制终端读取输入会怎样？例子如下：
	   cat > temp.foo &
	如果有作业控制，那么会把后台作业放到后台进程组中。这样如果后台作业尝试从控制终端读取的时候，会导致产生SIGTTIN信号。如果没有作业控制的处理，而且进程没有重定向它自己的标准输入，那么shell会自动地把后台进程的标准输入重定向到/dev/null。从/dev/null读取，会读取到一个文件结束符号，这样，我们后台的cat进程会立刻读取到文件结束符号，然后正常停止。

	前面说了后台进程通过读取标准输入访问控制终端遇到的各种情况的处理。如果，一个后台进程特别地打开一个/dev/tty然后从这个控制终端读取信息会怎么样呢？实际上这依赖许多因素，但可能不是我们想要的。例如：
	   crypt < salaries | lpr &
	就是这样的。我们在后台运行这个管道，但是crypt程序打开/dev/tty,然后把改变终端字符映射（禁止回显），从设备读取，然后重置终端字符。当我们执行这个管道的时候，提示符号"Password"被crypt程序打印到终端上面来，但是我们的输入(被加密的密码)被终端shell读取，当做是一个命令的名字。我们键入到shell的下一行输入，被作为password，这样文件"salaries"就没有被正确地加密，会给打印机发送一些杂乱的信息。这里，我们有两个进程尝试同时从同一个设备读取输入，结果取决于系统。前面我们说的作业控制，就可以很好地处理处理多个进程访问一个终端的情况。

	回到我们的Bourne shell的例子上面，如果我们在管道中执行三个进程，我们可以发现进程控制被这个shell使用:
	   ps -o pid,ppid,pgid,sid,comm | cat1 | cat2
	输入如下：
	   PID  PPID  PGID  SID COMMAND
	   949   947   949  949 sh
	  1988   949   949  949 cat2
	  1989  1988   949  949 ps
	  1990  1988   949  949 cat1
	有可能你的系统上面显示的命令名称不一样，例如可能为如下:
	  PID  PPID  PGID  SID COMMAND
	  949   947   949  949 sh
	 1831   949   949  949 sh
	 1832  1831   949  949 ps
	 1833  1831   949  949 sh
	这是因为ps和shell产生了竞争条件（在shell调用exec执行cat的时候）。这时候，shell还没有完成对cat进行的exec调用的时候，ps程序就获得了将要打印的进程列表。
	这里，和前面一样，管道最后一个进程(cat2)是shell的子进程，前面的进程是cat2的子进程，cat2结束的时候会通知父进程shell。参考资料用图表示了这个过程，大概描述如下：
	a)shell(949)调用fork产生新shell(1988)
	b)shell(1988)调用fork两次产生shell(1989)(1990),然后调用exec执行了cat2(1988)
	c)shell(1989)调用exec执行了ps(1989),shell(1990)调用exec执行了cat1(1990),两者之间通过管道进行通信
	d)cat1(1990)和cat2(1988)通过管道通信，cat2(1988)结束的时候会通知父进程shell(949)结束状态。

	现在，我们看看在Linux上面的作业控制shell执行同样的命令会怎样。这里我们使用Bourne-again shell.
	   ps -o pid,ppid,pgrp,session,tpgid,comm
	输出如下：
	     PID  PPID  PGRP  SESS  TPGID COMMAND
	    2837  2818  2837  2837   5796 bash
	    *5796  2837 *5796  2837   5796 ps
	在这个例子之后，我们把前台的进程组进程号前面加一个'*'标记。我们可以看到与Bourne shell例子的不同。Bourne-again shell把前台进程放到它自己的进程组中了(5796)，ps命令是进程组的leader,也是这个进程组中唯一的一个进程。
	另外，这个进程组为前台进程组，它有控制终端。我们的登陆shell在我们执行ps的时候属于后台进程组(2837)。需要的是进程组5796和2837都属于同一会话. 本节例子中我们会发现，session不会改变。

	在后台执行这个进程：
	   ps -o pid,ppid,pgrp,session,tpgid,comm &
	输出如下：
	     PID  PPID  PGRP  SESS  TPGID COMMAND
	    *2837  2818  *2837  2837   2837 bash
	    5797  2837  5797  2837   2837 ps
	这里，ps命令也是被放到了它自己的进程组中。但是，这个时候进程组(5797)不再是前台进程组，它是一个后台进程组。TPGID的值为2837,也就是说前台进程组是我们的login shell.(从这里可以看出，TPGID是前台进程组id，它是terminal的属性，不是进程的属性)

	在一个管道中执行两个进程：
	   ps -o pid,ppid,pgrp,session,tpgid,comm | cat1
	输出如下:
	     PID  PPID  PGRP  SESS  TPGID COMMAND
	    2837  2818  2837  2837   5799 bash
	    *5799  2837  *5799  2837   5799 ps
	    *5800  2837  *5799  2837   5799 cat1
	ps和cat1两个进程属于一个新的进程组（5799),并且这个新进程组是前台进程组。我们可以看到和Bourne shell例子的不同。Bourne shell首先创建管道中最后一个进程,然后管道第一个进程是其子进程。而Bourne-again shell中，shell进程是管道中所有进程的父进程。

	如果我们在后台执行这个管道：
	   ps -o pid,ppid,pgrp,session,tpgid,comm | cat1 &
	结果类似，但是，cat1和ps被放到了同样一个后台进程组(5801)中。
	     PID  PPID  PGRP  SESS  TPGID COMMAND
	    *2837  2818  *2837  2837   2837 bash
	    5801  2837  5801  2837   2837 ps
	    5802  2837  5801  2837   2837 cat1
	需要注意shell创建进程的次序根据shell而有所不同。
	***注意，ps输出中，TPGID是前台进程组id，它是terminal的属性，不是进程的属性.

9)关于孤儿进程组
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec10.html
	我们曾经说过，一个进程如果它的父进程终止了，那么它就成为了孤儿进程，它将会被init收留。我们将会看到一个进程组也可以变成孤儿，并看看POSIX.1是如何处理这种情况的。
	想想一个进程创建一个子进程，然后这个进程终止了。尽管这个情况是非常普遍的，但是，如果一个子进程被停止了（在作业控制中），同时父进程却终止了，这时候会发生什么事情呢？子进程如何被重新开始？子进程怎样知道它是否变成了孤儿进程？在这里的一个图中，描述了这种情况：父进程创建了一个子进程，子进程被stop了，然后父进程打算退出。
	简单描述如下：login shell(2837)--(fork/exec)-->parent(6099)--(fork)-->child(6100)
	其中parent和child在一个进程组中。相应的程序源代码在参考资料中也给出了。假设程序所运行的shell支持作业控制，前面已经说过，shell会把前台的进程放到前台进程自己的进程组中(6099),shell保持自己的进程组(2837).在fork之后，子进程会继承父进程的进程组。

	*父进程父进程睡眠5秒，这样便于子进程在父进程终止之前执行。
	*子进程建立hang-up信号处理函数(SIGHUP)，这样我们就可以看到是否有SIGHUP发送给子进程了（后面讨论信号处理函数）。
	*子进程使用kill给它自己发送stop(SIGTSTP)信号,这样会将子进程stop,效果和我们使用[Ctrl]z停止前台进程一样。
	*当父进程终止的时候，子进程变成孤儿，所以子进程的父进程ID变成了1,也就使init进程的id。
	*这时候，子进程变成了一个孤儿进程组的成员。在POSIX.1定义中指出，孤儿进程组就是这样的进程组：其中所有成员的父进程要么是该组的成员，要么是不在该组的同一个会话中。换句话说，进程组只要有一个成员进程其父进程是在同一会话的不同进程组，那么这个进程组就不是孤儿进程组。如果进程组不是孤儿进程组，那么就有机会通过它不同组同一会话的一个父进程来重新启动一个进程组中停止的非孤儿进程。
	*由于在父进程结束的时候进程组变成孤儿了，POSIX.1要求给新孤儿进程组中每一个stopped了的进程发送一个hang-up信号(SIGHUP)，然后紧跟着一个conginue 信号(SIGCONT).
	*这样就会导致子进程在处理完hang-up信号之后继续执行了。默认来说hang-up信号会终止进程，所以我们这里提供了一个信号处理函数来处理相应的hang-up信号。

	当变成孤儿进程之后，我们例子中的子进程由于hang-up而继续了，这时候，如果子进程立即尝试读取的话，根据前面的描述子进程会被停止（因为子进程这时是后台进程），但是又由于子进程组孤儿，所以没有办法恢复了，所以这种情况下，POSIX.1要求读取会返回错误，错误码errno为EIO.

	10)FreeBSD的实现
	参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch09lev1sec11.html
	经过学习我们对进程，进程组，会话，控制终端的属性有了一个定的了解，如果能够了解一下它们是怎么实现的也是很不错的。我们简单地看一下在Free BSD上面的实现。参考文件给出了一个图形展示FreeBSD使用的各种数据结构以及相应的关系。
	这里我们不说图了，说一下图中几个重要的数据结构。
	总共就5个结构：session结构，tty结构，pgrp结构，proc结构，vnode结构。

	session结构包含如下成员：
	*s_count表示这个会话中进程组的数目。如果值为0那么会将此session结构释放。
	*s_leader指针指向session leader进程的proc结构。
	*s_ttyvp指针指向控制终端的vnode节点结构。
	*s_ttyp指针指向控制终端的tty结构。
	*s_sid是session ID,注意这个session ID并不是UNIX Specification中的概念。
	当setsid被调用的时候，在内核中会创建一个新的session结构，这时候，s_count被设置为1，s_leader就指向调用setsid的进程的proc结构，s_sid设置为相应的进程id,s_ttyvp和s_ttyp设置成空指针，所以这个新的session没有控制终端。

	对于tty结构，内核包含这个结构，用于终端设备和伪终端设备。
	tty结构包含的成员如下：
	*t_session指向以本terminal为控制终端的session结构（注意session结构中也有指向本tty结构的指针）。当终端失去carrier(什么是carrier???)的时候，terminal通过这个指针给session leader发送hang-up信号。
	*t_pgrp指针指向前台进程组的pgrp结构。通过这个成员，terminal driver给前台进程组发送信号。通过特殊按键产生的三个信号(interrupt,quit,suspend)就发送给了前台进程。
	*t_termios是包含了这个终端的所有特殊字符以及相关信息的结构，信息例如波特率，是否echo on或者off等。
	*t_winsize是一个winsize结构，包含了当前terminal窗口的大小，当terminal窗口大小发生变化的时候，会给前台进程发送一个SIGWINCH信号。以后会讲述如何设置和获取当前terminal的大小。
	需要注意的是，为了找到一个会话的前台进程组，内核需要从session结构开始，通过s_ttyp找到控制终端的tty结构，然后通过t_pgrp获取前台进程组的pgrp结构。

	pgrp结构包含了一个特定的进程组的一些信息,其成员有：
	*pg_id是进程组ID.
	*pg_session指针指向进程组所在session的session结构。
	*pg_members是一个指向prog结构的链表，其中的元素本进程组中的进程成员。相应地在proc结构中，有一个p_pglist结构，它是一个双向链表。指向组中下一个和上一个进程。

	proc结构包含一个单个进程所有的信息，其成员有：
	*p_pid包含进程id。
	*p_pptr是指向父进程proc结构的指针。
	*p_pgrp指针指向该进程所属的进程组的pgrp结构。
	*p_pglist是包含proc结构的双向链表，这个链表元素是和本进程同组的进程。

	最后，我们看看vnode结构。这个结构在控制终端被打开的时候分配，进程中所有/dev/tty的引用都会通过这个vnode结构。实际的i-node是v-node的一部分。

*关于信号
==========================
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec1.html
	1)信号是软中断，许多重要的程序都需要处理信号。信号提供了一种异步事件的途径：一个用户在终端键入中断按键，来停止一个程序，或者提前结束管道中的下一个程序。
	早期的unix系统提供了信号机制，但是像Version 7这样的系统提供的信号模型并不是可靠的，信号可能会丢失，也可能在执行关键代码的时候，很难关闭选择的信号。4.3BSD和SVR3改变了信号模型，提供了稳定的信号机制，Berkeley和AT&T所作的改变并不是兼容的。POSIX.1提供了标准化的可靠信号处理，我们就讨论这个。
本章开始给处了所有信号的大致描述，然后出了早期的不可靠的信号处理然后才给出正确的处理。

参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec2.html
	2)每个信号都有一个名字，信号的名字都以SIG做为前缀。例如SIGABRT信号会在进程调用abort函数的时候产生。SIGALRM信号会在alarm函数设置的时间到期的时候产生,等等。每种系统所能够支持的信号的数目各不相同，有些还会额外增加一些应用程序自定义的信号，便于扩展等等。
	信号的名称是用正整数常量（信号号）定义的，定义在头文件signal.h中。
	实现上，实际是在另外一个头文件中定义每个信号的，但是这个头文件会被signal.h包含。内核包含一个用于用户程序层的头文件，是一个不好的习惯，所以，如果应用程序和内核同时需要一样的定义，那么信息会被放在一个内核的头文件中，然后被一个用户层的头文件包含。因此，FreeBSD 5.2.1和Mac OS X 10.3再<sys/signal.h.头文件中定义了信号，Linux 2.4.22定义信号的地方是<bits/signum.h>，Solaris 9定义的地方是<sys/iso/signal_iso.h>.
	没有哪个信号的信号号码是0，后面我们将会看到kill函数使用信号号码0用做特殊目的。POSIX.1把这个信号号称作空信号。

	有许多可以产生信号的原因，
	a)用户按下特定的终端按键产生信号。在终端按下DELETE按键(或者在许多系统中的Ctrl-c),会产生SIGINT信号,通过这种方法可以停止一个跑飞的程序。(后面我们会介绍一种方法，可以把这个信号映射成为任意的终端按键。)
	b)硬件原因产生中断：除以0，非法内存引用，等等。这个原因经常会被硬件检测到，然后通知给内核，内核会产生特定的信号发送给这时候运行的进程。例如:SIGSEGV信号会在进程引用一个非法内存的时候产生。
	c)kill函数可以允许一个进程发送任意信号给其他进程或者进程组。当然这是有所限制的，我们必须是被发送信号的进程的所有者或者是超级用户。
	d)kill 命令允许我们给其它进程发送信号。这个程序只是kill函数的一个接口，经常用来终止运行在后台的跑飞的程序.
	e)软件条件也可以产生信号，这种信号一般在发生一些特殊事情的时候产生，进程需要知道这些事情发生了。这些不是硬件原因产生的（例如除以0），但是却是软件原因产生的。例如，SIGURG信号（这个信号会在带外的数据到达网络连接的时候产生）,	SIGPIPE(当一个进程向管道中写入的时候，而管道的读取端的进程结束了，这时候会产生这个信号),SIGALRM(这个信号会在进程设置的定时器到期的时候产生)。

	信号是一种典型的异步事件的例子，对于进程来说，信号可能会在任何时候发生，进程无法简单的判断一个信号是否发生了（例如通过一个变量来判断就不太可能），但是进程却需要告诉内核:"如果发生了某某信号，那么应该做什么什么"。

	当产生一个信号的时候，我们可以通知内核来做如下的三件事情之一，我们把这些称作信号的disposition或者信号关联的action.
	a.忽略信号。这个对于大多数信号是可以的，但是有两个信号一定不能被忽略：SIGKILL和SIGSTOP.这两个信号不能忽略的原因是为了给内核和超级用户提供一个可以肯定能够杀掉以及停止任何进程的手段。而且，如果我们忽略一些由于硬件错误产生的信号（例如除以0）,进程的行为将会是不可预知的。
	b.捕捉信号。为了做到这个，我们需要告诉内核在发生信号的时候，调用我们自己定义的一个函数。在我们的函数中，我们可以做我们想做的任何事情来处理产生信号的条件。例如，我们写一个命令解释器，当用户通过键盘输入中断信号的时候，会回到程序的主循环，并且结束用户运行的任何命令;如果一个SIGCHLD信号被捕捉了，这说明有一个子进程终止了，所以信号捕捉函数可以通过调用waitpid来捕获子进程的PID以及退出状态;另外再举一个例子，如果进程已经创建了临时文件，我们想要为SIGTERM信号写一个信号处理函数（termination信号是kill命令默认发送给进程的信号）来清除临时文件;我们一定要注意，SIGKILL和SIGSTOP这两个信号不能被捕捉。
	c.使用默认的动作处理。
	每一个信号有一个默认的动作，参考资料中的表中列出了这些动作，这里就不详细说明了。我们需要注意的是，大多数信号的默认行为就是终止程序。
	参考资料中的"Figure 10.1. UNIX System signals"列出了所有信号的名字，哪个系统支持哪些信号，以及产生这些信号时系统默认的动作。
	当上述发生信号时候的动作是"terminate+core"的时候，表示这个进程会在它的当前工作目录留下一份名字为"core"的文件，保存该进程的内存状态。这个文件可以被许多unix系统调试者使用，用来检查进程在退出的时候的状态。
	    UNIX Specification's XSI extension.
	core文件的生成是大多数unix系统的实现特性，尽管这个特性并不是POSIX.1的一部分，但是在Single UNIX Specification的XSI扩展中，它已经被指定，成为一个潜在的实现特性了。

	core文件的名字在不同的实现中有所不同。在FreeBSD5.2.1中，core文件被命名为cmdname.core,这里，cmdname就是接收到信号的相应进程的命令名称；在Mac OS X10.3中，core文件被命名为core.pid，这里pid就是相应接受到信号的进程PID.这些系统允许通过sysctl命令的参数来配置生成的core文件的名称。
	大多数实现都会把core文件保存在相应进程的当前工作目录；而MacOS X会把所有的core文件放在/cores中。

	core文件在如下的情况中不会生成：(a)进程有set-user-ID并且当前用户不是程序文件的拥有者。(b)进程有set-group-ID并且当前用户不是当前文件的组主。（c）用户没有向当前工作目录写的权限。（d）文件已经存在，并且用户没有写这个文件的权限。（e）文件太大了（参考本书7.11章的RLIMIT_CORE限制）。
	core文件（假设这个文件还没有存在）的权限一般是用户读写的，Mac OS X设置为用户只读。

	在图10.1中信号的描述如果是"hardware fault"的，那么就相应于实现定义的硬件错误。所有这些名称都来自原来的PDP-11的unix系统实现。可以查阅一下你的系统的main手册，来确定具体这些信号和什么类型的错误相关。

	接下来的内容对上面所有的信号进行了详细的描述。这里不再翻译。

	3)UNIX系统中最简单的一个信号相关的接口就是signal函数。
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec3.html
	#include <signal.h>
	void (*signal(int signo, void (*func)(int)))(int);
	如果成功，这个函数返回信号之前的特性，如果有错，函数返回SIG_ERR错误。
	这个信号函数由ISO C定义，它不支持进程，进程组，终端输入/输出等等特性。
	如果成功，这个函数返回信号之前的特性，如果有错，函数返回SIG_ERR错误。所以，在unix系统上面它的这个定义几乎是没有用的。
	从UNIX V系统上继承过来的实现，支持信号函数，但是它提供的是非可靠的信号。这个函数为需要旧有语法的应用程序提供向后兼容的特性。新的程序不使用这些不可靠的信号。
	4.4BSD提供signal函数，但是它以sigaction的形式定义，所以在4.4BSD使用它，提供了一个新的可靠信号的语法。FreeBSD5.2.1和Mac OS X 10.3采用了相同的策略。
	Solaris 9源于System V和BSD,但是它采用System V的signal语义。
	Linux 2.4.22系统中，signal的语义可以采用BSD或者System V的，这取决与C库的版本，以及你如何编译你的应用程序。
	因为不同实现的signal的语义有所不同，所以最好使用sigaction函数。我们后面描述sigaction函数的时候，将会提供一个使用sigaction实现的signal.本文所有的例子都使用后面的Figure10.18中的signal函数。
	Figure 10.18的地址在：
	http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec14.html#ch10fig18
	参数signo就是信号号，在前面提到过。参数func的值可以是SIG_IGN，SIG_DFL或者产生信号时候将要调用的函数的地址;如果我们指定了SIG_IGN,那么就告诉了系统，来忽略这个信号（注意SIGKILL和SIGSTOP不能被忽略）;当我们指定了SIG_DFL的时候，就告诉了系统发生信号的时候采取默认的动作;当我们指定一个函数地址的时候，函数会在发生信号的时候被调用，这个函数就是我们指定的信号处理函数。
	从signal的原型可以看出，这个函数需要两个参数并且返回一个void类型的函数指针(指向的函数有一个int参数)。signal函数的第一个参数signo是一个整数，第二个参数是一个指针，它指向void类型的需要一个整数参数的函数。当我们调用signal建立信号处理的时候，用第二个参数指定处理信号的函数，并且返回上次的信号处理函数。
	有许多系统使用额外的独立于实现的参数调用信号处理函数,我们后面会讨论到这个问题的。
	如果我们检查系统头文件<signal.h>我们可能会发现如下的声明:
	#define SIG_ERR (void (*)())-1
	#define SIG_DFL (void (*)())0
	#define SIG_IGN (void (*)())1
	这些常量可以用来替换signal中的第二个参数以及相应的返回值部分。这三个值不一定必须是-1,0,和1,他们必须不能为任何已经声明的函数的地址。大多数Unix系统上面使用的就是这个值。

	举例：
	我们用一个简单的例子，运行的时候如下：
	$ ./a.out &                   从后台启动这个进程。
	[1]      7216
	$ kill -USR1 7216             给它发送信号SIGUSR1
	received SIGUSR1
	$ kill -USR2 7216             给它发送信号SIGUSR2
	received SIGUSR2
	$ kill 7216                   给它发送信号SIGTERM
	[1]+  Terminated    ./a.out
	上面，我们使用kill命令给这个进程发送信号，也可以使用kill函数给进程发送信号。kill这个名字有点误导人，它的意思不是杀掉进程的意思，它就是用来发送信号用的。
	这个程序的源代码如下所示：
	static void sig_usr(int signo)
	{
	    if (signo == SIGUSR1)
	        printf("received SIGUSR1\n");
	    else if (signo == SIGUSR2)
	        printf("received SIGUSR2\n");
	    else
	        err_dump("received signal %d\n", signo);
	}
	int
	main(void)
	{
	    if (signal(SIGUSR1, sig_usr) == SIG_ERR)
	        err_sys("can't catch SIGUSR1");
	    if (signal(SIGUSR2, sig_usr) == SIG_ERR)
	        err_sys("can't catch SIGUSR2");
	    for ( ; ; )
	        pause();
	}

	关于程序的启动：
	当一个程序执行的时候，所有信号的状态要么是默认，要么是忽略。一般来说，除非调用exec的进程忽略这个信号，否则所有的信号都会被设置为它们默认的行为。特别地，exec函数会改变任何信号的属性（处理函数）为它们默认的属性，并且保留其他状态。（这一点很自然，因为一个进程调用了exec之后，在新的程序收到信号，这是后原来的程序中的信号处理函数的地址在新的进程的地址空间中没有任何意义，所以就不应该再捕获原来的那个函数的地址空间了）。
	一个特例就是，交互的shell如何处理后台进程的interrupt和quit信号。
	如果一个shell不支持作业控制，那么当我们后台执行如下进程：
	    cc main.c &
	shell会自动将interrupt和quit信号的属性设置成为忽略。这样如果我们键入interrupt字符，它不会影响到后台进程。如果不是这样（即设置为忽略），那么当我们键入interrupt字符的时候，它不仅会终止前台的进程，后台的所有进程也都被终止了。
	许多交互程序使用如下代码来捕获这两个信号：
	void sig_int(int), sig_quit(int);
	if (signal(SIGINT, SIG_IGN) != SIG_IGN)
		signal(SIGINT, sig_int);
	if (signal(SIGQUIT, SIG_IGN) != SIG_IGN)
		signal(SIGQUIT, sig_quit);
	这样，进程只有在当前信号不是被忽略的时候，才会捕捉信号。
	这样做了之后，进程只有在当前信号不会被忽略的情况下才会去捕捉信号。
	(具体点解释，假设进程在后台运行，原本交互shell是要忽略后台进程的这两个信号的，如果直接就这样设置，那么之前shell的忽略就无效了，所以设置之前要检查看是否这两个信号之前是需要被忽略的，如果是那么就不设置了，否则才设置)
	这两个signal调用也展示了signal函数的一个局限：我们不能够在不改变当前信号属性的前提下确定当前的信号属性(即要想获得当前属性，需要先调用signal,通过signal函数返回值，返回当前的属性,也就是新设置之前的属性)。后面我们将会看到，sigaction函数会允许我们在不改变信号属性的前提下来确定信号属性。
	进程创建:
	当一个进程调用fork的时候，子进程会继承父进程的信号属性。这里，由于子进程启动的时候就是父进程内存的拷贝，所以信号捕捉函数的地址空间对于子进程来说也是有同样的意义的。

	4)不可靠的信号
参考： http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec4.html
	在早期的unix版本中，信号是不可靠的，也就是说，信号是容易丢失的(信号发生了，但是进程却不知道信号已经发生了);同时，进程对信号的控制也是有限的，进程只能获取或者忽略一个信号. 有时候我们需要告诉内核来阻塞一个信号，也就是说，产生信号的时候不忽略这个信号而是记住这个信号，当我们准备好了之后再告诉我们。
	在4.2BSD的时候，做了一些改变提供了可靠的信号机制,在SVR3的时候，有一套不同的改变的机制为SystemV实现可靠的信号机制，POSIX.1把BSD的模式作为了标准模式。
	早期的问题是，每当信号发生的时候，信号对应的动作会被重置为它的默认值.(在前面的例子中，当我们运行程序的时候,我们忽略了这个问题，只对信号捕捉一次)，一般来说经典书籍里面早期系统中处理信号中断的代码大致如下：
	     int     sig_int();        /* 自定义的信号处理函数 */
	     ...
	     signal(SIGINT, sig_int);  /* 建立信号处理函数和信号之间的联系 */
	     ...
	     sig_int()
	     {
	         signal(SIGINT, sig_int);  /* 再次建立处理函数和信号之间的联系 */
	         ...                       /* 处理信号 ... */
	     }
	(这里，信号处理函数返回int类型的原因是早期的系统不支持ISO C的void类型.)
	前面的代码片段的一个问题是，有一个时间窗口,它发生在信号产生的时候之后，信号处理函数时候调用signal再次建立信号处理函数连接之前;期间可能会再次发生一次信号。这第二次发生信号的时候，信号处理的函数已经被重置为默认的了，还没有来的及设置就被执行了（导致进程终止）。大多数时候，代码都能正常的工作，但是如果有这样的情况，我们就需要仔细考虑考虑了。

	另外一个问题就是，早期的系统进程，当它不想信号发生的时候，不能将一个信号“关闭”。所有进程只能忽略这个信号，有时后，我们想要告诉系统“阻止这些信号发生，但是当它们发生的时候把它们记住”。描述这个缺陷的典型的例子（捕获这个信号，然后为进程设置一个标记表明这个信号发生过）:
	      int     sig_int_flag;         /* 当信号发生的时候将这里设置为非0 */

	      main()
	      {
	          int      sig_int();       /* 自定义的信号处理函数 */
	          ...
	          signal(SIGINT, sig_int);  /* 建立信号和处理函数之间的联系 */
	          ...
	          while (sig_int_flag == 0)
	              pause();              /* 暂停，等待信号发生就进入下一次循环 */
	          ...
	      }

	      sig_int()
	      {
	          signal(SIGINT, sig_int);  /* 再次建立处理函数和信号之间的联系 */
	          sig_int_flag = 1;         /* 设置main函数中的循环检测的标记 */
	      }
	这里的例子，进程调用pause函数进入睡眠等待一直到捕捉了一个信号。当信号被捕捉的时候，信号处理函数会设置sig_int_flag为非0。这个进程在信号处理函数返回的时候，自动地被内核唤醒，然后会注意到标记变成了非0，然后做相应的处理。但是，存在一个可以导致问题的时间窗口：如果信号发生在检测sig_int_flag之后但是调用pause之前，那么进程就可能永远睡眠不会醒过来了（前提假设是信号不会再次发生了）.这样，信号就丢失了，这就是另外一个问题。尽管这个问题发生的可能性很小，但是如果它发生了，那么就很难调试。

	5)被中断的系统调用：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec5.html
	早期Unix系统的一个特性是当一个进程被阻塞在一个很慢的系统调用的时候捕捉到一个信号,这时候，这个系统调用就会被中断了。系统调用会返回一个错误，错误号码是EINTR,这个在发生信号并且进程捕捉到这个信号的时候就会发生,当进程被阻塞在系统调用的时候，这可以用来唤醒进程。
	这里，我们一定要区分系统调用和一个函数之间的区别。这是内核中的系统调用在捕获信号的时候被打断了。
	系统把系统调用区分为两类以支持这个特性：“慢”系统调用，以及其他的系统调用。慢系统调用是可以被永远阻塞的系统调用,比如说：
	*如果特定文件(管道，终端驱动，网络设备)的数据不存在，可以导致调用者永久阻塞的读取操作。
	*如果向相应的特定文件写数据不能被立即接受，可导致调用者永久阻塞的操作。
	*打开特殊文件需要特殊条件导致的阻塞。（例如打开终端设备等待连接的modem应答的情况）
	*pause函数（这个函数将调用进程睡眠，直到捕获到了一个信号）和wait函数。
	*特定的ioctl操作。
	*一些内部进程的通信函数。
	这些慢系统调用中一个例外是和磁盘相关的I/O操作。尽管对磁盘文件的读写操作可以临时阻塞一个调用者(磁盘驱动中会将请求排队，然后依次执行这些请求),除非出现硬件错误，I/O操作一般都会很快地返回，并且取消对调用者的阻塞。

	一个被打断的系统调用的情况就是当用户从终端处初始化了读取的操作，然后终端前的用户离开了很长时间，这样进程将被阻塞好久，直到系统挂掉。
	POSIX.1的2001标准版本改变了被打断的读／写操作的语义。早期的版本实现，处理只传输了一部分的读写操作的方式有不同的选择。如果读取操作将数据接收到应用程序的缓存，但是并没有将所有请求的数据接收就被打断了，那么操作系统可以让这次的read系统调用失败，然后设置errno为EINTR或者允许这次系统调用成功，然后返回被传输的那部分数据。类似地，如果write操作也是在传输了一部分数据的时候被打断了，那么操作系统也可以让write有类似地两种返回的情况。以前，继承自System V的系统会让系统调用失败，然而继承自BSD的系统，会让返回部分的数据。在2001版本的POSIX.1标准中，BSD类型的系统的语义被采用了。
	一个被打断的系统调用的问题就是我们需要显示地处理返回的错误状态,一个典型的代码序列如下(假设有一个读取操作并且我们就算在它被打断的时候也想要重新启动这个读取操作)：

	again:
	if ((n = read(fd, buf, BUFFSIZE)) < 0)
	{
		if (errno == EINTR)
			goto again;     /* just an interrupted system call */
		/* handle other errors */
	}

	为了防止应用程序处理被打断的系统调用，4.2BSD对一些特定的被打断的系统调用引入了一个自动启动的机制。可以自动启动的系统调用有ioctl,read,readv,write,writev,wait,waitpid.前5个操作只有在操作一个比较慢的设备的时候，才会被信号打断;wait和waitpid在捕获信号的时候就会被打断。由于这个可能会导致应用程序的一些问题，有的应用程序并不是想要那个操作在被打断的时候重启动，4.3BSD允许进程在信号的地方来禁止这个特性。

	POSIX.1允许执行重新启动系统调用，但是这个不是需要的。Single UNIX Specification为sigaction定义了一个SA_RESTART标记作为XSI扩展，允许应用程序请求那个系统调用被重新启动。
	默认来说System V不会重新启动系统调用。而BSD如果被信号打断的时候，会重新启动他们。默认来说FreeBSD 5.2.1, Linux 2.4.22, 和 Mac OS X 10.3会重新启动被信号打断的系统调用。然而，Solaris9 会返回error为(EINTR).

	4.2BSD引入自动启动系统调用这个特性的一个原因就是，有时候，我们不知道输入输出设备是一个慢速设备。如果我们写的程序可以被用来交互，那么它可能在读写一个慢速的设备，终端就是这个类型。如果我们在这个程序中捕获信号，并且系统不提供重新启动系统调用的能力，那么我们就得在每次读写的时候测试中断错误，或者返回并且重新进行读写操作。

	参考资料中的一个表格中给出了各种系统实现的和signal相关的函数以及它们的含义。

	我们没有讨论旧的sigset和sigvec函数。他们的作用已经sigaction替换了；包含它们只是为了完整。相反，有些实现提倡使用signal函数作为简化的sigaction接口。

	需要注意的是其他的UNIX系统，可能会和表中的有所不同。例如，在SunOS 4.1.2的sigaction默认会重新启动被中断的系统调用，这和上面表中列出的是不一样的。

	在图10.18中，我们提供了自己的signal函数，这个函数尝试自动重新启动被打断的系统调用（除了SIGALRM信号）。后面我们会提供另外的函数signal_intr这个函数就从来不会尝试重新启动。

	我们会在后面涉及到select和poll函数的时候讨论更多关于被打断的系统调用。

	6)可重入函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec6.html
	进程捕捉到信号时，进程正常执行的指令次序会被信号处理打断。进程会继续执行，但是这时候执行的是信号处理函数中的指令。如果信号处理函数返回（不是调用exit或者调用longjmp等方式返回的），那么在捕捉到信号之前的普通的指令会依次执行（这一点和硬中断发生的情况类似）。但是，在信号处理函数中，我们无法判断当捕捉到信号的时候进程执行到了哪里。如果进程正在调用malloc分配内存的过程中被信号打断，并且在信号处理函数中还调用malloc分配内存，这时候会怎样?如果进程正在执行一个函数的过程中，例如getpwnam函数，这个函数使用了局部静态了变量存储它运行的结果，然后我们在信号处理函数中调用了相同的函数，这时候会怎么样？在malloc的例子中，进程会发生很严重的错误；这是因为，malloc通常会维护一个链表，这个链表存放它分配的区域，很可能在它修改这个链表的时候捕捉到信号并且在信号处理函数中又调用malloc函数，这样修改链表的操作就被打乱了。在getpwnam的例子中，由于getpwnam每次调用都有一个不同的结果，并且把结果返回到一个局部的静态变量中，所以在捕捉到信号并且信号处理的时候调用了getpwnam的时候，很可能捕捉信号之前的getpwnam的结果被后来的getpwnam覆盖，这样先前的getpwnam的结果就是错误的了。
	Single UNIX Specification指定了哪些函数是可重入的函数，在参考资料中也以表格的方式列出了这些函数(这里就省略了)。

	有许多函数没有在列出的函数之内，那是因为：(a)它们使用了静态数据结构 (b)它们调用了malloc或free (c)它们是标准I/O库的一部分。大多数标准I/O库实现的时候，都采用一种不可重入的方式，来访问一个全局的数据结构。我们还需注意的是，尽管我们的一些例子在信号处理的时候，使用了printf函数，但是这并不保证会产生正确的输出结果，因为可能产生信号的时候，正是我们的主程序运行printf函数的时候。

	(在这里补充一下关于可重入的概念:可重入函数可以被一个以上的任务调用，而不必担心数据被破坏,它在任何时候都可以被中断，一段时间后又可以运行，而应用数据不会丢失.满足条件是：不使用共享资源；在使用共享资源时关中断，使用完毕后再开中断;在使用共享资源时申请信号量，使用完后释放信号量.例如:含静态局部变量的函数是非可重入的).

	还有一个需要注意的地方是，尽管我们在信号处理函数中调用的是列出的那些个可重入的函数，但是不要忘记在每个线程中只有一个errno变量，我们可能会把这个errno变量的值改变了。比如说，我们的main函数中由于某些原因导致设置了errno,之后就产生了信号，导致执行信号处理函数；如果这个信号处理函数调用了read，那么可能就会修改errno变量的值，从而覆盖main函数中的errno的值。因此，一般来说，我们在信号处理函数中调用前面列出的“可重入”函数的时候，要确保能够保存和恢复errno的值。（需要注意，一个比较经常发生的信号是SIGCHLD信号，这个信号的处理函数中，经常调用各种wait函数，所有的wait函数都会修改errno的值！）.

	需要注意的是longjmp函数和siglongjmp函数也没有列在“可重入”函数的里面。因为，可能在main函数正在以不可重入方式修改一个数据结构，有可能在信号处理函数中调用siglongjmp的时候这个数据结构正处于被修改了一半的状态。如果修改的数据结构是一个全局的数据结构，那么，如果捕获一个导致sigsetjmp被调用的信号的时候，这个应用程序应该在修改这个数据结构的时候阻塞那个信号。

	参考资料中有一个例子，这里只给出关键的部分：
	static void my_alarm(int signo)
	{
	    struct passwd   *rootptr;
		...
		rootptr = getpwnam("root");
		...
	    alarm(1);
	}
	int main(void)
	{
	    struct passwd   *ptr;
	    signal(SIGALRM, my_alarm);
	    alarm(1);
	    for ( ; ; ) {
			...
			ptr = getpwnam("sar");
			...
			strcmp(ptr->pw_name, "sar");
			...
	    }
	}
	这里例子主要说，在信号处理函数my_alarm中，以及main中都调用了getpwnam，由于getpwnam是不可重入的，所以在my_alarm中调用这个函数，就可能导致各种问题,出现的问题或者是结果很不正确，或者是提示free了没有malloc的数据，或者是正确的结果等等，这里省略详细解释，具体参见参考资料。

	7)SIGCLD的含义.
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec7.html
	有两个很容易导致混淆的信号是SIGCLD和SIGCHLD.首先，SIGCLD是System V下的名字，这个信号和BSD下面的SIGCHLD(多一个H)含义是不同的。POSIX.1中的相应信号也命名为SIGCHLD.

	BSD中的SIGCHLD信号含义比较普通。它的含义和其他的信号的含义类似。当信号发生的时候，子进程的状态已经变化了,我们需要调用wait函数来确定究竟发生了什么事情。
	然而SystemV处理SIGCLD的传统方式一般和其他的信号有点不同。如果我们使用signal或者sigset(早期SVR3兼容的设置信号特性的函数)设置信号的处理特性,基于SVR4的系统继续这个有争议的传统（在兼容性上面有所争议）。旧的SIGCLD处理如下：
	a)如果进程设置它(指的是信号SIGCLD)的特性为SIG_IGN，那么那么调用进程的子进程将不会产生僵尸进程（僵尸进程指,该进程terminate了，但是它的父进程没有wait它）。注意，这一点和默认动作(SIG_DFL)不同,在最前面说过它的默认动作虽然描述为“被忽略”，但是在终止的时候，这些子进程的状态已经被丢弃了。如果接下来调用wait函数的话，调用进程将会阻塞直到所有子进程终止，然后wait返回1并且设置errno为ECHILD（默认的信号处理特性是忽略，但是这个默认的忽略并没有像前面的SIG_IGN那个忽略的含义，所以，我们需要特别地把信号的处理特性设置为SIG_IGN）。
	*POSIX.1没有特别指定如果SIGCHLD被忽略的时候会发生什么，所以这个行为是被允许的。Single UNIX Specification包含了XSI扩展，来指定为SIGCHLD支持这个行为。
	*4.4BSD在SIGCHLD被忽略的时候，一直会产生僵尸进程。如果我们想要避免僵尸进程，我们需要等待子进程。FreeBSD 5.2.1工作方式类似4.4BSD. Mac OS X 10.3在SIGCHLD被忽略的时候就不会创建僵尸进程。
	*对于SVR4,如果signal或者sigset被调用来设置SIGCHLD的处理特性为忽略，那么就不会产生僵尸进程。Solaris 9和Linux 2.4.22在行为上和SVR4类似.使用sigaction,我们可以设置SA_NOCLDWAIT标记来避免僵尸进程。这个行为在本文中所有的四个平台：FreeBSD 5.2.1, Linux 2.4.22, Mac OS X 10.3, 和Solaris 9上面都支持。
	b)如果我们设置SIGCLD进程的特性为捕获它,内核会立即检查是否有子进程需要被等待,如果有，那么就调用捕获SIGCLD对应的处理函数。
	上面的b)条目使得我们为这个信号编写信号处理函数的时候，方式有些不同了，如下面的例子中会进行说明。

	举例
	从前面的例子中我们看到，我们进入到信号处理函数中需要做的第一件事情，就是调用signal来重新建立信号处理函数得连接。（这个动作会减少信号被重置然后又重新连接这个期间的时间窗，减小了信号丢失的机率）我们在后面的例子中将会看到，这个程序在一些个平台上面将不能工作。如果我们编译这个程序，然后在传统的System V上面运行（例如OpenServer 5或者UnixWare 7),那么输出结果将会是许多收到SIGCLD信号的提示。最终程序会由于栈空间不足而异常终止。
	*FreeBSD 5.2.1和Mac OS X不会展示这样的问题，因为基于BSD的系统，不支持以前的System V的SIGCLD信号的语义。Linux 2.4.22也不会出现这样的问题，因为它在进程准备捕捉SIGCHLD以及子进程准备被等待的时候不会调用SIGCHLD的信号处理函数(尽管SIGCLD和SIGCHLD的值被定义成一样的)。Solaris 9却会调用信号处理函数，但是它在内核中包含一些额外的代码，避免了这个问题。尽管本文中的四个平台都解决了这个问题，但是应该注意，并不是所有已有的平台都解决了这个问题。
	这个程序中的问题是，在信号处理函数最开始的signal调用，会导致前面的b)现象,内核检查子进程是否需要被等待（这里当然是需要了，因为我们正在处理SIGCLD信号），所以它会又产生一个信号处理函数的调用。这个信号处理函数调用signal，然后整个进程又开始了。
	为了修正这个问题，我们需要把signal调用放在wait调用的后面。这样，我们再获得子进程的结束状态之后才调用signal重新建立信号的连接；这样只有其他子进程结束的时候信号才会再次发生(而当前处理的子进程产生的信号处理函数中已经在设置再次捕获信号之前，先把当前子进程的状态获得了)。
	POSIX.1指出，当我们为SIGCHLD建立一个信号处理函数的时候，如果有一个我们没有wait的已经终止的子进程，这时候并没有规定是否会产生信号。这就允许前面说到的行为了（什么行为？）。但是，POSIX.1没有在信号发生的时候将信号的特性重新设置为它的默认值（假定我们使用POSIX.1的sigaction来设置信号的特性），我们无须在信号处理函数中重新为SIGCHLD建立信号处理函数的连接。
	实例代码片断如下：
	static void sig_cld(int signo)   /*会唤醒pause()*/
	{
	    pid_t   pid;
	    int     status;
	    printf("SIGCLD received\n");
	    if (signal(SIGCLD, sig_cld) == SIG_ERR) /*重新建立信号的连接*/
	        perror("signal error");
	    if ((pid = wait(&status)) < 0)      /*获取子进程状态*/
	        perror("wait error");
	    printf("pid = %d\n", pid);
	}

	int main()
	{
	    pid_t   pid;
	    if (signal(SIGCLD, sig_cld) == SIG_ERR)
	        perror("signal error");
	    if ((pid = fork()) < 0) {
	        perror("fork error");
	    } else if (pid == 0) {      /*子进程*/
	        sleep(2);
	        _exit(0);
	    }
	    pause();    /*父进程*/
	    exit(0);
	}

	一定要认识到你的机器上面的SIGCHLD的含义。尤其要注意在有些系统上面会定义"#define SIGCHLD SIGCLD"或者相反。这样把名字改变之后，你可以编译其他系统的程序，但是如果那个程序依赖别的含义，那么有可能就无法工作了。
	在本文中的四个平台上面，SIGCLD的含义和SIGCHLD是一样的。

	8）可靠的信号技术，以及相应的语义
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec8.html
	在我们讨论信号的时候，需要知道一些事情:首先，当导致信号的事件发生的时候，就会给进程产生相应的信号(或者信号发送给进程)，这个事件可能是硬件错误（例如：除以0）,软件错误(例如时钟信号)，终端发起的信号，或者是使用kill发起的信号.当产生信号的时候，内核经常会给进程的进程表设置一个标记。
	当调用了信号相应的动作，我们就说信号已经被发送(deliverd)给进程了。在产生信号(generate)和发送信号(delivered)之间的时间,被称作信号的提交(pending)。
	进程可以阻塞发送给它的信号.如果发送给一个进程的信号被阻塞了,并且这个信号的处理动作是默认的动作或者捕获信号，那么这个进程的信号会保持提交的状态，直到发生如下：a)将信号的阻塞取消 b)改变信号的处理动作以忽略信号.系统在信号被发送的时候而不是产生的时候来确定对一个阻塞的信号做什么。这样，进程可以在信号被发送给它之前，改变信号处理动作的行为。进程可以调用函数sigpending来决定哪些信号被阻塞或者提交。
	如果被阻塞的信号在进程取消对它的阻塞之前发生了多次会怎么样？POSIX.1允许系统给进程提交多次信号.如果系统发送信号的次数超过了一次，我们就说那个信号被排队了。然而许多unix系统不支持信号的排队，除非它们POSIX.1的实时扩展。UNIX系统内核只支持信号被发送给进程一次。
	SVR2的man手册说SIGCLD信号在进程处理它的处理函数的时候会被排队。虽然这个在概念上面是正确的，但是实际的实现上面却不是这样的。相反，信号会被内核重新产生，就像我们在前面说的那样。在SVR3中，man手册修改了，并且示意SIGCLD信号在进程处理它的处理函数的时候被忽略。SVR4手册把进程处理SIGCLD处理函数时候，又产生SIGCLD究竟会发生什么的相关内容删除了。在AT&T的SVR4的sigaction的man手册中声明SA_SIGINFO导致信号排队的时候是可靠的。这个是错误的！很明显，这个特性是内核中实现的特性，但是它并没有在SVR4中被启用。很奇怪的是，SVID没有阐述相同的可靠排队的内容。
	当不止一个信号要被发送给一个进程的时候会发生什么?POSIX.1没有指定发送给进程的信号的次序,但是POSIX.1提供了一个建议：那就是和进程当前状态相关的信号，先于其他信号被发送给进程（SIGSEGV就是这样的信号）。
	每个进程都有一个signal mask，它定义了当前被阻塞发送给进程的信号的集合。我们可以认为这个mask的每一个位代表一个信号，如果某个信号的对应的位被打开了，那么这个信号当前就会被阻塞。一个进程可以通过调用sigprocmask检查和改变它当前的signal mask，我们后面有说明。
	因为信号的数目可能会超过整数的位数，所以POSIX.1定义了数据类型sigset_t来保存一个信号集合，用这个数据结构保存信号的集合。例如signal mask就存放在这些集合中的其中一个。我们后面会描述5个操作信号集合的函数。

	9）kill和raise函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec9.html
	kill用来给一个进程或者一组进程发送信号，raise函数允许进程给它自己发送信号。
	raise原来是由ISO C定义的.POSIX.1把它包含进来，并且让它自己(指的谁？)符合ISO C的标准，但是POSIX.1扩展了raise让它可以支持多线程情况(后面我们会讨论多线程下面如何进行信号的交互)。因为ISO C不能处理多进程，所以它不能定义像kill这样需要一个进程ID参数这样的函数。
	#include <signal.h>
	int kill(pid_t pid, int signo);
	int raise(int signo);
	两个函数在成功的时候返回0，在错误的时候返回1.
	调用raise(signo);等价于kill(getpid(),signo);

	对于kill的参数，有以下四种不同的情况：
	a)pid > 0 表示信号发送给进程ID值为pid的进程。
	b)pid == 0 表示信号发送给所有进程组ID和发送者进程组ID一样的，并且当前发送进程有相应权限发送的所有的进程。注意，这里提到的“ 所有的进程”指的是排除了基于系统实现定义的系统进程。对于大多数UNIX系统，这样的系统进程几何包括内核进程init(它的pid为1).
	c)pid < 0 信号发送给所有进程组id等于pid的绝对值的，并且当前发送进程有相应权限发送的所有的进程。这里提到的“ 所有的进程”也排除了基于系统实现定义的系统进程。
	pid == 1  信号发送给系统中sender有相应权限发送的所有的进程。同样，这里提到的“ 所有的进程”也排除了基于系统实现定义的系统进程。

	如前所述，一个进程发送信号给另外一个进程，需要一定的权限。超级用户可以发送信号给任何进程，对于其他用户，一个基本得原则就是，发送进程的real或者effective用户ID 与接收进程的real或者effective用户ID一样;如果实现支持_POSIX_SAVED_IDS(现在POSIX.1要求这样)，那么就会把检测effective用户ID的部分替换成检测saved set-user-ID的部分。当然，对于权限检测这里也有例外的情况：如果被发送的信号是SIGCONT，那么进程可以把它发送给任何与它在同一个会话中的其他进程。

	POSIX.1把信号号0做为空信号。如果signo参数是0，那么kill只进程普通的错误检测，并不会发送信号。这个经常用来决定一个指定的进程是否存在。如果我们给进程发送一个空的信号，但是这个进程不存在，那么kill会返回1，然后把errno设置为ESRCH。然而，我们需要注意UNIX系统会在一定的时间之后回收进程ID，所以一个给定进程ID的存在的进程，并不一定就是你所想像的那个进程。

	还需要知道的是，这个测试进程存在的方法不是原子的。当kill给调用这返回答案的时候，那个进程可能已经退出了，所以返回值是受限制的。

	如果调用kill导致给调用者产生了信号，而且这个信号不是被阻塞的，（无论是信号号还是其他的提交），没有被阻塞的信号教会在kill返回之前发送给进程（在线程中会有其他的情况，后面会提到）

	10）alarm和pause函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec10.html
	alarm函数允许我们设置一个计时器，这个计时器可以在一个指定的时间内到期。当计时器到期的时候，SIGALRM信号就会产生。如果我们忽略或者不捕获这个信号，那么这个信号的默认处理动作就是把进程结束。
	#include <unistd.h>
	unsigned int alarm(unsigned int seconds);
	返回0或者返回前面设置的alarm的剩余到期秒。
	秒值是信号将要发生的时钟的秒值。需要注意的是，如果时间到了，那么内核中发送信号，但是在进程真正处理这个信号之前，还会有一点延迟，这是处理器调度产生的延时。
	早期的UNIX系统实现，会警告信号信号早一秒发送。POSIX.1不允许这样。
	每一个进程只有一个这样的时钟。如果我们调用alarm，同时之前注册的alarm时钟没有到期，那么剩下的秒会被做为alarm函数的返回值，然后之前的注册的alarm始终被新的所替代。
	如果进程之前注册的alarm时钟没有到期，并且alarm的seconds参数是0，那么之前的alarm时钟会被取消，同时返回之前时钟距到期剩余的秒数。

	虽然SIGALRM信号的默认动作是终止进程，大多数进程使用alarm时钟来捕获信号。如果进程想要终止，那么它可以在终止之前进行需要的清理工作。如果我们想要捕获SIGALRM信号，我们需要注意在调用alarm之前来安装它的信号处理函数。因为如果我们先调用alarm，然后再我们安装信号处理函数之前发送SIGALRM信号了，那么我们的进程将会被终止。

	pause函数会挂起调用它的进程，直到发起了一个信号。
	#include <unistd.h>
	int pause(void);
	返回1，同时设置errno为EINTR.
	pause只能在信号处理函数被执行并且返回的时候才能返回。这个时候，pause返回的是1，同时设置errno为EINTR.

	举例：
	我们可以使用pause和alarm让进程sleep指定的时间.后面的sleep1函数就是这个样子的。
	#include     <signal.h>
	#include     <unistd.h>
	static void sig_alrm(int signo)
	{ /* 什么也不做，只是返回并唤醒pause调用 */}

	unsigned int sleep1(unsigned int nsecs)
	{
	    if (signal(SIGALRM, sig_alrm) == SIG_ERR)
	        return(nsecs);
	    alarm(nsecs);       /* 启动定时器 */
	    pause();            /* 暂停等待下一个信号来唤醒它 */
	    return(alarm(0));   /* 关闭计时器同时返回睡眠剩余的时间 */
	}

	这个函数的功能和sleep大体相当，但是这个简单的实现有以下三个问题：
	a)这里的alarm可能会把以前的alarm设置的时钟给覆盖掉。为了修正这个问题，我们可以查看alarm的返回值：如果返回值小于我们的参数，那么我们只需等待那个alarm时钟到期就行了（为什么？）。如果返回值大于我们的参数，那么在返回之前我们应该重新设置alarm时钟在那个时间发生信号(不太明白？)
	b)我们修改了SIGALRM的动作.如果我们写一个让别人调用的函数，我们应该在被调用的时候保存原来的处理动作，然后在我们返回的时候恢复原来的处理动作。
	c)在alarm调用和pause调用之间有一个竞争条件。对于一个比较忙的系统，可能在我们调用pause之前就发生了alarm信号并且这个信号处理函数已经被调用了。如果这样的话之后我们再调用pause这个pause就永远不会再醒来了（假设期间不会再有其他的信号发生）。
	早期实现的sleep和我们这里给处的类似，同时它修正了以上描述的前两个问题，对于第三个问题，有两种解决的方法：第一个方法是使用setjmp我们后面会看到这个，另外一个方法是使用sigprocmask和sigsuspend我们在后面会提到这个。

	SVR2使用setjmp和longjmp来避免描述前面例子中存在的第三个问题.实现的函数这里是sleep2,后面给出(为了减少例子的代码量，这里我们没有处理第一、二个问题)。
	#include   <setjmp.h>
	#include   <signal.h>
	#include   <unistd.h>
	static jmp_buf  env_alrm;
	static void sig_alrm(int signo)
	{
	    longjmp(env_alrm, 1); /*通过这个跳转就不用担心pause无法返回了，因为一旦发生信号就跳到pause后面执行*/
	}

	unsigned int sleep2(unsigned int nsecs)
	{
	    if (signal(SIGALRM, sig_alrm) == SIG_ERR)
	        return(nsecs);
	    if (setjmp(env_alrm) == 0) {
	        alarm(nsecs);
	        pause();
	    }
	    return(alarm(0));
	}

	这里，sleep2有另外一个问题，它会干扰其他的信号。如果SIGALRM打断了其他信号的信号处理函数，当我们调用longjmp的时候，实际上我们也取消了那个被打断的信号处理函数的处理,那个被打断的信号处理函数的剩下的部分就无法执行到了。这里也有一个例子，我就不在本文中列出了，需要看的话请参考参考资料吧。

	这里给出的sleep1和sleep2这两个例子，是为了说明如果过于简单的处理信号，会出现什么问题。后面的章节中，将会展示所有和这些有关的问题，这样我们就可以可靠地处理信号，同时不干扰其他的代码。

	另外一个例子
	除了sleep之外，一个比较常用的使用alarm函数的另外一个例子就是设置一个阻塞操作的时间上限。例如，我们有一个慢设备，在这个设备上面进行可以阻塞的读取操作，我们可能只想等待读取一定的时间让它超时，下面的例子就展示了这个。它从标准输入读取一行，然后输出到标准输出。
	static void sig_alrm(int signo)
	{}

	int main(void)
	{
	    int     n;
	    char    line[MAXLINE];
	    if (signal(SIGALRM, sig_alrm) == SIG_ERR)
	        err_sys("signal(SIGALRM) error");

	    alarm(10);
	    if ((n = read(STDIN_FILENO, line, MAXLINE)) < 0)
	        err_sys("read error");
	    alarm(0);

	    write(STDOUT_FILENO, line, n);
	    exit(0);
	}
	这样的代码次序在UNIX程序中是非常常见的，但是这个程序有两个问题,
	1，在第一个alarm调用和read之间有一个时间竞争窗口.如果内核在这两个函数之间阻塞进程并且阻塞的时间比alarm设置的时间长，那么read函数将会被永远阻塞。大多数这个类型的操作使用一个比较长的时钟时间,例如一分钟，或者更多,这样发生这样无限阻塞的时间就非常的少了，但是这也毕竟是一个竞争时间窗口。
	2，如果系统调用被自动重新启动了，那么read在AIGALRM信号处理函数返回的时候并不会被打断。这时候，超时不会发生任何事情。
	这里，我们特别地，需要一个慢的系统调用被中断。POSIX.1没有为我们提供一个可以移植的办法来做这件事，然而，Single UNIX Specification的XSI扩展做了这件事情,后面会讨论更多的相关内容。

	这里，我们使用longjmp来重新实现这个例子，这样我们就不用担心一个慢的系统调用是否被中断了。这个例子工作的很正常，不用考虑系统是否重启被打断的系统调用，然而我们还需要注意在和其他信号处理函数进行交互的时候还是会有问题的。
	static jmp_buf    env_alrm;
	static void sig_alrm(int signo)
	{
	    longjmp(env_alrm, 1);
	}

	int main(void)
	{
	    int     n;
	    char    line[MAXLINE];

	    if (signal(SIGALRM, sig_alrm) == SIG_ERR)
	        err_sys("signal(SIGALRM) error");
	    if (setjmp(env_alrm) != 0)
	        err_quit("read timeout");

	    alarm(10);
	    if ((n = read(STDIN_FILENO, line, MAXLINE)) < 0)
	        err_sys("read error");
	    alarm(0);

	    write(STDOUT_FILENO, line, n);
	    exit(0);
	}
	如前面所示，如果我们想要设置一个I/O操作的时间限制，那么我们需要使用longjmp，但是我们也要意识到它可能和其他信号处理函数交互。另一个可选的方法是使用select或者poll函数，后面会讲到。

	11）信号集合
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec11.html
	我们需要一种数据类型来表示包含多个信号的信号集合，我们使用诸如sigprocmask这样的函数来告诉内核不让信号集合中的信号发生。我们前面也提到过，信号的数量可能会超过整数的位数，所以我们不使用整数来表示信号集合（其中每个位代表一个信号）。POSIX.1定义了数据类型sigset_t来包含信号集合，使用如下5个函数来操作信号集合。
	#include <signal.h>
	int sigemptyset(sigset_t *set);
	int sigfillset(sigset_t *set);
	int sigaddset(sigset_t *set, int signo);
	int sigdelset(sigset_t *set, int signo);
	以上四个函数成功的时候返回0，错误的时候返回1。
	int sigismember(const sigset_t *set, int signo);
	这个函数如果返回1表示真，返回0表示假，有错误返回1。

	函数sigemptyset初始化set参数指向的信号集合，这样所有的信号都被排除。函数sigfillset初始化信号集合，这样所有的信号都被包含进来。所有的应用程序在使用信号集合(signal set)之前，都应该调用sigemptyset或者sigfillset对信号集合操作一次，因为我们不能假设C对外部变量或者静态变量的初始化（为0）是和相应系统的信号实现相对应的。
	当我们初始化一个信号集合之后，我们可以为这个信号集合添加或者删除指定的信号。函数sigaddset添加一个信号到已经存在的信号集合(set参数)，sigdelset从信号集合(set参数)中删除一个信号。所有这些需要一个信号集合(set)做为参数的函数，我们一般都将信号集合set的地址作为参数传递。

	关于这些函数的实现：
	如果系统的信号数目比整数的位数少，那么信号集合就可以用一个整数来表示，用这个整数的每个位表示集合中的一个信号。前面已经提过这些，当然这要假定系统有31个信号，整数位数是32位。sigemptyset函数把这个整数清零，sigfillset函数把这个整数所有的位打开。这两个函数在<signal.h>头文件中，可以用如下宏来实现。
	   #define sigemptyset(ptr)   (*(ptr) = 0)
	   #define sigfillset(ptr)    (*(ptr) = ^~(sigset_t)0, 0)
	注意，sigfillset必须返回0，这里我们使用C语言中的逗号表达式的语法特性来实现这个目的。
	本节后面分别给出了sigaddset,sigdelset,sigismember的实现，这里就不赘述了。
	我们可能想在<signal.h>头文件中，用一行宏来实现这三个函数的功能，但是POSIX.1要求我们检查信号参数的合法性，如果不合法就设置errno。这个在宏中比较难做，所以使用函数来实现它们。

	12)sigprocmask 函数
参考： http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec12.html
	前面说过，一个进程的signal mask是一个信号集合，这个信号集合中的信号是将要发送给这个进程的但是被阻塞了的信号的集合。进程可以检测它的signal mask,也可以修改它的signal mask或者通过下面的sigprocmask函数来一步达到上述两个目的。
	#include <signal.h>
	int sigprocmask(int how, const sigset_t *restrict set, sigset_t *restrict oset);
	这个函数在成功的时候返回0，错误的时候返回1。
	首先，如果参数oset是非空指针，那么当前进程的signal mask会被返回到这个oset上面。
	第二，如果set参数非空，那么就通过how参数来指定怎样修改当前的信号。关于how参数的可能取值下面已经列出，
	SIG_BLOCK 使进程的signal mask变成set参数和oset参数的合并。也就是说set指定要增加的signal mask集合。
	SIG_UNBLOCK 使进程的signal mask变成当前signal mask和set参数指定的signal mask的补集的交集.也就是说，set包含的是我们想要取消阻塞的signal mask。
	SIG_SETMASK 使进程的当前signal mask被set参数所指的signal mask替换。也就是说set包含的就是新设置的signal mask.
	这里，SIG_BLOCK是一个"或"操作，SIG_SETMASK是一个赋值操作。同时注意，SIGKILL和SIGSTOP不能被阻塞。
	如果set参数为空，进程的signal mask不会变化，并且how参数也会被忽略。
	调用sigprocmask之后，如果有任何非阻塞的信号处于提交状态，那么这些信号中至少有一个会在sigprocmask返回的时候被发送给进程。
	sigprocmask只是为单线程的进程所定义的，如果操作多线程进程中线程的signal mask,那么有别的函数，以后会讲。

	举例：
	void pr_mask(const char *str)
	{
	    sigset_t    sigset;
	    int         errno_save;

	    errno_save = errno;     /* 可被信号处理函数调用 */
	    if (sigprocmask(0, NULL, &sigset) < 0)
	        err_sys("sigprocmask error");

	    printf("%s", str);
	    if (sigismember(&sigset, SIGINT))   printf("SIGINT ");
	    if (sigismember(&sigset, SIGQUIT))  printf("SIGQUIT ");
	    if (sigismember(&sigset, SIGUSR1))  printf("SIGUSR1 ");
	    if (sigismember(&sigset, SIGALRM))  printf("SIGALRM ");
	    /* 省略其他信号 */
	    printf("\n");
	    errno = errno_save;
	}
	上面的函数会打印调用进程的signal mask中的signal的名字。后面的讲解中可能会调用到这个函数,由于篇幅原因，这里没有列出所有的信号的检测。

	13)sigpending函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec13.html
	sigpending函数返回发送给进程的被阻塞的信号的集合以及处于提交给当前进程的信号的集合。通过函数的参数返回这个信号的集合。
	#include <signal.h>
	int sigpending(sigset_t *set);
	函数如果成功返回0，失败返回1。
	举例：
	static void sig_quit(int signo)
	{
	    printf("caught SIGQUIT\n");
	    if (signal(SIGQUIT, SIG_DFL) == SIG_ERR)
	        err_sys("can't reset SIGQUIT");
	}
	int main(void)
	{
	    sigset_t    newmask, oldmask, pendmask;

	    if (signal(SIGQUIT, sig_quit) == SIG_ERR)
	        err_sys("can't catch SIGQUIT");

	    /*
	     * 保存当前的signal mask并且阻塞信号SIGQUIT
	     */
	    sigemptyset(&newmask);
	    sigaddset(&newmask, SIGQUIT);
	    if (sigprocmask(SIG_BLOCK, &newmask, &oldmask) < 0)
	        err_sys("SIG_BLOCK error");

	    sleep(5);   /* 这里,SIGQUIT会保持提交状态 */
	    if (sigpending(&pendmask) < 0)
	        err_sys("sigpending error");
	    if (sigismember(&pendmask, SIGQUIT))
	        printf("\nSIGQUIT pending\n");

	    /*
	     * 恢复原来的signal mask，以取消对SIGQUIT的阻塞
	     */
	    if (sigprocmask(SIG_SETMASK, &oldmask, NULL) < 0)
	        err_sys("SIG_SETMASK error");
	    printf("SIGQUIT unblocked\n");

	    sleep(5);   /* 这里，SIGQUIT将会终止进程同时产生core文件*/
	    exit(0);
	}

	例子给出了我们已经描述的所有的信号的特性。
	进程阻塞SIGQUIT,保存它当前的signal mask，然后睡眠5秒。任何在这个期间发生的quit信号都会被阻塞，不会发送给进程直到这个信号取消阻塞。在5秒睡眠的最后，我们检查信号是否处于提交状态并且取消信号的阻塞。
	注意，我们在阻塞信号之前，把原来的mask保存，在我们取消信号阻塞的时候，我们使用原来的mask做了一步SIG_SETMASK。当然，我们可能会使用SIG_UNBLOCK来取消我们已经阻塞的信号。但是，我们需要注意，如果我们写的函数可以被其他地方调用，并且如果我们需要在我们的函数中阻塞一个信号，我们不能使用SIG_UNBLOCK来取消对信号的阻塞。这里，我们需要使用SIG_SETMASK然后把信号恢复成它原来的值.这样做，是因为，那个调用我们函数的地方，可能在调用我们之前就特别地指定了要阻塞这个信号，所以我们不能仅仅简单地取消那个信号的阻塞。
	如果我们在睡眠时发送了quit信号，而这个信号现在处于提交状态并且是取消阻塞的状态，那么它会在sigprocmask返回之前被发送给进程。我们将会看到这个现象的发生，因为处理函数中的printf输出，在sigprocmask调用接下来的printf输出之前。
	进程然后再睡眠5秒，由于捕获信号之后，我们会把信号处理还原成默认，如果我们发送quit信号的时候是在睡眠的期间，信号就会把进程终止。
	在下面的输出中，当我们输入[Ctrl]\的时候，终端会打印^\（终端退出字符）:
	$ ./a.out

	    ^\                       generate signal once (before 5 seconds are up)
	    SIGQUIT pending          after return from sleep
	    caught SIGQUIT           in signal handler
	    SIGQUIT unblocked        after return from sigprocmask
	    ^\Quit(coredump)         generate signal again
	    $ ./a.out

	    ^\^\^\^\^\^\^\^\^\^\     generate signal 10 times (before 5 seconds are up)
	    SIGQUIT pending
	    caught SIGQUIT           signal is generated only once
	    SIGQUIT unblocked
	    ^\Quit(coredump)         generate signal again
	消息"Quit(coredump)"是shell看到它的一个子进程非正常结束的时候，打印出来的。需要注意的是，当我们第二次运行程序的时候，我们在进程睡眠的时候发起quit信号10次，然而这个信号在它取消阻塞的时候只给进程发送了一次，这说明在这个系统上，信号没有被排队。

	14)sigaction函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec14.html
	sigaction允许我们检查或修改，或者检查并修改和一个特定信号相关联的动作。这个函数取代了早期Unix发行版本中的signal函数,实际后面我们将给出使用这个函数实现的signal函数。
	#include <signal.h>
	int sigaction(int signo, const struct sigaction  *restrict act, struct sigaction *restrict oact);
	如果成功，这个函数返回0,如果错误，这个函数返回1.
	参数signo是我们要修改或者检测的动作相关联的信号号。如果act参数非空，那么我们修改这个动作;如果oact参数非空，那么系统通过这个参数返回之前的动作。这个函数使用的结构如下：
	struct sigaction
	{
	  void      (*sa_handler)(int);   /* 信号处理函数的地址,可以是SIG_IGN或者SIG_DFL */
	  sigset_t sa_mask;               /* 需要阻塞的额外的信号*/
	  int      sa_flags;              /* 信号选项，后面会说 */
	  /*备选的信号处理函数,sigaction使用SA_SIGINFO时候会用到，参见后面解释*/
	  void     (*sa_sigaction)(int, siginfo_t *, void *);
	};
	当我们修改一个信号的处理动作的时候，如果sa_handler包含了信号处理动作的地址(而不是SIG_IGN或者SIG_DFL)，那么sa_mask会指定在调用信号处理函数之前添加到进程的一系列signal mask中的信号的集合，当信号处理函数返回的时候，进程的signal mask再被恢复成原来的样子。这样，我们就可以在调用信号处理函数的时候指定我们想要阻塞的信号.操作系统会包含调用信号处理函数是发送的signal mask中的信号。这样我们可以保证，无论何时当我们处理一个信号的时候，另一次同样的信号的产生会被阻塞，直到我们处理完这个信号的第一次发生。回忆前面所讲的，一个信号发生多次的时候，一般不会被排队,也就是说，假设一个信号在它被阻塞期间被发送了5次，那么当取消它的阻塞的时候，这个信号的信号处理函数一般只会被调用一次。
	一旦我们给一个指定的信号添加了动作，这个信号的动作会一直保持安装的状态，直到我们调用sigaction显示地改变它。这和早期unix系统的非可靠信号机制有所不同，POSIX.1要求，一个信号的信号处理函数会一直保持被安装的状态，直到我们显示地去改变它们。
	action结构的sa_flags域指定了信号的处理函数的各种处理方式选项,后面的表中就列出了这些选项的意义。
	一定注意！！！这些选项有的系统支持，有的系统不支持，这里只是大致说一下它们的含义，详细的请参见参考资料。
	SA_INTERRUPT :被这个信号所打断的系统调用不会被自动重启。（可以参见前面相关内容）
	SA_NOCLDSTOP :如果信号是SIGCHLD,那么当子进程停止（作业控制中）的时候不会发送信号。当然，当子进程终止的时候，还是会发送这个信号的(但是请参考后面的SA_NOCLDWAIT选项),作为XSI的扩展，当这个标记被设置的时候，子进程从停止到继续的时候不会发送SIGCHLD信号。
	SA_NOCLDWAIT :如果信号是SIGCHLD的时候，这个选项会在调用进程的子结束的时候，阻止系统创建僵尸进程。如果进程后来调用wait，那么调用进程会阻塞，直至所有的子进程终止，然后返回1并且设置errno为ECHILD.
	SA_NODEFER :当捕获信号的时候，在信号捕捉函数执行的时候，信号不会被系统自动的阻塞(除非信号在sa_mask中).需要注意的是这样的操作符合早期的非可靠信号的特点。
	SA_ONSTACK :如果一个可选的堆栈使用sigaltstack声明了，那么信号会在可选的堆栈上被发送给进程。
	SA_RESETHAND :这个特性使得信号被恢复成默认的值，并且在进入信号处理函数的时候清除SA_SIGINFO标记.需要注意的是，这种操作符合早期的非可靠信号.然而，SIGILL和SIGTRAP不能被自动地重置。设置这个标记，会使得sigaction的行为好似设置了SA_NODEFER标记。
	SA_RESTART :被信号打断的系统调用会被自动重启。
	SA_SIGINFO :这个标记为信号处理函数提供了一个额外的信息:一个指向siginfo结构的指针，以及一个指向进程上下文标记的指针。
	sa_sigaction域是一个可选的信号处理函数，sigaction当使用SA_SIGINFO标记的时候，会使用它。在实现中，有可能对sa_sigaction域和sa_handler域使用了同一个存储区域，所以应用程序每次只能使用其中的一个域。
	一般来说，信号处理函数的调用如下：
	void handler(int signo);

	但是,如果设置了SA_SIGINFO标记，那么信号处理函数的调用如下：
	void handler(int signo,siginfo_t *info,void *context);
	siginfo_t结构的信息包含信号产生的原因。下面给出了它定义的一个常用形式，所有遵守POSIX.1的实现都必须至少包含si_signo和si_code成员。
	struct siginfo {
	int    si_signo;  /* 信号号码 */
	int    si_errno;  /* 如果非0表示<errno.h>中的errno */
	int    si_code;   /* 一些依赖于信号的额外的信息 */
	pid_t  si_pid;    /* 发送信号的进程ID */
	uid_t  si_uid;    /* 发送进程的real user ID */
	void  *si_addr;   /* 导致错误的地址 */
	int    si_status; /* 退出码或者信号号 */
	long   si_band;   /* SIGPOLL的标志数 */
	/* 这里，可以增加其它可能的域 */
	};
	再后面，给出了许多信号的si_code信息含义，这些是Single UNIX Specification定义的，不同的实现可能会增加一些其他的si_code.这里，限于篇幅就不一一列出了。具体请参考参考资料。

	如果信号是SIGCHLD，那么si_pid,si_status,和si_uid域会将被设置。如果信号是SIGILL或者SIGSEGV，那么si_addr包含相应的错误地址（尽管地址可能不是非常精确）.如果信号是SIGPOLL，那么si_band域将会包含一些流消息的优先标志，这些流消息会产生POLL_IN, POLL_OUT,或者POLL_MSG事件。si_errno域包含导致信号被产生的条件的错误号码(尽管它的作用已经被实现定义了)。
	信号处理函数的context参数是一个无类型的指针，它可以被强制转换成ucontext_t结构，这个结构标志发送信号时候的进程的上下文。
	当实现支持实时信号扩展的时候，信号处理函数使用SA_SIGINFO来建立的话，会导致信号被“可靠地”排队。为了实时应用程序的使用，有一个独立的保留的信号范围。如果信号是被sigqueue来发起的，那么siginfo结构可以包含应用程序相关的数据。这里，我们不会过于深入地讨论实时扩展。


	信号函数举例
	现在让我们来使用sigaction实现signal函数，这也是许多平台所做的。有些二进制兼容的系统，可能会提供旧有的，非可靠的信号函数的支持。除非你特别指定要使用这些旧有的非可靠的信号（为了向后兼容），否则你应该使用下面实现的signal函数，或者直接调用sigaction.(正如你可能会猜测的，对旧有的signal函数的实现，应该是调用sigaction同时指定SA_RESETHAND和SA_NODEFER)，本文所有的调用signal的例子，调用的都是下面的方式实现的signal。

	注意，我们必须使用sigemptyset来初始化结构的sa_mask成员，因为我们无法保证"act.sa_mask=0;"这句话是好用的。
	我们特地为除了SIGALRM之外的所有的信号设置SA_RESTART标记，这样任何被其他信号打断之后，都会自动地重新启动。我们没有设置SIGALRM重启的原因是想要允许我们设置一个I/O操作的超时(前面应该也提到过)。
	一些旧的系统，例如SunOs，定义了SA_INTERRUPT标记，这些系统默认重新启动被打断的系统调用，所以指定这个标记导致系统调用被中断。Linux定义了SA_INTERRUPT标记，便于和使用它的应用程序相互兼容，但是，默认在sigaction安装到信号处理函数的时候是没有重新启动系统的。Single UNIX Specification 的XSI扩展指定sigaction函数如果不设置SA_RESTART标记，就不会重新启动被打断的系统调用。

	一个使用sigaction实现的signal：

	/*这个是使用POSIX的sigaction()实现的可靠版本的signal()*/
	Sigfunc *signal(int signo, Sigfunc *func)
	{
	    struct sigaction    act, oact;
	    act.sa_handler = func;
	    sigemptyset(&act.sa_mask);
	    act.sa_flags = 0;
	    if (signo == SIGALRM) {
	#ifdef SA_INTERRUPT
	       act.sa_flags |= SA_INTERRUPT;
	#endif
	    } else {
	#ifdef  SA_RESTART
	        act.sa_flags |= SA_RESTART;
	#endif
	    }
	    if (sigaction(signo, &act, &oact) < 0)
	        return(SIG_ERR);
	    return(oact.sa_handler);
	}

	一个signal_intr函数的例子
	下面给出了一个signal函数，这个函数尝试阻止任何被打断的系统调用被重启。
	为了增加可移植特性，我们指定了SA_INTERRUPT标记，如果这个标记被定义了，那么就会防止被中断的系统调用重新启动。

	signal_intr函数
	Sigfunc *signal_intr(int signo, Sigfunc *func)
	{
	    struct sigaction    act, oact;

	    act.sa_handler = func;
	    sigemptyset(&act.sa_mask);
	    act.sa_flags = 0;
	#ifdef  SA_INTERRUPT
	    act.sa_flags |= SA_INTERRUPT;
	#endif
	    if (sigaction(signo, &act, &oact) < 0)
	        return(SIG_ERR);
	    return(oact.sa_handler);
	}

	15)sigsetjmp 和 siglongjmp 函数
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec15.html
	前面，我们描述了setjmp和logjmp函数，这个函数可以用于跳转。在前面我们也看到了，longjmp函数经常会在信号处理函数中被调用，通过跳转的方式返回到主程序循环中，而不是return的方式。

	然而，调用longjmp的时候，有一个问题：当一个信号被捕获的时候，会进入到捕获的信号处理函数，同时当前的信号会被自动添加到进程的signal mask中，这会阻止随后发生的那个信号打断信号处理函数。如果我们使用longjmp从信号处理函数中跳转出去，那么进程的signal mask会怎么样?

	在FreeBSD5.2.1和Mac OS X 10.3，setjmp和longjmp会保存和恢复signal mask. Linux 2.4.22和Solaris 9却不这样。FreeBSD和Mac OS X提供了_setjmp和_longjmp函数，这个函数不会保存和恢复signal mask.

	为了能够支持两种行为，POSIX.1没有指定setjmp和longjmp对signal masks的影响。相应地，两个新的函数：sigsetjmp和siglongjmp被POSIX.1定义了，如果是从一个信号处理函数中跳转，那么应该使用这两个函数。

	#include <setjmp.h>
	int sigsetjmp(sigjmp_buf env, int savemask);
	返回：调用的时候会返回0，如果是由于siglongjmp导致的返回，那么返回非0。
	void siglongjmp(sigjmp_buf env, int val);

	这些函数和setjmp与longjmp函数的区别就是，sigsetjmp有一个额外的参数。如果savemask参数非0，那么sigsetjmp也会把当前进程的signal mask保存到env参数中。当siglongjmp被调用的时候，如果evn参数存放了sigsetjmp指定的非0的savemask，那么，siglongjmp会将保存的signal mask恢复。

	举例：
	static void                         sig_usr1(int), sig_alrm(int);
	static sigjmp_buf                   jmpbuf;
	static volatile sig_atomic_t        canjump;
	int main(void)
	{
	    if (signal(SIGUSR1, sig_usr1) == SIG_ERR){...}
	    if (signal(SIGALRM, sig_alrm) == SIG_ERR){...}
		/*main开始,并且打印当前signal mask*/

	    if (sigsetjmp(jmpbuf, 1)) {/*main结束*/exit(0);}
	    canjump = 1;         /* sigsetjmp()完毕 */

	    for ( ; ; )
	        pause();
	}
	static void sig_usr1(int signo)
	{
	    time_t  starttime;
	    if (canjump == 0) return;     /*canjump为0则无法预测的结果，所以忽略 */

		/*开始sig_usr1,并且打印当前signal mask*/
	    alarm(3);               /* 3时钟 */
	    starttime = time(NULL);
	    for ( ; ; )             /* 忙等待5秒 */
	        if (time(NULL) > starttime + 5)
	            break;
		/*结束sig_usr1,并且打印当前signal mask*/

	    canjump = 0;
	    siglongjmp(jmpbuf, 1);  /* 跳到main函数 */
	}

	static void sig_alrm(int signo)
	{
		/*sig_alrm中的处理,并且打印当前signal mask*/
	}

	上面的程序，列举出当一个信号处理函数被自动调用的时候，signal mask（包括被捕捉的信号）是如何被系统安装上去的。这个程序也列举了使用sigsetjmp函数和siglongjmp函数的方法。
	这个程序也列举了当我们在信号处理函数中调用siglongjmp时经常使用的另外一个技术：在调用sigsetjmp之后我们设置一个canjump变量为非0;这个变量会在信号处理函数中被检测，如果这个变量被检测的时候的值非0，那么调用siglongjmp(当然，调用之前也可把这个变量设置为0)。这个技术提供了一个保护机制，保护信号处理函数被过早的调用或者调用的太晚了，那个时候jump buffer还没有被sigsetjmp初始化好。（在我们的这个简单的程序中，我们在siglongjmp中很快就将程序结束了，但是在大一点的程序中，信号处理函数可能会在siglongjmp之后保持安装很长一段时间,这期间再发生信号而没有上述保护机制，就可能出现问题）提供这样的保护机制，在普通C代码中的longjmp时候是不需要的（这一点和在信号处理函数中相对），因为一个信号可能会在任何可能的时间发生，所以我们得在信号处理函数中加上额外的保护机制。
	这里，我们使用sig_atomic_t类型，这个类型由ISO标准C定义，它可以在被写的时候不被打断。通过这个，我们要说明，一个这样类型的变量不应该跨越一个虚拟内存系统的页边界，并且这样的变量可以被一个单个的机器指令所访问。我们也常常为这样的数据类型包含ISO的volatile修饰符，因为这个变量被两个不同的线程控制流程所访问：main函数，还有异步执行的信号处理函数。参考资料中也给出了这个代码的时间图,时间图就不说了，请参考参考资料吧。

	我们运行前面的程序，会输出如下的类似信息：
	$ ./a.out &                      从后台启动进程
	starting main:
	[1]   531                        作业控制shell打印它的进程id
	$ kill -USR1 531                 给进程发送USR1信号
	starting sig_usr1: SIGUSR1
	$ in sig_alrm: SIGUSR1 SIGALRM
	finishing sig_usr1: SIGUSR1
	ending main:
	                                    键入回车
	[1] + Done          ./a.out &


	输出的信息和我们期望的一样：当信号处理函数被调用的时候，信号会被添加到当前进程的signal mask。原始的mask会被在信号处理函数返回的时候被恢复。同时，siglongjmp会恢复sigsetjmp保存的signal mask.

	如果我们将上面程序中的sigsetjmp和siglongjmp改成Linux中的setjmp和longjmp(或者FreeBSD中的_setjmp和_longjmp),那么最后一行将会变成:
	    ending main: SIGUSR1

	也就是说，在调用setjmp之后，main函数执行的时候，SIGUSR1信号被阻塞了.这个也许不是我们想要期望的。

	16)sigsuspend函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec16.html
	我们已经知道如何改变一个进程的signal mask来阻塞或者取消阻塞被选择的信号。我们可以使用这个技术来保护代码的关键区域，防止它被信号打断。如果我们想要取消阻塞一个信号然后pause，并等待之前被阻塞的信号发生，这会怎样？假设信号是SIGINT，正确的做法是：

	sigset_t     newmask, oldmask;
	sigemptyset(&newmask);
	sigaddset(&newmask, SIGINT);

	/*阻塞SIGINT信号，然后保存当前的signal mask*/
	if (sigprocmask(SIG_BLOCK, &newmask, &oldmask) < 0)
		err_sys("SIG_BLOCK error");

	/*代码的关键区域*/

	/*重新设置signal mask，这样会取消对SIGINT的阻塞*/
	if (sigprocmask(SIG_SETMASK, &oldmask, NULL) < 0)
		err_sys("SIG_SETMASK error");

	/* 容易发生问题的时间窗口在这里出现了!!!(也就是重新设置signal mask和suspend这两步之间易发生问题) */

	pause();  /* wait for signal to occur */

	/*后续的处理*/


	当信号在被阻塞的时候被发送给进程，这个信号的发送将会被延迟，直到信号被取消阻塞。对于应用程序来说，这个看起来就好象信号是在取消阻塞和调用pause之间发生的(取决于内核如何执行信号相关的处理).如果信号真的是在取消对它的阻塞和pause调用之间发生了，那么我们就会有一个问题。然后出现在上述容易发生问题的时间窗口中的这个信号，都会丢失，我们无法再看到这个信号了，这样pause就会被永远地阻塞在了那里。这个问题，也是早期非可靠信号机制中的另一种问题。

	为了修正这个问题，我们需要一个方法，可以把重新设置信号，以及将进程设置到sleep状态这两步操作变成一个单一的原子性质的操作。通过sigsuspend函数就可以实现这个目的。
	#include <signal.h>
	int sigsuspend(const sigset_t *sigmask);
	返回：返回1并且将errno设置成EINTR.

	进程的signal mask被设置成参数sigmask指向的值，然后进程被suspend，直到信号被捕获，或者直到一个信号发生导致进程被终止。如果一个信号被捕获，并且如果信号处理函数返回了，那么sigsuspend会返回，然后进程的signal mask被设置成调用sigsuspend之前的值。

	注意，这个sigsuspend没有成功的返回值，如果它从调用中返回了，那么它一定会返回一个1，并且同时将errno设置成EINTR(表征一个被打断的系统调用).

	举例:
	static void sig_int(int signo)
	{
	    pr_mask("\nin sig_int: ");
	}

	int main(void)
	{
	    sigset_t    newmask, oldmask, waitmask;
	    pr_mask("program start: ");/*打印字符串以及signal mask.*/

	    if (signal(SIGINT, sig_int) == SIG_ERR)
	        err_sys("signal(SIGINT) error");
	    sigemptyset(&waitmask);
	    sigaddset(&waitmask, SIGUSR1);
	    sigemptyset(&newmask);
	    sigaddset(&newmask, SIGINT);

	    /*
	     * 阻塞SIGINT 信号并且保存当前的signal mask.
	     */
	    if (sigprocmask(SIG_BLOCK, &newmask, &oldmask) < 0)
	        err_sys("SIG_BLOCK error");

	    /*
	     * 关键代码区域.
	     */
	    pr_mask("in critical region: ");/*打印字符串以及signal mask.*/

	    /*
	     * 暂停并允许除了SIGUSR1之外所有的信号.
	     * 这里就将重新设置signal mask和suspend合并为一个原子操作了，没有时间窗口问题了。
	     */
	    if (sigsuspend(&waitmask) != -1)
	        err_sys("sigsuspend error");

	    pr_mask("after return from sigsuspend: ");

	    /*
	     * 恢复SIGINT信号的阻塞.
	     */
	    if (sigprocmask(SIG_SETMASK, &oldmask, NULL) < 0)
	        err_sys("SIG_SETMASK error");

	    /*
	     * 继续处理...
	     */
	    pr_mask("program exit: ");

	    exit(0);
	}

	上面的例子，给出了保护关键代码区域不被指定的信号所打扰的正确的方法。
	需要注意的是，当sigsuspend返回的时候，它会把signal mask设置成这个调用之前的signal mask.在这个例子中，SIGINT信号将会被阻塞。所以我们后来将signal mask重新设置为之前我们保存的值（oldmask）.

	运行上述代码程序，输出大致如下：
	$ ./a.out
	program start:
	in critical region: SIGINT

	^?                               键入中断信号字符.
	in sig_int: SIGINT SIGUSR1
	after return from sigsuspend: SIGINT
	program exit:

	在调用sigsuspend的时候，我们把SIGUSR1添加到现有的signal mask中了，所以当信号函数运行的时候，我们可以看到signal mask实际上被改变了。在sigsuspend返回的时候，我们可以看到signal mask 被恢复到调用之前的值了。

	第二个例子省略了，主要思想就是，虽然前面posix列出了许多可重入的函数，但是为了让非posix的系统尽可能的好用，我们在信号处理函数中只设置标记，而不是调用什么系统调用。

	第三个例子涉及到父子进程同步，有待仔细考虑其中的问题...

	17)abort函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec17.html
	在前面我们提到过abort函数会导致程序非正常地终止，
	#include <stdlib.h>
	void abort(void);
	这个函数不会返回。
	这个函数会发送SIGABRT信号给调用者.(进程不应该忽略这个信号.)ISOC要求调用abort将会通过raise(SIGABRT)给主机环境发送一个非成功的标记。
	ISO C要求，如果信号被捕获，并且信号处理函数返回了，那么abort也不会返回到它的调用者处。如果信号被捕获了，只能通过调用exit,_exit,_Exit,longjmp,或者siglongjmp让信号处理函数不返回。POSIX.1也指定abort会覆盖进程对信号的阻塞和忽略(?).

	让进程捕获SIGABRT的目的是让它在进程终止之前可以进行它想要进行的清理工作。如果进程没有从信号处理函数中终止，POSIX.1已经说了，当信号处理函数返回的时候，abort会终止进程。

	这个函数的ISO C标准，让具体实现取决定是否刷新输出流，或者删除临时文件。POSIX.1更进一步要求,如果调用abort终止了进程，那么对进程打开的I/O流的影响就像进程在终止之前为每一个流调用了fclose一样。

	早期版本的System V会在abort函数中产生SIGIOT信号.此外，进程有可能会忽略或者捕获这个信号，并且从信号处理函数中返回，这时候，abort函数会返回到它的调用之处。

	4.3BSD会产生SIGILL信号。在做这个之前，4.3BSD函数会取消信号的阻塞，并且重置信号处理动作为SIG_DFL（终止进程并产生core文件）。这个会阻止一个进程忽略或者捕获信号。

	历史上，对abort的实现对标准I/O流的处理有所不同。对于保守点的编程以及更好的可移植的角度来说，如果我们想要标准I/O流被刷新，我们需要在调用abort之前来做它们。

	由于大多数UNIX 系统在创建了tmpfile之后立即对tmpfile执行unlink操作，ISO C会警告这样的文件，但是不会考虑我们。

	举例
	void abort(void)         /* POSIX风格的abort函数 */
	{
	    sigset_t           mask;
	    struct sigaction   action;

	    /*
	     * 调用者不能忽略SIGABRT，如果忽略则设置成默认的.
	     */
	    sigaction(SIGABRT, NULL, &action);
	    if (action.sa_handler == SIG_IGN) {
	        action.sa_handler = SIG_DFL;
	        sigaction(SIGABRT, &action, NULL);
	    }
	    if (action.sa_handler == SIG_DFL)
	        fflush(NULL);           /* 刷新所有打开的标准输入输出流 */

	    /*
	     * 要确保调用者没有对SIGABRT进行阻塞.
	     */
	    sigfillset(&mask);
	    sigdelset(&mask, SIGABRT);  /* signal mask中只有 SIGABRT 被排除在外 */
	    sigprocmask(SIG_SETMASK, &mask, NULL);
	    kill(getpid(), SIGABRT);    /* 发送信号 */

	    /*
	     * 如果我们到达了这里，说明进程已经捕获到了 SIGABRT 信号并且返回。
	     */
	    fflush(NULL);               /* 刷新所有打开的标准输入输出流 */
	    action.sa_handler = SIG_DFL;
	    sigaction(SIGABRT, &action, NULL);  /* 设置信号为默认的处理 */
	    sigprocmask(SIG_SETMASK, &mask, NULL);  /* just in case ... */
	    kill(getpid(), SIGABRT);                /* and one more time */
	    exit(1);    /* this should never be executed ... */
	}


	例子给出了一个根据POSIX.1指定的abort函数的实现。

	我们首先查看是否有默认的动作发生，如果有，那么我们会刷新所有打开的标准I/O流。这一点和fclose所有打开的流的效果不是一样的，因为前者是只刷新流并没有关闭它们,但是当进程终止的时候，系统会关闭所有打开的文件。如果进程捕获到了信号并且返回了，那么我们再次刷新流，因为期间进程可能又会产生一些输出的。如果进程捕获到了信号，并且调用了_exit或者_Exit，只有这种情况我们不这样做。这时候，内存中任何没有被刷新的标准I/O缓存都会被丢弃。我们假设调用者在不想要刷新缓存的时候这样做。

	根据前面所说过的，如果调用kill给caller发送一个信号，并且如果信号没有被阻塞，那么这个信号会在kill返回的时候被发送给进程。我们阻塞了除SIGABRT之外的所有信号，所以我们知道，如果调用的kill返回了，那么进程就捕获到了信号，并且信号处理函数已经返回了。


	18)system函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec18.html
	前面我们讲述过system函数的实现。但是前面讲过的没有对信号处理的部分。POSIX.1要求system忽略SIGINT和SIGQUIT，阻塞SIGCHLD。再给出可以正确处理这些信号的system之前，我们来看看为什么需要考虑信号处理的部分。
	例子：

	static void sig_int(int signo)
	{
		printf("caught SIGINT\n");
	}

	static void sig_chld(int signo)
	{
		printf("caught SIGCHLD\n");
	}

	int main(void)
	{
		if (signal(SIGINT, sig_int) == SIG_ERR)
			err_sys("signal(SIGINT) error");
		if (signal(SIGCHLD, sig_chld) == SIG_ERR)
			err_sys("signal(SIGCHLD) error");
		if (system("/bin/ed") < 0)
			err_sys("system() error");
		exit(0);
	}

	程序运行大致如下：
	loginshell--fork,exec-->a.out--fork,exec-->/bin/sh--fork,exec-->/bin/ed

	例子中使用system来启动ed程序。ed是一个编辑器，使用它是因为：它是一个可以交互的程序，并且捕捉interrupt和quit信号。如果我们从shell启动ed，然后输入interrupt字符，那么它会捕获到interrupt信号，并且打印一个问号。ed程序也设置了忽略quit信号。在例子中，捕获SIGINT和SIGCHLD信号，如果我们启动了例子中的程序，那么如下：
	$ ./a.out
	a                         向编辑器缓存中追加文本。
	Here is one line of text
	.                         结束追加。
	1,$p                      打印buffer中的第1到最后一行。
	Here is one line of text
	w temp.foo                将buffer中的内容写入文件。
	25                        编辑器提示写入的行数
	q                         退出编辑器。
	caught SIGCHLD			  我们的程序输出，提示捕捉到了SIGCHLD信号。

	当编辑器终止的时候，系统发送SIGCHLD信号给父进程，我们会捕获到它并且从signal处理函数中返回。捕获到SIGCHLD之后应该由父进程这样做，这样它自己创建的子进程结束的时候它才能够知道。当执行system函数的时候，发送给parent的这个SIGCHLD应该被阻塞。POSIX.1也是这样指定的。否则，当由system创建的子进程终止的时候，它会导致调用system的进程误以为它自己的一个子进程终止了。调用者将调用wait函数来获得子进程的状态，这样就导致阻止system函数可以从子进程的返回中获得子进程的结束状态。
	如果我们运行例子程序，同时给编辑器发送一个interrupt信号，输入输出如下：
	$ ./a.out
	a
	hello, world
	.
	1,$p
	hello, world
	w temp.foo
	13
	^?             键入interrupt字符
	?              编辑器捕获到信号，打印"?".
	caught SIGINT  父进程也捕捉到信号。
	q
	caught SIGCHLD

	前面说过，如果键入interrupt字符，会导致interrupt信号发送给所有前台进程组中的进程(这里，前台进程组中的进程有a.out,/bin/sh,/bin/ed)。在这个例子中，SIGINT会发送给三个进程(shell忽略它)，我们已经从前面的过程中的输出看到了这一点,ed编辑器和a.out都收到了这个信号。但是，当我们使用system函数运行另外一个程序的时候，我们不应该让父子进程都接收到两个中断发起的信号:interrupt和quit。这两个信号应该被发送到运行的程序：子进程。因为通过system运行的命令可以是交互的命令（例如这里的ed），也因为调用system的调用者在执行时放弃了控制并等待执行的结束，所以调用system的调用这应该不再接收这两个终端发起的信号了。这也是为什么POSIX.1指定system函数应该在等待一个命令结束的时候忽略这两个信号。

	举例
	正确的POSIX.1的system
	#include      <sys/wait.h>
	#include      <errno.h>
	#include      <signal.h>
	#include      <unistd.h>

	int system(const char *cmdstring)   /*考虑信号处理的system */
	{
	    pid_t               pid;
	    int                 status;
	    struct sigaction    ignore, saveintr, savequit;
	    sigset_t            chldmask, savemask;

	    if (cmdstring == NULL)
	        return(1);

	    ignore.sa_handler = SIG_IGN;    /* 忽略SIGINT 和 SIGQUIT */
	    sigemptyset(&ignore.sa_mask);
	    ignore.sa_flags = 0;
	    if (sigaction(SIGINT, &ignore, &saveintr) < 0)
	        return(-1);
	    if (sigaction(SIGQUIT, &ignore, &savequit) < 0)
	        return(-1);
	    sigemptyset(&chldmask);         /* 阻塞信号SIGCHLD */
	    sigaddset(&chldmask, SIGCHLD);
	    if (sigprocmask(SIG_BLOCK, &chldmask, &savemask) < 0)
	        return(-1);

	    if ((pid = fork()) < 0) {
	        status = -1;
	    } else if (pid == 0) {          /* 子进程 */
	        /* 恢复之前的信号处理动作和signal mask */
	        sigaction(SIGINT, &saveintr, NULL);
	        sigaction(SIGQUIT, &savequit, NULL);
	        sigprocmask(SIG_SETMASK, &savemask, NULL);

	        execl("/bin/sh", "sh", "-c", cmdstring, (char *)0);
	        _exit(127);     /* exec error */
	    } else {                        /* parent */
	       while (waitpid(pid, &status, 0) < 0)
	           if (errno != EINTR) {
	               status = -1; /* error other than EINTR from waitpid() */
	               break;
	           }
	    }

	    /* restore previous signal actions & reset signal mask */
	    if (sigaction(SIGINT, &saveintr, NULL) < 0)
	        return(-1);
	    if (sigaction(SIGQUIT, &savequit, NULL) < 0)
	        return(-1);
	    if (sigprocmask(SIG_SETMASK, &savemask, NULL) < 0)
	        return(-1);

	    return(status);
	}


	例子中给出了考虑信号处理的system函数的实现。
	如果我们把之前的程序用这个system函数链接，那么结果的二进制文件会有如下不同的地方：
	1.当我们键入interrupt或者quit字符的时候，不会有信号被发送到调用进程。
	2.当ed命令退出的时候，SIGCHLD不会发送给调用进程。然而，这个信号会一直被阻塞，直到我们在system函数通过waitpid获取到子进程的结束状态之后，最后调用了sigprocmask函数。
		POSIX.1指出，如果wait或者waitpid在SIGCHLD提交的时候返回子进程的状态，那么SIGCHLD就不应该被发送给进程了，除非又有另外一个子进程的状态可用（意思似乎是不wait就会发送这个信号，wait就没有必要发送了）。本书的四个系统都没有实现这个描述的含义，所以，SIGCHLD在system函数调用了waitpid之后，还是保持着提交的状态；当信号被取消阻塞之后，就会被发送给调用者。如果我们在之前的程序中的sig_chld函数中调用wait函数，那么这个wait函数会返回1同时设置errno为ECHILD，因为system函数里面已经用wait获取过子进程的终止状态了。

	许多早期的实现忽略interrupt和quit信号的方法如下：
	if((pid = fork()) < 0)
	{
		err_sys("fork error");
	}
	else if (pid == 0)
	{
		/*子进程*/
		execl(...);/*注意，前面说过execl出来的子进程，会继承父进程的signal mask以及正在提交的信号*/
		_exit(127);
	}

	/*父进程*/
	old_intr = signal(SIGINT, SIG_IGN);
	old_quit = signal(SIGQUIT, SIG_IGN);
	waitpid(pid, &status, 0);
	signal(SIGINT, old_intr);
	signal(SIGQUIT, old_quit);

	这段代码的问题在于，我们无法保证fork之后是父进程先运行，还是子进程先运行。如果子进程首先运行而父进程在一段时间内还没有来得及运行，那么很可能在父进程改变它的信号处理方式为忽略之前，就产生一个interrupt信号。也由于这个原因，在例子中我们是调用fork之前才修改信号处理的方式的。

	需要注意的是，我们必须在子进程中execl调用之前将这两个信号属性重新设置回去。这个允许execl基于调用者的信号属性，改变它们的属性为默认的（意思到底是默认属性就是默认属性，还是默认属性变成了父进程的信号属性???）。

	从system的返回值
	注意system的返回值。这个返回值是shell的结束状态，一般它不总是命令行对应的程序命令的结束状态。在第8章中的一个例子中(参见：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec13.html#ch08fig23)，我们可以看到，如果我们执行一个简单的命令例如date，那么结束状态是0。执行shell命令以44进行exit也会给我们一个44的结束状态，那么如果有了信号机制会怎么样呢？

	对于第8章的例子(参见:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch08lev1sec13.html#ch08fig24)，我们运行它，并且给执行的命令发送一些信号：

	$ tsys "sleep 30"

	^?normal termination, exit status = 130    键入interrupt按键
	$ tsys "sleep 30"

	^\sh: 946 Quit                             键入quit按键
	normal termination, exit status = 131
	当我们使用interrupt按键终止sleep的时候，pr_exit函数认为终止状态是正常的。当我们使用quit按键的时候也是。这里，Bourne shell对进程结束状态为128加上信号号这个特性的解释很是模糊，但是当命令通过信号被终止的时候，我们可以从shell的交互中看到这样的信息。

	   $ sh                             make sure we're running the Bourne shell
	   $ sh -c "sleep 30"

	   ^?                               type the interrupt key
	   $ echo $?                        print termination status of last command
	   130
	   $ sh -c "sleep 30"

	   ^\sh: 962 Quit - core dumped     type the quit key
	   $ echo $?                        print termination status of last command
	   131
	   $ exit                           leave Bourne shell
	这里的系统中，SIGINT的值是2，SIGQUIT的值是3，这样我们得到结束状态分别是128+2=130，以及128+3=132。

	我们来看一个类似的例子，这次我们直接发送信号给shell来看看system会得到什么返回值：

	    $ tsys "sleep 30" &                 start it in background this time
	    9257
	    $ ps -f                             look at the process IDs
	         UID   PID   PPID   TTY    TIME CMD
	         sar  9260    949   pts/5  0:00 ps -f
	         sar  9258   9257   pts/5  0:00 sh -c sleep 60
	         sar   949    947   pts/5  0:01 /bin/sh
	         sar  9257    949   pts/5  0:00 tsys sleep 60
	         sar  9259   9258   pts/5  0:00 sleep 60
	    $ kill -KILL 9258                   kill the shell itself
	    abnormal termination, signal number = 9


	这里，我们可以看到，system的返回值在只有shell本身结束的时候，报告了一个非正常的终止。

	当使用system函数写程序的时候，应该确保正确地解释了返回值。如果你自己亲自调用fork，exec，和wait，那么返回的终止状态就和你调用system的返回不一样了。


	19)sleep函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec19.html
	我们在本文中的许多例子里都使用了sleep函数，并且我们在本章前面给出了两个有缺陷的sleep函数。

	#include <unistd.h>
	unsigned int sleep(unsigned int seconds);
	返回：0或者未睡眠的秒数。

	这个函数会导致调用进程被挂起，直到：
	1.指定的睡眠时间到。
	2.进程捕获到一个信号并且信号处理函数返回。
	由于该函数和alarm信号相关，实际返回的时间往往比要求的实现稍微晚，因为可能有其他的系统活动。
	在第1个情况中，返回的值为0。当由于捕捉到信号导致sleep返回早的时候，返回值就是还未睡眠的秒数（请求的时间减去实际的睡眠时间）。
	虽然sleep可以通过alarm函数来实现，但是不提倡这样做。如果使用了alarm，那么这两个函数之间会相互影响。POSIX.1标准没有指定会有什么样的影响。例如，如果我们使用alarm(10)然后3秒之后，我们又做了一个sleep(5)，那么会发生什么呢？sleep将会在5秒内返回（假设期间没有收到其它的信号），但是之前的那个SIGALARM会在2秒之后产生吗？详细的情况还依赖系统的实现。
		solaris9使用alarm实现sleep，其man手册上已经说明会正确地处理之前的alarm。例如前面的情况中，在sleep返回之前，会重新设置一个2秒之后产生的alarm；这时候sleep返回0（显然，sleep必须保存SIGALARM信号处理函数的地址，然后在返回之前重新将它设置回来）。另外，如果我们使用alarm(6)然后3秒之后又调用了sleep(5)，那么sleep会在3秒中之后返回（也就是第一个alarm到期的时候），而不是我们期望的5秒。这里，从sleep中的返回值就是2（没有睡眠的时间）。
		FreeBSD5.2.1，Linux 2.4.22，和Mac OS X 10.3使用另外一种技术：延迟是通过naosleep(2)来提供的。这个函数是Single UNIX Specification 实时扩展中高精确度的延迟。这个函数允许sleep的实现和信号相互独立。
		为了可移植的性质，你不能对sleep的实现做任何的假定，但是如果你将sleep和其他的时间函数相互混淆的调用的话，你就需要知道一些可能会产生的影响。

	举例：
	sleep的可靠实现：
	static void sig_alrm(int signo)
	{
	    /* 不做任何事情，只是返回，以唤醒sigsuspend() */
	}

	unsigned int sleep(unsigned int nsecs)
	{
	    struct sigaction    newact, oldact;
	    sigset_t            newmask, oldmask, suspmask;
	    unsigned int        unslept;

	    /* 设置信号处理函数，保存之前的信息 */
	    newact.sa_handler = sig_alrm;
	    sigemptyset(&newact.sa_mask);
	    newact.sa_flags = 0;
	    sigaction(SIGALRM, &newact, &oldact);

	    /*阻塞SIGALRM信号，保存当前的signal mask */
	    sigemptyset(&newmask);
	    sigaddset(&newmask, SIGALRM);
	    sigprocmask(SIG_BLOCK, &newmask, &oldmask);

	    alarm(nsecs);

	    suspmask = oldmask;
	    sigdelset(&suspmask, SIGALRM);    /* 虽然代码之前oldmask没有阻塞SIGALRM，但是这样确保SIGALRM一定没阻塞 */
	    sigsuspend(&suspmask);            /* 等待信号被捕获 */

		/*信号被捕获了，SIGALRM现在又被阻塞了*/

	    unslept = alarm(0);
	    sigaction(SIGALRM, &oldact, NULL);  /* 恢复之前的动作 */

	    /* 重新设置回之前的signal mask，取消对SIGALRM的阻塞 */
	    sigprocmask(SIG_SETMASK, &oldmask, NULL);
	    return(unslept);
	}

	前面例子给出了一个POSIX.1的sleep函数实现。这个函数对之前的例子进行了改进，它会可靠地处理信号，避免了之前版本中存的竞争条件。我们也没有处理和之前设置的alarm之间的相互影响（因为前面我们也说了，POSIX.1中没有指定是什么影响）

	这里使用可靠的实现，比之前的代码量要多很多，我们也没有使用任何跳转，所以这里当发生SIGALRM时候不会对其他正在运行的信号处理函数造成影响。

	20)作业控制信号
	POSIX.1考虑用下面6种信号来进行作业控制：
	SIGCHLD  子进程被停止或者终止。
	SIGCONT  如果之前停止的话，继续进程。
	SIGSTOP  停止信号（无法被捕获或者忽略）。
	SIGTSTP  用于交互的停止信号。
	SIGTTIN  后台进程组的一个进程从控制终端读取。
	SIGTTOU  后台进程组的一个进程向控制终端写。
	除了SIGCHLD之外，大多数应用程序不会处理这些信号：交互的shell一般已经做了处理这些信号的所有工作。当我们键入挂起字符的时候（一般为C-z），SIGTSTP信号会发送给所有在前台进程组的进程。当我们告诉shell重新启动一个前台或者后台的作业的时候，shell会给所有作业中的进程发送一个SIGCONT信号。类似，如果SIGTTIN或者SIGTTOU被发送给了一个进程，那么进程默认来说会被停止（stop），并且作业控制shell会识别出这个现象，并且通知我们。

	一个例外的进程就是控制terminal的进程，例如vi编辑器。它需要知道什么时候用户想要进行挂起，这样它能够恢复终端的状态到vi启动时候的状态。并且，当它在前台重新开始的时候，vi编辑其需要设置终端状态为之前它想要的状态，并且它需要重新绘制终端屏幕。后面的例子中我们将会看到一个类似vi的程序是如何处理这个状况的。

	有一些作业控制的交互信号。当四个停止信号（SIGTSTP,SIGSTOP,SIGTTIN,或者SIGTTOU）被发送给一个进程的时候，那个进程中任何提交状态的SIGCONT信号都会被丢弃。类似的，当SIGCONT信号被发送给一个进程的时候，那个进程任何提交状态的stop信号都会被丢弃。

	注意：默认SIGCONT的行为是重新开始一个被停止的进程；如果进程没有被停止，那么它被忽略。一般来说，我们不必对这个信号进行什么特殊的处理。当SIGCONT被发送给一个被停止的进程的时候，进程会被继续，即使这个信号被阻塞或者忽略。


	举例：
	如何处理SIGTSTP

	#define BUFFSIZE   1024
	static void sig_tstp(int signo) /* SIGTSTP的信号处理函数 */
	{
	    sigset_t    mask;

	    /* ... 将光标移动到左上角，重新设置tty的模式... */

	    /*
	     * 解开SIGTSTP的阻塞，因为在我们处理的时候它被阻塞。
	     */
	    sigemptyset(&mask);
	    sigaddset(&mask, SIGTSTP);
	    sigprocmask(SIG_UNBLOCK, &mask, NULL);

	    signal(SIGTSTP, SIG_DFL);   /* 重新设置SIGTSTP的特性为默认 */

	    kill(getpid(), SIGTSTP);    /* 给我们自己发送SIGTSTP信号. */

	    /* 我们不会从kill中返回，直到我们重新继续了 */

	    signal(SIGTSTP, sig_tstp);  /* 重新建立信号处理函数 */

	    /* ... 重新设置tty模式，重新绘制屏幕... */
	}
	int main(void)
	{
	    int     n;
	    char    buf[BUFFSIZE];

	    /*
	     * 只有我们使用作业控制的shell运行的时候才捕获SIGTSTP。
	     */
	    if (signal(SIGTSTP, SIG_IGN) == SIG_DFL)
	        signal(SIGTSTP, sig_tstp);

	    while ((n = read(STDIN_FILENO, buf, BUFFSIZE)) > 0)
	        if (write(STDOUT_FILENO, buf, n) != n)
	            err_sys("write error");

	    if (n < 0)
	        err_sys("read error");

	    exit(0);
	}

	上面例子中的程序，给出了当一个程序处理作业控制的时候，使用的一般的代码次序。这个程序只是简单地把它的标准输入拷贝到它的标准输出，但是，在信号处理函数中，已经用注释给出了用来管理屏幕的程序的典型的动作。当程序启动的时候，只有当SIGTSTP的处理动作被设置为SIG_DFL的时候，它才会捕获SIGTSTP信号。这样的原因是，当程序通过一个不支持作业控制的shell（例如/bin/sh）启动的时候，信号的处理动作应该被设置为SIG_IGN。实际上，shell并不会显示地忽略这个信号，init会设置三个作业控制信号的处理动作(SIGTSTP,SIGTTIN,SIGTTOU)为SIG_IGN。这个动作然后会被所有的登陆shell继承下来。只有作业控制的shell才会设置这三个信号的处理动作为SIG_DFL.

	当我们键入suspend字符的时候，进程接收到SIGTSTP信号，调用信号处理函数。这里，我们做了所有与终端处理相关的动作：将光标移动到左上角，恢复终端模式，等等。我们然后在重新设置SIGTSTP的处理动作为默认的动作（即停止进程）并将它解阻塞之后，给自己发送一个同样的SIGTSTP（我们还得解阻塞这个信号的原因是我们目前正在处理同样的信号）。这样，进程停止了，只有当它接收到SIGCONT的时候（一般这个信号来自作业控制shell,而且是源于一个fg命令），它才继续执行。我们不会捕获SIGCONT信号，它的默认处理动作就是重新开始一个停止了的进程；当发生这个的时候，程序会继续执行，就好象它刚刚从kill中返回一样。当程序继续的时候，我们会重新设置SIGTSTP信号的处理动作，并且做我们想要作的一些终端处理动作（例如我们可以重新绘制屏幕）。

	21)其它的特性
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec21.html
	在这里，我们描述一些和实现相关的额外的信号特性。
	信号名称
	有一些系统使用一个数组：
	extern char *sys_siglist[];
	这个数组的索引就是信号的号码，相应的数组元素指向一个表示信号名称的字符串。
	FreeBSD 5.2.1,Linux 2.4.22,和Mac OS X 10.3提供了这样的信号名称数组。Solaris9也这样做了，但是它使用名字_sys_siglist。这些系统都提供如下的psignal函数：
	#include <signal.h>
	void psignal(int signo, const char *msg);
	字符串msg(一般是程序的名称)会被输出到标准错误输出，然后跟着一个冒号和空格，再跟着信号的描述，和一个换行符号。这个函数和perror非常类似。

	另外一个比较普遍的函数就是strsignal.这个函数和strerror很类似:
	#include <string.h>
	char *strsignal(int signo);
	返回：一个指向描述信号的字符串指针。
	给定一个信号号码，strsignal将会返回一个描述这个信号的字符串，这个字符串可以被应用程序使用，来打印关于接到的信号的错误消息。

	这本书中描述的所有平台，都提供了psignal和strsignal函数，但是有所不同。Solaris 9中，如果信号号码是非法的话，strsignal将会返回一个空指针；FreeBSD 5.2.1，Linux 2.4.22,和Mac OS X 10.3在信号号码未知的时候会返回一个表示信号号码未知的字符串。为了有一个psignal函数的声明，你需要包含<siginfo.h>文件。


	信号映射
	Solaris提供了一对用来在信号号码和信号名称之间映射的函数。
	#include <signal.h>
	int sig2str(int signo, char *str);
	int str2sig(const char *str, int *signop);
	两者返回：如果成功返回0，如果错误返回1。

	这些函数在写打印和接收信号名称和信号号码的交互程序的时候，很有用。
	sig2str函数把指定的信号号码变成一个字符串，并且把结果存放在str指向的内存中。调用这必须保证内存足够大（包含null）.Solaris在<signal.h>里面提供了常量SIG2STR_MAX，用来定义最大字符串长度。字符串将会包含信号的名称（没有SIG前缀）。例如SIGKILL会被映射成"KILL".
	str2sig函数会把指定的名字转换成信号号码。信号号码被存放在一个signop指向的整数指针中。名字可以是没有SIG前缀的字符串，也可以是代表十进制信号值的字符串(例如"9")。
	注意sig2str和str2sig和一般的函数不一样，它门不会设置errno.

	22)总结
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch10lev1sec22.html
	信号在许多重要的应用程序中都有应用。对于高级unix系统编程来说，了解信号处理函数为什么以及如何做的是非常重要的。本章对unix系统的信号部分做了一个比较全面的介绍。我们首先见识了早期系统实现中信号部分的缺陷；然后我们涉及到POSIX.1中的可靠信号概念以及所有相关的函数；当我们把所有这些的细节都说明过了之后，我们就能够编写POSIX.1的abort,system,和sleep函数的实现了；我们最后介绍了作业控制信号和信号名称和信号号码之间的切换。
------
	需要注意的问题：
	1)signal需要在捕获signal的时候重新建立signal连接，是否都这样？而signalaction方式就不许要了？还是新的signal本身就不许要这样了？
	2)sigchld信号是否是wait的时候才进行捕捉？还是不用wait就会捕捉？
	3)上一章的一些库函数摘抄出来。

*关于线程
==========================
	1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch11lev1sec1.html
	我们前面讨论了进程，知道了unix的进程环境，进程之间的关系以及控制进程的方法。我们可以看到，进程间可以进程有限的共享。

	本章，我们将会深入到进程的内部，来看看我们如何在单进程环境中使用多线程控制。所有同一个进程中的线程都可以共享访问例如文件描述符号，内存等进程资源。

	任何时候，你想要在多个用户之间共享单个资源的时候，你都需要处理一致性的问题。我们后面引入了线程的同步机制，防止在它们之间出现共享的资源不一致的情况。

	2)线程的概念
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch11lev1sec2.html
	一个典型的UNIX进程，可以被认为是单线程控制的：每个进程每个时刻只做一件事情。在多线程控制中，我们可以让自己的程序每次做更多的事情，每个线程处理一个任务，这样的方法有许多的好处：
	*我们可以简化可以通过指定一个线程来处理每个事件，来简化对异步事件处理的代码。每个线程之后可以使用一个同步的编程模型来处理它的事件。同步编程模型要比异步简单的多。
	*多进程需要使用操作系统提供的复杂的机制来共享内存和文件描述符号。而多线程的化，可以直接访问同一个进程中的同一个内存地址和文件描述符号。
	*有些问题可以被分割，这样整体的程序吞吐量会提升。而单个进程处理多个任务的话会隐式地将这些任务串行化，因为只有一个线程控制。在多线程控制中，每个线程可以处理独立的任务，独立的任务可以交叉地执行，所谓独立的任务就是它们之间不会相互依赖。
	*类似地，交互程序通过使用多线程技术，可以提升用户的响应时间，主要是把和用户输入输出交互的部分和程序的其它部分别用不同的线程处理。
	有些用户把多线程和多处理器联系起来。实际多线程带来的好处即使是在单个的cpu系统中也是存在的。一个程序可以通过多线程被简化，而不必考虑处理器的数目，因为处理器的数目不会影响程序的结构。另外，只要你的程序在串行任务中被阻塞，你就可能可以通过多线程提高程序吞吐，因为线程在其它线程阻塞的时候还是可以运行的。

	在进程中，一个线程包含了代表一个执行单元的必要的信息，这些信息包含：线程ID（用来标识一个进程中的线程），一系列寄存器的值，一个堆栈，调度优先级和策略，一个signal mask,和errno变量，还有线程相关的数据。所有在一个进程中的东西在线程中都是可以被共享的，包含程序的可执行代码，程序的全局变量和堆内存，堆栈，和文件描述符号。

	我们将要看的线程接口来自POSIX.1-2001.这些线程的接口也被称作“pthreads”（POSIX threads），是POSIX.1-2001中的一个可选的部分。这个特性，可以使用_POSIX_THREADS宏来进行测试。应用程序可以在编译的时候使用#ifdef来测试是否支持线程，也可以在运行的时候使用sysconf的_SC_THREADS常量来确定是否支持线程。


	3)线程标识符号
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch11lev1sec3.html
	就像每个进程都有一个进程ID，每个线程都有线程ID。和进程ID不一样，进程ID在系统中是唯一的；线程ID只有在它所在的进程的上下文中才有意义。

	需要记住的是，进程ID使用pid_t类型来表示，并且它是一个非负的整数。线程ID用pthread_t数据类型来代替，有些实现允许使用一个数据结构来代表pthread_t数据类型，所以可移植的实现不允许把它们做为整数来看待。所以有一个专门用来比较thread ID的函数。

	#include <pthread.h>
	int pthread_equal(pthread_t tid1, pthread_t tid2);
	返回：如果相等返回非0，如果不等返回0。
		Linux2.4.22使用无符号长整数代表pthread_t数据类型。Solaris 9使用pthread_t数据类型是unsigned int. FreeBSD 5.2.1和Mac OS X 10.3使用一个指向pthread数据结构的指针来表示pthread_t数据类型。

	允许pthread_t数据类型是一个结构，这样会导致无法使用一个比较容易移植的方法来打印它的值。有时，在调试程序的时候打印线程ID是很重要的，但是其他时候，一般来说也没有必要非得这么做.最差的时候，会得到一个不可移植的调试程序的代码，所以这也不是一个不能接受的限制。
	线程可以通过调用thread_self函数来获得它自己的线程ID.
	#include <pthread.h>
	pthread_t pthread_self(void);
	返回：调用线程的thread ID.
	这个函数可以和pthread_equal一块使用，来辨别一个数据结构是否是它自己的thread ID.例如一个主线程可能会把工作分配到一个队列上面，使用thread ID来判断那个作业被那个工作线程处理。
	这里给出了一个图示（参见参考资料的网址），图示中，一个单个的主线程将新的作业放到工作队列中，有三个工作线程会把作业从队列中移走。为了可以让每个线程处理队头的作业，主线程在每个作业结构中添加了一个thread ID成员来表示应该处理这个作业的线程，每个线程只会从工作队列中移走它对应的线程ID的工作。


	4)线程创建
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch11lev1sec4.html
	传统的unix进程模型，只支持每个进程只有一个线程控制。在概念上来说，这和基于线程模型的只有一个线程的进程是一样的。使用pthreads,当一个程序运行的时候，它会启动一个只有一个线程的进程，程序运行的时候，如果它不创建新的线程，那么它和传统的unix进程运行没有什么两样.通过pthread_create可以创建线程。
	#include <pthread.h>
	int pthread_create(pthread_t *restrict tidp, const pthread_attr_t *restrict attr,
	                   void *(*start_rtn)(void), void *restrict arg);
	返回0表示成功，失败则返回错误号码。

	当pthread_create函数返回成功的时候，tidp指向新创建的线程的id的内存地址；attr用来自定义各种线程属性，后面会讲到，这里设置为NULL表示采用默认的属性.
	新创建的线程从start_rtn函数指针指向的地址开始运行，arg是传递给这个函数的参数，它是一个无类型的指针，如果想要给函数传递多个参数那么就将参数存放在一个结构体中，把结构体的地址赋给arg.
	当一个线程创建的时候，无法确保是调用线程先运行还是新创建的线程先运行。新创建的线程可以访问进程空间地址，继承调用线程的floating-point环境和signal mask,然而被pending的信号会被清除。
	注意，线程函数失败的时候会返回一个错误码。它不象其他会设置errno变量，为每个线程提供错误码，只是为了兼容使用它们的函数.对于线程来说，从函数中返回错误码是很清晰的做法，这样把错误的范围就只限定在产生这个错误的函数的身上了,而不是通过修改一个全局性质的变量，使得这个函数具有一些副作用。

	举例：
	尽管没有一个打印线程ID的可移植的方法，我们可以自己写一个小的测试程序来实现它，这样可以看到一些线程是如何工作的信息。后面的程序就是创建了一个线程，然后打印进程ID,主线程ID,以及新创建的线程ID.
	为了处理主线程和新线程之间的竞争，这个例子有两个比较奇怪的行为：
	1）主线程需要睡眠一会。如果主线程不睡眠，那么可能在新创建的线程还没有来得及运行的时候主线程就结束了，进而导致整个进程的退出。这个取决于系统的线程功能实现以及调度算法。
	2）新线程是通过pthread_self来获取自己的线程id。新线程不是通过读取共享的内存或者pthread_create的参数(tidp)来获得它的线程id的，因为这样不安全。如果这样使用，那么新创建的线程若先运行的话，那么调用线程还没有来得及初始化这些数据，就会被新线程使用了。
	对于这个例子，具体的代码参见参考资料，我们看到的现象是：
	Solaris中，两个线程的进程id相等，线程id是两个整数。主线程比新线程先运行。
	FreeBSD中，两个线程的进程id相等，线程id是两个相差范围不大的地址。主线程比新线程先运行。
	MacOS X中，两个线程的进程id相等，线程id是两个相差范围很大的地址。主线程比新线程先运行。
	Linux中，两个线程的进程id不相等，线程id是两个整数。新线程比主线程先运行。
	Linux中两个线程的进程id不相等，这是个不足的地方,它是使用特殊参数的clone系统调用来创建子进程，子进程可以通过参数配置共享父进程哪些上下文环境，例如文件描述符号或者内存。
	注意这个例子的现象中我们可以看到，除了linux之外，其他的系统都是主线程先运行。这样我们可以知道我们不能随意假设主线程或者新线程究竟哪个首先被运行。

	5)线程终止
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch11lev1sec5.html
	当进程的任何一个线程调用exit,_exit或者_Exit的时候，整个进程都会被终止。类似地，当信号的默认处理动作是终止进程的时候，给一个线程发送信号会导致整个进程的终止。我们后面会讨论线程和信号的交互。
	正常地终止一个线程而不终止整个进程，有三个方法：
	a)线程从它的起始函数中正常地返回。这时候，线程的退出码就是返回值。
	b)线程被同一个进程中的其他线程取消。
	c)线程调用pthread_exit.

	#include <pthread.h>
	void pthread_exit(void *rval_ptr);
	参数rval_ptr是一个无类型的指针，它可以被进程中的其他线程通过调用pthread_join来使用。

	#include <pthread.h>
	int pthread_join(pthread_t thread, void **rval_ptr);
	如果成功返回0，如果失败，返回错误号码。
	调用这个函数的线程将会阻塞，直到这个函数所指定的线程调用了pthread_exit,或者从其主函数中返回，或者被取消。如果线程从它的主函数中返回，rval_prt将会包含相应的返回码;如果线程被取消，rval_ptr指向的内存地址将会被设置为PTHREAD_CANCELED.
	调用pthread_join会自动地把线程至于detached状态，以便恢复线程的资源（稍后会讲到）。如果线程已经是detached状态了，那么pthread_join会失败并且返回EINVAL.
	如果我们对线程的返回值不感兴趣，那么我们可以把rval_ptr设置为空，这样会等待指定的线程但是不获取线程的退出状态。

	举例

	void *thr_fn1(void *arg)
	{
		printf("thread 1 returning\n");
		return((void *)1);
	}

	void *thr_fn2(void *arg)
	{
		printf("thread 2 exiting\n");
		pthread_exit((void *)2);
	}

	int main(void)
	{
		int         err;
		pthread_t   tid1, tid2;
		void        *tret;

		err = pthread_create(&tid1, NULL, thr_fn1, NULL);
		if (err != 0)
			err_quit("can't create thread 1: %s\n", strerror(err));//一个出了错就退出程序的函数.
		err = pthread_create(&tid2, NULL, thr_fn2, NULL);
		if (err != 0)
			err_quit("can't create thread 2: %s\n", strerror(err));
		err = pthread_join(tid1, &tret);
		if (err != 0)
			err_quit("can't join with thread 1: %s\n", strerror(err));
		printf("thread 1 exit code %d\n", (int)tret);
		err = pthread_join(tid2, &tret);
		if (err != 0)
			err_quit("can't join with thread 2: %s\n", strerror(err));
		printf("thread 2 exit code %d\n", (int)tret);
		exit(0);
	}

	运行如下：
	$ ./a.out
	    thread 1 returning
	    thread 2 exiting
	    thread 1 exit code 1
	    thread 2 exit code 2

	可以看出，一个线程如果从start函数中退出，或者调用pthread_exit退出，那么其他的进程可以通过pthread_join来获取进程的结束状态。
	我们可以给pthread_create和pthread_exit传递一个无类型的指针，这样指针可以指向复杂的结构，包含更多得信息。需要注意的是当线程结束的时候，指针指向的位置应该还是合法的。如果指针指向的位置是在栈上面分配的，那么当线程结束之后，栈内容就不确定了。而调用pthread_join的调用者却使用了刚才栈所在地址的内容。

	线程可以通过调用pthread_cancel函数请求同一个进程中的其他线程被取消。
	#include <pthread.h>
	int pthread_cancel(pthread_t tid);
	返回值：0表示成功，错误码表示失败。
	默认情况下pthread_cancel调用和线程tid自己调用具有PTHREAD_CANCELED参数的pthread_exit。线程可以选择忽略其他线程对它的取消，以及选择如何被取消以后会讲到。然而pthread_cancel不会等待线程结束，它只是做一个请求。

	线程可以设置退出时候调用的函数，这个和进程使用atexit函数设置进程退出时候调用得函数类似。这些函数叫做“线程清理函数”，可以为线程设置多个清理函数，这些清理函数被记录在栈中，这也意味这这些函数的调用次序和它们被注册的次序相反。
	#include <pthread.h>
	void pthread_cleanup_push(void (*rtn)(void *), void *arg);
	void pthread_cleanup_pop(int execute);
	当线程执行如下动作的时候，pthread_cleanup_push会调度清理函数，函数由rtn指向并且参数是arg:
	a)调用pthread_exit
	b)响应取消请求
	c)使用非0的execute参数调用pthread_cleanup_pop.
	当pthread_cleanup_pop参数为0的时候，不会调用清理函数，这个时候会把最后一次调用pthread_cleanup_push的函数去掉。
	这些函数的使用限制就是它们是使用宏实现的，它们必须在一个线程的同一个作用域内成对匹配使用，pthread_cleanup_push宏包含是一个'{',pthread_cleanup_pop宏包含一个'}'。

	举例：
	void cleanup(void *arg)
	{
	    printf("cleanup: %s\n", (char *)arg);
	}

	void * thr_fn1(void *arg)
	{
	    printf("thread 1 start\n");
	    pthread_cleanup_push(cleanup, "thread 1 first handler");
	    pthread_cleanup_push(cleanup, "thread 1 second handler");
	    printf("thread 1 push complete\n");
	    if (arg)
	        return((void *)1);
	    pthread_cleanup_pop(0);
	    pthread_cleanup_pop(0);
	    return((void *)1);
	}

	void * thr_fn2(void *arg)
	{
	    printf("thread 2 start\n");
	    pthread_cleanup_push(cleanup, "thread 2 first handler");
	    pthread_cleanup_push(cleanup, "thread 2 second handler");
	    printf("thread 2 push complete\n");
	    if (arg)
	        pthread_exit((void *)2);
	    pthread_cleanup_pop(0);
	    pthread_cleanup_pop(0);
	    pthread_exit((void *)2);
	}

	int main(void)
	{
	    int         err;
	    pthread_t   tid1, tid2;
	    void        *tret;

	    err = pthread_create(&tid1, NULL, thr_fn1, (void *)1);
	    if (err != 0)
	        err_quit("can't create thread 1: %s\n", strerror(err));
	    err = pthread_create(&tid2, NULL, thr_fn2, (void *)1);
	    if (err != 0)
	        err_quit("can't create thread 2: %s\n", strerror(err));
	    err = pthread_join(tid1, &tret);
	      if (err != 0)
	        err_quit("can't join with thread 1: %s\n", strerror(err));
	    printf("thread 1 exit code %d\n", (int)tret);
	    err = pthread_join(tid2, &tret);
	    if (err != 0)
	        err_quit("can't join with thread 2: %s\n", strerror(err));
	    printf("thread 2 exit code %d\n", (int)tret);
	    exit(0);
	}

	上面的例子展示了如何使用线程的清理函数。需要注意的是尽管我们没有打算给线程的启动函数传递非0参数，我们还是需要调用pthread_cleanup_pop函数来匹配pthread_cleanup_push函数，否则程序无法编译通过。

	运行这个程序的输出是：
	$ ./a.out
	thread 1 start
	thread 1 push complete
	thread 2 start
	thread 2 push complete
	cleanup: thread 2 second handler
	cleanup: thread 2 first handler
	thread 1 exit code 1
	thread 2 exit code 2
	从输出中我们可以看到，两个线程都正常地启动和退出了，但是只有第二个线程调用了清理函数。因此，如果线程是通过从启动函数中正常返回而终止的话，就不会执行清理函数。并且我们也应该注意启动函数的调用次序和它们被安装的次序是相反的。

	实际线程和进程有许多类似的函数，参考资料列出了一个表格可以对比，这里就不给出了。
	默认来说，一个线程的终止状态会一直保留到pthread_join被调用。一个终止的线程所占的内存会在detached的时候立即被回收，当一个线程被detached的时候，不能使用pthread_join函数等待获取它的终止状态。对一个detached的线程调用pthread_join会失败，并且返回EINVAL。我们可以使用pthread_detach来将一个线程detach.

	#include <pthread.h>
	int pthread_detach(pthread_t tid);
	返回：如果成功返回0，如果失败返回错误编号。
	后面我们可以看到，我们可以通过修改传递给pthread_create的线程属性参数来建立一个开始就处于detached状态的线程。

	6)线程同步
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch11lev1sec6.html
	当多个线程共享同一片内存的时候，我们需要保证每个线程看到的数据是一致的。如果线程使用的变量没有被其他线程使用，那么不会存在一致性的问题。类似，如果一个变量是只读，那么多个线程同时访问也不会出现一致性的问题。然而当有一个线程可以修改这个变量，而这个变量同时也可以被其他的线程修改和读取的时候，我们需要在线程之间进行同步，来保证它们访问变量内存的内容的时候的数据是合法的。

	当一个线程修改变量的时候，别的读取这个变量的线程会潜在地遭遇不一致的情况。在修改操作占用多于一个存储周期的处理器架构上面，这个情况在两次写周期之间进行读内存的时候很容易发生。虽然这个取决于处理器架构，但是一个可移植的程序不能对使用的处理器的架构做任何的假设。

	文中先给出了一个简单的情况:
	线程A:读－写－写
	线程B:-----读----
	当B的读发生在A的两个写周期之间的时候，A，B就存在不一致性的问题了。
	图中先给了一个解决方案：规定在访问变量之前，先对变量进行加锁。这样当一进程持有锁的时候，其它申请锁将被阻塞。
	然后又给出了一些其它导致不一致的情况的例子，具体参见参考资料以及其中的图示。

	mutex(互斥信号量)
	通过使用pthreads中的互斥信号量接口，我们可以保护我们的数据，保证同一个时间，只有一个线程访问我们的数据。实际，mutex就是我们访问共享资源设置的以及使用完共享资源时释放的锁。如果我们解锁mutex的时候有多余一个线程处于阻塞状态，那么所有在这个锁上面阻塞的线程都变成可执行，然后第一个运行的将会设置锁，其他的看到锁被设置了就继续返回阻塞等待锁的下一回释放了。这样，在一个时间里面，只有一个线程在执行。

	要想使用互斥机制，我们需要自己设计数据访问规则。操作系统不会将我们的数据访问串行化。如果我们的一个线程访问数据的时候没有获取锁那么即使其他的线程加锁，也会出现不一致的情况。

	mutex变量用数据类型pthread_mutex_t数据类型替代，在我们使用mutex变量之前，我们必须首先将它用常量PTHREAD_MUTEX_INITIALIZER初始化（只用于静态分配的mutex）或者用pthread_mutex_init初始化。如果我们动态分配mutex（例如通过malloc），我们需要在释放内存之前调用pthread_mutex_destroy。

	#include <pthread.h>
	int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);
	int pthread_mutex_destroy(pthread_mutex_t *mutex);
	返回：如果成功，两者返回0；如果失败，返回错误码。
	我们可以把参数attr设置为NULL这样，就会使用默认的初始值。以后讨论非默认的mutex属性。

	下面的函数用来对mutex进行加锁或者解锁。
	#include <pthread.h>
	int pthread_mutex_lock(pthread_mutex_t *mutex);
	int pthread_mutex_trylock(pthread_mutex_t *mutex);
	int pthread_mutex_unlock(pthread_mutex_t *mutex);
	如果一个线程无法接受被阻塞，那么可以使用pthread_mutex_trylock有条件地添加锁。这样，如果调用pthread_mutex_trylock的时候mutex没有被上锁，那么将会正常一样上锁并且返回0；如果之前mutex被上了锁，那么pthread_mutex_trylock将会失败并且立即返回EBUSY。

	举例：
	#include <stdlib.h>
	#include <pthread.h>
	struct foo {
	    int             f_count;
	    pthread_mutex_t f_lock;
	    /* ... more stuff here ... */
	};

	struct foo *foo_alloc(void) /* allocate the object */
	{
	    struct foo *fp;

	    if ((fp = malloc(sizeof(struct foo))) != NULL) {
	        fp->f_count = 1;
	        if (pthread_mutex_init(&fp->f_lock, NULL) != 0) {
	            free(fp);
	            return(NULL);
	        }
	        /* ... continue initialization ... */
	    }
	    return(fp);
	}

	void foo_hold(struct foo *fp) /* add a reference to the object */
	{
	    pthread_mutex_lock(&fp->f_lock);
	    fp->f_count++;
	    pthread_mutex_unlock(&fp->f_lock);
	}

	void foo_rele(struct foo *fp) /* release a reference to the object */
	{
	    pthread_mutex_lock(&fp->f_lock);
	    if (--fp->f_count == 0) { /* last reference */
	        pthread_mutex_unlock(&fp->f_lock);
	        pthread_mutex_destroy(&fp->f_lock);
	        free(fp);
	    } else {
	        pthread_mutex_unlock(&fp->f_lock);
	    }
	}
	这个例子使用mutex来保护一个数据结构，当有多个线程访问一个动态分配的对象的时候，我们可以给这个对象内嵌一个引用计数保护对象不会在线程被访问的时候被释放。
	在增加，减少，以及检查引用计数是否为0的时候，我们都会锁住mutex来保护它，最开始foo_alloc初始化的时设置引用计数为1的时候，不用设置这个锁保护，因为此时只有分配空间的那个线程引用它。如果这时候我们把这个结构放到一个链表中，那么它可以被其他线程找到，我们需要先为它加锁。
	在使用这个对象之前，线程要增加这个结构对象的引用计数；用完之后要减少引用计数；当引用计数为0的时候，要释放结构对象的内存空间。

	死锁的避免
	当线程将要尝试对同一个信号两次加锁的时候，它会产生死锁但是实际上，由于mutex而产生死锁这个现象发生的很不明显。例如：我们在程序中使用了一个以上的互斥信号量，如果第一个线程在持有第一个互斥信号量的时候再申请第二个互斥信号量，而第二个互斥信号量被第二个线程持有并且第二个线程想要加锁第一个互斥信号量；这样两个线程都无法继续了，它们都互相等待对方持有的资源，这时发生的现象就叫做死锁。

	死锁可以通过仔细控制信号量加锁的次序来避免。例如：假设你有两个互斥信号量A和B。如果所有的线程都首先给A加锁然后才给B加锁，那么对于这两个互斥信号量之间将不会发生死锁的现象（当然你有可能在其它的信号量上面发生死锁），只有当存在其它的线程对A，B加锁的次序相反的时候，才有可能会产生死锁。

	有时一个应用程序的体系使得很难将一个特定顺序的加锁应用在它的身上。如果包含了足够的锁和数据结构，而你的函数还是无法用一个简单的方法来实现，那么应该换一个思路。这个时候，你兴许可以把你的锁释放，然后在稍后的一个时间尝试。你可以使用pthread_mutex_trylock来避免死锁。如果你已经成功的持有了pthread_mutex_trylock，那么你可以继续。如果没有，你可以释放你已经持有的资源，并且清理其它的工作，一会再尝试。

	举例
	具体的例子不多说了，参见参考资料的源代码。这里主要是给了两个例子，都使用两个信号量。为了避免死锁，在添加信号量的时候都按照相同的次序加锁。第一个例子锁的粒度比较细，导致程序代码结构有点复杂，但是性能应该更好；第二个例子锁的粒度比较粗，性能相对差一些，但是代码结构很简单。


	读写锁
	读写锁和互斥信号量类似，但是读写锁允许更高程度的并行。使用互斥信号量的状态只能是锁和非锁两种状态，并且在一个时间只有一个线程可以拥有锁。读写锁有三种可能的状态：读锁，写锁，和解锁。同一时刻只能有一个线程可以有写锁的状态，但是可以有多个线程处于读锁的状态。
	当读写锁被处于写锁的时候，所有尝试加锁（无论是写锁还是读锁）的线程都会阻塞直到写锁释放；当处于读锁状态的时候，所有尝试加读锁的线程都会允许加锁，但任何尝试加读锁的线程都会被阻塞直到所有线程的读锁被释放。(有一句不太确定的原句，没有翻译，如下： Although implementations vary, readerwriter locks usually block additional readers if a lock is already held in read mode and a thread is blocked trying to acquire the lock in write mode. This prevents a constant stream of readers from starving waiting writers.)


	读写锁适合读取操作比修改操作频繁的情况。读写锁也叫共享互斥锁。当一个读写所处于读锁状态的时候，它处于共享模式；当处于写锁状态的时候，它处于互斥模式。
	和互斥信号量类似，读写锁也需要初始化之后才能使用。
	#include <pthread.h>
	int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr);
	int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
	函数成功返回0，失败返回错误号码。
	读写锁通过调用pthread_rwlock_init来进行初始化，如果使用默认的属性，我们可以给attr传递一个空指针，我们后面会讨论读写锁的属性。

	在释放读写锁占用的内存之前，我们需要调用pthread_rwlock_destroy来清除它。如果pthread_rwlock_init为读写锁分配了任何的内存，那么pthread_rwlock_destroy就会释放这些资源。如果我们没有调用pthread_rwlock_destroy就直接释放读写锁的内存，那那么读写锁之前占用的那些额外的资源就会丢失。

	为了让一个读写锁处于读模式，我们调用pthread_rwlock_rdlock函数；使它处于写模式，我们需要调用pthread_rwlock_wrlock。无论我们处于什么锁模式，我们都使用pthread_rwlock_unlock来释放读写锁。

	#include <pthread.h>
	int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
	int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
	int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
	函数成功返回0，失败返回错误号码。
	系统实现，可能会对读写锁的共享模式数量有所限制，所以我们需要检查pthread_rwlock_rdlock的返回。尽管pthread_rwlock_wrlock和pthread_rwlock_unlock有错误的返回码，如果我们设计妥当，我们就不许要检查其返回，只有我们不正确地使用它们的时候才会返回定义的错误码，例如使用一个没有初始化的锁，或者当我们请求了一个我们已经持有的锁导致死锁的时候。

	Single UNIX Specification也定义了有条件的读写锁。
	#include <pthread.h>
	int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock);
	int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock);
	正确返回0，失败返回错误号码。
	如果能够获取到锁，这两个函数就会返回0，如果不能获取到锁，这两个函数就会返回错误码EBUSY。这些函数使用的情况和前面的类似。
	举例：
	例子参见相应的参考资料。这个例子是通过一个读写锁来保护一系列的工作请求队列。当有作业被插入，删除到队列中的时候，加写锁；如果只是查询队列中的作业，那么只需要读锁。

	条件变量
	条件变量是另外一个用于线程的同步机制。条件变量提供一个线程同步的点，当使用互斥信号量的时候，条件变量允许线程以一种无竞争的方式等待任何条件的发生。
	条件本身被互斥信号量保护，线程改变条件状态的时候必须先锁住这个信号。其它线程在请求信号量之前，不会注意到条件的变化，因为锁住互斥信号量才能对条件进行检测。
	使用条件变量之前，必须首先对这个条件变量进行初始化。条件变量使用数据结构pthread_cond_t来进行表示。我们可以把常量PTHREAD_COND_INITIALIZER分配给静态分配的条件变量，但是如果我们采用动态的方式分配条件变量那么我们使用pthread_cond_init函数对它进行初始化。
	在释放条件变量所占用的内存空间的之前我们可以使用函数pthread_mutex_destroy对这个条件变量进行反初始化。
	#include <pthread.h>
	int pthread_cond_init(pthread_cond_t *restrict cond, pthread_condattr_t *restrict attr);
	int pthread_cond_destroy(pthread_cond_t *cond);
	两者在成功的时候都返回0，如果失败会返回错误码。
	这里如果想要创建一个使用默认的属性的条件变量，那么我们就给pthread_cond_init函数的attr参数传递NULL指针。

	我们使用pthread_cond_wait来等待条件为true，如果在一定的时间之内条件没有被满足，那么会返回一个错误号码到一个指定的变量中。
	#include <pthread.h>
	int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);

	int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex,
						const struct timespec *restrict timeout);
	两个函数如果成功都返回0，如果失败则返回一个错误号码。
	传递给函数pthread_cond_wait的互斥信号量mutex会保护这个条件。调用者把已经锁住的信号量传递给函数，这个函数原子性地把调用线程放到等待这个条件变量的线程等待队列上面，然后解锁这个互斥信号量。这样就把检测条件变量和线程为了等待条件变化而进入睡眠之间的时间窗口关闭了，这样线程不会错过条件的变化(因为检测到条件不行，才会解锁让其它线程有机会修改条件使之满足)。当pthread_cond_wait返回的时候，mutex会再次被锁住(因为条件满足了，所以再次锁住，继续后面的操作)。（这里可能比较难理解，总之是在这个函数的内部先在检查完条件并且等待之后做了一步解锁操作，收到满足条件的通知之后继续执行准备返回但是返回前又加锁了,看后面的例子会比较容易明白）
	函数pthread_cond_timedwait和pthread_cond_wait 的功能类似，但是它设置了一个超时的机制，指定我们等待的时间。这个时间通过timespec结构来表示，
	struct timespec {
		time_t tv_sec;   /* seconds */
		long   tv_nsec;  /* nanoseconds */
	};
	使用这个结构，我们需要使用绝对时间值来指定我们将要等待多久，而不是一个相对的时间值。例如，我们想要等待3分钟，我们不是给这个结构赋值为3分钟，而是把now+3这个时间赋值给它。
	我们可以使用gettimeofday来获取使用timeval结构表示的当前时间，然后把这个结构转化成timespec结构，来获取绝对的时间值。函数如下：
	void maketimeout(struct timespec *tsp, long minutes)
	{
		struct timeval now;

		/* 获取当前时间 */
		gettimeofday(&now);

		/*把timeval表示的时间转换成timespec结构表示的时间*/
		tsp->tv_sec = now.tv_sec;
		tsp->tv_nsec = now.tv_usec * 1000; /* 微秒转换成纳秒 */

		/* 为当前时间增加超时等待时长*/
		tsp->tv_sec += minutes * 60;
	}
	如果超时了条件也没有满足，那么pthread_cond_timewait将会重新请求互斥信号量并且返回ETIMEDOUT。当pthread_cond_wait和pthread_cond_timedwait成功返回的时候，需要一个线程重新估计条件值，因为可能另外有线程已经运行并且改变了条件。
	有两个函数用来通知线程一个条件已经被满足了。pthread_cond_signal函数将会唤醒一个等待在一个条件上面的线程;pthread_cond_broadcast函数将会唤醒所有的线程等待一个条件。
		POSIX标准允许pthread_cond_signal的实现唤醒不止一个线程，这样会使得实现更为简单。
	#include <pthread.h>
	int pthread_cond_signal(pthread_cond_t *cond);
	int pthread_cond_broadcast(pthread_cond_t *cond);
	两者如果成功返回0，如果失败返回错误号码。
	当我们调用pthread_cond_signal或者pthread_cond_broadcast的时候，也就是说我们将会给线程或者条件发送信号。我们需要足够地仔细，只能在修改了条件状态的时候才给线程发送信号。

	举例：
	条件变量的使用方法如下：
	#include <pthread.h>
	struct msg {
	    struct msg *m_next;
	    /* ... more stuff here ... */
	};
	struct msg *workq;
	pthread_cond_t qready = PTHREAD_COND_INITIALIZER;
	pthread_mutex_t qlock = PTHREAD_MUTEX_INITIALIZER;

	void process_msg(void) {
	    struct msg *mp;

	    for (;;) {
	        pthread_mutex_lock(&qlock);/*这里是互斥相关，因为需要访问工作队列，所以进行操作之前首先上锁，保证其他线程不能再修改了*/
	        while (workq == NULL)
	            pthread_cond_wait(&qready, &qlock);/*这里是同步相关，发现队列为空，所以在相应的条件变量上面等待，等待函数的内部实际做的操作是检测并且将线程置于等待队列之后再解开锁便于其它线程修改工作队列使条件满足*/
	        mp = workq;/*到这里表示刚才解锁等待的时候有线程修改了工作队列并且通知本线程条件满足了，于是从前面的等待函数中返回，并且返回之前再将刚才解开的锁重新加上，防止之后的修改期间又有其他线程干扰*/
	        workq = mp->m_next;
	        pthread_mutex_unlock(&qlock);/*修改之后真正地解开锁*/
	        /* now process the message mp */
	    }
	}

	void enqueue_msg(struct msg *mp) {
	    pthread_mutex_lock(&qlock);/*这里是互斥相关，准备修改工作队列，所以加锁*/
	    mp->m_next = workq;
	    workq = mp;
	    pthread_mutex_unlock(&qlock);
	    pthread_cond_signal(&qready);/*这里是同步相关，通知队列状态的变化给等待的线程*/
	}

	上面的例子，展示了如何使用条件变量和互斥信号量一起来实现线程之间的同步。
	条件用来表示工作队列(work queue)的状态。我们通过互斥信号量来保护条件并且通过一个while循环来对条件进行检测。当我们把一个消息放到工作队列上(work queue)的时候，我们需要持有这个互斥信号量，但是我们再条件满足通知等待线程的时候不需要持有这个互斥信号量。只要线程在我们调用cond_signal之前将消息推送至工作队列，我们就可以释放互斥信号量。因为我们是在一个while循环中检查这个条件，所以不会导致问题：线程将会醒来，发现队列还是空的，然后又继续进入等待状态了。如果代码无法忍受这个竞争（比如没有那个while循环???），那么我们将需要在发送信号给线程的时候也持有这个锁。

	7)总结
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch11lev1sec7.html
	这一章里面我们介绍了线程相关的内容，讨论了创建和销毁一个线程的POSIX相关函数。我们也介绍了线程的同步。我们讨论了三个基本的同步机制，互斥信号量，读写锁，以及条件变量，同时我们也看到了我们是如何利用它们来保护共享资源的。

*线程控制
==========================
	1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec1.html
	前面我们讲述了和线程以及线程同步相关的基础知识，本章我们将学习对线程的具体控制。我们会看到一些线程和线程同步相关的一些属性，而这些属性在前面的章节中都是忽略没有谈到的（通过只使用其默认值而略去不谈的）。
	接下来，我们讨论同一进程中的线程如何和其他的线程保持数据的私有性。然后我们谈到了一些基于进程的系统调用如何和线程进行交互来结束本章。

	2)线程限制
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec2.html
	前面我们讲述过sysconf函数，一些和线程相关的资源限制，可以通过这个函数来获取，本文列出了一些线程的资源限制。具体参见参考资料。大致描述如下：
	PTHREAD_DESTRUCTOR_ITERATIONS:通过给sysconf传递参数_SC_THREAD_DESTRUCTOR_ITERATIONS来获得，描述了线程退出的时候，需要尝试析构线程相关数据的最大尝试次数。
	PTHREAD_KEYS_MAX:通过给sysconf传递参数_SC_THREAD_KEYS_MAX获取，描述了一个进程可以创建的key的最大数目。
	PTHREAD_STACK_MIN:通过给sysconf传递参数_SC_THREAD_KEYS_MAX获取，描述了线程栈可以使用的最小字节数目。
	PTHREAD_THREADS_MAX:通过给sysconf传递参数_SC_THREAD_THREADS_MAX获取，描述了进程中可以创建的最大的线程数目。

	通过使用sysconf获取的限制，可以让程序在不同的操作系统上面的可移植性增强。例如，如果每管理一个文件就需要4个线程而系统不能提供足够的线程，你就需要限制文件的数目了。

	书中也给出了这些限制在本书中的四个系统上面的具体数值，这里就不列举了。我们需要知道的一个就是，尽管系统没有提供访问这些限制的方法，但是这并不意味这系统没有这些限制，只是表示系统没有给我们提供访问这些限制的方法。

	3)线程属性
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec3.html
	在前面我们使用pthread_create函数的时候，我们都在其pthread_attr_t参数的位置传入了一个NULL指针。我们可以使用一个pthread_attr_t结构变量来修改线程的默认属性，在创建线程的时候将属性和线程相关联。
	#include <pthread.h>
	int pthread_attr_init(pthread_attr_t *attr);
	int pthread_attr_destroy(pthread_attr_t   *attr);
	两个函数当成功的时候返回0，失败的时候返回错误号码。
	我们使用pthread_attr_init函数来初始化pthread_attr_t结构，调用完pthread_attr_init函数之后，pthread_attr_t将会包含所有线程具有的默认属性。如果想要修改特定的属性，我们可以调用相应的特定函数后面会对这些函数进行讲解。
	我们使用pthread_attr_destroy来反初始化一个pthread_attr_t结构，如果pthread_attr_init为属性对象分配了一些动态的空间，那么pthread_attr_destroy将会把这些内存释放。另外pthread_attr_destroy会把属性对象初始化成一个非法的值，这样如果错误地使用了它，那么pthread_create将会返回错误。
	pthread_attr_t属性对应用程序来说是封装好了的，应用程序不需要知道这个结构的内部是如何实现的，这提高了程序的可移植性质。POSIX.1定义了一些独立的函数来获取或者设置这些属性。
	参考资料中列出了POSIX.1定义的一些线程的属性，POSIX.1也定义了一些使用real-time线程选项时候的额外属性，但是这里不对它们进行讨论。资料中也列出了那些属性在那些平台上面是可用的以及在哪些平台上可以通过一些废弃的接口来进行访问等等，下面只列出这些属性以及含义，具体请参考参考资料。
	detachstate:这个属性描述线程是否处于detached状态。
	guardsize:线程栈结尾哨兵缓存的字节大小。
	stackaddr:线程栈的最低地址。
	stacksize:线程栈的字节大小。
	前面我们介绍了线程的detached的概念，如果我们不关心已经存在的线程的结束状态，那么我们可以调用pthread_detach函数让操作系统在线程结束的时候回收线程所占有的资源。

	如果我们在创建线程的时候就知道我们对线程的结束状态不关心，那么我们可以通过修改线程属性结构pthread_attr_t的detachstate属性（成员），让线程在启动的时候就处于detached状态。我们可以通过pthread_attr_setdetachstate函数来修改线程的属性，可以设置成两种值：PTHREAD_CREATE_DETACHED表示可以以detached的状态启动一个线程;以及PTHREAD_CREATE_JOINABLE表示正常启动一个线程，这样线程结束时应用程序可以获取线程的终止状态。
	#include <pthread.h>
	int pthread_attr_getdetachstate(const pthread_attr_t *restrict attr, int *detachstate);
	int pthread_attr_setdetachstate(pthread_attr_t *attr, int detachstate);
	两个函数成功的时候都返回0，失败的时候返回错误号码。
	我们可以通过调用pthread_attr_getdetachstate来获取线程当前的detached状态，获取的状态存放在第二个整数指针的参数里面，它的值取决于给定的pthread_attr_t结构，可以为PTHREAD_CREATE_DETACHED或者PTHREAD_CREATE_JOINABLE。
	举例：
	一个创建deatched的线程的函数的例子：
	#include "apue.h"
	#include <pthread.h>

	int makethread(void *(*fn)(void *), void *arg)
	{
		int             err;
		pthread_t       tid;
		pthread_attr_t  attr;

		err = pthread_attr_init(&attr);
		if (err != 0)
			return(err);
		err = pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);
		if (err == 0)
			err = pthread_create(&tid, &attr, fn, arg);
		pthread_attr_destroy(&attr);
		return(err);
	}


	注意，我们忽略了从pthread_attr_destroy的返回值。在这个case里面，我们对线程的属性做了适当的初始化，所以pthread_attr_destroy没有失败。虽然如此，但是如果真的失败了，那么清理的工作会很困难：我们需要首先析构我们刚刚创建的线程，这个线程很可能已经运行了，并且和当前的函数是异步执行的。通过忽略pthread_attr_destroy的错误返回，最差的情况就是如果pthread_attr_init分配了任何的内存那么会泄露一小部分内存。但是如果pthread_attr_init成功地初始化了线程的属性之后pthread_attr_destroy没有成功地清理，那么我们没有任何方法可以恢复，因为属性的结构对于应用程序来说是不可见的。总之，只有pthread_attr_destroy这个接口可以清理这个结构，要是它也失败了，那就没有办法了。

	支持线程栈属性对于POSIX的操作系统来说是可选的，但是对于XSI的系统来说确实需要的。在编译的期间，你可以检查_POSIX_THREAD_ATTR_STACKADDR和_POSIX_THREAD_ATTR_STACKSIZE标号来确定你的线程是否支持这些堆栈属性，如果有相应的定义，那么线程就支持相应的属性。也可以在运行期间通过传入参数_SC_THREAD_ATTR_STACKADDR和_SC_THREAD_ATTR_STACKSIZE对sysconf函数进行调用来进行检测。

	POSIX.1定义了一些可以操作堆栈属性的接口，pthread_attr_getstackaddr和pthread_attr_setstackaddr是两个比较旧的函数，在Single UNIX Specification 3中已经标记它们为作废，最好不要使用它们了，应该使用pthread_attr_getstack和pthread_attr_setstack做为替代的方法。这样可以消除一些旧接口的二义性。
	#include <pthread.h>
	int pthread_attr_getstack(const pthread_attr_t *restrict attr, void **restrict stackaddr, size_t *restrict stacksize);
	int pthread_attr_setstack(const pthread_attr_t *attr, void *stackaddr, size_t *stacksize);
	两个函数成功的时候返回0，失败的时候返回错误号码。
	这两个函数可以用来操作stackaddr和stacksize的线程属性。
	在进程中的虚拟地址空间是固定的，因为只有一个堆栈所以大小一般不会存在问题。但是如果在线程的环境下，所有的线程共享同一个虚拟地址空间。如果你的应用程序使用了过多的线程，那么这些线程的总共的堆栈大小可能会超过总共的虚拟地址空间的大小，这个时候你可能需要减小你的线程的默认堆栈的大小。另外，如果你的线程调用函数分配了很大的自动化变量或者调用函数的堆栈祯层次很深，那么你可能会需要比默认堆栈大小更多的堆栈空间。
	如果你的进程会由于线程堆栈消耗光地址空间，那么可以使用malloc或者mmap来分配空间做为备选的堆栈空间，并且使用pthread_attr_setstack设置线程的堆栈地址为你刚才创建的空间的地址。通过参数stackaddr设置的地址必须是内存中可以访问的地址中的最低地址，并且根据处理器的架构进行了相应的对齐。
	stackaddr属性被定义为堆栈的内存最低地址，但是不一定是堆栈的最开始地址，因为如果给定的处理器结构的堆栈增长方向是从高地址向低地址增长的话stackaddr属性表示的就是堆栈的末尾而不是开始。
	原来的pthread_attr_getstackaddr和pthread_attr_setstackaddr的一个缺陷就是，stackaddr是无法确定的，它可能会被解释为堆栈的起始或者被堆栈使用的最低内存地址.如果堆栈增长方向是从高向低增长的并且stackaddr参数指向的是内存的低地址，这时候你需要知道堆栈的大小来确定堆栈的起始位置。而替代它们的pthread_attr_getstack和pthread_attr_setstack就解决了这个问题。

	应用程序可以使用pthread_attr_getstacksize和pthread_attr_setstacksize来获取和设置堆栈的大小。
	#include <pthread.h>
	int pthread_attr_getstacksize(const pthread_attr_t *restrict attr, size_t *restrict stacksize);
	int pthread_attr_setstacksize(pthread_attr_t *attr , size_t stacksize);
	pthread_attr_setstacksize函数可以用来改变默认的堆栈大小，并且我们也不用亲自处理线程堆栈的空间分配问题。

	guardsize线程属性控制线程结尾的扩展内存的大小，保护堆栈溢出。默认被设置为PAGESIZE字节。我们可以设置guardsize线程属性为0来禁止这个特性：即没有guardbuffer.当然，如果我们改变了线程的stackaddr属性，那么系统假设我们会自己管理我们的堆栈，并且禁止guard缓存，这就像我们已经将guardsize线程属性设置成0一样。
	#include <pthread.h>
	int pthread_attr_getguardsize(const pthread_attr_t *restrict attr, size_t *restrict guardsize);
	int pthread_attr_setguardsize(pthread_attr_t *attr , size_t guardsize);
	如果线程的guardsize属性被修改了，那么操作系统会自动对它们“向上取整”设置为页大小的整数倍。如果线程的堆栈指针溢出到guard区域，那么应用程序将会接受到错误，可能会伴随这一个信号。
	Single UNIX Specification定义了一些其他的可选的线程属性作为real-time线程选项的一个部分，我们这里不会讨论它们。

	更多的线程属性
	Threads have other attributes not represented by the pthread_attr_t structure:
	线程还有许多在pthread_attr_t结构之外的线程属性：

	*取消状态(后面讲)
	*取消类型(后面讲)
	*并发度
		并发度控制用户层线程映射的底部的内核线程或者进程的数目。如果一个实现其用户线程和内核级线程映射关系是一对一的，那么改变并发程度并没有什么效果（因为可能所有的用户级的线程被调度了???）。然而，在内核线程或者进程的上面如果映射了多个用户线程，那么我们可能就能够通过提高在一段时间内用户层线程的数目来提高性能。函数pthread_setconcurrency可以提示系统使用需要的并发度。
	#include <pthread.h>
	int pthread_getconcurrency(void);
	返回：当前的并发度。
	int pthread_setconcurrency(int level);
	如果成功返回0，如果失败返回错误号码。
	函数pthread_getconcurrency返回当前并发度，如果操作系统控制并发程度（也就是说没有之前的pthread_setconcurrency调用），那么这个函数将会返回0。
	通过pthread_setconcurrency来指定的并发度，实际只是给操作系统的一个提示。我们不能保证设置的并发度一定会被采纳,只是告诉操作系统应用程序想要采用除了0之外的其他并发度。所以，应用程序也可以通过调用参数为0的pthread_setconcurrency来取消之前用非零参数对它的调用。

	4)同步属性
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec4.html
	和线程属性类似，同步对象也有同步属性。在这里，将要介绍mutexes, readerwriter locks, 和 condition variables的相关属性。

	*Mutex属性
	我们使用pthread_mutexattr_init函数来初始化pthread_mutexattr_t结构，pthread_mutexattr_destroy来反初始化结构。
	#include <pthread.h>
	int pthread_mutexattr_init(pthread_mutexattr_t *attr);
	int pthread_mutexattr_destroy(pthread_mutexattr_t *attr);
	两者在成功的时候都返回0，失败的时候返回错误号码。
	函数pthread_mutexattr_init会使用默认的值来初始化这个Mutex（互斥信号量）属性结构,这里有两个重要的属性就是process-shared属性和type属性。在POSIX.1中，process-shared属性是可选的，可以在编译期间检查_POSIX_THREAD_PROCESS_SHARED来看是否支持这个选项或者运行期间调用_SC_THREAD_PROCESS_SHARED 参数的sysconf函数来进行检查。尽管POSIX标准没有要求这个属性，但是Single UNIX Specification 的XSI扩展需要支持这个选项。
	在一个进程中，多个线程可以访问同一个同步对象，这个行为是默认的，这个时候，process-shared属性被设置成PTHREAD_PROCESS_PRIVATE.
	我们后面将会看到会有一种机制允许每个独立的进程把同一个范围的内存映射到他们自己独立的地址空间。通过多个进程之间共享数据经常会要求同步，类似在多个线程之间访问共享数据一样。如果process-shared的属性被设置成PTHREAD_PROCESS_SHARED，那么从一个共享区域分配的互斥量将会用于在多个进程之间进行同步。

	我们可以使用pthread_mutexattr_getpshared函数来获取process-shared属性对应的pthread_mutexattr_t结构,我们可以通过函数pthread_mutexattr_setpshared来更改process-shared属性。
	#include <pthread.h>
	int pthread_mutexattr_getpshared(const pthread_mutexattr_t * restrict attr, int *restrict pshared);
	int pthread_mutexattr_setpshared (pthread_mutexattr_t *attr, int pshared);
	两者成功的时候都返回0，失败的时候返回错误号码。
	process-shared属性被设置为PTHREAD_PROCESS_PRIVATE的时候，线程库会提供非常高效的mutex实现，这也是多线程程序中的默认情况。这样，线程库可以限制实现代价比较大的在进程之间共享互斥信号量的情况。


	互斥信号量的属性类型控制这互斥信号量的特性。POSIX.1定义了四种类型。PTHREAD_MUTEX_NORMAL类型是一个标准的互斥信号量，这样的类型不会作任何的特定错误检查或者死锁检查。PTHREAD_MUTEX_ERRORCHECK类型的互斥信号量提供错误的检查。
	PTHREAD_MUTEX_RECURSIVE类型的互斥量允许同样一个线程多次上锁而不用首先解锁。递归互斥两维护一个锁数目，并且它会一直持有锁，一直到解锁次数达到了上锁的次数。所以如果你对一个递归类型的互斥量进行锁定两次，但是解锁一次，这个互斥量仍然处于被锁状态，知道第二次解锁。
	最后，PTHREAD_MUTEX_DEFAULT类型用来请求特定的默认含义，允许系统实现把这个映射成为其他的类型。例如在Linux上面，这个类型就被映射成普通互斥量类型。
	本节给出了一个表，这个表列举出了四种类型的互斥量分别在：“本线程没有持有被锁住的锁，但是调用了解锁”，“解锁一个已经被解开的锁”，“没有释放锁的前提下再次加锁”这三种情况下的行为。具体也可以参照参考资料中的内容。
	PTHREAD_MUTEX_NORMAL:解锁不是自己持有的锁（未定义其行为），重复解锁（未定义其行为），重复加锁（会死锁）。
	PTHREAD_MUTEX_ERRORCHECK:解锁不是自己持有的锁（返回错误），重复解锁（返回错误），重复加锁（返回错误）。
	PTHREAD_MUTEX_RECURSIVE:解锁不是自己持有的锁（返回错误），重复解锁（返回错误），重复加锁（可以）。
	PTHREAD_MUTEX_DEFAULT:解锁不是自己持有的锁（未定义行为），重复解锁（未定义行为），重复加锁（未定义行为）。

	我们可以使用pthread_mutexattr_gettype来获得互斥量类型的属性，可以使用pthread_mutexattr_settype来改变互斥量类型的属性。
	#include <pthread.h>
	int pthread_mutexattr_gettype(const pthread_mutexattr_t * restrict attr, int *restrict type);
	int pthread_mutexattr_settype(pthread_mutexattr_t *attr, int type);
	两者成功返回0，失败返回错误号码。

	记得前面说过，需要使用一个互斥量来保护和一个条件变量相关联的条件。在阻塞这个线程之前，pthread_cond_wait 和 pthread_cond_timedwait函数释放这个和条件相关联的互斥量。这就允许其他线程获得这个互斥量，改变条件，释放互斥量，再通知给条件变量信号。因为必须持有互斥量以改变条件，所以这里使用一个递归互斥量并不是一个好的办法。如果一个递归互斥量多次被上锁，然后在调用pthread_cond_wait的时候使用了，那么这个条件永远不会被满足，因为pthread_cond_wait的解锁行为并没有释放互斥量。

	当你需要把一个存在的单线程下的接口修改用于多线程环境下但是却由于考虑兼容性的限制不能修改你的函数的接口的时候，递归递归互斥量就很有用了。然而，使用递归锁也是不太好的方法，最好在没有其它的解决方法的时候使用递归锁。

	例子：
	图12.6中就给出了一个使用递归锁解决并发问题的例子。这里func1和func2是库中的函数，由于存在使用这函数的程序，而我们无法改变这样的程序所以我们不能改变函数的接口(可以改变函数的实现)。
	具体情况应该参考参考资料这里不给出图形了。这个图形描述的意义大概就是：如果func1和func2都操作某一个数据结构，同时可能会有多个线程调用这两个函数，那么func1和func2函数在操作这个数据结构的时候必须要进行上锁。而如果func1调用了func2而互斥量却是非递归的话，就会在一个线程中造成死锁（即还没有解锁就对同一个信号量上锁两次）。当然，我们可以通过这种方式来避免使用递归锁：(func1中)在调用func2之前释放锁，在func2返回之后重新获取锁。但是这却在func1函数中打开了一个时间窗口，期间可能会有其他的线程将互斥量的控制权“抢”走,这样func1还在执行中就失去了互斥量。

	图12.7给出来一种不用递归互斥量的情况。我们通过使用一个“私有”的func2_locked函数使得func2和func1的接口不用被修改，并且也不用使用递归锁了。func2的内容就仅仅是上锁->调用func2_locked->解锁，而func1原来调用func2的地方改成调用func2_locked，func2_locked只用来操作数据。具体参见图示。这样的结果是，不会出现因原来func1调用func2导致同一个线程上锁两次的情况，因为把func2中"上锁的部分"和"实际操作的部分"分离了，func1实质调用func2只是需要其"实际操作的部分"也就是func2_locked,而不需要其"上锁的部分"，根据这样修改func1就避免了那一次没有必要的加锁。
	提供一个函数的上锁版本以及非上锁版本这在简单情况下经常好用。在更复杂的情况中，例如当一个库函数需要调用其外的某个函数，然后这个函数利用回调机制又调用到了这个库，这时候我们就需要依赖递归锁了。

	参考资料中的12.8也给出了一种使用递归互斥量的情况，内容有点复杂，这里不详细列举了。具体可以参考其中的内容，加深对递归互斥量的理解。

	*读写锁属性
	和互斥量类似，读写锁也具有一些类似的属性。我们使用pthread_rwlockattr_init来初始化一个pthread_rwlockattr_t结构，使用pthread_rwlockattr_destroy来反初始化这个结构。
	#include <pthread.h>
	int pthread_rwlockattr_init(pthread_rwlockattr_t *attr);
	int pthread_rwlockattr_destroy (pthread_rwlockattr_t *attr);
	两个函数在成功的时候都返回0，失败的时候返回错误的号码。

	读写锁只提供process-shared属性，这个属性和互斥量的process_shared属性的功能是一样的。也有一对函数来获取或者设置这个属性，如下：
	#include <pthread.h>
	int pthread_rwlockattr_getpshared(const pthread_rwlockattr_t * restrict attr, int *restrict pshared);
	int pthread_rwlockattr_setpshared (pthread_rwlockattr_t *attr, int pshared);
	这两个函数在成功的时候都返回0，在失败的时候返回错误号码。
	虽然POSIX只为读写锁定义了一个属性，但是我们在系统的实现上也可以定义其他的非标准属性。

	*条件变量属性
	类似互斥量和读写锁，条件变量也有相应的属性，并且也有一对函数来初始化和反初始化相应的条件属性结构变量。
	#include <pthread.h>
	int pthread_condattr_init(pthread_condattr_t *attr);
	int pthread_condattr_destroy(pthread_condattr_t *attr);
	两个函数成功的上返回0，失败的时候返回错误号码。

	和其他的同步机制类似，条件变量也具有process-shared属性,以及相应的设置和获取函数。
	#include <pthread.h>
	int pthread_condattr_getpshared(const pthread_condattr_t * restrict attr, int *restrict pshared);
	int pthread_condattr_setpshared(pthread_condattr_t *attr, int pshared);
	两个函数成功的时候都返回0，失败的时候都返回错误号码。

	5)可重入性
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec5.html
	前面我们讨论过了和signal相关的函数的可重入问题，在线程中同样会有这样的问题。
	如果一个函数可以被多个线程在同时被调用，那么我们就说这个函数是线程安全的。
	参考网址中给出了一个列表，列出了哪些函数不是线程安全的。具体请参照其中的内容。

	如果实现支持线程安全的函数，那么需要再unistd.h中定义变量_POSIX_THREAD_SAFE_FUNCTIONS，当然我们也可以在运行的时候使用sysconf带参数_SC_THREAD_SAFE_FUNCTIONS来检测是否支持线程安全函数。所有遵从XSI标准的实现都要求支持线程安全函数。

	当支持线程安全函数特性的时候，实现会为POSIX.1的一些非线程安全函数提供一个可选则的线程安全的版本。图12.10就列出了线程安全的函数。具体请参考参考资料。
	有许多函数并不是线程安全的，因为它们使用了静态内存来存放返回的数据。通过修改它们的接口，使用它们自己的缓存，来让它们线程安全。图12.10中的函数就是在原来的函数名称后面加上了一个_r后缀，这样表示它们是线程安全的。

	如果一个函数在多线程环境下面是可重入的，那么我们把这个函数称作是thread-safe的，但是这并不意味这个函数是在信号处理条件下面也可重入。如果一个函数在异步信号处理函数中也是可重入的，那么我们把这个函数称作是async-signal的。

	除了前面所说的，POSIX.1提供了一种可以线程安全地管理文件对象的方法。你可以使用flockfile和ftrylockfile函数获得一个和给定的文件对象相互关联的锁。这个锁是递归锁。尽管这个锁的具体实现是不确定的，但是要求所有标准输入输出函数管理文件对象的时候，表现的都像人安眠药非已经在内部调用了flockfile和funlockfile一样。
	#include <stdio.h>
	int ftrylockfile(FILE *fp);
	如果成功返回0，如果锁无法获得则返回非0。
	void flockfile(FILE *fp);
	void funlockfile(FILE *fp);

	尽管标准输入输出函数在他们自己的内部数据来看是线程安全的，但是能够将相关的锁暴露出来也是很有用的。这允许应用程序把多个标准输入输出调用合并成一个单个的原子操作序列，当然在处理多个文件对象的时候，你需要注意文件死锁的问题，仔细管理你上锁的次序。
	在进行字符输入输出的时候，如果标准输入输出函数请求它们自己的锁那么会导致性能下降很多，因为每次进行一个字符的读写的时候，我们都得进行锁的申请和释放。为了改善这种状况，有一对非上锁的面向字符的输入输出操作函数，如下：
	#include <stdio.h>
	int getchar_unlocked(void);
	int getc_unlocked(FILE *fp);
	两个函数如果成功都会返回下一个字符，如果失败就会返回文件的结尾EOF。
	int putchar_unlocked(int c);
	int putc_unlocked(int c, FILE *fp);
	两个函数如果成功都会返回c，如果失败会返回错误。

	调用这四个函数，需要在它们的附近调用flockfile或者ftrylockfile以及funlockfile。否则，会出现无法预测的结果（多个线程访问数据出现的非同步的问题）。
	当你锁住文件对象的时候，你可以在释放锁的之前多次调用这些函数,这样可以减少上锁和释放锁的开销。

	例子
	参考资料中的12.11给出了一个getenv的非线程安全版本和线程安全版本。
	具体参见其中的代码。主要需要注意的是：
	非可重入版本（非线程安全）的getenv把东西存放在了其函数的一个静态变量中，这样所有的线程都共享这个静态变量。所以修改了这个函数的接口，让它使用自己的缓存存放相应的内容，而不是静态变量，这样就成了线程安全的（也就是多线程可重入的）getenv函数也就是getenv_r。
	注意虽然是多线程下可重入，但是不一定信号处理的方面也是可重入的。
	还有一个需要注意的地方，就是我们使用了一个pthread_once函数来调用某个函数(thread_init)，保证这个函数(thread_init)在一个进程中只被执行一次。

	6)线程特定数据
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec6.html
	这里的线程特定数据也就是线程私有数据，是一种只存取指定线程相关的数据的一种机制。使用线程私有数据，每个线程就可以访问它自己的私有数据拷贝，而不用担心和其他线程同步的问题了。
	本来提出线程可以方便地共享进程的数据和属性，然而引入接口让线程私有数据保持和其它线程的隔离，也有它自己的道理。
	首先，有时候我们需要基于线程来维护一些数据。线程的ID不一定是整数，所以我们不能构通过使用线程ID做为一个存放线程数据的数组的索引来实现这个机制，即使线程的ID是整数，我们也可能对数据进行一些额外的保护，防止其他的线程访问到本线程的数据。
	第二个使用线程私有数据的原因就是，希望能够提供一种机制可以在多线程的环境下使用基于进程的接口。一个典型的例子就是，errno.根据前面的内容我们可以知道，这是一个在进程范围内的全局数据，在系统调用或者是一些库函数失败的时候会设置这个变量。为了在进程的环境下也能够使用同样的系统调用和库函数，errno被重新定义为一个线程的私有数据，这样在进程中，一个线程调用函数设置的errno不会影响到其它的线程。
	需要注意的是，所有的线程都可以访问整个的进程地址空间，除非使用寄存器，一个线程无法阻止其它的线程访问它的数据。对于线程私有数据也是如此，尽管实现上没有提供访问的保护，但是可以通过一些函数，来管理这些线程私有数据，这样来保证线程在这些私有数据上与其他的线程保持独立。

	在分配线程私有数据的时候，我们需要创建一个和这个数据相关的关键字，利用这个关键字来访问线程私有数据。我们使用函数pthread_key_create来创建一个线程关键字。
	#include <pthread.h>
	int pthread_key_create(pthread_key_t *keyp, void (*destructor)(void *));
	如果成功返回0，如果失败返回错误号码。
	由keyp来指向创建的关键字在内存中的位置，在进程中同样的关键字可以被所有的线程使用，但是每个线程会向这个关键字关联一个不同的（它自己的）线程私有数据的地址。创建关键字之后，和这个关键字相关联的每个线程的私有数据地址为空。
	创建一个关键字(key)的时候，pthread_key_create会将一个可选的析构函数和这个key相关联，当线程退出并且数据的地址被设置为非空的时候，会以数据地址做为析构函数的参数，调用这个析构函数。如果析构函数的指针为空，那么不会有析构函数和这个关键字相互关联。当线程使用pthread_exit或者return来正常退出的时候，会调用到这个析构函数，但是如果线程调用exit,_exit,_Exit或者abort这些函数异常退出的时候，就不会调用到这个析构函数了。
	线程一般使用malloc来分配它们自己的线程私有数据，析构函数使用free来释放这些数据。如果线程退出的时候没有释放这些数据会导致内存泄露。
	线程可以为使用线程私有数据，创建多个关键字，每一个关键字有一个析构函数和它相关联。操作系统对一个进程中可以创建的关键字的数目有所限制(PTHREAD_KEYS_MAX)。
	线程退出的时候，线程私有数据的析构函数的调用次序是和系统实现相关的。有可能一个线程私有数据会调用另外一个函数，而那个函数会再次创建线程私有数据并且将私有数据和一个关键字相互关联，当所有析构函数调用完了之后，系统会检查是否还存在非空的线程似有数据指针和关键字相互关联，如果有则再次调用析构函数，直至所有的私有数据为空或者达到了一个最大的迭代次数PTHREAD_DESTRUCTOR_ITERATIONS。

	我们可以通过调用pthread_key_delete来将所有线程的私有数据和一个关键字的关系断开。
	#include <pthread.h>
	int pthread_key_create(pthread_key_t *keyp, void (*destructor)(void *));
	如果成功返回0，如果失败返回错误号码。
	注意，调用pthread_key_delete并不会调用和key相关联的析构函数，如果想要释放和key相关的线程私有数据占用的内存，我们需要在应用程序中进行额外的步骤。

	由于可能会在初始化的时候存在竞争的关系，我们必须要保证自己分配的key在期间不会被改变，而下面的代码就有可能出现两个线程同时调用pthread_key_create函数：
	void destructor(void *);
	pthread_key_t key;
	int init_done = 0;
	int threadfunc(void *arg)
	{
		if (!init_done) {//这里，可能另外一个线程先进入了这个分支，还没有来得及修改init_done本线程就又进来了。
			init_done = 1;
			err = pthread_key_create(&key, destructor);
		}
		...
	}
	可能一个线程看到的key值和另外一个线程的不一样，这取决于系统线程调度的实现。我们可以使用pthread_once来解决这个问题。
	#include <pthread.h>
	pthread_once_t initflag = PTHREAD_ONCE_INIT;
	int pthread_once(pthread_once_t *initflag, void (*initfn)(void));
	如果成功返回0，如果失败返回错误号码。
	这里，initflag必须是一个非局部变量(得是全局或者静态的)，并且要被初始化为PTHREAD_ONCE_INIT.
	如果每个线程都调用pthread_once，这样系统能够保证初始化函数initfn只被调用一次，也就是在第一次调用pthread_once的时候，所以，正确的创建一个key而不会有竞争发生的方法如下：
	void destructor(void *);
	pthread_key_t key;
	pthread_once_t init_done = PTHREAD_ONCE_INIT;
	void thread_init(void)
	{
		err = pthread_key_create(&key, destructor);
	}

	int threadfunc(void *arg)
	{
		pthread_once(&init_done, thread_init);
		...
	}

	创建了一个key之后，我们可以调用pthread_setspecific将线程私有数据和一个key相关联，可以调用pthread_getspecific来获取和key相关联的本线程私有数据的地址。
	#include <pthread.h>
	void *pthread_getspecific(pthread_key_t key);
	返回线程似有数据值或者如果没有相应的值与key相关联就返回NULL。
	int pthread_setspecific(pthread_key_t key, const void *value);
	如果成功返回0，如果失败返回错误号码。
	因为如果线程没有私有数据和key相关联的时候，我们会得到一个空指针，所以利用这个特性我们可以用来判断是否应该调用pthread_setspecific。

	举例：
	这里给出了一个使用线程私有数据实现线程安全的getenv的例子，在前面，我们已经通过修改接口，实现了一个线程安全的新的getenv,但是如果我们不能修改应用程序来使用新的接口的时候，我们就需要使用线程私有数据的机制来实现这个线程安全的getenv了，具体请参见参考资料。主要我们需要注意的就是，使用pthread_once来创建key保证key只创建一次，使用pthread_getspecific来获取私有数据的指针，如果获取的指针为空我们需要使用malloc分配内存用来存放私有数据并且将其地址用pthread_setspecific和key相关联，这样我们之后就能够使用pthread_getspecific来获取关联过的数据地址了，我们需要在一个析构函数里面使用free来释放刚才用malloc分配的内存，如果线程私有数据的地址非空那么会做为参数传给这个析构函数.
	另外需要注意，这样写出来的函数是线程安全的但是不一定是信号可重入的，即使使用了递归互斥量也是如此，因为malloc函数本身就不是信号安全的。

	7)取消相关的选项
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec7.html
	有两个没有包含在pthread_attr_t结构中的属性是取消状态和取消类型，它们会影响线程对pthread_cancel属性的响应。
	取消状态的属性值可以是PTHREAD_CANCEL_ENABLE或者PTHREAD_CANCEL_DISABLE.线程可以通过pthread_setcancelstate改变它的取消状态。
	#include <pthread.h>
	int pthread_setcancelstate(int state, int *oldstate);
	如果成功返回0，如果失败返回错误号码。
	这个函数将线程的取消属性设置成state，并且把之前的属性保存在oldstate所指向的内存中，这些在一个原子操作中完成。

	通过前面的讲述我们可以知道调用pthread_cancel之后并不会等待一个线程的终止。默认来说，在做出了取消的请求之后，那个线程会继续执行直到到达一个“取消点”。取消点就是线程检查它是否被取消的地方，并且执行取消请求。POSIX.1保证线程调用某些函数会遇到取消点，这些函数在这里的参考资料中都有列出，详细请参考其中的内容。

	默认线程启动的时候，其取消状态是PTHREAD_CANCEL_ENABLE.如果取消状态设置成PTHREAD_CANCEL_DISABLE,那么pthread_cancel调用不会将线程杀死，反而这个线程的取消请求会被挂起，知道状态再次被设置成enabled，线程将会在下一个取消点执行挂起的取消的请求。除了前面列出的一定保证遇到取消点的函数，POSIX.1也提供了一些可选的函数，可以做为取消点，具体请参见参考资料。

	如果你的程序在很长的时间内没有调用前面列出的取消点函数，那么你可以调用pthread_testcancel来自己亲自为程序添加取消点。
	#include <pthread.h>
	void pthread_testcancel(void);
	调用了这个函数之后，如果存在被提交的取消请求并且取消的状态没有被disable,那么这个线程将会被取消。如果取消状态被disabled了，那么这个函数没有任何作用。

	我们所描述的默认的取消类型是"延迟取消"，也就是说调用pthread_cancel函数之后，实际的取消动作并没有立即发生而是在遇到了第一个取消点的时候才发生。我们可以通过调用pthread_setcanceltype函数来设置取消类型。

	#include <pthread.h>
	int pthread_setcanceltype(int type, int *oldtype);
	函数成功返回0，失败返回错误号码。
	参数type可以是PTHREAD_CANCEL_DEFERRED或者PTHREAD_CANCEL_ASYNCHRONOUS，这个函数会设置线程的取消类型为type，然后返回之前的类型保存在oldtype整形指针所指的地方。
	异步取消类型和延迟取消类型是不一样的，异步取消类型导致线程可以在任何时候被取消而不用非得遇到一个取消点。

	8)线程和信号
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec8.html
	本来在进程中信号处理就已经很麻烦了，再引入线程使得这个问题变得更加麻烦。
	每个线程都有它自己的signal mask，但是整个进程中的信号的处理特性（动作等）却被所有的线程共享。也就是说，单个的一个线程就可以阻塞信号，但是如果修改了信号的处理动作，那么所有的线程的信号处理动作都变了。所以，一个线程忽略了一个信号，那么另一个线程可以通过为这个信号设置默认动作或者安装信号处理函数来取消忽略。
	信号会被发送给进程中的单个线程，如果信号和硬件相关或者超时相关，那么信号会被发送给导致这个事件的线程。而其它的信号会被发送给任意一个线程。

	前面讲述了进程使用sigprocmask来阻塞信号发送的方法。然而这个函数并不适用于多线程环境，线程应该使用pthread_sigmask来替代这个函数。
	#include <signal.h>
	int pthread_sigmask(int how, const sigset_t *restrict set, sigset_t *restrict oset);
	这个函数如果成功返回0，如果失败返回错误号码。
	此函数和sigprocmask的功能是一样的，不同的只是它应该被线程使用并且失败的时候返回错误号码，而不想sigprocmask失败的时候返回－1并且设置errno.

	线程使用sigwait来等待一个或者多个信号的发生。
	#include <signal.h>
	int sigwait(const sigset_t *restrict set, int *restrict signop);
	如果成功返回0，如果失败返回错误号码。
	参数set指定线程等待的信号的集合，返回的时候，signop指向的整数包含被发送的信号的号码。
	如果在调用sigwait的时候，set中的某个信号处于提交状态，那么sigwait会立即返回不会阻塞。返回之前，会将这个信号从进程的处于提交状态的信号集合中移走。为了防止出现错误的情况，sigwait被调用之前线程应该阻塞它所等待的信号，然后sigwait会自动解锁这些信号并且等待它们中的一个发生。返回之前sigwait会恢复线程的signal mask。而如果调用sigwait信号没有被阻塞的话会出现一个时间窗口，导致被等待的信号在发生的时候，sigwait还没有来得及完成它的调用。
	使用sigwait的一个优点就是，它可以通过让我们使用一种同步的方式来对待异步产生的信号，这样简化信号的处理方式。我们可以通过将信号加入到线程的signal mask中来阻止信号打断线程的执行。然后我们可以指定特定的线程来处理信号，这些被指定的线程可以使用函数调用并且不用担心哪些函数从信号处理中被调用是安全的，因为它们是在一个普通的线程上下文中进行调用，而不是在打断线程执行的那个信号处理函数中了。
	如果多个线程调用sigwait阻塞在一个信号上面，那么当这个信号被发送的时候，只有一个线程会从sigwait中返回。如果一个信号被捕获（例如进程通过sigaction为信号建立起来了一个信号处理函数）并且有一个线程调用了sigwait等待这个信号，那么如何处理发送信号的方法取决于系统实现。这时候，系统实现可以允许sigwait返回，或者调用信号处理函数，但是不能两者都做。

	我们使用kill给进程发送信号，使用pthread_kill来给线程发送信号。
	#include <signal.h>
	int pthread_kill(pthread_t thread, int signo);
	如果成功返回0，如果失败返回错误号码。
	我们可以给signo赋值为0，来检测线程是否存在。如果我们使用pthread_kill来给一个线程发送信号，并且信号的默认处理动作是终止整个进程，那么结果仍然会导致整个进程被终止。
	注意时钟计时器(alarm timers)是一个进程资源，所有的线程共享同样的一套时钟。所以，如果多线程在进程中使用时钟，不可能对其他的线程不造成影响(也就是说多个线程中使用时钟计时那么需要它们之间有一定的协调)。

	举例
	前面我们曾经举过一个例子，一个程序当它捕获信号的时候会在信号处理函数中设置一个标记标志是否需要退出，然后主程序检测这个标记，来确定程序是否应该退出。因为这个程序的线程只有一个主线程，还有相应的信号处理函数，所以我们只要阻塞相应的信号就不会丢失对那个标记的修改。然而在多个线程中我们就需要使用互斥量来保护这个标记了。
	本书这一节给出了一个例子，具体参见参考资料。这里只大致说明一下：这个例子使用一个单独的线程来设置标记而不是使用信号量处理函数，它在互斥量的保护下修改那个标记，这样主线程不会丢失pthread_cond_signal时候的唤醒动作，我们在主线程中检查这个标记的时候也使用同样的互斥量来访问这个标记(在等待条件的时候当然会自动释放这个信号量具体参考前面讲述的条件变量).
	还有一个需要注意的地方就是我们在主线程的开始阻塞了那些(可能导致标记被修改的)信号，然后创建子线程来捕获那些信号（使用sigwait函数），捕获到信号的时候就可能会修改标记（取决于具体实现）。这样，只有一个线程会接收到相应的信号，我们也不用担心主线程会被那个信号所打断了。

	Linux把线程作为一个独立的进程来实现，进程之间分享相应的资源，使用clone(2)来创建这样的进程。因为这个原因，在涉及到信号处理的时候，linux上面的线程的行为就和其他实现上的行为不一样了。在POSIX.1的线程模型中，异步信号会被发送给一个进程，然后选择进程中的一个独立的线程来接收这个信号，这基于那个线程当前没有阻塞这个信号。在Linux上面，一个异步的信号会被发送给一个特定的线程，并且因为每个线程做为一个独立的进程运行，这样系统也无法选择当前没有阻塞这个信号的线程。这样的结果就是线程可能不会注意到这个信号。因此像本例子中的程序，如果信号是从终端驱动中生成的，那么就会好用，因为会发送信号给整个进程组(这样无论线程进程都会收到信号)，但是当你使用kill想要发送一个信号给进程的时候，在Linux上面它就不会如你所期望的那样工作了(一个进程就是一个线程而不是一组线程的集合的原因吗？)。

	9)线程和fork
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec9.html
	当线程调用fork的时候，会为这个子进程创建整个进程地址空间的拷贝。根据我们之前所说的copy-on-write，子进程和父进程是完全不同的两个进程，只要内存中的内容不发生变化，那么这部分内存就会在父子进程之间共享（这样尽可能地减少了额外的拷贝）。
	通过继承拷贝过来的地址空间，子进程也会从父进程那里继承每个互斥量，读写锁，条件变量。如果父进程包含不止一个线程，并且子进程fork返回之后不立即调用exec，那么子进程需要清除锁的状态。
	在子进程中只有一个线程，这个线程就是父进程中调用fork的那个线程的拷贝。如果父进程中的线程持有锁那么子进程也将会持有这个锁.问题是子进程不包含持有锁的线程的拷贝，所以子进程无法知道哪些锁被持有，那些锁需要被释放。
	如果子进程在调用fork之后直接调用exec函数那么这个问题就会被避免，这个情况下旧的地址空间会被丢弃，所以锁的状态就不用在意了.这个不总是发生的，所以如果子进程想要在fork之后继续处理，那么我们需要采用另外一种策略。

	我们可以调用pthread_atfork来创建fork处理函数来清除锁的状态。
	#include <pthread.h>
	int pthread_atfork(void (*prepare)(void), void (*parent)(void), void (*child)(void));
	如果成功返回0，如果失败返回错误号码。
	使用这个函数我们安装了三个fork处理函数来帮助我们清除锁的状态。prepare在父进程中，创建子进程之前被调用,它的作用是请求所有父进程定义的锁；parent在父进程中，fork创建子进程之后但是fork返回之前被调用,这个函数用来解锁prepare请求的所有锁；child函数在子进程中fork返回之前被调用，和parent函数一样，用来释放prepare请求的所有的锁。
	注意，这里并不是加锁一次却释放两次这个错误的操作。因为子进程空间创建的时候会拷贝父进程的所有锁，因为prepare请求了所有的锁，所以父子进程中的内容都是一个样子的（就是锁上的状态）。当parent和child解锁它那份拷贝的时候，由于copy-on-write，就会实际分贝并拷贝子进程的空间了。所以在我们看起来，父进程锁住锁的拷贝并在子进程中释放这些锁住的锁的拷贝。child和parent函数以释放它们自己内存区域中的锁的拷贝为结束，过程等价如下：
	*父进程请求所有的锁。
	*子进程请求所有的锁。
	*父进程释放它的锁。
	*子进程释放它的锁。
	这里，前两个请求所有的锁的操作实际都是prepare函数做的。
	我们可以多次调用pthread_atfork来安装不止一个fork处理函数的集合，如果我们不需要其中的一个函数，我们可以为相应的函数参数的地方传递一个空指针。当使用了多个fork处理函数的集合的时候，它们的调用次序也是不一样的，parent和child处理函数的调用次序和它们的安装次序是一样的，而prepare的调用次序却和它们安装的次序相反。这样能够保证多个模块注册它们自己的fork处理函数而且还满足锁的使用规则。

	例如，模块A调用模块B中的函数，并且每个模块都有它自己的锁的集合。如果上锁的过程是A在B之前，那么模块B必须在模块A之前注册它的fork处理函数。当父进程调用fork的时候，会发生如下过程（假设子进程在父进程之前运行）：
	a.模块A的prepare处理函数被调用，请求A的锁。
	b.模块B的prepare处理函数被调用，请求B的锁。
	c.创建子进程。
	d.模块B的child处理函数被调用，释放子进程中B模块的所有锁。
	e.模块A的child处理函数被调用，释放子进程中A模块的所有锁。
	f.fork函数返回到子进程。
	g.模块B的parent处理函数被调用，释放父进程中模块B的所有锁。
	h.模块A的parent处理函数被调用，释放父进程中模块A的所有锁。
	i.fork函数返回到父进程。

	如果fork处理函数用来清除锁的状态，那么谁来清除条件变量的状态呢？在有一些实现中，条件变量并不需要被清除；然而实现如果使用锁来做为条件变量实现的一部分，那么就需要清除了;问题是，没有相应的接口来让我们做这件事情.如果锁嵌入到了条件变量的数据结构中，那么我们就不能在调用fork之后使用条件变量了,因为没有一个可移植的方法来清除条件变量的状态。另一方面，如果实现使用一个全局变量来保护一个进程中的条件变量,那么在fork库中，实现本身可以清除锁的状态；尽管如此，应用程序也不应当依赖这样的实现。

	例子：
	参考资料给出了使用pthread_atfork的例子代码，这里不列出了，具体参见参考资料.
	在这个例子中，我们定义了两个互斥量，lock1和lock2.prepare处理函数给它们两个上锁，child处理函数在子进程上下文中释放锁，parent处理函数在父进程上下文中释放锁。
	从这个例子的运行结果我们可以看出:prepare处理函数在调用fork之后被调用(但是在创建的进程运行之前被调用)，child处理函数在子进程的fork返回之前被调用；parent处理函数在父进程的fork返回之前被调用。

	10)线程和输入输出
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec10.html
	在前面我们介绍了pread函数和pwrite函数，这些函数在多线程的环境中是非常有用的，因为进程中所有的线程共享同样的文件描述符号。
	假设线程A和B在如下的情况同时读写文件：
	线程A:lseek(fd, 300, SEEK_SET);read(fd, buf1, 100);
	线程B:lseek(fd, 700, SEEK_SET);read(fd, buf2, 100);
	如果线程A在调用完lseek之后，但是read之前的时候，线程B调用了lseek，那么两个线程将会读取同样的数据，显然这样的结果很可能就不是我们所需要的了。

	为了解决上述问题，我们使用pread，这个函数将lseek和read合并为一个原子的操作：
	线程A:pread(fd, buf1, 100, 300);
	线程B:pread(fd, buf2, 100, 700);
	使用线程A，我们就可以保证线程A从300开始读取，而线程B一定是从700开始读取。同理，我们可以使用pwrite来解决多个线程同时写同一个文件导致的竞争条件。

	11)总结：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch12lev1sec11.html
	线程提供了在unix系统中将一个任务分割的可选的途径.使用线程，可以在各个线程之间方便地共享数据，但是也会引入一些同步的问题。在本章，我们介绍了如何使用线程并且处理这些线程之间的同步问题，我们也讨论了线程中存在的可重入性.我们也看到了线程如何和一些面向进程级别的系统调用进行交互。


*守护进程
==========================
	1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec1.html
	守护进程一般是运行时间特别长的进程，它们一般在系统启动的时候运行，在系统关闭的时候终止。因为它们都没有控制终端，所以它们一般都在后台运行。Unix下面有许多的守护进程，用来执行一些日常的行为。
	这一章我们来看一下守护进程的结构，以及如何写一个守护进程，由于守护进程没有控制终端，所以我们需要查看一下守护进程如何在发生错误的时候报告错误的情况。

	2)守护进程的特点
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec2.html
	我们首先来看一下普通的系统守护进程以及它们和前面我们讲到的进程组，控制终端，以及session(会话)之间的关系。我们使用如下的方式运行ps命令：
	ps -axj
	此命令运行在基于BSD的系统上面，可以查看我们关心的信息。-a选项会显示其它人拥有的进程的状态，-x选项显示没有控制终端的进程，-j选项显示作业相关的信息：会话ID，进程组ID，控制终端，和终端进程组ID.在基于system V的系统上面，类似的命令是ps -efjc，在有的Unix系统上面，出于对安全性的考虑，不允许我们查看不属于我们的进程。这个命令输出得信息类似如下：
	PPID   PID  PGID   SID  TTY  TPGID  UID  COMMAND

	   0     1     0     0  ?       -1    0  init

	   1     2     1     1  ?       -1    0  [keventd]

	   1     3     1     1  ?       -1    0  [kapmd]

	   0     5     1     1  ?       -1    0  [kswapd]

	   0     6     1     1  ?       -1    0  [bdflush]

	   0     7     1     1  ?       -1    0  [kupdated]

	   1  1009  1009  1009  ?       -1   32  portmap

	   1  1048  1048  1048  ?       -1    0  syslogd -m 0

	   1  1335  1335  1335  ?       -1    0  xinetd -pidfile /var/run/xinetd.pid

	具体不多列举了，可以参考本节相应的参考资料。
	我们将实际输出中我们不关心的列给去掉了，这里的每一列，依次是：PPID-父进程ID，PID-进程ID，PGID-进程组ID，SID-会话ID，TTY-终端名称，TPGID-终端进程组ID(和控制终端相关的前台进程组)，UID-用户ID和COMMAND-命令行。
	在这个系统中(ps运行在Linux上面)，支持会话ID的概念。实际我们前面已经说过，这个就是session leader的进程ID。然而在基于BSD相关的系统上，将会打印出相应进程所属的进程组相关的session的数据结构地址。
	你的操作系统实现决定了你能够看到哪些系统进程。父进程id为0的进程一般都是做为系统启动一部分的内核进程(init程序是一个例外，因为它是内核在启动阶段启动的一个用户命令)。内核进程是比较特殊的，它一般在整个系统的生命周期中都存在着它以超级用户权限运行，没有命令行，没有控制终端.
	进程ID为1的进程一般为init进程，我们前面也说过了它。这个进程是一个系统的守护进程，它特别用来启动各种级别的系统服务。这些服务通常通过它们自己的守护进程来实现。
	在linux中，keventd守护进程为在kernel中运行调度函数提供进程上下文。kapmd守护进程提供许多计算机系统中通用的高级电源管理特性的支持。kswapd守护进程也被称作pageout守护进程，它通过（随着时间的流逝）向硬盘慢慢地写入脏页，以便回收这些页，来支持虚拟内存子系统。
	Linux内核通过两个额外的守护进程来把缓存中的数据刷新到硬盘中，bdflush和kupdated.bdflush守护进程在可用内存的数目低到一定程度的时候，将“脏”缓存中的数据刷回到硬盘上面；而kupdated守护进程是在一定的时间间隔就会将“脏”缓存中的数据刷回到磁盘，防止系统崩溃引起的数据丢失。
	portmaper守护进程（portmap），提供将远程调用程序号映射成网络端口号码的服务。syslogd守护进程可以让任何程序记录某一个操作的消息日志信息，这些消息可以被打印到终端上面，也可以写到一个文件中去（我们后面会讲到）。
	我们讨论过inetd(xinetd)守护进程，它在系统的网络接口上面侦听来自各种网络服务的请求.nfsd,lockd,和rpciod守护进程提供网络文件系统（NFS）的支持。
	cron守护进程(crond)用来在指定的时间和地点执行特定的命令，许多系统管理任务都是通过cron定期执行某些程序来实现的。cupsd守护进程是打印池，用来相应系统上面的打印请求。
	我们要注意：大多数守护进程都是以超级用户（用户ID为0）的权限运行的。所有的守护进程都没有控制终端，所以ps中其控制中断的名称被设置成问号（?），并且其终端前台进程组号为-1(参考资料中说是1应该是写错了)。内核守护进程启动的时候就没有控制终端，而用户级别的守护进程一般都是因为调用了setsid导致它们和控制终端的连接断开的。所有的用户级别的守护进程都是组leader厌session leader，并且他们都是自己组或者会话中的唯一进程。最后，我们需要注意大多数这些守护进程的父进程都是init进程。

	3)一些编码规范
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec3.html
	写一个守护进程，有一些基本的编码规则，可以避免一些由于交互产生的问题。我们先说一下这些规则，然后在后面我们写了一个函数daemonize来实现这些规则。
	a）首先使用umask来设置文件创建模式的mask为0。被继承下来的文件创建模式被设置成拒绝特定的权限，如果守护进程创建了文件，它可能会想要设置为特定的权限。例如它想要把文件设置成组内可以读写的权限，这个时候，如果文件模式的umask屏蔽了这些权限，那么以上的设置将会没有作用。
	b）调用fork让父进程退出。这会做如下一些事情，首先，一个守护进程作为一个简单的shell命令被运行，这样父进程的终止会使得shell认为这个程序已经运行完毕了。其次，子进程继承父进程的进程组id，这样我们可以保证它不是一个进程组的leader。这为后面可以调用setsid提供了前提条件。
	c）调用setsid创建一个新的会话。这样前面也说过，会发生如下的三件事情：进程变成了新session的session leader；进程变成新进程组的组leader；进程不再拥有控制终端。
	在基于system V的系统中有些人建议再次调用fork并且终止父亲进程，第二个子进程作为守护进程来运行。这样可以保证守护进程不是一个session leader，这样阻止守护进程按照System V的一些规则来请求控制终端（具体应该参照前面System V的有关内容）。另外，为了避免请求控制中断，我们要确保一旦打开终端就会设置O_NOCTTY。
	d）改变当前工作目录为根目录。当前工作目录继承自父进程，并且这个目录可能是一个被挂载了某个文件系统的目录.守护进程一般都会一直运行直到系统的重启，所以如果一个守护进程的所在的工作目录是一个被挂载的文件系统，那么这个文件系统将会无法被卸载。
	当然也有一些守护进程会将它们的工作目录切换到别的地方，这样它们的工作都在那个目录下面进行。例如打印机相关的守护进程将会把它的工作目录切换到spool目录。
	e)有些守护进程会将文件描述符号0,1,2重新定向到/dev/null上面。这样任何尝试从标准输入读取，或者写入标准输出和标准错误输出的操作将会无效。因为守护进程没有和它相关联的终端设备，所以没有显示输出的地方,也没有读取用户输入的地方。即使守护进程是从一个交互的会话中启动的，由于它是运行在后台，登陆会话会终止并且不会影响到守护进程。如果其它的用户登陆到相同的终端设备上面，我们不想让守护进程的输出输出到终端上面，用户也不期望从终端上面读取数据。

	例子：
	具体的例子参见给出的参考网址。这里的例子用一个函数实现了前面的五个将进程变成守护进程的规则，并且写了一个守护进程。我们可以通过ps来查看。查看结果发现，该守护进程所在进程组PGID对应的那个进程ID在系统进程中没有，说明守护进程在一个孤儿进程组中，并且不是一个session leader所以它没有机会获取设备终端,我们在daemonize函数中的两次调用fork，导致了这个现象。

	4)登陆错误
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec4.html
	守护进程的一个问题就是如何处理错误消息。不能将消息简单地写入到标准错误输出中，因为守护进程并没有控制终端。我们也不想让守护进程往console设备上面写，因为在许多工作站上面，console设备运行在窗口系统中。我们也不想要每个守护进程将信息写入到一个特定的文件中，因为这样管理员需要知道哪些守护进程向哪些文件写，需要基于某个规则来检查这些文件，这是很麻烦的。所以，需要一个集中管理错误日志登记的守护进程工具。
	BSD的syslog工具在4.2BSD中应用很多，大多数继承自BSD的系统都支持syslog。
	直到SVR4，System V从来没有一个用来集中登记日志的守护进程工具。
	syslog函数作为Single UNIX Specification的XSI扩展被包含。
	由于BSD的syslog从BSD4.2之后工具应用很广，大多数的守护进程都使用这个工具。参考资料中给出了一个图来描述其结构。这里简单描述一下图的结构，具体参见参考资料。
	*syslogd守护进程读取/dev/log，UDP的514号端口，或/dev/klog,并把日志写入到文件或者发送到别的主机上面。
	*对于上面三个文件，用户进程通过syslog写/dev/log;来自TCP/IP的网络写UDP的514号端口;内核进程通过log写/dev/klog。

	有三种方法生成日志消息：
	a)内核例程可以调用log函数。这些消息可以通过打开/dev/klog文件被其他用户进程读取。我们这里不详细讨论这个函数了，因为我们不打算讨论编写内核例程。
	b)大多数用户进程（守护进程）通过调用syslog函数生成日志消息。我们后面描述它。这会导致消息被发送到UNIX套接字/dev/log上面。
	c)一个本地用户进程，或者通过TCP/IP网络连接到本地机器上面的其它主机，可以把日志消息发送到UDP的514端口上面。需要注意的是，syslog函数不会生成这些UDP数据报，他们需要进程通过网络编程的方式生成日志消息。

	一般来说，syslogd守护进程读取所有三种类型的日志消息。在启动的时候，这个守护进程读取一个配置文件（一般为/etc/syslog.conf），这个配置文件决定了不同种类的消息被发送到哪里。例如，比较紧急的消息可以给发送到系统管理员，并且打印到console屏幕上面，而一些警告类型的消息可以被登记到一个特定的文件当中。

	我们把syslog函数做为使用这个工具的接口。
	#include <syslog.h>
	void openlog(const char *ident, int option, int facility);
	void syslog(int priority, const char *format, ...);
	void closelog(void);
	int setlogmask(int maskpri);
	返回：前次的日志优先级mask值。

	openlog函数的调用是可选的，如果第一次使用syslog的时候没有调用openlog，那么会自动调用openlog函数。closelog也是可选的，它只是关闭用户来和syslogd守护进程通信的文件描述符号。
	openlog函数允许我们向每一条日志消息添加一个ident，一般它就是程序的名称（例如cron,inetd,等等）。option参数是一个位码(bitmask)的组合，可以用来指定各种选项。(注意对Single UNIX Specification 的XSI扩展支持)详细请见参考网址。大致如下：
	a)LOG_CONS :如果日志消息没有通过UNIX域的数据报发送给syslogd，那么会被写到console上面。
	b)LOG_NDELAY :立即打开到syslogd守护进程的UNIX 域数据报套接字，而不是等到第一条日志消息的登记。一般来说，这个套接字知道登记第一条日志的时候才会被打开。
	c)LOG_NOWAIT :不会等待那些可能会在登记日志过程中创建的子进程。这样会防止与捕获SIGCHLD的进程产生冲突，因为程序可能会在syslog调用wait的时候已经获取了子进程的状态(???)。
	d)LOG_ODELAY :延迟打开到syslogd守护进程的连接，直到登记第一条日志消息。
	e)LOG_PERROR :除了将日志消息发送给syslogd之外，也将其写到标准错误输出。(Solaris上不可用)
	f)LOG_PID :为每一条消息登记进程ID。这个用于调用fork创建子进程的守护进程来处理不同的请求(相对于一些守护进程,例如syslogd守护进程从来不会使用fork创建子进程)。
	openlog函数的facility参数参见参考网址给出的表格，注意Single UNIX Specification 只给出了在一些平台上可用的常用的facility码的子集。facility参数存在的意义就是允许使用配置文件指出，来自不同facility的消息使用不同的方式处理。如果我们不使用openlog或者我们使用facility值为0来调用这个函数，我们仍然可以指定facility做为syslog函数priority参数的一个部分。 facility参数的值(例如LOG_FTP,LOG_CRON,LOG_DAEMON等)在参考网址中的一个表中列出了，这里不详细给出，请参考参考网址。

	syslog函数用来产生日志消息，其中priority参数可以是openlog函数的facility参数和一个表示优先级别(level)的值的组合（按位或）。级别的值按照由高到低的顺序排列如下：
	LOG_EMERG :紧急消息（例如系统无法使用），优先级最高。
	LOG_ALERT :应该立刻被修正的情况。
	LOG_CRIT :关键情况（例如硬件设备故障）。
	LOG_ERR :错误情况。
	LOG_WARNING :警告情况。
	LOG_NOTICE :正常的但是也比较重要的情况。
	LOG_INFO :一些信息。
	LOG_DEBUG :调试信息（优先级最低）。
	format参数以及剩下的参数被传送给了vsprintf函数，如果在format中遇到了'%m'那么它会被替换成相应于errno的错误消息的字符串。

	setlogmask函数可以为进程用来设置日志的优先级屏蔽码(priority mask)。这个函数返回之前的屏蔽码。当日志优先级屏蔽码被设置的时候，消息不会被登记除非它们的优先级别被设置到优先级屏蔽码中。需要注意的是，如果设置日志优先级屏蔽码为0将会没有任何作用。

	许多系统也提供logger程序，这个程序可以给syslog工具发送日志消息。尽管Single UNIX Specification没有定义任何选项，有些系统实现允许为这个程序指定一些选项参数，例如facility,level,和ident.logger命令可以用于没有交互但是需要产生日志消息的shell脚本。

	举例：
	在一个打印机守护进程中，你可能会遇到这样的行：
	openlog("lpd", LOG_PID, LOG_LPR);
	syslog(LOG_ERR, "open error for %s: %m", filename);
	第一个调用设置ident参数为程序的名称（lpd），用LOG_PID指定始终打印进程ID，设置默认的facility参数为行打印系统(LOG_LPR)。调用syslog函数指定为错误条件(LOG_ERR)，并且指定了消息字符串。如果我们没有调用openlog那么我们可以用如下方式调用第二条语句：
	syslog(LOG_ERR | LOG_LPR, "open error for %s: %m", filename);
	这里我们将priority 参数指定为level和facility的组合。

	除了syslog之外，有一些系统也提供了一个变体的函数，这个函数可以处理可变参数列表:
	#include <syslog.h>
	#include <stdarg.h>
	void vsyslog(int priority, const char *format, va_list arg);
	本书中的所有四个平台都支持这个vsyslog函数，但是这个函数并没有被包含在Single UNIX Specification标准中。
	Most syslogd implementations will queue messages for a short time. If a duplicate message arrives during this time, the syslog daemon will not write it to the log. Instead, the daemon will print out a message similar to "last message repeated N times."
	大多数的syslogd实现都会对消息进行一个短期的排队。如果在这个期间有重复的消息到达，那么syslog守护进程会不登记这个消息，而是打印出一条消息，内容类似“上次这个消息已经重复了N次”。

	5)单实例守护进程
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec5.html
	有些守护进程，由于有一些特殊的操作，要求在它们运行的同时只能有一个该守护进程的实例运行。比如，守护进程可能需要互斥地访问某个设备。在使用cron守护进程的时候，如果有多个cron实例运行，那么每一个拷贝都会尝试启动一个已经调度好了的操作，这样会导致多重的操作也可能会引起一些问题。
	如果守护进程访问一个设备，有时设备驱动会阻止对/dev下面设备节点（设备文件）的多重打开，这样就限制了同一个时间只能有一个守护进程在运行。如果没有这样的设备，那么我们就需要自己来处理这些工作了。
	file-和record-locking机制提供了保证只有一个该守护进程运行的一种基本方式(后面我们会讨论文件和记录锁)，如果每个守护进程都创建一个文件并且给整个文件加上一个写锁，只允许一个这样的写锁被创建，那么后来尝试创建文件并且加锁的操作将会失败，通过这样的方式就可以通知后面重复运行的某个守护进程拷贝，已经有一个这样的守护进程实例在运行了。
	文件和记录锁提供了一种方便的互斥访问机制。对于一个已经获得了整个文件范围写锁的守护进程，该锁将会在守护进程退出的时候自动被移除，这样简化了恢复的操作，不用我们为之前的守护进程做清理的工作了。

	举例：
	下面的函数给出使用文件和记录锁保证只有一个守护进程运行的方法。
	每个守护进程都尝试创建一个文件并且把它们自己的进程ID写入这个文件，这样系统管理员可以很容易地识别这个进程。如果文件已经上锁，那么加锁函数会失败并且设置errno为EACCES或者EAGAIN,并且返回1,表示这个守护进程已经运行了。否则，我们就会将这个文件清零(truncate)，写入进程ID并且返回0。
	我们需要清零这个文件，因为之前的守护进程的ID可能比当前的大，并且字符串也长。例如原来的ID:12345，后来的ID:9999那么我们写入之后可能会变成99995，所以清零这个文件可以防止之前运行的守护进程数据对当前的守护进程造成影响。

	例子代码：
	#define LOCKFILE "/var/run/daemon.pid"
	#define LOCKMODE (S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH)
	extern int lockfile(int);
	int already_running(void)
	{
		int     fd;
		char    buf[16];

		fd = open(LOCKFILE, O_RDWR|O_CREAT, LOCKMODE);//这里打开文件
		if (fd < 0) {
			syslog(LOG_ERR, "can't open %s: %s", LOCKFILE, strerror(errno));
			exit(1);
		}
		if (lockfile(fd) < 0) {//这里上锁
			if (errno == EACCES || errno == EAGAIN) {
				close(fd);
				return(1);
			}
			syslog(LOG_ERR, "can't lock %s: %s", LOCKFILE, strerror(errno));
			exit(1);
		}
		ftruncate(fd, 0);//这里清零
		sprintf(buf, "%ld", (long)getpid());
		write(fd, buf, strlen(buf)+1);//这里写入进程id
		return(0);
	}
	以上代码关键的地方用注释标记了，只有四个关键步骤：
	a)打开文件
	b)给文件上锁
	c)给文件清零
	d)写入进程id

	6)守护进程遵循的一些标准
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec6.html
	Unix上面的守护进程，一般会遵循如下的通用标准：
	a)如果守护进程使用锁文件，那么锁文件一般会存放在/var/run目录下面。这里我们需要注意的是，我们需要拥有超级用户权限才能在这里面创建文件。创建的文件名称一般就是<name>.pid，这里的<name>就是守护进程的名称,例如crond守护进程的锁名称就是/var/run/crond.pid。
	b)如果守护进程支持配置选项，那么它们一般存放在/etc目录下面。配置文件的名称就是<name>.conf，这里<name>就是守护进程或者服务的名称,例如syslogd守护进程的名称就是/etc/syslog.conf。
	c)守护进程可以从命令行启动,但是它们一般都从某个系统初始化脚本中启动（/etc/rc*或者etc/init.d/*），如果守护进程在退出的时候应该自动重新启动，那么我们可以修改init程序的配置文件/etc/inittab的相关条目（加上respawn），让init程序来做这个工作。
	d)如果守护进程具有一个配置文件，那么守护进程在启动的时候会读取它，但是之后就不会再次读取它了。如果管理员修改了配置，那么需要重新启动这个守护进程才能让新配置起作用。对于此情况，有些守护进程会捕获SIGHUP信号，并且在收到这个信号的时候会重新读取它们的配置文件。因为守护进程并不和终端关联，并且是没有控制终端的session leader或者孤儿进程组的一员，所以信号SIGHUP对于守护进程来说是没有什么意义的，所以可以通过这种方式来重新利用这个信号。

	举例：
	这里也给出了一个例子来展示一个守护进程如何重新读取它的配置文件。程序使用sigwait和多线程技术实现这个功能，具体例子代码就不给出了，请参见参考资料。后面对这个例子进行一下简单的说明。

	我们先调用前面的daemonize函数（将一个进程变成守护进程的函数）对守护进程进行初始化，当这个函数返回的时候，我们调用already_running（判断这个守护进程是否只有一个实例在系统中运行）。这个时候，SIGHUP信号还是处于忽略的状态，所以我们需要把这个信号的处理动作重新设置成默认的行为；否则调用sigwait(线程用来等待特定信号的函数，具体前面讲过)的线程就无法看到这个信号了。

	我们按照多线程编程的一些合理性建议，把所有的信号都阻塞，然后创建了一个独立的线程来处理信号。这个线程的唯一工作就是等待SIGHUP和SIGTERM信号，当它收到SIGHUP信号的时候，线程会调用reread函数来重新读取配置文件。当线程收到SIGTERM信号的时候，它会登记一个消息并且退出。

	前面讲过，SIGHUP和SIGTERM信号的默认行为就是终止一个进程。因为我们阻止了这些信号，所以当它们发生的时候，守护进程并不会终止。相反，调用sigwait的线程会返回一个状态来标记这个信号被接收到了。

	又一个例子：
	如前面所说，Linux的线程对信号的反应有点不同，因此前面的例子中要想给合适的进程发送信号是比较困难的。另外，由于实现的不同，我们也不能保证守护进程的表现将会和我们期望的那样。
	这里的另外一个例子展示了一个守护进程如何捕获SIGHUP信号并且在不使用多线程的情况下重新读取它的配置文件。

	初始化完了守护进程之后，我们安装了SIGHUP和SIGTERM信号。我们把重新读取的逻辑放到信号处理函数中执行(本例子就是这样的)，或者在信号处理函数中设置一个标记，然后在程序的主线程中做相应的工作。
	这里就不给出具体的代码了，详细可以参见参考网址。

	7)客户服务模型
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec7.html
	常常把守护进程作为一个服务进程来使用。就像前面那样，我们使用syslogd进程作为服务进程，用户进程使用UNIX消息域给它发送消息。
	一般来说，服务进程就是一个等待客户连接的进程，客户通过连接来请求特定类型的服务。前面，syslogd服务进程所提供的服务，就是登记错误消息。
	在前面，客户进程和服务进程（syslogd）的通信是单向的。客户进程发送服务请求给服务进程，服务进程不向客户进程返回任何消息。在后面的章节中，我们将会看到大量双向通信的客户进程和服务进程的例子。客户进程给服务进程发送一个请求，服务进程反馈特定的信息给客户。

	8)总结
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch13lev1sec8.html
	在大多UNIX系统中，守护进程是一直运行的。将我们的进程初始化运行成一个守护进程，需要我们对之前讲述的进程之间的关系有一定的了解。而这一章我们就实现了一个函数，适合用来把一个进程初始化为守护进程。
	因为守护进程一般都没有控制终端所以我们讨论了守护进程登记错误消息的一些方法。我们也讨论了一些UNIX系统上面守护进程遵循的一些比较传统的约定俗成的规则，然后给出了一些实现这些规则的例子。

*高级输入输出
==========================
	1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec1.html
	这一章描述了大量的函数和内容，它们涉及到高级的i/o操作：非阻塞i/o，记录锁，System V流，多i/o(select和poll函数相关的内容)，readv和writev函数，内存映射i/o（关于mmap）。我们需要在后面描述进程内部通信以及许多例子的时候涉及到这些内容。

	2)非阻塞i/o
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec2.html
	在前面我们描述了系统调用可以分为慢系统调用以及其他的系统调用，慢系统调用实际上就是那些可以导致永远阻塞的系统调用。它们包括：
	*当特定的文件类型(管道，终端设备，网络设备)中的数据不存在的时候，可以导致调用者永远阻塞的读操作。
	*特定文件类型（管道，网络流等）无法理解接收向其中写入数据时，可以导致调用者永远阻塞的写操作。
	*对一些特定类型文件的打开操作阻塞，直到发生某些特定的条件（例如打开终端设备的操作会等待一直到modem有了响应，以写的方式打开管道而同时没有其他进程在读取其数据）
	*对持有强制记录锁的文件进行读写操作
	*一些特定的ioctl操作
	*一些进程通信函数(后面会说)
	同时那些对于磁盘的输入输出的系统调用并不是慢系统调用，尽管对磁盘文件的读写操作会临时阻塞那个调用者。
	非阻塞i/o发起的i/o操作，例如open,read,或者write等不会导致永远阻塞。如果操作不能被完成，那么调用会立即返回，并且给出一个错误以标识操作应该阻塞。

	对于一个给定的描述符，有两种方式用来指定非阻塞的i/o：
	*调用open获得文件描述符的时候，我们可以指定O_NONBLOCK标记。
	*对于已经打开的文件描述符我们可以调用fcntl来打开文件的O_NONBLOCK状态标记，
	早期版本的System V使用O_NDELAY标记来指定非阻塞模式。如果read函数没有足够的数据读取，那么这些版本的System V返回一个0。因为返回0和正常unix系统中表示文件结束的返回0相冲突，所以POSIX.1选择了另外一个不同的名字和语义来表示一个非阻塞的标记。在早期的System V中，当我们从read函数中返回一个0的时候，我们无法确定这个调用应该阻塞还是到达了文件的结尾。我们将会看到，POSIX.1要求如果从一个非阻塞的文件描述符号中读取的时候没有数据，那么read将会返回1并且设置errno为EAGAIN。有一些从System V继承下来的平台既支持原来的O_NDELAY也支持POSIX.1的O_NONBLOCK，但是在本文中，我们使用POSIX.1的方式，原来的O_NDELAY只是为了向后兼容，不应该在新的应用程序中使用了。
	4.3BSD为fcntl函数提供了一个FNDELAY标记，并且它的语义有一点不一样的地方。它不仅仅是影响文件描述符号的文件状态标记，而且终端设备或者socket的标记也会被改变成费阻塞的了，并且会影响到所有使用终端和socket的用户而不仅仅是只影响共享同样的文件描述表（4.3BSD的非阻塞I/O只在terminal和socket上面工作）的用户。同时，如果对于一个非阻塞的文件描述符号的操作如果无法完成，那么4.3BSD返回EWOULDBLOCK。今天，基于BSD的系统提供了POSIX.1的O_NONBLOCK标记，并且将EWOULDBLOCK定义成和EAGAIN一样。这些系统提供的非阻塞的语义一和其他POSIX兼容的系统相一致了：即文件状态标记的改变会影响使用同样的文件描述表的用户，但是和通过其他文件描述表访问同样设备的用户无关。

	举例
	这里给出了一个非阻塞i/o的例子。例子从标准输入读取500,000个字节，然后尝试把它们写到标准输出。标准输出首先被设置成非阻塞的。输出在一个循环中进行，每次都把将要打印的结果写到标准错误输出。
	char    buf[500000];
	int main(void)
	{
	int     ntowrite, nwrite;
	char    *ptr;

	ntowrite = read(STDIN_FILENO, buf, sizeof(buf));
	fprintf(stderr, "read %d bytes\n", ntowrite);

	set_fl(STDOUT_FILENO, O_NONBLOCK); // 设置成非阻塞

	ptr = buf;
	while (ntowrite > 0) {//通过循环对非阻塞的设备不断地写，直到写完
		errno = 0;
		nwrite = write(STDOUT_FILENO, ptr, ntowrite);
		//如果本次写无法满足那么立即返回并打印错误，等下次写
		fprintf(stderr, "nwrite = %d, errno = %d\n", nwrite, errno);

		if (nwrite > 0) {
			ptr += nwrite;
			ntowrite -= nwrite;
		}
	}

	clr_fl(STDOUT_FILENO, O_NONBLOCK); //清除非阻塞标记
	exit(0);
	}

	这里运行程序的时候将标准输入重新定向成一个普通文件了。
	如果标准输出被重新定向成了一个普通的文件那么只写了一次，过程大致如下：
	$ ls -l /etc/termcap                           打印将要读取的文件以及大小
	-rw-r--r-- 1 root      702559 Feb 23  2002 /etc/termcap
	$ ./a.out < /etc/termcap > temp.file           标准输入重新定向为那个文件，标准输出也重新定向
	read 500000 bytes
	nwrite = 500000, errno = 0                     a single write
	$ ls -l temp.file                              verify size of output file
	-rw-rw-r-- 1 sar       500000 Jul   8 04:19 temp.file
	从输出信息中，我们看到并没有打印任何的错误信息。

	但是如果标准输出是一个终端，我们将会看到写多次，每次write会返回一部分数据，有时候还打印错误信息，过程如下：
	$ ./a.out < /etc/termcap 2>stderr.out           只将标准错误重新定向，标准输出是原来的终端
		.................							这里会打印许多输出到标准输出
		$ cat stderr.out 							查看被重定向的标准错误信息
		read 500000 bytes
		nwrite = 216041, errno = 0
		nwrite = -1, errno = 11                            1,497 of these errors
		...
		nwrite = 16015, errno = 0
		nwrite = -1, errno = 11                            1,856 of these errors
		...
		nwrite = 32081, errno = 0
		nwrite = -1, errno = 11                            1,654 of these errors
		...
		nwrite = 48002, errno = 0
		nwrite = -1, errno = 11                            1,460 of these errors
		...											省略更多信息
		nwrite = 7949, errno = 0
	从这里可知有许多尝试写的操作没有成功。

	在这个系统中，错误号码11就是EAGAIN，终端驱动可以接收的数据的数目因系统有所不同。输出的结果也因你登陆系统的方式而不同：通过系统终端，有线终端，还是使用伪终端的网络连接。如果你在终端上运行一个窗口系统，你也可能通过一个伪终端设备。
	在这个例子中，程序会发起上千的写调用，尽管如此，也只是大概有10到20次需要输出数据，剩余的只是返回错误。这个类型的循环叫做polling，它也是一种对多用户系统上cpu时间的浪费。在后面的章节中，我们将会看到对于非阻塞文件描述符号的多I/O操作的方式其效率会更高一些。
	有时候，我们可以通过使用多线程技术来避免使用非阻塞i/o，我们可以通过让独立的线程阻塞在I/O调用上面，其他的线程继续它们的处理。有时侯，这样会简化设计，我们在后面会看到。然而有时候，用于同步的开销可能会增加系统的复杂，可能还不如不用线程。

	3)记录锁
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec3.html
	当两个人同时编辑一个文件的时候，在大多数unix系统上面，文件的最终状态取决于那个最后写文件的进程。在有一些应用程序中，例如数据库系统，进程需要保证只有它自己在写这个文件。商业化的unix系统通过记录锁的机制来提供这样的功能(在本书的后面就给出了一个使用记录锁实现的简单的数据库的函数库)。
	记录锁(record locking)可以用来描述一种功能，它在一个进程读写文件的某一个部分时，保护文件不被其它进程相应的内容。在Unix中"record"这个词容易引起歧义，因为unix系统中对于文件并没有记录的概念，一个稍微好点的描述应该是字节锁（byte-range locking），因为它只是用来表示文件被保护的那部分在文件中的字节范围。

	历史信息：
	早期unix的一个问题就是，它不能用来运行数据库系统，因为没有可以锁一个文件某个区域的锁机制。随着unix向商业化计算环境的迈进，许多组织开始向其中添加各种记录锁的机制（当然它们之间各不相同）。
	早期的伯克利发行版本，只支持flock函数，这个函数只能用来锁住文件的整个区域而不是部分区域。
	记录锁在System V的第3个发行版本中通过fcntl函数被添加进来。lockf就是基于此提供了一个简单的接口，这个函数允许调用这锁住文件的任何范围，从整个文件，到单个字节。
	POSIX.1选择了对fcntl函数进行了标准化，本节给出了各种系统可以支持的记录锁的形式。注意Single UNIX Specification把lockf函数包含在其XSI扩展中了。
	这里各种系统支持的记录锁的形式有(Advisory,Mandatory,fcntl,lockf,flock)，具体参见参考资料。
	在后面会对advisory和mandatory锁的区别进行描述，这里我们只描述POSIX中的fcntl函数。
	记录锁原来是1980年被Joh Bass加入到版本7中的。进入到内核的系统调用入口是一个叫做locking的函数。这个函数提供了mandatory记录锁，并且广泛应用在许多System III的版本中，Xenix系统采用了这个函数，其他基于intel的System V衍生系统系统，例如Open Server 5在Xenix兼容的库中还在支持它。

	fcntl记录锁
	前面已经进行过它的介绍，其声明如下：
	#include <fcntl.h>
	int fcntl(int filedes, int cmd, ... /* struct flock *flockptr */ );
	返回：如果成功则取决于cmd参数，如果出错则返回1。

	用于记录锁的cmd参数是F_GETLK,F_SETLK,或者F_SETLKW。第三个参数（后面我们称flockptr）是一个指向flock结构的指针。
	struct flock {
		short l_type;   /* F_RDLCK, F_WRLCK, 或者 F_UNLCK */
		off_t l_start;  /* 相对于l_whence的字节偏移量 */
		short l_whence; /* SEEK_SET(绝对位置), SEEK_CUR（当前位置）, 或者 SEEK_END(结尾) */
		off_t l_len;    /* 字节长度；0代表一直锁到EOF */
		pid_t l_pid;    /* 和F_GETLK一起返回 */
	};
	这个结构描述的信息：
	*所需要的锁的类型：F_RDLCK(共享读锁)，F_WRLCK(互斥写锁)，或者F_UNLCK(解锁一个区域)。
	*将要加锁或者解锁的起始字节偏移（l_start和l_whence）。
	*区域的字节大小（l_len）。
	*可以阻塞当前进程(只通过F_GETLK返回)的持有锁的进程ID。

	对于区域的上锁和解锁，有各种规则和标准。
	* 用于指定区域的起始偏移的两个元素和lseek函数的最后两个参数类似。l_whence成员被设置为SEEK_SET,SEEK_CUR,或者SEEK_END。
	* 锁的起始和扩展可以超过文件的结尾，但是不能越过文件的开头。
	* 如果l_len为0，那么意思是说锁被扩展到尽可能大的文件偏移。这允许我们从文件的任意一个位置开始开始锁定一个区域，达到超过并包含后追加到文件结尾的数据（我们不用尝试猜测可能向文件添加了多少个字节）。
	*为了锁住整个文件，我们设置l_start和l_whence指向文件的开始（有很多方法可以指定文件的开始，最常用的方法就是指定 l_start为0并且指定l_whence为SEEK_SET），指定l_len为0。

	我们提到了两种类型的锁：一个是共享读锁（l_type为F_RDLCK）以及互斥写锁（F_WRLCK）。对于这个锁，一个基本的规则就是，（在某一个时刻）对于给定的字节，可以有任何数目的进程持有共享读锁，但是只能有一个进程可以持有互斥写锁。另外，如果有一个或者多个进程拥有了一个字节上的共享读锁，那么那个字节上不能有互斥写锁；反之如果一个字节上有了互斥写锁，那么那个字节上不能有任何的其它锁（写和读都不能有）。在本节用一个图表描述了这个关系，这里就不给出了，想要直观地看到这个关系的话请参见那个图表。
	上面描述的锁规则，是用于多个进程之间的，而不是同一个进程中的多个锁。如果一个进程在文件的范围内持有一个锁，那么这个进程接下来如果尝试向同样的范围申请添加锁的话那么将会将原来的锁替换成新的锁。因此，一个进程如果在文件上的1632字节处持有了一个写锁，之后它想要向这个1632字节处加入读锁，那么这个请求也会成功（假设我们没有和其他的进程竞争地向文件的同样一个地方添加锁），并且之前的写锁会被后来申请的读锁替换。
	为了获得一个读取锁，文件描述符号必须以读取的方式被打开；为了获得一个写入锁，文件描述符号必须以写入的方式被打开。我们现在描述一个fcntl函数的这三个命令：
	F_GETLK:
	用于决定flockptr参数描述的锁是否被其他的锁阻塞。如果已经存在其他的锁那么如果我们创建锁的话将会被阻止，并且那个已经存在的锁的信息将会被写入到flockptr参数中，覆盖我们之前传入的值。如果没有其他的锁存在，那么我们创建锁的操作就不会被阻止了，并且flockptr参数指向的数据结构的l_type成员被设置为F_UNLCK，其他的成员保持不变。
	F_SETLK:
	设置锁为flockptr参数表示的锁。如果我们尝试获取一个读锁(l_type值为F_RDLCK)，或者写锁（l_type值为F_WRLCK），但是根据前面的规则系统无法给我们锁，那么这个时候fcntl会立即返回，并且将errno设置成EACCES或者EAGAIN。
	尽管POSIX允许实现返回错误代码（errno），本书描述的四个系统在锁请求无法满足的时候也会返回EAGAIN。这个命令也用来清除flockptr所表示的锁的状态（l_type的值为F_UNLCK）。
	F_SETLKW:
	这个命令是F_SETLK的阻塞版本（W代表的意思是wait）。如果请求的读或者写锁是由于其它进程的锁和请求区域重叠，导致无法成功，那么调用进程将会睡眠。进程会在锁变成可用的时候或者当收到一个信号的时候被唤醒。

	需要注意的是，我们使用F_GETLK测试锁然后使用F_SETLK或者F_SETLKW获取锁，这两步操作并不是原子的操作。我们无法保证在这两次fcntl期间不会有其他的进程进入，并且获取同样的锁。如果我们不想在等待锁变成可用的期间阻塞，那么我们必须处理F_SETLK返回的错误。
	需要注意的，对于一个特殊的情况POSIX.1并没有指明在这个情况的时候会发生什么。这个情况就是：当一个进程拥有了文件指定范围的读锁，另外一个进程由于这个读锁的存在当它在同样的区域请求写锁导致阻塞，然后第三个进程在同样的区域请求读锁。如果让第三个进程请求读锁成功（因为这不和前面的加锁规则冲突，所以可以有多个读锁存在，所以可以成功），那么第二各请求写锁的进程将可能等待更长的时间（因为写锁必须等所有锁都释放才能请求成功，而在它等待的期间锁的数目没有减少反而增加了）。
	当设置或者释放文件上面的锁的时候，系统将会根据请求合并或者分割相应的区域。例如，如果我们锁住了100-199的字节区域，然后释放150字节，那么内核会保持100-149以及151到199字节区域上面的锁。本文中有一个图示便于直观地了解这个情况，这里不给出了。
	如果我们再将150字节处锁上，那么系统同样会将其邻近的两个有锁区域与之合并，这样锁区域就由原来的100-149,150,151-199三个区域合并成100-199这一个区域了。

	请求和释放锁的例子
	下面的lock_reg函数，可以方便我们，不用在每次申请锁的时候都需要填充其中的每一个成员了。
	#include <fcntl.h>
	int lock_reg(int fd, int cmd, int type, off_t offset, int whence, off_t len)
	{
	    struct flock lock;
	    lock.l_type = type;     /* F_RDLCK, F_WRLCK, F_UNLCK */
	    lock.l_start = offset;  /* 相对于l_whence的字节偏移 */
	    lock.l_whence = whence; /* SEEK_SET, SEEK_CUR, SEEK_END */
	    lock.l_len = len;       /* 字节数 (0 表示 EOF，即文件结尾) */
	    return(fcntl(fd, cmd, &lock));
	}

	由于大多数的操作都是加锁或者解锁的操作（F_GETLK很少被用到），所以定义了下面的宏：
	#define read_lock(fd, offset, whence, len) \
	            lock_reg((fd), F_SETLK, F_RDLCK, (offset), (whence), (len))
	#define readw_lock(fd, offset, whence, len) \
	            lock_reg((fd), F_SETLKW, F_RDLCK, (offset), (whence), (len))
	#define write_lock(fd, offset, whence, len) \
	            lock_reg((fd), F_SETLK, F_WRLCK, (offset), (whence), (len))
	#define writew_lock(fd, offset, whence, len) \
	            lock_reg((fd), F_SETLKW, F_WRLCK, (offset), (whence), (len))
	#define un_lock(fd, offset, whence, len) \
	            lock_reg((fd), F_SETLK, F_UNLCK, (offset), (whence), (len))

	测试锁的例子：
	这里，给出了一个lock_test函数，用于对锁的测试，如果
	如果锁存在，将会阻塞参数指定的特定请求，并且返回持有锁的进程ID。否则函数返回0（就是false）。

	#include <fcntl.h>
	pid_t lock_test(int fd, int type, off_t offset, int whence, off_t len)
	{
	    struct flock lock;
	    lock.l_type = type;     /* F_RDLCK 或者 F_WRLCK */
	    lock.l_start = offset;  /* 相对于l_whence的字节偏移 */
	    lock.l_whence = whence; /* SEEK_SET, SEEK_CUR, SEEK_END */
	    lock.l_len = len;       /* 字节数 (0 表示 EOF，即文件结尾) */

	    if (fcntl(fd, F_GETLK, &lock) < 0)
	        err_sys("fcntl error");

	    if (lock.l_type == F_UNLCK)
	        return(0);      /* 如果区域没有被其他的进程锁住，那么返回false */
	    return(lock.l_pid); /* 如果区域被其他的进程锁住，返回持有锁的进程的id，也就是true */
	}

	我们一般使用如下的两个宏来调用这个函数：
	#define is_read_lockable(fd, offset, whence, len) \
	          (lock_test((fd), F_RDLCK, (offset), (whence), (len)) == 0)
	#define is_write_lockable(fd, offset, whence, len) \
	          (lock_test((fd), F_WRLCK, (offset), (whence), (len)) == 0)

	需要注意的是进程不能使用lock_test函数来查看它本身当前是否持有文件某一个区域内的锁。F_GETLK命令所描述的信息是：返回的锁如果存在的话那么那个锁应该是阻止我们创建自己的锁。因为F_SETLK和F_SETLKW命令在本进程已经持有锁的情况下，也会设置成功并且会替换本进程原来的锁，也就是说我们永远不会因为自己持有锁而被阻塞；所以，使用F_GETLK命令，并不会获取我们自己是否持有锁，这样的信息。

	死锁的例子：
	死锁出现在两个进程互相等待对方持有的锁住的资源的时候。当一个进程持有一个锁区域，然后它向另外一个进程申请锁，因为没有申请到而进入睡眠，这个时候就可能发生死锁。
	这里就给出了一个例子，例子中父子进程分别持有锁，并且向文件中写数据，然后又分别向对方申请对方持有的锁。具体代码不给出了，具体参见参考资料。
	当发现死锁的时候，内核会选择一个进程接收错误并且返回。在这个例子中，选择子进程接收错误并返回，但是这是和实现相关的特性。有些系统中总是选择子进程接收错误，还有些系统中总是选择父进程接受错误，还有些系统你会发现在尝试使用多个锁的时候，在父子进程中都会发生错误。

	锁的继承和释放:
	有三个规则用来管理锁的继承和释放：
	a,锁是和进程与文件相关的。这有两个含义。第一个含义很明显，就是当进程终止的时候，它所持有的所有的锁都会被释放；第二个含义就不是那么明显了，意思是当一个文件描述符被关闭的时候，进程持有的所有那个文件描述符所引用的文件上面的锁将都会被释放。具体点说：
	fd1 = open(pathname, ...);
	read_lock(fd1, ...);
	fd2 = dup(fd1);
	close(fd2);
	当我们调用close(fd2)的时候，在fd1上面获取的锁也会被释放(因为fd1引用同一个文件)。我们使用dup替代open的时候，也会发生同样的事情如下：
	fd1 = open(pathname, ...);
	read_lock(fd1, ...);
	fd2 = open(pathname, ...)
	close(fd2);
	这里在fd2上面打开的文件和fd1是同样的文件。
	b,子进程不会通过fork继承锁。这个意思是说，当父进程获取锁之后调用fork，那么子进程对于父进程所获取的那个锁来说是另外一个进程。子进程需要调用fcntl函数向继承自父亲的文件描述符申请自己的锁。这个是很重要的，因为锁存在的意义就是阻止多个进程同时向同样的文件中写入数据，如果子进程通过fork从父进程那里继承了锁，那么父子进程就都可以同时向同样的文件中写入数据了。
	c,锁通过exec函数调用，被新的进程继承。但是需要注意的是，如果文件描述符号的close-on-exec标记被设置了，那么当这个文件描述是符号在exec中被关闭的时候，这个文件上面相应的所有的锁都会被释放。

	FreeBSD上面的实现
	这里给出了一个FreeBSD上面实现时的数据结构，可以帮助我们理解前面规则1中说的“锁是和进程与文件相关的”意思。
	代码如下：
	fd1 = open(pathname, ...);
	write_lock(fd1, 0, SEEK_SET, 1);
	if ((pid = fork()) > 0) {
		fd2 = dup(fd1);
		fd3 = open(pathname, ...);
	} else if (pid == 0) {
		read_lock(fd1, 1, SEEK_SET, 1);
	}
	pause();
	由这个代码，会在内存中生成两个进程的进程表，文件表，以及文件索引表，其图示关系这里就不给出了，具体参见参考资料。这里给出一些相对关键的描述：
	我们可以知道，运行完前面的代码之后，无论是父还是子进程，其文件描述符号fd1,fd2,fd3无论是如何打开的，最终都指向了同一个索引节点（因为它们本身就代表的同一个文件）就是i-node结构。我们看到在这个i-node结构中有一个lockf结构的成员链表，链表中的每一个lockf结构变量都描述了一个特定进程的锁区域，其中lockf结构中有一个成员变量指明这个锁对应的进程的进程ID。从这个例子中，我们可以知道，目前i-node结构中得lockf结构链表中有两个成员，一个表示子进程的锁，一个表示父进程的锁。
	在父进程中，关闭fd1,fd2,fd3中的任何一个，都会导致父进程的锁被释放。释放的时候，内核会遍历i-node中的锁链表，找到调用进程对应的锁并且释放。内核无法知道也不关心父进程是通过这三个文件描述符号中的哪一个来获取到锁的。

	例子
	在前面我们看到过守护进程使用文件锁来确保同一时刻只有一个守护进程的实例在运行。这里，给出了前面守护进程给文件加上写锁所使用的那个lockfile函数的实现。
	我们可以使用如下宏定义将lockfile定义为write_lock的一个宏（write_lock前面已经给出过定义）：
	#define lockfile(fd) write_lock((fd), 0, SEEK_SET, 0)
	代码如下：
	#include <unistd.h>
	#include <fcntl.h>
	int lockfile(int fd)
	{
		struct flock fl;
		fl.l_type = F_WRLCK;
		fl.l_start = 0;
		fl.l_whence = SEEK_SET;
		fl.l_len = 0;
		return(fcntl(fd, F_SETLK, &fl));
	}

	关于文件结尾的加锁解锁
	向相对文件结尾的位置加锁或者解锁的时候需要注意一些事情。大多数的实现会根据文件当前的位置和长度，将值为SEEK_CUR或SEEK_END的l_whence转换成文件的绝对位移。然而我们需要经常相对于文件的当前位置和长度指定一个锁(一个“整体”的操作)，因为我们不能使用lseek来获得文件的当前位移(这是因为我们不持有文件的锁,这样其他的进程就有机会在lseek和lock之间改变文件的长度)。
	考虑如下的步骤：
	writew_lock(fd, 0, SEEK_END, 0);
	write(fd, buf, 1);
	un_lock(fd, 0, SEEK_END);
	write(fd, buf, 1);
	这个代码序列，可能不会做到你所期望的事情。它从当前的文件结尾获取到了一个可以扩展的写锁，这个锁将会覆盖将来我们追加到文件中的任何数据（但是这个锁当前没有锁住文件的任何内容，特别注意没有锁最后一个字节）。假设我们做第一个写操作的时候正在文件的结尾，那样将会使文件扩展一个字节并且那个扩展的字节将会被锁住。接下来的unlock操作会使将来追加到文件中的数据不再被锁住了，但是它并没有去掉当前新增的文件的最后一个字符的锁（因为文件最后一个字符的位置是SEEK_END-1）。当第二个写操作发生的时候，文件的结尾又被扩展了一个字节，但是这个字节就不是被锁的了。通过这一系列的操作，最后文件中有一个被锁住的字节（就是第一次写的那个字符被锁住了），参考资料中用图示的方式对其进行了描述，这里就省略了。
	当文件的一个部分被锁住的时候，内核会将指定的偏移转换成文件的绝对偏移位置。除了使用SEEK_SET可以指定文件的绝对偏移之外，fcntl还允许我们指定相对于文件某个位置的偏移：SEEK_CUR指定相对当前位置的偏移，SEEK_END指定相对文件结尾的偏移。内核需要记住相应的锁，但是这个锁本身和文件的当前位置以及文件结尾没有关系（尽管这个锁是有范围的），因为当前的位置以及文件的结尾是不断变化的，但是不能因为这些属性发生了变化就改变已经存在的锁的状态（也就是说这个覆盖了一定范围的锁是固定的，不会随着文件的长度当前文件的指针得变化而变化和移动）。
	这里，如果我们想要将第一次写入的字节的锁移除，那么我们可以指定length为-1。用负数的长度值代表指定位置的前面。

	建议锁和强制锁
	假设有一个包含访问数据库函数的库。如果库中的所有函数以一种一直的方式处理记录锁，那么我们就说任何使用这些函数访问数据库的进程集合都是协作的进程。如果只使用这些函数来访问数据库，那么可以让这些数据库访问函数使用强制锁。但是强制锁不能组织其他具有写权限的进程向数据库写数据。这些进程因为没有使用那个库中的函数来访问数据库，所以它们就是非协作进程。
	强制锁导致内核对进程所访问的文件的每一次打开和读写进行检查和验证，看它们是否符合锁的规则。有时候，强制锁也被称作强制模式(enforcement-mode)的锁。
	我们在前面的资料中可以知道，Linux2.4.22和Solaris9提供了强制记录锁，但是FreeBSD5.2.1和MacOS X 10.3并没有提供。强制锁并不是Single UNIX Specification的一部分。在Linux上，如果你想要使用强制锁，需要通过使用mount命令的"-o mand"选项在文件系统的级别上将它激活。
	对于一个特定的文件的强制锁，我们是通过打开set-group-ID位并且关闭group-execute位来将其激活的。可以这样做的原因是，本来关闭group-execute位的同时打开set-group-ID是没有意义的(我们可以查阅前面的章节来确认这一点)，所以 SVR3的设计者们选择了这个方式来指定对一个特定文件的锁不是建议锁(advisory locking)而是强制锁(mandatory locking)。

	当一个进程尝试读写一个文件，而其他进程持有这个文件的读或者是写的强制锁的时候，运行的结果取决于进程的读写类型，其他进程持有的锁类型，以及操作文件是否阻塞。
	文中用一个表描述了这个规则，这里就不重复了，具体参见参考资料，大致描述一下这个表格：
	表格的大致意思就是:和前面的读写锁规则类似，读是可以共享操作的，写却是互斥的，如果出现了不能读或者写的情况，那么根据所操作的文件的特性要么阻塞，要么返回EAGAIN错误。
	除了上述表格描述的读写函数的行为，其它进程持有强制锁，对文件的open操作也会有所影响。一般来说，即使其他进程持有文件的强制锁，open函数也会成功地返回，而接下来的读写操作就会依照上述表格的规则进行。但是调用open时候指定了O_TRUNC 或者 O_CREAT，那么无论是否指定了O_NONBLOCK，open都会立即返回EAGAIN错误。
	只有Solaris将O_CREAT视为一种错误的情况,Linux允许open的O_CREAT标记在文件持有强制锁的时候也可以被指定。对于O_TRUNC生成open的错误是有意义的，因为如果文件具有读或者写锁的时候，无法对文件进行truncate。但是为open的O_CREAT生成错误就没有太大的意义了，因为这个标记的意思是当文件不存在的时候创建一个文件，而只有文件的存在的时候，其它进程才会持有这个文件的记录锁。
	open调用对锁冲突进行如此的处理，会导致一些意外的结果。在本章的一个练习中，有一个测试程序，它运行的时候打开一个可以具有强制锁模式的文件，然后申请了整个文件的读锁，然后进入了睡眠。在睡眠期间，一些典型的UNIX系统应用程序行为的如下：
	a)ed编辑器可以编辑这个文件，并且结果会写入到磁盘中去！这个时候强制锁记录的检查没有一点效果，使用系统调用trace可以看到，ed编辑器是把新的内容写到了一个临时的文件中，然后将原始的文件删除，再将临时的文件重新命名为原始的文件。由于强制锁对unlink函数没有效果，所以发生了这样的情况。
	在Solaris中，进程的trace系统调用通过truss命令获得。FreeBSD和Mac OS X使用ktrace和kdump命令。Linux使用strace命令来跟踪进程发起的系统调用。
	b)vi编辑器无法编辑文件。它可以读取文件中的内容，但是当它尝试向文件写入新的内容的时候，会返回EAGAIN错误。如果我们尝试向文件中追加新的数据，那么写操作会被阻塞。vi所表现出来的行为就是我们所期望的行为。
	c)使用Korn shell的>和>>操作符号来覆盖或者向文件追加内容会导致"cannot create"错误。
	d)使用Bourne shell的时候，>操作符号会返回错误，但是>>符号会阻塞，直到强制锁被移除，然后继续执行。（导致两种shell的>>追加操作符号不同的原因是：Korn shell使用O_CREAT和O_APPEND来打开文件，而我们前面说过使用O_CREAT会产生错误；Bourne Shell在文件已经存在的时候，不指定O_CREAT，所以打开操作是成功的，但是后来的写操作却发生了阻塞）
	根据你所使用的系统的不同，结果也会不同。ed编辑器的处理却绕过了这些不同。另外，注意一个居心叵测的用户可能会利用Mandatory来达到他邪恶的目的。

	例子：
	参考资料中给出了一段程序用来检测一个系统是否支持强制锁。
	这个程序创建了一个文件并且打开这个文件的强制锁特性。程序然后分成两个进程：父进程和子进程。父进程获取整个文件的写锁。子进程首先设置它自己的文件描述符号为非阻塞状态，然后尝试获取文件的读锁，这样期望会获得一个错误，让我们看到系统是返回EACCES或者EAGAIN。然后，子进程回到文件的开始，尝试从文件中读取数据。如果强制锁是支持的，那么读的操作将会返回EACCES或者EAGAIN（因为文件描述符号是非阻塞的），否则读操作会返回它所读取的数据。（通过上面的这个描述，我们可以知道，如果锁是非强制的，那么我们需要自己通过对锁的申请来控制数据的访问，而如果锁是强制的话读写的系统调用里面就进行了自动的检测我们其实就不用显式加锁了^_^）。
	程序的描述大致如上，源代码就不给出了，具体参见参考资料：
	在Solaris 9上面运行程序，那么会返回如下输出：
	$ ./a.out temp.lock
	read_lock of already-locked region returns 11
	read failed (mandatory locking works): Resource temporarily unavailable
	通过"man 2 intro"我们可以知道，errno为11表示EAGAIN错误。
	在FreeBSD 5.2.1上面运行这个程序，我们得到如下输出：
	$ ./a.out temp.lock
	read_lock of already-locked region returns 35
	read OK (no mandatory locking), buf = ab
	这里，errno 为35表示EAGAIN。强制锁是不被支持的。

	又一个例子：
	再回到我们开始的问题：如果两人同时编辑同一文件会怎样？一般的UNIX系统的文本编辑器不会使用记录锁，所以结果取决于最后写文件的进程。
	有些版本的vi编辑器使用建议锁和记录锁。尽管我们使用了这些版本的vi编辑器，也无法阻止其它没有建议锁和记录锁的编辑器运行并修改这个文件。
	如果系统提供了强制记录锁，我们可以修改我们的编辑器以支持它（这需要我们有编辑器的源代码）。如果没有编辑器的源代码，我们可以做如下的尝试：写一个我们自己的程序做为vi的前端。这个程序立即执行fork饭后父进程只是等待子进程的结束。子进程打开命令行指定的文件，使能强制锁，获取整个文件的写锁，然后对vi程序执行excute。当vi运行的时候，文件就是写状态的了，所以其它的用户无法修改它。当vi结束的时候，父进程等待到了子进程并返回，然后我们的前端程序就结束了。
	事实上，我们可以写一个这样的小的程序前端，但是它不能工作。问题是，大多数的编辑器读取它的输入文件，然后就将文件关闭了。这样，当文件描述符号被关闭的时候，这个文件上面的锁就被释放了。也就是说，编辑器在读取到文件内容之后，就关闭了它所打开的文件，导致锁被释放。我们没有办法在前端程序中阻止这个事情的发生。
	我们将在后面的章节中，在一个数据库程序库中使用记录锁，提供多进程并发访问的功能。我们也给出了它的执行时间，并看到记录锁对一个进程到底有什么影响。

	4)流
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec4.html
	System提供的Streams(流)机制作为驱动向内核通信的一种通用接口。为了了解System V的终端接口，以及多I/O的poll函数的使用，以及基于流的管道和有名管道的实现，我们需要对流(STREAMS)进行讨论。
	这里注意不要将这里说的"流"和我们之前讨论标准I/O库中说的"流"相互混淆。这里的流机制由Dennis Ritchie开发，澄清传统的字符I/O系统和适应网络协议。流的机制在被加强并且标准化了其名字之后，被加入到SVR3。SVR4提供了对流（也就是一个基于流的终端I/O系统）的完全支持。在本书列出的参考资料，SVR4的实现，[AT &T 1990d]有描述，Rago[1993]描述了用户级别的流编程以及内核级别的流编程。
	流在Single UNIX Specification作为一个可选的选项(包含在"XSI STREAMS Option Group")。本书所讨论的四种平台上，只有Solaris提供了对流的本地支持。流的子系统在linux上面是可用的，但是需要你自己添加，它并不是默认被包含进去的。
	流在用户进程和设备驱动之间提供了一条全双工的路径。不需要流向硬件设备发出信息，可以通过伪终端设备使用流，参考资料给出了一个简单的流的基本图示。这里不给出了。
	对于这个图示，详细参见参考资料，简单描述一下层次结构从上到下为：
	User Process<-->Stream head(系统调用接口)<-->device driver(或者伪终端设备驱动)
	其中stream head和device driver属于内核的部分。我们可以通过ioctl命令将进程模块推送到Stream head下面。参考资料也给出了一个基本图示。这里不给出了。
	对于这个图示，详细参见参考资料，简单描述一下层次结构从上到下为：
	User Process<-->Stream head(系统调用接口)<-->Process module<-->device driver(或者伪终端设备驱动)
	我们可以推送任何数目的模块，这里使用推送，是因为新的模块就在stream head下面，并且将旧模块向下推（有点类似于后进先出的栈），我们向stream head写入数据叫"send downstream"，从device driver读取数据叫"send upstream"。
	STREAMS模块在做为内核的一个部分被执行的时候，有点类似设备驱动模块，它们一般在编译内核的时候被直接链接进内核中了。如果系统支持动态内核模块加载（例如Linux和Solaris），那么我们可以不直接将STREAMS模块链接到内核中，而是将它推送到一个流中。然而我们无法保证这样任意组合的模块和驱动在一起能够正常地工作。
	我们在前面访问流的时候，通过如下函数：open,close,read,write,以及ioctl。另外，有三个新的函数被添加到SVR3(System V Release 3)的内核中，用来支持STREAMS(getmsg,putmsg,以及poll)，另外还有两个函数（getpmsg和putpmsg）在SVR4中被添加进来，用来处理流中不同优先级的消息。我们后面会描述这5个函数。
	我们用来打开流的路径位置一般位于目录/dev下面。所有的STREAMS设备都是字符设备文件。
	尽管STREAMS文档暗示我们可以写进程模块，并且把它们就那么推送到一个流（stream）中，编写这些模块和编写设备驱动需要同样的技术。一般来说，一个特定的应用程序或者函数会将STREAMS的模块进行推送或者弹出。
	在STREAMS之前，终端通过c-list机制进行处理。添加另外一个字符设备到内核中包含的工作有：写一个设备驱动，并且将所有内容放到驱动中。访问新的设备一般通过一个原始设备进行。也就是说，每个用户的读写都直接在设备驱动中结束。STREAMS机制对这个交互方式进行了重新整理，允许数据流以STREAMS消息的方式在stream head和驱动之间流动，并且允许任何数目的中间进程模块对数据进行操作。

	流消息
	所有在STREAMS下的输入输出都是基于消息的。stream head和用户进程通过read,write,ioctl,getmsg,getpmsg,putmsg和putpmsg来交换消息。消息也会在stream head,进程模块，和设备驱动之间上下地传递流。
	在用户进程和stream head之间，消息包含消息类型，选项控制信息，以及数据。这里我们给出来了一个表格列出各种类型的消息是如何通过传递给write,putmsg,和putpmsg的不同参数产生的。表格就不列出了，具体参见参考资料。
	控制和数据信息通过strbuf结构来表示：
	struct strbuf
	int maxlen;  /* 缓存大小 */
	int len;     /* 当前缓存的字节数目 */
	char *buf;   /* 指向缓存的指针*/
	};

	当我们使用putmsg或者putpmsg发送消息的时候，len指定缓存中的数据字节数目。当我们使用getmsg或者getpmsg接收消息的时候，maxlen指定缓存的大小（这样内核不会使缓存溢出），并且len被内核设置用来指明存放在缓存中的数据量。我们将会看到0长度的消息是OK并且len为1可以用来指定没有控制信息或者数据。
	为什么我们需要传递控制信息和数据？因为提供两者就允许我们在用户进程和流之间执行服务的接口。关于服务的接口，需要参考额外的参考资料这里不说了。
	另外一个控制信息的例子就是发送无连接的网络消息（datagram）。为了发送消息，我们需要指定消息的内容(数据)以及消息的目标地址（控制信息）。如果我们不将控制信息和数据一起发送，那么就需要一些ad hoc策略。例如，我们可以通过ioctl指定地址，接下来将数据write。另外一个技术就是让地址信息占据使用write写入的数据的前N个字节。从数据中区分控制信息，然后提供函数处理两者（putmsg和getmsg）是一个简洁的方法。
	有大约25中不同类型的消息，但是只有一部分在用户进程和stream head之间使用。其他的在内核里面的上下流传递（这些消息类型对于编写STREAMS进程模块的人来说是有用的，但是用户级别可以完全忽略它们）。我们只根据我们使用的函数(read,write,getmsg,getpmsg,putmsg和putpmsg)来说一下三种类型的消息：
	    * M_DATA (用于I/O的用户数据)
	    * M_PROTO (协议控制信息)
	    * M_PCPROTO (高优先级别的协议控制信息)
	每个流中的消息有一个队列优先级别：
	    * 高优先级消息（最高优先级）
	    * 有优先级别的消息
	    * 一般的消息 (最低优先级)
	普通消息就是优先级别为0的消息。有优先级别的消息有一个1255的优先级标志，高的优先级的标志会更大。高优先级消息是一种特殊的消息，在同一个时刻，stream head只能对一个高优先级的消息进行排队。另外，如果stream head 的读队列中如果已经有了一个高优先级的消息，那么后来的高优先级消息将会被忽略。
	每个STREAMS模块有两个输入队列。一个队列从模块的上方接收消息（消息从stream head向下流动到驱动），还有一个从模块的下方接收消息（消息从驱动向上流动到stream head）。在输入队列中的消息通过优先级进行安排。我们在前面已经提到过如何通过write,putmsg,和putpmsg函数的参数来产生各种不同优先级的消息的。
	还有一些我们没有考虑的其他类型的消息。例如，如果stream head从下面接收到了一个M_SIG消息，那么它会产生一个信号。这也是终端行模块给一个具有控制终端的前台进程组发送终端信号的方式。

	putmsg和putpmsg函数
	putmsg和putpmsg函数用来向一个流中写入流消息（包含控制信息或者数据信息或者两者都有）:
	#include <stropts.h>
	int putmsg(int filedes, const struct strbuf *ctlptr, const struct strbuf *dataptr, int flag);
	int putpmsg(int filedes, const struct strbuf *ctlptr, const struct strbuf *dataptr, int band , int flag);
	两个函数都在成功的时候返回0，错误的时候返回1。
	我们也可以向一个流进行write效果等价于没有任何控制信息并且flag为0的putmsg。
	这两个函数可以产生三种不同优先级的消息:普通消息，带有优先级的消息，以及高优先级的消息。前面提到的参考资料中的表格中就说明了如何通过对这两个函数参数的不同组合产生不同优先级的消息。
	在这个表格（表格请参照参考资料）中，如果控制信息部分为no那么对应ctlptr参数为NULL或者ctlptr->len为1;如果控制信息部分为yes那么对应ctlptr为非NULL并且ctlptr->len大于等于0。数据信息部分的处理方式和控制信息部分类似。

	STREAMS的ioctl操作
	前面我们说过ioctl函数处理所有其他I/O函数无法处理的工作。STREAMS系统也尊崇这个传统。
	在Linux和Solaris之间，有几乎40种不同的流操作可以使用ioctl实现。大多数这些操作在streamio(7)的man手册中列出来了。在c程序中使用这些函数的时候必须包含头文件<stropts.h>。ioctl函数的第二个参数就是请求，它指定了要进行什么操作，所有的请求以I_开头。第三个参数取决于请求，有时它是一个整数，有时它是一个指向整数或者结构变量的指针。

	例子：
	isastream函数
	有时候，我们需要确定一个文件描述符引用的是否是一个流。这个有点类似于isatty函数，isatty函数就是用来判断一个文件描述符是否是一个终端设备。Linux和Solaris提供了isastream函数。
	#include <stropts.h>
	int isastream(int filedes);
	返回：如果是STREAMS设备则返回1(true)，如果不是则返回0（false）。
	这个函数和isatty类似只是一个非常小的函数，所做的工作只是发送一个只有STREAMS设备上才合法的ioctl请求。后面的例子给出这个函数的可能实现。我们使用ioctl的I_CANPUT命令，用来检查被第三个参数设置的优先级(这里是0)是否可写。如果ioctl成功那么流不会变化。然后我们又将写一个程序对这个函数进行测试，具体代码参见后面。
	代码：
	int isastream(int fd)
	{
	    return(ioctl(fd, I_CANPUT, 0) != -1);
	}


	int main(int argc, char *argv[])
	{
	    int     i, fd;
	    for (i = 1; i < argc; i++) {
	        if ((fd = open(argv[i], O_RDONLY)) < 0) {
	            err_ret("%s: can't open", argv[i]);
	            continue;
	        }
	        if (isastream(fd) == 0)
	            err_ret("%s: not a stream", argv[i]);
	        else
	            err_msg("%s: streams device", argv[i]);
	     }
	     exit(0);
	}

	Running this program on Solaris 9 shows the various errors returned by the ioctl function:
	在Solaris 9上面运行这个程序，显示如下：
	$ ./a.out /dev/tty /dev/fb /dev/null /etc/motd
	/dev/tty: streams device
	/dev/fb: not a stream: Invalid argument
	/dev/null: not a stream: No such device or address
	/etc/motd: not a stream: Inappropriate ioctl for device
	需要注意的是/dev/tty是一个STREAMS设备，而字符设备文件/dev/fb并不是一个STREAMS设备,但是它支持其他的ioctl请求。这些设备在ioctl请求未知的情况下返回EINVAL。字符设备文件/dev/null不支持任何ioctl操作，所以会返回ENODEV错误。最后，/etc/motd是一个正规文件（普通文件），它并不是字符设备文件，所以会返回ENOTTY错误。我们从来没有接受到我们期望的ENOSTR("Device is not a stream")错误。
	消息ENOTTY用来表示"Not a typewriter"，这是一个历史的遗留问题，UNIX内核当ioctl尝试一个非字符设备的文件标号的时候，会返回这个错误。这个消息在Solaris被更新成了"Inappropriate ioctl for device."

	例子
	如果ioctl请求是I_LIST，那么系统会返回推送到流上面的所有模块的名称,包含最顶端的驱动(这里，我们说到最顶端是因为在多I/O的时候，可能会有不止一个驱动)。第三个参数是一个指向str_list结构的指针。
	struct str_list {
		int                sl_nmods;   /* 数组元素数目 */
		struct str_mlist  *sl_modlist; /* 数组第一个元素 */
	};

	struct str_mlist {
		char l_name[FMNAMESZ+1]; /* null terminated module name */
	};
	我们把sl_modlist设置指向str_mlist结构中的数组的第一个元素，并且将sl_modlist设置成为数组当中元素的数目。
	在l_name成员中,常量FMNAMESZ在 <sys/conf.h>中被定义，一般为8，另外还有一个空字节结束符号。
	如果ioctl的第三个参数设置为0，那么会返回模块的数目(做为ioctl的返回值)而不是模块的名称。我们根据这个来确定模块的数目并且分配指定数目的str_mlist结构。
	下面的例子给出了I_LIST操作的使用，返回的名称中模块的driver没有什么不同，我们打印模块名称的时候，我们知道链表中的最后一项就是流底部的驱动。
	列出stream上的模块名称
	int main(int argc, char *argv[])
	{
		int                 fd, i, nmods;
		struct str_list     list;
		if (argc != 2)
			err_quit("usage: %s <pathname>", argv[0]);
		if ((fd = open(argv[1], O_RDONLY)) < 0)
			err_sys("can't open %s", argv[1]);
		if (isastream(fd) == 0)
			err_quit("%s is not a stream", argv[1]);

		/*获取模块数目*/
		if ((nmods = ioctl(fd, I_LIST, (void *) 0)) < 0)
			err_sys("I_LIST error for nmods");
		printf("#modules = %d\n", nmods);

		/*根据数目分配标记每个模块名称的链表元素*/
		list.sl_modlist = calloc(nmods, sizeof(struct str_mlist));
		if (list.sl_modlist == NULL)
			err_sys("calloc error");
		list.sl_nmods = nmods;

		/*获得模块名称*/
		if (ioctl(fd, I_LIST, &list) < 0)
			err_sys("I_LIST error for list");

		/*打印名称*/
		for (i = 1; i <= nmods; i++)
			printf(" %s: %s\n", (i == nmods) ? "driver" : "module", list.sl_modlist++->l_name);

		exit(0);
	}
	如果我们从控制台(console)登陆和网络登陆上面运行这个程序，可以看到控制终端上面被推送了哪些流模块，如下：
	$ who
	sar        console     May 1 18:27
	sar        pts/7       Jul 12 06:53
	$ ./a.out /dev/console
	#modules = 5
	module: redirmod
	module: ttcompat
	module: ldterm
	module: ptem
	driver: pts
	$ ./a.out /dev/pts/7
	#modules = 4
	module: ttcompat
	module: ldterm
	module: ptem
	driver: pts
	在两种情况下，模块几乎相同。不同的地方就是控制台登陆的时候最顶部多了一个模块，这个模块用于虚拟控制台的重定向。在这台计算机上面，有一个窗口系统运行在控制台上面，所以/dev/console实际引用了一个伪终端而不是硬件设备。我们在后面会对伪终端进行介绍。

	向流设备中写
	在前面我们说过对一个STREAMS设备进行write操作会导致产生M_DATA消息。虽然这在一般时候都是正确的，但是有些细节的东西需要考虑。首先，流的最顶部处理模块指定了向下发送的包的最大和最小长度（我们无法从模块请求这些值）。如果我们写入的长度超过了最大的长度，那么stream head通常会将数据分割为多个包。
	下一个需要考虑的是，如果我们向流中写入了0字节，那么会发生什么？除非流指向一个管道或者FIFO，否则会向下发送一个0长度的消息。而管道或FIFO默认会忽略0长度的write，这样才能和从前的版本兼容。我们可以通过ioctl修改流的写模式来改变这个默认的特性。
	当前，只定义了两种写模式
	SNDZERO 一个向管道或者FIFO的0长度的写将会导致一个0长度的消息向下发送。默认来说，这个0长度的写不发送任何消息。
	SNDPIPE 导致SIGPIPE被发送给调用的进程，而这个进程在流发生了错误之后还调用了write或者putmsg.
	一个流也拥有一个读模式，我们将在描述了getmsg和getpmsg函数之后再看看它们。

	getmsg和getpmsg函数
	STREAMS消息通过read,getmsg或者getpmsg从一个stream head进行读取。
	#include <stropts.h>
	int getmsg(int filedes,struct strbuf *restrict ctlptr,struct strbuf *restrict dataptr,int *restrict flagptr);
	int getpmsg(int filedes, struct strbuf *restrict ctlptr, struct strbuf *restrict dataptr, int *restrict bandptr, int *restrict flagptr);
	返回:两个函数在正确的时候返回非负，错误的 时候返回1。

	需要注意的是flagptr和bandptr是指向整数的指针。这些整数指针所指向的整数必须在调用这个函数之前被设置以便指定所需要的消息的类型，并且这个整数也会在函数返回的时候被设置成读取的消息类型。
	如果整数指针指向的flagptr为0，那么getmsg会返回stream head中的读队列中的下一条消息。如果下一条消息是高优先级的消息（此时flagptr是0吗??????），那么被 flagptr 所指向的整数会在返回的时候被设置成RS_HIPRI。如果我们只是想要接收高优先级的消息，那么我们在调用getmsg函数之前必须先设置指针flagptr所指定的整数为RS_HIPRI.

	getpmsg使用不同的常量。我们可以设置flagptr所指向的指针为MSG_HIPRI这样仅仅接收高优先级别的消息。我们也可以设置为MSG_BAND并且设置bandptr所指向的整数为某个非0的优先级数值，这样来接收指定优先级的消息(当然更高级别的消息同时也会被接收)。如果我们只想接收第一个可用的消息，我们可以设置flagptr所指向的整数为MSG_ANY；返回的时候，这个整数会被MSG_HIPRI或者MSG_BAND所覆盖，这取决于所接收的消息类型。如果我们所接收的消息不是一个高优先级的消息，那么bandptr所指向的整数将会包含消息的优先级。

	如果ctlptr是空或者ctlptr->maxlen是1，那么消息的控制部分将会留在stream head的读取队列，我们将会不处理它。类似地，如果dataptr是空或者dataptr->maxlen是1，那么消息的数据部分不会被处理并且留在stream head的读取队列中。另外，我们将会获得我们的缓存能够容纳的尽量多的消息的数据和控制部分，并且任何在stream head队列中剩余的部分用于下次调用。

	如果调用的getmsg或者getpmsg返回了一个消息，那么返回值为0。如果消息中的一些控制部分留在了stream head读取队列中，那么会返回MORECTL；类似地，如果消息中的一些数据部分留在了stream head的读取队列中，那么会返回MOREDATA；如果控制和数据信息都有留下，那么返回(MORECTL|MOREDATA)。

	读取模式
	我们需要考虑如果我们从一个STREAMS设备中读取，会发生什么。有两个潜在的问题：
	1.在流上的消息的记录边界上会发生什么？
	2.如果我们调用read并且下一条流上面的消息是控制信息的时候，会发生什么？
	默认的对情况1的处理叫做字节流模式。在这个模式中，一个从流中的读取会不断地取得数据，直到请求的字节数目被读取到或者直到已经没有更多的数据了。STREAMS消息的边界在这个模式下面被忽略。默认对情况2的处理导致的是如果在队列的开始有一个控制消息，那么读取会返回一个错误。我们可以改变这两个默认的处理。
	使用ioctl，如果我们将请求设置为I_GRDOPT，第三个参数是一个指向整数的指针，并且当前的流的读模式会被返回到那个整数当中。一个I_SRDOPT请求会将第三个参数的整数的值获取到并且设置读的模式为那个值。
	读的模式可以被指定为如下的三个常量：
	RNORM: 默认的正常情况，也就是前面提到的字节流模式。
	RMSGN: 消息的非忽略模式。读取的时候会从流中取得数据知道请求的字节数目已经被读取到，或者直到遇到了一个消息的边界。如果读取使用一部分消息，那么消息中剩余的数据会被留在流中用于后面的读取。
	RMSGD: 消息的忽略模式。这个和非忽略模式类似，不同的是如果读取使用的是消息的一部分，那么剩余的消息会被忽略。
	当在流中遇到了包含协议控制信息的消息的时候，有三个额外的常量可以被用来指定到读模式中以设置读取操作的行为：
	RPROTNORM: 协议正常模式，读取的时候会返回一个EBADMSG错误码。这是默认的行为。
	RPROTDAT: 协议数据模式，读取的时候会把控制部分当做数据返回。
	RPROTDIS: 协议忽略模式，读取会忽略控制信息，但是会返回消息中的任何数据。
	在同一个时间，只能设置一种消息读模式和协议读模式。默认的读取模式就是（RNORM|RPROTNORM）

	举例
	下面的代码作用是将标准输入的内容拷贝到标准输出，前面章节中实际有一个类似的例子，这个例子和前面例子的区别是，这里使用getmsg而不是read来从标准输入中读取信息。
	代码大致如下：
	#include "apue.h"
	#include <stropts.h>
	#define BUFFSIZE     4096
	int main(void)
	{
		int             n, flag;
		char            ctlbuf[BUFFSIZE], datbuf[BUFFSIZE];
		struct strbuf   ctl, dat;

		ctl.buf = ctlbuf;
		ctl.maxlen = BUFFSIZE;
		dat.buf = datbuf;
		dat.maxlen = BUFFSIZE;
		for ( ; ; ) {
			flag = 0;       /* 返回任何消息 */
			if ((n = getmsg(STDIN_FILENO, &ctl, &dat, &flag)) < 0)
				err_sys("getmsg error");
			fprintf(stderr, "flag = %d, ctl.len = %d, dat.len = %d\n",
					flag, ctl.len, dat.len);
			if (dat.len == 0)
				exit(0);
			else if (dat.len > 0)
				if (write(STDOUT_FILENO, dat.buf, dat.len) != dat.len)
					err_sys("write error");
		}
	}
	如果我们在Solaris中运行这个程序(Solaris的管道和终端都是使用stream实现)，我们会得到如下的输出：
	$ echo hello, world | ./a.out           请求基于流的管道
	flag = 0, ctl.len = -1, dat.len = 13
	hello, world
	flag = 0, ctl.len = 0, dat.len = 0     表示一个STREAMS已经挂断
	$ ./a.out                              请求基于流的终端
	this is line 1
	flag = 0, ctl.len = -1, dat.len = 15
	this is line 1
	and line 2
	flag = 0, ctl.len = -1, dat.len = 11
	and line 2
	^D                                      输入终端的EOF字符
	flag = 0, ctl.len = -1, dat.len = 0     tty的文件结束末尾和挂断是不一样的。
	$ ./a.out < /etc/motd
	getmsg error: Not a stream device
	当管道关闭的时候（echo结束时），上面程序会看到流被挂断，控制部分和数据部分的长度都是0。（我们后面讨论管道）然而通过终端键入文件结束符号，只导致数据长度被返回为0。终端的文件结束符号和流的挂断是不一样的。另外正如我们所预料的，当我们把标准输入重新定向成一个非流的设备(文件)的时候，getmsg会返回一个错误。


	5)多I/O
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec5.html
	当我们从一个文件描述符号读取，写入到另外一个文件描述符号的时候，我们可以在一个循环中使用"阻塞"I/O，如下：
		while ((n = read(STDIN_FILENO, buf, BUFSIZ)) > 0)
			if (write(STDOUT_FILENO, buf, n) != n)
				err_sys("write error");
	我们经常看到这种形式的I/O阻塞。如果我们需要读取两个文件描述符号的时候会怎么样呢？在这种情况下，我们不能在两个文件描述符号上面做阻塞的读取，因为当我们在一个文件描述符号阻塞读取的时候，数据可能会在另外一个文件描述符号中出现。所以需要一种不同的技术来处理这种情况。
	让我们来看一下telnet命令。在这个程序中，我们从终端（标准输入）中读取，然后写到网络连接中，我们又从网络连接中读取，然后再写到终端上（标准输出）。在网络的另一端，telnetd守护进程读取到我们键入的字符并且把它传递给shell，就好象我们登陆到了远程的机器上面一样。telnetd守护进程发送我们通过telnet命令键入的命令产生的任何输出给我们，然后显示到我们的终端上。
	本章的参考资料中给出了一个图示，这里简单描述一下：
		终端前面的用户<--->telnet命令<--->telnetd守护进程
	telnet进程有两个输入以及两个输出，这里我们不能在读取任何一个输入的时候阻塞，因为我们也不知道在哪个输入上面有我们所需要的数据。
	有一个处理这个问题的方法就是把进程分成两个部分(使用fork)，每一个部分处理一个方向的数据。如下图所示：
	               /-->telnet命令(父) -->\
	  终端前面的用户                     telent守护进程
	               \<--telnet命令(子) <--/
	如果我们使用进程，我们可以让每一个进程做阻塞读取。但是这样会在操作结束的时候导致一些问题。如果子进程收到了文件结束符号，子进程会终止,同时父进程收到SIGCHLD信号。但是如果父进程结束(用户在终端收到文件描述符号)，那么父进程会告诉子进程结束(谁结束??????)。我们可以通过信号来实现这个（例如SIGUSR1信号），但是这让程序在一定的程度上复杂化了。
	我们也可以通过使用多线程来代替多进程的方案，这样就避免了结束时候的复杂机制，但是却增加了同步的问题，这让问题更为复杂。
	我们可以为两个文件描述符号设置非阻塞标志，然后在单个进程中使用非阻塞I/O，为第一个文件描述符号发起读操作。如果存在数据，那么我们就读取数据并且处理它们，如果不存在数据那么就立即返回。然后我们在第二个文件描述符号上面做同样的事情。在这些之后，我们会等待一定时间（例如几秒钟），然后再次尝试从第一个文件描述符号开始读取数据，这种类型的循环叫做polling(轮询)，问题是它会浪费cpu时间，大多数的时候我们没有数据可以读取所以我们把时间浪费在执行系统调用上面，我们需要猜测每次循环的时候需要等待多少时间。虽然任何系统上面都支持非阻塞I/O，但是我们要在多任务系统上面避免轮询。
	另外一个技术叫做异步I/O。为了执行这个，我们告诉内核当有文件描述符号可以用来输入输出的时候通知我们。对于这个技术，有两个问题：首先，并不是所有的系统都支持这个特性（在Single UNIX Specification中这是一个可以选择的特性），System V提供了SIGPOLL信号用于这个技术，但是这个信号只有在文件描述符号引用一个流设备的时候才好用。BSD系统有一个类似的信号，SIGIO，但是这个也有类似的限制，它只有在文件描述符号引用一个网络设备或者终端的时候才有用。第二个问题是每个进程只能有一个这些信号(SIGPOLL或者SIGIO)。如果我们为两个文件描述符号激活这个信号（这个例子我们已经说过，也就是从两个文件描述符号中读取），那么发生信号的时候，我们无法分辨到底是哪个文件可以读取。为了能够可以确定是那个文件描述符号可以读取，我们还是需要对每个文件描述符号设置成非阻塞标志，然后依次对它们进行尝试。我们在后面会对异步I/O进行简单的介绍。
	一个更好的技术就是使用多I/O技术。通过这个技术，我们建立一个我们所感兴趣的文件描述符号列表，然后调用一个函数，这个函数不会返回，它会一直等待直到其中的一个文件描述符号可以I/O操作。在返回的时候，我们可以知道是哪个文件描述符号可以进行I/O了。
	有三个函数:poll,pselect,以及select允许我们执行多I/O操作。下面的表格告诉我们哪个平台支持它们(如果表格不够清晰可以参见参考资料中给出的表格)。需要注意的是，select是在POSIX.1的基础上定义的，但是poll却是一个XSI扩展标准基础上定义的。
	┌───────────────┬──────┬─────────┬────────┬─────────────────┐
	│ System        │ poll │ pselect │ select │ <sys/select.h>  │
	├───────────────┼──────┼─────────┼────────┼─────────────────┤
	│ SUS           │ XSI  │    •    │   •    │        •        │
	├───────────────┼──────┼─────────┼────────┼─────────────────┤
	│ FreeBSD 5.2.1 │  •   │    •    │   •    │                 │
	├───────────────┼──────┼─────────┼────────┼─────────────────┤
	│ Linux 2.4.22  │  •   │    •    │   •    │        •        │
	├───────────────┼──────┼─────────┼────────┼─────────────────┤
	│ Mac OS X 10.3 │  •   │    •    │   •    │                 │
	├───────────────┼──────┼─────────┼────────┼─────────────────┤
	│ Solaris 9     │  •   │         │   •    │        •        │
	└───────────────┴──────┴─────────┴────────┴─────────────────┘

	POSIX指明包含<sys/select>来推送select的信息到你的程序中。然而在以前我们可能需要包含三个文件，并且有些实现并不符合标准。我们可以检查man手册来确定你的系统支持什么样的select。原来的系统可能需要你包含<sys/types.h>,<sys/time.h>,以及<unistd.h>.
	多I/O在4.2BSD中通过select函数实现。虽然一般都是用在终端I/O以及网络I/O中，但是这个函数可以用于任何文件描述符号。SVR3在加入流机制的时候添加了poll函数。然而最初，poll只能用于流设备，在SVR4的时候poll才增加了任何文件描述符号的支持。

	select和pselect函数
	select函数允许我们在所有的POSIX兼容的平台下面使用多I/O操作。我们传递给select的参数会告诉内核：
	* 我们对哪些文件描述符号感兴趣
	* 对于我们感兴趣的文件描述符号的条件性质（用于读取？用于写入？还是用于意外输出？）
	* 我们可以等待多久。（我们可以设置永远等待，或者等待一个固定的时间，或者根本不等待）
	在从select中返回来的时候，内核会告诉我们:
	* 已经准备好了的文件描述符号的总数目。
	* 对于三个条件(读，写，意外)的文件描述符号，哪些已经准备好了。
	根据这些返回的信息，我们就可以调用合适的I/O函数（一般都是read或者write函数），并且知道这些被调用的函数是不会阻塞了。

	#include <sys/select.h>
	int select(int maxfdp1, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict exceptfds,
	           struct timeval *restrict tvptr);
	返回：准备好了的文件描述符号的数目，0表示超时，1表示错误。
	我们先看看最后一个参数，这个参数指定我们需要等待多长时间：
	struct timeval {
		long tv_sec;     /* 秒数 */
		long tv_usec;    /* 微秒数 */
	};
	有三种情况：
	tvptr == NULL
	表示永远等待。这个无限的等待可以被我们捕捉的信号打断。当指定的文件描述符号准备好了，或者捕获到了一个信号的时候，这个函数会返回。如果是捕获到了一个信号的话，select会返回1并设置errno为EINTR。
	tvptr->tv_sec == 0 && tvptr->tv_usec == 0
	一点也不等待。检测所有指定的文件描述符号并且立即返回。采用这个方法对系统进行轮询，可以检测指定的多个文件描述符号的状态，而不用在select函数中阻塞了。
	tvptr->tv_sec != 0 || tvptr->tv_usec != 0
	等待指定数目的秒数或者微秒数，当指定文件描述符号中的一个准备就绪或者超时的时候，就会返回。(应该是阻塞式的等待)如果没有一个指定的文件描述符号准备好但是却超时了，那么返回0。如果系统没有提供微秒级别的精度那么会取整选择最接近的支持的值。同第一种情况类似这个等待也可以被信号打断。
	POSIX.1允许实现修改这个timeval结构，所以当select返回的时候，你不能假定这个结构变量的值和调用select之前的值一样。FreeBSD5.2.1，Mac OS X 10.3和Solaris9不会改变这个结构变量的值，但是Linux2.4.22会更新这个结构变量，如果select函数在超时之前返回，那么这个结构变量包含的就是剩余的等待时间。
	中间的三个参数readfds,writefds,和exceptfds指向文件描述符号集合的指针。这三个集合指定了我们所感兴趣的文件描述符号，以及它们可能的情况（用于读取，用于写入，以及用于例外条件）。一个文件描述符号集合存放在一个fd_set类型中，这个数据类型由具体实现来选择以便它能够使用一个位来表示每个可能的文件描述符号。我们可以把它当做一个大的位数组，每一位表示一个文件描述符号。具体在参考资料中有一个图示，可以参考一下。

	我们可以对fd_set类型所做的操作只能是：分配一个这个类型的变量，将这个类型的变量赋值给其他同样类型的变量，使用下面的函数对这个变量进行操作：
	#include <sys/select.h>
	int FD_ISSET(int fd, fd_set *fdset);
	如果fd属于集合中的一个元素，那么返回非0，否则返回0。
	void FD_CLR(int fd, fd_set *fdset);
	void FD_SET(int fd, fd_set *fdset);
	void FD_ZERO(fd_set *fdset);
	这些接口可以用宏也可以用函数来实现。一个fd_set可以通过FD_ZERO来将其所有的位设置为0。可以通过FD_SET将一个单个的位设置为1，FD_CLR可以将一个单个的位清零。最后，我们可以使用FD_ISSET来检测一个给定的位是否是打开状态（即为1）。
	声明完了一个文件描述符号集合之后，我们必须通过调用FD_ZERO将它清零。然后我们可以设置这个集合中的位表示每个我们感兴趣的文件描述符号，如下：
	fd_set   rset;
	int      fd;

	FD_ZERO(&rset);
	FD_SET(fd, &rset);
	FD_SET(STDIN_FILENO, &rset);
	从select返回的时候，我们使用FD_ISSET来检测文件集合中的一个给定的位是否仍然处于打开状态（也就是一个文件描述符号是否属于这个文件集合）:
	if (FD_ISSET(fd, &rset)) {
		...
	}
	如果我们对某一个条件不感兴趣，那么我们可以将中间的三个参数（也就是指向文件描述符号集合的指针）的任何设置为空。如果三个参数都是空，那么我们会得到一个比sleep函数更精度的定时器。（前面我们说过，sleep函数等待的时间精度是秒，而通过select我们可以等待小于1秒的时间，实际的精度取决于系统的时钟）本章后面有一个练习就涉及到这个。
	select函数的第一个参数maxfdp1代表最大的文件描述符号加1。我们会计算我们所感兴趣的文件描述符号（它们都包含在三个文件描述符号集合中，这三个文件描述符号集合由中间三个参数表示），然后对最大的文件描述符号加1，这样得到第一个参数。我们可以只设置第一个参数为FD_SETSIZE，这个常量在<sys/select.h>中定义，指定了最大的文件描述符号（一般为1024），但是这个值太大了。实际上，大多数应用程序一般只使用大约3到10的文件描述符号，（有些应用程序可能会使用更多的文件描述符号，但是这样的unix程序不是常见的程序），通过指定我们所感兴趣的最大的文件描述符号，我们可以防止内核为了查看一个打开的位而从这三个文件描述符号集合中检测非常多没有使用的位。

	下面是一个使用的例子:
	fd_set readset, writeset;
	FD_ZERO(&readset);
	FD_ZERO(&writeset);
	FD_SET(0, &readset);
	FD_SET(3, &readset);
	FD_SET(1, &writeset);
	FD_SET(2, &writeset);
	select(4, &readset, &writeset, NULL, NULL);
	在参考资料中有相应的图，这里就不给出了。这个图表示的执行之后的结果意思大致如下：
	readset:1001......
	write:0110......
	并且最大文件描述符号maxfdp1的值为4。
	第一个参数的值是最大文件描述符号加1的原因是，这个参数表示我们将要检测的文件描述符号的数目，而文件描述符号的数值的开始为0。
	select函数有三种可能的返回值：
	a. 返回1表示一个错误的发生。例如，如果在任何一个文件描述符号准备好之后，捕获到一个信号，这个时候，文件描述符号集合没有被修改。
	b.返回0表示没有文件描述符号被修改。如果在任何文件描述符号准备好了之前超时，那么就会发生这个情况。当发生这个情况的时候，所有的文件描述符号集合会被清0。
	c.返回正数表示有一定数目的文件描述符号准备好了。这个返回值就是所有三个文件描述符号集合中准备好的文件描述符号的数目，所以如果同样的一个文件描述符号准备好了读写，那么将会在返回值中被计算两次。三个文件描述符号集合中留下来的位将只对应相应准备好了的文件描述符号。
	这里，准备好的含义如下：
	a.一个在read文件描述符号集合(readfds)中的文件描述符号，当被读取的时候不会导致阻塞，那么就认为它已经准备好了。
	b.一个在write文件描述符号集合(writefds)中的文件描述符号，当被写入的时候不会导致阻塞，那么就认为它已经准备好了。
	c.一个在异常文件描述符号集合(exceptfds)中的文件描述符号，如果有一个异常的情况提交在那个文件描述符号上面，就认为它已经被准备好了。当前，异常情况一般对应的包含：在网络连接中，到达了一个带外的数据，或者有一个特定的条件在伪终端上发生而这个终端已经在packet模式(这个不太了解)。
	d.普通文件的读，写，例外情况的文件描述符号总是准备好了的。
	有一个非常重要的，需要我们意识到的问题就是，文件描述符号是否是阻塞的并不会影响select函数是否阻塞。也就是说，如果我们有一个非阻塞的文件描述符号想要从中读取，并且我们调用select函数设置超时值为5秒，那么select也将会阻塞5秒（尽管文件描述符号是非阻塞的文件描述符号）。类似地，如果我们指定一个无限超时，那么select也会一直阻塞，直到有数据来或者接收到了一个信号。

	POSIX.1也定义了一个select函数的变种函数叫做pselect.
	#include <sys/select.h>
	int pselect(int maxfdp1, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict exceptfds,
				             const struct timespec *restrict tsptr, const sigset_t *restrict sigmask);
	返回已经准备好了的文件描述符号的数目，或者如果超时的时候返回0，或者如果错误的时候返回1。
	pselect函数和select函数是一样的，不同之处在于：
	* select函数的超时值用timeval结构表示，但是pselect使用timespec结构（前面有提到过）。这个timespec不是像timeval那样使用秒和微秒表示时间，它使用秒和纳秒表示时间。如果平台支持这样级别的精度，那么它会有更高的精度。
	* pselect的超时值被声明成常量，这样我们就能够确保，当pselect函数返回的时候，它的超时值不会发生变化。
	* pselect有一个signal mask参数。如果sigmask参数为空，那么pselect处理信号的方式和select一样。否则，sigmask指向一个signal mask，这个signal mask在pselect被调用的时候会被自动地安装上。返回的时候，之前的signal mask会被恢复。

	poll函数
	poll函数和select函数类似，但是它们的编程接口不太一样。之前我们已经知道，poll本来是来自system V的，尽管我们可以将它用于各种文件类型，但是poll一般用于STREAMS系统。
	#include <poll.h>
	int poll(struct pollfd fdarray[], nfds_t nfds, int timeout);
	返回已经准备好的文件描述符号的数目，超时的时候返回0，错误的时候返回1。
	使用poll，不像select那样分别使用文件描述符号集合表示每种条件(读，写，例外)，而是使用一个pollfd结构的数组，这个数组的每个成员指定了文件描述符号以及相应的条件。如下：
	struct pollfd {
		int   fd;       /* 将要检测的文件描述符号，如果小于0则表示忽略 */
		short events;   /* 对于文件描述符号所感兴趣的事件 */
		short revents;  /* 发生在fd上面的事件 */
	};
	fdarray数组元素的数目通过nfds来指定。
	对于nfds参数的声明，以前有所不同。SVR3指定数组中元素的数目为unsigned long类型，这样感觉有点多余。在SVR4的手册上面，poll函数的声明中的第二个参数类型是size_t。但是，实际上<poll.h>头文件中的第2个参数仍然是unsigned long类型。Single UNIX Specification定义了一个新的nfds_t类型允许选择合适的类型并且向应用程序隐藏了细节。需要注意的是，这个类型足以容纳一个整数，返回值代表满足事件的数组元素的数目。
	SVR4相应的SVID将第一个参数作为pollfd结构的数组fdarray[]。然而SVR4的手册上面却将其声明为pollfd *fdarray，在c语言中这两种声明是等价的，我们使用第一个方法只是为了强调它是一个数组而不是一个指向单个结构体的指针。
	为了告诉内核我们对文件描述符号的哪个事件感兴趣，我们需要如下设置每个数组元素的events成员(表格可能不清晰需要参见参考资料)。返回的时候revents成员由内核来进行设置，用来指定文件描述符号上面发生了什么事件（这里注意和select有所不同的是poll不会改变events成员，这样表示什么准备好了）。
	poll的events和revents
	POLLIN: events 且revents，除了高优先级别的数据可以非阻塞的读取（等价POLLRDNORM|POLLRDBAND）。
	POLLRDNORM: events 且revents，正常数据（优先级范围为0）可以非阻塞读取。
	POLLRDBAND: events 且revents，非0优先级别的数据可以被无阻塞的读取。
	POLLPRI: events 且revents，高优先级别的数据可以被无阻塞的读取。
	POLLOUT:events 且revents，正常数据（优先级范围为0）可以非阻塞写。
	POLLWRNORM:events 且revents，同POLLOUT.
	POLLWRBAND:events 且revents，非0优先级别的数据可以被无阻塞的写。
	POLLERR:revents，发生错误。
	POLLHUP:revents，发生hangup。
	POLLNVAL:revents，文件描述符号没有引用一个打开的文件。
	前4行用于读，接下来的3行用于写，最后3行表示例外条件。最后3行在返回的时候通过进行设置。甚至在没有指定events的时候，这三个值在发生条件的时候会返回到revents中。

	当一个文件描述符号挂起的时候（POLLHUP），我们不能向文件描述符号中写。然而在文件描述符中或许仍有数据需读取。
	poll的最后一个参数指定我们想要等待多长时间。类似select函数，它也有三种情况：
	timeout == -1:
	永远等待。（有些系统将<stropts.h>中的INFTIM定义为1）当有一个指定的文件描述符准备好了或者捕捉到信号之时，我们会返回。如果捕获到了信号，那么poll返回1并且设置错误号码(errno)为EINTR。
	timeout == 0:
	不进行等待。所有指定的文件描述符都会被测试，然后我们会立即返回。使用这种方法可以对系统进行轮询以获取多个文件描述符的状态，并且不会在poll函数中被阻塞。
	timeout > 0:
	等待指定的微妙数。我们会在一个文件描述符号准备好了之后或者超时之后返回。如果在文件描述符号准备好了之前就超时了，会返回0。（如果你的系统不提供微秒的精度，那么会取最接近的整数值）

	注意到文件结尾和hangup的区别是非常重要的。如果我们从终端输入数据，并键入文件结尾字符，POLLIN被打开这样我们可以读取到文件结束标记(read返回0)。POLLHUP不在revents中被打开。如果我们从modem读取并且telephone行hangup了，那么我们会接收到POLLHUP通知。
	和select类似，文件描述符号是否阻塞不会影响poll函数是否阻塞。

	select和poll函数的可中断性
	当4.2BSD中介绍了被中断的系统调用的自动重新启动的时候，select不被重新启动。这个特性在大多数系统中都是这样，指定了SA_RESTART选项的时候也是如此。但是在SVR4中，如果指定了SA_RESTART的时候，select和poll函数会自动重新启动。为了防止我们将软件从基于SVR4的系统移植的时候遇到这个问题，如果信号可以中断一个select或者poll函数，那么我们使用signal_intr函数(前面自己编写的一个防止被中断的系统调用重新启动的一个方法)。
	本书中的四种系统，在接收到信号的时候，甚至设置了SA_RESTART标记的时候，也不会重新启动poll或者select函数。

	6)异步I/O
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec6.html
	前面使用的select或者poll是一种同步通知的方式。如果我们不发出询问(调用select或者poll函数)，那么系统不会给我们任何通知。我们前面已经知道，信号就是一种异步通知的形式。所有从BSD和System V系统继承过来的系统，都提供了一定形式的异步I/O调用，可以使用信号（System V中是SIGPOLL；BSD中是SIGIO）来通知进程，在一个文件描述符号上面发生了某些值得注意的事情。
	我们看见，select和poll可以在任何文件描述符号上面工作。但是在System V上面继承过来的系统上面的异步I/O有一些限制，这里的异步只能工作在STREAMS设备或者STREAMS管道上面。在BSD继承过来的系统上面，异步I/O只能工作在终端或者网络上。
	异步I/O还有一个限制就是，每个进程只能有一个信号。如果我们在多个文件描述符号中使用了异步I/O机制，那么我们无法判别出在信号发送的时候，是哪个文件描述符号产生的信号。
	Single UNIX Specification包含了一个可选的通用异步I/O机制，这个机制是根据实时草案标准的，它和我们这里描述的机制没有多大关系。这个机制解决了许多旧有的异步I/O机制中的限制，但是我们这里不会讨论这个机制。

	System V的异步I/O机制
	在System V中异步I/O属于STREAMS系统的一个部分，只工作在STREAMS设备和STREAM管道上面。System V的异步I/O信号是SIGPOLL。
	为了使用STREAMS设备的异步I/O机制，我们调用ioctl并且让第2个参数为I_SETSIG。第3个参数是一个整数值，这个值是"stropts.h"中定义的常量，在本文中的参考资料中也用表格的形式列出了它们以及其含义，这里就不重复给出了。只列出常量，它们分别是：S_INPUT,S_RDNORM,S_RDBAND,S_BANDURG,S_HIPRI,S_OUTPUT,S_WRNORM,S_WRBAND,S_MSG,S_ERROR,S_HANGUP.
	除了使用ioctl指定产生SIGPOLL信号的条件，我们也需要为这个信号建立一个信号处理函数。因为从前面讲解信号的时候，我们就可以知道，SIGPOLL会导致进程终止。所以，我们需要在调用ioctl之前先建立信号处理函数。

	BSD的异步I/O机制
	基于BSD系统的异步I/O调用机制，使用了两个信号，SIGIO和SIGURG。SIGIO信号用来通知进程产生了异步I/O信号，后者用于通知进程在网络连接上面接收到了一个带外的数据。
	为了接收SIGIO信号，我们需要执行如下三个步骤：
	a)使用signal或者sigaction建立SIGIO的信号处理函数，
	b)通过调用使用F_SETOWN的fcntl函数，我们设置进程ID或者进程组ID，用来接收发生在相应文件描述符号上面的数据。
	c)通过调用使用F_SETFL命令的fcntl函数，设置文件的O_ASYNC状态标记，这样就能够使用文件描述符号的异步I/O机制了。
	第3步只用于引用终端和网络的文件描述符号，这是BSD系统的异步通知机制的基本限制。
	对于SIGURG信号，我们只需要执行前面的两个步骤就行了，因为SIGURG只用于那些可以支持带外信息的网络连接的文件描述符号。


	7)readv和writev函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec7.html
	readv和writev函数允许我们只通过一个函数调用，完成读取数据到不连续的缓存或者从不连续的缓存中向外写数据。这些操作被称作分散读和聚集写。
	#include <sys/uio.h>
	ssize_t readv(int filedes, const struct iovec *iov , int iovcnt);
	ssize_t writev(int filedes, const struct iovec *iov, int iovcnt);
	两个函数的会返回读取或者写入的字节数目，或者出错的时候返回错误。
	两个函数的第2个参数是一个指向iovec结构的数组的指针。
	struct iovec {
		void   *iov_base;   /* 缓存的起始地址 */
		size_t  iov_len;    /* 缓存的大小 */
	};
	iov数组的元素的数目通过参数iovcnt来指定。最多为IOV_MAX。参考资料中还用图示的方式表示了这个数组参数，这里不给出了，主要知道，数组的每个成员其实只是代表不同地址不同大小的缓存即可。
	writev函数依序从缓存iov[0],iov[1],...,iov[iovcnt]中收集输出数据，并返回输出数据的总字节大小，一般它就等于这些缓存的总长度。
	类似地，readv函数依序向每个数组元素填充数据，每次都填充完一个缓存元素之后再填充下一个元素，readv函数会返回被读取的总字节数。返回0代表没有数据，或者遇到了文件结束符号。
	这两个函数源于BSD4.2后来被添加到SVR4，它们被 Single UNIX Specification的XSI扩展包含。(尽管Single UNIX Specification将缓存地址iov_base设置为void*类型，但是还是有许多早期的实现使用char*类型)

	举例：
	在后面的章节中，我们的一个_db_writeidx函数需要连续地向一个文件写入缓存内容。第2个输出的缓存是一个调用者传入的参数，第一个缓存是我们自己创建的缓存，包含了第2个缓存的长度以及文件中其它信息的文件偏移量。有三种方式来实现这个：
	a)调用两次write函数，每次写一个buffer.
	b)分配一个我们自己的足够大的缓存，缓存包含了两个buffer，然后把两者拷贝到新的缓存中去。我们然后调用write一次写入这个新的缓存。
	c)调用writev来输出两个缓存。
	我们其实使用的writev来实现这个功能，但是比较其它两种方法，我们可以了解到更多的一些信息。

	图表中描述了三个方法的结果。
	我们的测试程序，输出一个100字节的头后面跟着200字节的数据。这个过程做1,048,576次，生成一个300兆的文件。测试程序分别对三种情况进行测试。我们使用times获取其写的前后的CPU时间，系统CPU时间，以及clock时间。所有三个时间用秒来描述。
	表格的具体内容，就不描述了，需要参见参考资料。实际我们将会看到，和调用write以及writev一次进行比较，系统cpu时间在我们两次调用write时候增加了。
	另外注意的就是(不要只局限于这里测试的两台机器)，实际上，这里占用的总共CPU时间(用户和系统CPU时间之和)，使用单次的write比writev要少(虽然少了，但是还是writev好，后面会说明原因)。因为单次write的时候，我们把用户级别的缓存拷贝到一个staging缓存中，然后当我们调用write的时候，内核将数据拷贝到它自己的内部缓存中。使用writev，我们拷贝的次数会减少了，因为内核只需要将数据直接拷贝到它的staging缓存中。对于writev函数的这一个调整带来的开销，在这里的少量数据中，虽然比实际的收益反而大了，但是随着数据量的增加，writev的性能将会越来越好，最终比write要好。
	总之，我们应该尝试使用所需最少数目的系统调用的方法来进行我们的工作。如果我们写入的数据量少，我们可以发现使用单一的write而不是使用writev会比较省。但是我们也可以发现，表现性能的好处，和实际管理我们buffer的代价之间需要做一个权衡。

	8)readn和writen函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec8.html
	管道，FIFOs，和一些设备尤其是终端设备，网络设备，STREAMS设备，都有如下的两个特性：
	a)读取操作返回的可能会比所要求的少，即使我们没有遇到文件结尾符号也是如此。这不是一个错误，我们应当继续从设备中读取。
	b)write返回的也可能会比我们指定的要少。这可能是由于流控制导致的，例如downstream模块。当然这也不是一个错误，我们可以继续将剩下的数据进行写。(一般来说这个短暂的写返回只在非阻塞文件描述符号或者捕获到信号的时候产生)
	当读写磁盘文件的时候，我们不会遇到这个情况，除非文件系统空间不足，或者我们达到了我们自己分配得空间限制导致我们无法写入我们想要写入的所有数据。
	一般来说当我们读写管道、终端、网络设备的时候，我们需要考虑到这些因素。我们使用如下的两个函数来读写N字节的数据，让这两个函数自己处理读写请求数据多余返回数据的情况。这两个函数只是不断地多次调用read或者write函数，直到读或者写完全部N个字节的数据。
	#include "apue.h"
	ssize_t readn(int filedes, void *buf, size_t nbytes);
	ssize_t writen(int filedes, void *buf, size_t nbytes);
	两个函数会返回读或者写的字节数目，如果错误的时候会返回1。
	这两个函数并不是什么标准中的函数，我们只是为了后面例子的方便，自己定义了这两个函数。
	当我们想要向前面提到的任何文件类型的文件中写入数据的时候，我们调用writen函数；但我们只有提前知道我们所需要接收的字节数目的时候我们才使用readn函数。本书后面的例子中会用到这两个函数，所以这里给出了它们的实现。
	#include "apue.h"

	//从文件描述符号中读取"n"个字节的数据。
	ssize_t readn(int fd, void *ptr, size_t n)
	{
	    size_t       nleft;
	    ssize_t      nread;

	    nleft = n;
	    while (nleft > 0) {
	        if ((nread = read(fd, ptr, nleft)) < 0) {
	            if (nleft == n)
	                return(-1); //错误，返回-1
	            else
	                break;     //错误，返回当前读取的字节数目
	        } else if (nread == 0) {
	            break;         //文件结尾
	        }
	        nleft -= nread;
	        ptr += nread;
	    }
	    return(n - nleft);    //返回值>=0
	}

	//向文件描述符号写入"n"个字节.
	ssize_t writen(int fd, const void *ptr, size_t n)
	{
	    size_t      nleft;
	    ssize_t     nwritten;

	    nleft = n;
	    while (nleft > 0) {
	        if ((nwritten = write(fd, ptr, nleft)) < 0) {
	            if (nleft == n)
	                return(-1);//错误返回-1
	            else
	                break;//错误返回当前写入的字节数目
	        } else if (nwritten == 0) {
	            break;
	        }
	        nleft -= nwritten;
	        ptr   += nwritten;
	    }
	    return(n - nleft);//返回值>=0
	}

	注意，当我们遇到一个错误但是之前已经读取了一定的数据的时候，我们会返回已经读取的字节数而不返回错误。类似，如果我们达到了文件结尾那么我们会返回已经读取的数目，而不是我们请求的数目。

	9)内存映射I/O
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec9.html
	内存I/O映射，允许我们将一个磁盘文件映射到内存中的一块缓存。这样当我们从缓存中获取数据的时候，我们相当于读取了文件中相应字节的数据，我们向缓存中存放数据的时候，数据会被自动地写入到文件中。这允许我们不用通过read和write系统调用实现文件的读写(即输入输出)。
	内存I/O映射在虚拟内存系统中已经使用了许多年。在1981年的时候4.1BSD用它的vread和vwrite函数提供了一个不同的内存I/O映射方式。这两个函数后来从4.2BSD中被移走，打算要用mmap函数进行替换。但是mmap函数并没有被包含到4.2BSD中。mmap函数通过Single UNIX Specification的内存映射文件选项被包含，并且在所有遵循XSI的系统上面都需要有它。大多数的UNIX系统都支持它。
	#include <sys/mman.h>
	void *mmap(void *addr, size_t len, int prot, int flag, int filedes, off_t off );
	如果成功则返回映射区域的起始地址，如果错误则返回MAP_FAILED。
	我们可以使用addr参数指定映射区域的起始地址，一般我们选择0这样系统自己选择映射区域的起始地址。函数会返回映射区域的起始地址。
	filedes参数指定要映射文件的文件描述符号。我们需要首先打开这个文件描述符号，然后才能将它映射到内存的地址空间。
	len参数指定映射的字节数目，off指定要映射的字节在文件中的起始偏移(后面会讨论这个off值的一些限制)。
	prot参数指定映射区域的保护特性。我们可以指定保护特性为PROT_NONE或者PROT_READ,PROT_WRITE,PROT_EXEC的任意组合的按位或。为一个区域设定的保护特性，不会越过文件的打开模式，例如如果我们打开文件的时候指定了只读的方式，那么我们就不能指定PROT_WRITE特性。
	在对flag参数进行讨论之前，这里基于前面的进程内存模型，用一个图片描述了使用内存映射时候进程的内存布局。具体的图片可以参见参考资料，主要是说明，内存映射时候的区域，在进程的堆区和栈区之间。其实这是个实现的细节问题，不同的系统实现可能有所不同。
	flag参数会影响到映射区域的不同属性。
	MAP_FIXED: 指定返回的地址就是addr。不建议使用这个标记，因为它会影响程序的可移植特性。如果不指定这个标记并且addr参数非空，那么内核只是将addr作为一个可能的使用地址，不保证返回的映射地址一定就是addr。其实，将addr指定为0这样程序的可移植性才是最好的。这个MAP_FIXED标记在遵循POSIX的系统中是可选的，但是遵循XSI的系统中要求有这个标记。
	MAP_SHARED: 这个标记描述了进程对映射区域的存储操作的特性。这个标记表示存储操作会修改被映射的文件，也就是说，存储到缓存的操作就相当与对文件进行写的操作。这个标记，或者后面的MAP_PRIVATE标记必须指定一个，但是不能同时指定。
	MAP_PRIVATE: 这个标记表示对映射区域缓存的存储操作会导致创建一个被映射文件的拷贝，所有接下来对映射区域的引用都会映射成对这个拷贝的引用(有一个使用这个标记的情况：在调试的时候，调试器会映射程序的文本段，允许用户对其中的指令进行修改。而修改的操作只影响那个拷贝而不会影响原始的程序文件)。
	另外，每种实现都有一个额外的MAP_XXX标记，这个是和相应的实现相关的。可以查看你系统上面的mmap的man手册了解细节。
	参数off和addr(当指定了MAP_FIXED的时候)必须是系统虚拟内存页大小的整数倍数。如果映射区域的长度不是页的整数倍数会怎样呢？实际上，假设我们有个12字节大小的文件，系统的页大小是512字节，对这个文件进行映射的时候，系统会分配一个512字节大小的区域，前面12字节就是文件内容，而后面的500字节内容被设置为0，对后面500字节的修改不会影响文件内容，也因为这个原因mmap无法对文件实现追加内容的功能，如果追加文件的内容，我们必须先将文件的大小增加。
	例子：使用内存映射拷贝文件
	#include <fcntl.h>
	#include <sys/mman.h>
	int main(int argc, char *argv[])
	{
	    int         fdin, fdout;
	    void        *src, *dst;
	    struct stat statbuf;

	    if (argc != 3)
	        err_quit("usage: %s <fromfile> <tofile>", argv[0]);//报错并退出

	    if ((fdin = open(argv[1], O_RDONLY)) < 0)
	        err_sys("can't open %s for reading", argv[1]);//报错并退出

	    if ((fdout = open(argv[2], O_RDWR | O_CREAT | O_TRUNC, FILE_MODE)) < 0)
	        err_sys("can't creat %s for writing", argv[2]);//报错并退出

	    if (fstat(fdin, &statbuf) < 0)  //(1)获取输入文件的大小!!!(关键)
	        err_sys("fstat error");//报错并退出

	    if (lseek(fdout, statbuf.st_size - 1, SEEK_SET) == -1)//(2)设置输出文件的大小!!!(关键)
	        err_sys("lseek error");//报错并退出
	    if (write(fdout, "", 1) != 1)//(3)写一个文件，这样实现文件内容的追加!!!(关键)
	        err_sys("write error");//报错并退出

		//(4)映射输入文件!!!(关键)
	    if ((src = mmap(0, statbuf.st_size, PROT_READ, MAP_SHARED, fdin, 0)) == MAP_FAILED)
	        err_sys("mmap error for input");

		//(5)映射输出文件!!!(关键)
	    if ((dst = mmap(0, statbuf.st_size, PROT_READ | PROT_WRITE, MAP_SHARED, fdout, 0)) == MAP_FAILED)
	        err_sys("mmap error for output");

		//(6)通过拷贝缓存，实现输入文件拷贝到输出文件。
	    memcpy(dst, src, statbuf.st_size);
	    exit(0);
	}

	映射区域使用两个信号。SIGSEGV信号用来表示我们访问一个不可用的内存。这个信号也会在我们尝试将数据存放到一个只读的映射区域的时候发生。SIGBUS信号表示我们访问了一个没有意义的映射区域。例如，当我们使用文件大消将一个文件映射到内存区域之后，这个文件被truncated了，然后当我们通过映射区域访问被truncated的文件部分的时候，我们就会收到SIGBUS信号。
	内存映射区域可以通过fork被子进程继承（因为那也是父进程的地址空间）。但是，同理，exec的新程序却不会继承这个映射区域了。

	我们可以通过mprotect函数来修改一个映射区域的权限。
	#include <sys/mman.h>
	int mprotect(void *addr, size_t len, int prot);
	如果成功返回0，如果错误返回1。
	prot的值和mmap一样，addr参数也必须是系统中的页大小的整数倍。
	内存映射区域的保护值：
	PROT_READ:区域可读。
	PROT_WRITE:区域可写。
	PROT_EXEC:区域可执行。
	PROT_NONE:区域无法访问。
	mprotect在Single UNIX Specification的内存保护选项中被包含进去了，所有遵循XSI-conforming的系统都支持它。

	如果共享映射的页被修改了，那么我们可以调用msync将改动刷新到对应的映射的文件上面。msync函数和fsync函数类似但是只在内存映射区域上面有效。
	#include <sys/mman.h>
	int msync(void *addr, size_t len, int flags);
	返回：如果成功返回0，如果错误返回1。
	如果映射是私有的映射，那么被映射的文件不会被修改，同样这里的addr必须是页对齐的。
	flags允许我们对内存刷新的方式进行一些控制。我们可以使用MS_ASYNC来调度页面的写。如果我们想要等到写操作完成再返回，那么我们可以使用MS_SYNC。我们可以指定MS_ASYNC或者MS_SYNC。
	另外一个可选的标志，MS_INVALIDATE，用来告诉操作系统丢弃和相应存储不一致的页。在我们使用这个标记的时候，有一些实现会丢弃指定范围所有的页，但是这个行为不是需要的。
	(注意：flush是从缓存清空到内存，invalidate是从内存更新到缓存，实际在驱动的mmap实现中如果指定了no-cache的话那么MS_SYNC和MS_INVALIDATE就没有必要使用了,一般实现使用remap_pfn_range)

	内存映射区域会在进程结束或者调用munmap的时候取消映射，关闭被映射的文件描述符号并不会取消其到内存的映射。
	#include <sys/mman.h>
	int munmap(caddr_t addr, size_t len);
	返回：如果成功返回0，如果错误返回1。
	munmap并不会影响被映射的对象，也就是说，被映射的对象的内容不会在调用munmap时候被写入到其中。对于一个使用MAP_SHARED的映射文件，如果其映射区域中被写入了数据，那么会由内核的虚拟内存算法完成对文件内容的更新；如果使用的标记是MAP_PRIVATE那么相应的区域内容会在调用munmap的时候被丢弃。

	例子的说明
	前面的例子使用内存映射的方式拷贝一个文件，其效果类似命令cp。
	我们首先打开两个文件然后使用fstat获取输入文件的大小，因为我们需要这个大小来对输入文件进行映射。我们也设置输出文件的大小，我们使用lseek设置文件的大小然后向文件中写入一个字节。如果我们不设置输出文件的大小，那么我们调用mmap映射输出文件的时候返回虽然正确，但是我们第一次对这个映射区域进行引用的时候会产生一个SIG_BUS信号(前面说过这个信号)。我们可能会尝试使用ftruncate来设置文件的大小，但是并不是所有的系统使用这个函数都会增加文件的大小(虽然本书中提到的四个系统支持增加大小)。
	然后我们调用mmap对每个文件进行映射，通过memcpy从输入缓存将数据拷贝到输出缓存。当数据从输入缓存(src)获取的时候，输入文件会自动地被内核读取；当数据写入到输出缓存(dst)的时候，数据也会自动地被内核写入到输出文件。
	究竟数据什么时候会被写入到文件中，取决于系统的页管理算法。有些系统有相应的守护进程可以随着时间慢慢地将脏页（也就是包含数据的页）写入到磁盘。如果我们想要确保数据被安全地写入到了文件中，我们需要在退出之前调用使用MS_SYNC标记的msync。
	在这里，通过对比给出了使用内存映射和使用read/write对文件(300M)进行拷贝所需的时间。表格可能不清晰可以参见参考资料。
	┌─────────────┬───────────────────────────┬───────────────────────┐
	│             │ Linux 2.4.22 (Intel x86)  │   Solaris 9 (SPARC)   │
	│             ├──────┬──────────┬─────────┼──────┬────────┬───────┤
	│  Operation  │ User │  System  │  Clock  │ User │ System │ Clock │
	├─────────────┼──────┼──────────┼─────────┼──────┼────────┼───────┤
	│ read/write  │ 0.04 │   1.02   │  39.76  │ 0.18 │  9.70  │ 41.66 │
	├─────────────┼──────┼──────────┼─────────┼──────┼────────┼───────┤
	│ mmap/memcpy │ 0.64 │   1.31   │  24.26  │ 1.68 │  7.94  │ 28.53 │
	└─────────────┴──────┴──────────┴─────────┴──────┴────────┴───────┘
	Solaris 9中的cpu时间(user+system)两者几乎相等（9.88秒和9.62秒）。Linux中内存映射使用的总CPU时间几乎是read/write的两倍。可能这是由于两个系统的进程计时的方式有所不同。
	实际上，mmap和memcpy比read/write要快。因为，我们使用mmap和memcpy做的实际工作要少。使用read/write我们将数据从内核缓存中拷贝到应用程序缓存(read)，然后将数据从应用程序缓存拷贝到内核缓存(write)。使用mmap和memcpy，我们直接将数据从一块内核缓存(这个缓存被映射到我们的地址空间），拷贝到映射到我们地址空间的另外一块内核缓存(这里只涉及到两个缓存)。
	内存映射在拷贝正常文件的时候速度更快。也有一些限制，我们无法拷贝一些特定的设备文件（例如网络设备或者终端设备），而且我们也需要注意在文件映射之后文件的大小可能会变化。尽管如此，在一些应用程序中内存映射的好处是显然的，因为它简化了算法，我们只需要操作内存而不用读写文件了。有一个典型的使用内存映射的例子就是对一个引用位映射的显示的frame buffer设备进行操作。
	后面我们还会介绍到内存映射，并且给出一个例子，用于在两个相关的进程之间提供共享的内存。

	10)总结
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch14lev1sec10.html
	本章介绍了大量的高级I/O操作，后面的例子中许多地方都用到了它们。主要内容有：
	*非阻塞I/O是一种I/O操作，操作的时候没有阻塞的情况发生。
	*记录锁(本书最后面一个数据库操作函数的例子中对其进行了详细的说明可以做为参考)
	*System V的STREAMS(在后面我们讲述基于流的管道，传递文件描述符号，以及System V的客户服务端链接时会用到)
	*使用select 和poll函数的多I/O(后面的许多例子中会用到)
	*readv和writev函数(后面也有许多地方用到它们)
	*内存映射I/O

*进程内部通信
==========================
	1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec1.html
	前面我们讲述进程控制，以及如何发起多个进程。但是这些进程交互的方式却是通过fork传递打开的文件描述符号，或者通过文件系统。这里我们将要讲述进程之间通信的另外的技术：IPC，或者内部进程通信。
	过去UNIX中的IPC有非常多的实现方法，非常混乱，其中可移植到其它unix平台的不多。通过POSIX和Open Group（以前是X/Open）的标准化的努力，状况才有所改善。但是仍然有不同的地方。这里的参考资料就给出了一个表格，表格中列出的IPC可以在本书的四个平台上面使用。
	关于这些IPC通信方法，有的是在本地进程之间进行通信，有的是在不同机器进程之间的通信，哪些系统支持哪些通信的方式，在书中都有所说明，具体参考书中内容，这里不做重复。
	我们将IPC分为三个部分进行介绍，这里，我们对经典的IPC技术进行介绍，它们是：管道(fifos,pipes)，消息队列，信号量，共享内存。下一章我们讨论使用套接字技术的网络IPC技术。然后，我们再介绍IPC的一些高级特性。(这里管道有有名管道即fifos，和无名管道即pipes)

	2)Pipes
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec2.html
	Pipes是一种比较老的IPC(内部进程通信)技术，所有UNIX系统都提供这种通信方式.Pipes有两个限制：
	a)由于历史原因，它是半双工的（即数据只能在一个方向上面流动）。有些系统提供全双工的Pipes但是出于可移植的考虑，我们还是最好不要做“Pipes是全双工的”这样的假设。
	b)Pipes只能被具有共同祖先的进程之间使用。一般来说，一个进程创建了一个Pipes，然后这个进程调用fork，之后Pipes就在子进程和父进程之间使用了。
	我们在后面将会看到，FIFOs没有第二个限制，同时Unix domain sockets和基于流的有名管道两个限制都没有。
	尽管具有以上限制，半双工的pipes仍然是最常使用的IPC通信方式。每当你建立一系列管道线的命令让shell执行的时候，shell会为每个命令创建独立的进程，将一个命令的标准输出通过管道连接到下一个命令的标准输入。
	管道使用如下函数创建：
	#include <unistd.h>
	int pipe(int filedes[2]);
	如果成功，返回0，如果错误返回1。
	通过filedes参数返回两个文件描述符号，其中filedes[0]用于读，filedes[1]用于写，filedes[1]的输出就是filedes[0]的输入。
	在 4.3BSD, 4.4BSD, 和 Mac OS X 10.3中Pipes通过UNIX domain sockets来实现，尽管UNIX domain sockets默认是全双工的，这些操作系统使用管道的时候还是使用半双工的模式。
	POSIX.1允许支持全双工的pipes实现，在这些实现中，filedes[0]和filedes[1]可以被打开用来读或者写。在这里用一个图形展示了管道。具体参见参考资料，这里只是说明一下图的含义：在用户进程中，数据从filedes[1]流出，经过内核中的pipes，再由pipes流出，流入到用户进程中的filedes[0]。
	对于pipes两端的文件描述符号，fstat函数返回一个FIFO的文件类型，我们可以使用S_ISFIFO宏来对pipe进行检测。
	POSIX.1强调stat结构的st_size成员在pipe中是没有定义的，但是有许多系统会将st_size填充为pipe中可以读取的字节的数目，可是这个特性也是不具有移植性的。
	一个在单一进程中的pipe是没有多大意义的。一般来说，进程都先调用一个pipe然后调用fork，这样在父子进程之间创建一个IPC通道。如下图所示：

	 +-----Parent-------+             +--------Child---------+
	 |  fd0       fd1   |             |   fd0          fd1   |
	 +-----^------\-----+             +-^------------/-------+
	        \      \                   /            /
	         \      \                 /            /
	          \+-----v-----Kernel----/----------+ /
	           \              Pipes             |v
	           +--------------------------------+

	在fork之后，数据如何流动，是由我们自己决定的。如果是从父进程流向子进程，那么父进程关闭管道的读端(fd0)，子进程关闭管道的写端(fd1)，如下：

	 +-----Parent-------+             +--------Child---------+
	 |  fd0       fd1   |             |   fd0          fd1   |
	 +------------\-----+             +-^--------------------+
	               \                   /
	                \                 /
	           +-----v-----Kernel----/----------+
	           |              Pipes             |
	           +--------------------------------+

	当管道的一端被关闭的时候，通常会遵循如下原则：
	a)如果我们从一个写端被关闭的管道中读取数据，那么这个管道中的数据被读取完毕的时候，read将会返回一个0表示文件的结束(所以最好关闭多余的文件描述符号)。(技术上来说，除非没有向管道写的进程否则不会产生文件结束符号,在多进程中，我们可能会复制出多个管道的文件描述符号，对管道进行读写，但是一般来说，对于一个管道只有一个读和写的进程。后面我们讲到FIFO的时候，会看到有多个写，一个读的情况)
	b)如果我们写一个读端被关闭的管道，那么会产生SIGPIPE信号。如果我们忽略这个信号或者捕捉这个信号并且从信号处理函数中返回，那么write返回1并且设置errno为EPIPE。
	当我们写一个管道(pipe或者FIFO)的时候，常数PIPE_BUF指定内核的管道缓存大小。一个对同一个管道的小于或者等于PIPE_BUF字节的写操作将不会被其它进程打扰。但是如果多个进程写一个管道，并且我们写入的数据大于PIPE_BUF字节，那么数据可能会被其它写进程的数据干扰。我们可以使用pathconf或者fpathconf来确定PIPE_BUF的大小。
	例子：
	如下是在父子进程之间创建管道，并且向管道之中发送数据的例子：
	int main(void)
	{
	    int     n;
	    int     fd[2];
	    pid_t   pid;
	    char    line[MAXLINE];

	    if (pipe(fd) < 0)
	        err_sys("pipe error");
	    if ((pid = fork()) < 0) {
	        err_sys("fork error");
	    } else if (pid > 0) {       /* parent */
	        close(fd[0]);
	        write(fd[1], "hello world\n", 12);
	    } else {                /* child */
	        close(fd[1]);
	        n = read(fd[0], line, MAXLINE);
	        write(STDOUT_FILENO, line, n);
	    }
	    exit(0);
	}
	这个例子我们调用read和write直接对管道文件描述符号进行操作，实际更有趣的操作是将管道文件描述符号复制到标准输入输出上面。一般子进程之后会运行其他进程，然后那个程序从它的标准输入(管道)读取，写入到标准输出（管道）。

	又一个例子：
	假设一个程序显示它的标准输出，一次显示一页，我们想要使用自己喜欢的pager(页显示工具)而不是unix系统默认的来显示这些内容。为了防止将输出写入到一个临时文件然后再调用system来显示这个文件中的内容，我们使用管道直接输出到pager中。我们这样来做：我们创建一个pipe，然后调用fork创建子进程，然后在子进程中设置标准输入为管道的读端，然后使用exec执行我们喜欢的pager程序。代码如下：
	#include <sys/wait.h>
	#define DEF_PAGER   "/bin/more"     /* default pager program */
	int main(int argc, char *argv[])
	{
	    int    n;
	    int    fd[2];
	    pid_t  pid;
	    char   *pager, *argv0;
	    char   line[MAXLINE];
	    FILE   *fp;

	    if (argc != 2)
	        err_quit("usage: a.out <pathname>");

	    if ((fp = fopen(argv[1], "r")) == NULL)
	        err_sys("can't open %s", argv[1]);
	    if (pipe(fd) < 0)
	        err_sys("pipe error");

	    if ((pid = fork()) < 0) {
	        err_sys("fork error");
	    } else if (pid > 0) {                              /* parent */
	        close(fd[0]);       /* close read end */

	        /* parent copies argv[1] to pipe */
	        while (fgets(line, MAXLINE, fp) != NULL) {
	            n = strlen(line);
	            if (write(fd[1], line, n) != n)
	                err_sys("write error to pipe");
	        }
	        if (ferror(fp))
	            err_sys("fgets error");

	        close(fd[1]);   /* close write end of pipe for reader */

	        if (waitpid(pid, NULL, 0) < 0)
	            err_sys("waitpid error");
	        exit(0);
	    } else {                                        /* child */
	        close(fd[1]);   /* close write end */
	        if (fd[0] != STDIN_FILENO) {
	            if (dup2(fd[0], STDIN_FILENO) != STDIN_FILENO)
	                err_sys("dup2 error to stdin");
	            close(fd[0]);   /* don't need this after dup2 */
	        }

	        /* get arguments for execl() */
	        if ((pager = getenv("PAGER")) == NULL)
	            pager = DEF_PAGER;
	        if ((argv0 = strrchr(pager, '/')) != NULL)
	            argv0++;        /* step past rightmost slash */
	        else
	            argv0 = pager;  /* no slash in pager */

	        if (execl(pager, argv0, (char *)0) < 0)
	            err_sys("execl error for %s", pager);
	    }
	    exit(0);
	}


	在调用fork之前，我们创建一个pipe。在fork之后，父进程关闭它的读取端，子进程关闭它的写入端。子进程然后调用dup2把标准输入重新定向到管道的读取端。当pager程序执行的时候，它的标准输入就变成了管道的读取端。
	当我们将一个文件描述符号重新定向到另外一个文件描述符号上面的时候（例如这里子进程中的标准输入被重新定向到了fd[0]），我们需要确保那个文件描述符号不是程序使用过的。如果那个文件描述符号已经是是程序使用的了，那么我们调用dup2将会关闭这个文件描述符号（然后再重新打开这个文件符号不过打开的对应就是新的文件了），有可能整个程序就只有一份那个被关闭的文件符号的打开。在这个程序中，如果标准输入没有被shell打开过(默认shell会在启动程序的时候打开标准输入输出和错误文件描述符号)，那么程序开头的fopen将会使用文件描述符号0，也就是最小的未被使用的文件描述符号，这样fd[0]将会不等于标准输入。然而，当我们调用dup2关闭一个文件文件描述符号以便重定向到另外一个的时候，我们会做一个文件描述符号的比较，为了确保稳定。
	注意我们使用环境变量PAGER来获取用户pager程序的名称，如果这个不能工作，那么我们使用默认的，这也是一个使用环境变量比较常用的方法。

	使用管道实现的同步函数
	前面我们调用过TELL_WAIT, TELL_PARENT, TELL_CHILD, WAIT_PARENT,和WAIT_CHILD，并且我们曾经使用信号实现过这些函数，这里我们有一个使用管道实现这些函数的方法。(前面使用信号的方法，没有在这里列举出来，但是管道的方法比较简介，列举了)代码如下：
	static int  pfd1[2], pfd2[2];
	void TELL_WAIT(void)
	{/*创建管道*/
	    if (pipe(pfd1) < 0 || pipe(pfd2) < 0)
	        err_sys("pipe error");
	}
	void TELL_PARENT(pid_t pid)
	{/*子进程写*/
	    if (write(pfd2[1], "c", 1) != 1)
	        err_sys("write error");
	}
	void WAIT_PARENT(void)
	{/*子进程读*/
	    char    c;
	    if (read(pfd1[0], &c, 1) != 1)
	        err_sys("read error");

	    if (c != 'p')
	        err_quit("WAIT_PARENT: incorrect data");
	}
	void TELL_CHILD(pid_t pid)
	{/*父进程写*/
	    if (write(pfd1[1], "p", 1) != 1)
	        err_sys("write error");
	}
	void WAIT_CHILD(void)
	{/*父进程读*/
	    char    c;

	    if (read(pfd2[0], &c, 1) != 1)
	        err_sys("read error");

	    if (c != 'c')
	        err_quit("WAIT_CHILD: incorrect data");
	}
	我们在调用fork之前创建两个管道，然后父进程在调用TELL_CHILD的时候向前面的管道中写入字符p，子进程调用TELL_PARENT的时候向后面的（另外一个）管道写入字符c。相应的WAIT_xxx函数从对应的管道中阻塞的读取相应的字符。
	注意每个管道都有一个额外的读端，这并没有什么大问题。也就是说，子进程可以从管道pfd1[0]中读，父进程也可以，但是没有关系，父进程是不会尝试中这个管道中读取数据的。
                        使用两个管道用于父子进程同步

               parent                           child
            +----------+         "p"         +-----------+
            |   pfd1[1]|-------------------->| pfd1[0]   |
            |   pfd2[0]|<--------------------| pfd2[1]   |
            +----------+         "c"         +-----------+

	3)popen和pclose函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec3.html
	一个常用的操作就是给一个进程创建管道，通过管道读取它的标准输出以及向它的标准输入发送数据，标准输入输出库提供过一个popen以及pclose函数，这两个函数处理了我们需要的所有细节工作：创建管道，创建子进程，关闭无用管道端，执行shell运行命令，并且等待命令结束。
	#include <stdio.h>
	FILE *popen(const char *cmdstring, const char *type);
	返回：如果成功返回文件指针，如果错误返回NULL。

	int pclose(FILE *fp);
	返回：返回命令cmdstring的终止状态，或者如果错误就返回1。

	函数popen调用fork然后exec执行cmdstring表示的命令，然后返回一个标准输入输出文件指针。
	如果type是"r"，那么返回的文件指针连接的是cmdstring的标准输出。调用fp = popen(cmdstring, "r")之后：
	+parent---------+         +child(cmd)-----+
	|          fp   |<--------+  stdout       |
	+---------------+         +---------------+
	如果type是"w"，那么返回的文件指针连接的是cmdstring的标准输入。调用fp = popen(cmdstring, "w")之后：
	+parent---------+         +child(cmd)-----+
	|          fp   +-------->|  stdin        |
	+---------------+         +---------------+

	函数pclose关闭标准输入输出流，等待命令结束，并且返回shell命令的结束状态。如果shell命令无法执行，那么pclose返回的命令结束状态就像shell执行了"exit(127)"一样。
	cmdstring使用Bourne shell执行，类似"sh -c comdstring"的形式，可以处理cmdstring中的特殊字符，具体参见"man sh"。

	例子：使用popen实现刚才向pager程序标准输入发送数据的程序
	#include <sys/wait.h>
	#define PAGER   "${PAGER:-more}" /* environment variable, or default */
	int main(int argc, char *argv[])
	{
	    char    line[MAXLINE];
	    FILE    *fpin, *fpout;

	    if (argc != 2)
	        err_quit("usage: a.out <pathname>");
		/*打开文件*/
	    if ((fpin = fopen(argv[1], "r")) == NULL)
	        err_sys("can't open %s", argv[1]);

		/*打开管道和程序*/
	    if ((fpout = popen(PAGER, "w")) == NULL)
	        err_sys("popen error");

		/*通过管道将文件内容发送给程序*/
	    while (fgets(line, MAXLINE, fpin) != NULL) {
	        if (fputs(line, fpout) == EOF)
	            err_sys("fputs error to pipe");
	    }
	    if (ferror(fpin))
	        err_sys("fgets error");
	    if (pclose(fpout) == -1)
	        err_sys("pclose error");

	    exit(0);
	}
	使用shell命令${PAGER:-more}表示：如果PAGER定义了并且非空，那就使用PAGER的值。否则就使用字符串string.

	一个实现popen和pclose的例子：
	文中也给出了一个对popen和pclose函数的实现。如下：
	#include <errno.h>
	#include <fcntl.h>
	#include <sys/wait.h>
	static pid_t    *childpid = NULL;
	static int      maxfd;

	FILE * popen(const char *cmdstring, const char *type)
	{
	    int     i;
	    int     pfd[2];
	    pid_t   pid;
	    FILE    *fp;

	    /* only allow "r" or "w" */
	    if ((type[0] != 'r' && type[0] != 'w') || type[1] != 0) {
	        errno = EINVAL;     /* required by POSIX */
	        return(NULL);
	    }

	    if (childpid == NULL) {     /* first time through */
	        /* allocate zeroed out array for child pids */
	        maxfd = open_max();/*这个函数是自定义的为了获取最大文件描述符号*/
	        if ((childpid = calloc(maxfd, sizeof(pid_t))) == NULL)
	            return(NULL);
	    }

	    if (pipe(pfd) < 0)
	        return(NULL);   /* errno set by pipe() */

	    if ((pid = fork()) < 0) {
	        return(NULL);   /* errno set by fork() */
	    } else if (pid == 0) {                           /* child */
	        if (*type == 'r') {
	            close(pfd[0]);
	            if (pfd[1] != STDOUT_FILENO) {
	                dup2(pfd[1], STDOUT_FILENO);
	                close(pfd[1]);
	            }
	        } else {
	            close(pfd[1]);
	            if (pfd[0] != STDIN_FILENO) {
	                dup2(pfd[0], STDIN_FILENO);
	                close(pfd[0]);
	            }
	        }

	        /* close all descriptors in childpid[] */
	        for (i = 0; i < maxfd; i++)
	            if (childpid[i] > 0)
	                close(i);

	        execl("/bin/sh", "sh", "-c", cmdstring, (char *)0);
	        _exit(127);
	    }

	    /* parent continues... */
	    if (*type == 'r') {
	        close(pfd[1]);
	        if ((fp = fdopen(pfd[0], type)) == NULL)
	            return(NULL);
	    } else {
	        close(pfd[0]);
	        if ((fp = fdopen(pfd[1], type)) == NULL)
	            return(NULL);
	    }

	    childpid[fileno(fp)] = pid; /* remember child pid for this fd */
	    return(fp);
	}


	int pclose(FILE *fp)
	{
	    int     fd, stat;
	    pid_t   pid;

	    if (childpid == NULL) {
	        errno = EINVAL;
	        return(-1);     /* popen() has never been called */
	    }

	    fd = fileno(fp);
	    if ((pid = childpid[fd]) == 0) {
	        errno = EINVAL;
	        return(-1);     /* fp wasn't opened by popen() */
	    }

	    childpid[fd] = 0;
	    if (fclose(fp) == EOF)
	        return(-1);

	    while (waitpid(pid, &stat, 0) < 0)
	        if (errno != EINTR)
	            return(-1); /* error other than EINTR from waitpid() */

	    return(stat);   /* return child's termination status */
	}

	其中popen中有许多地方需要我们注意。首先，每次fopen被调用的时候，我们都需要记住子进程的pid以及相应的文件描述符号或者文件指针。我们采取的方法是将子进程的pid存放到一个childpid数组中，这个数组的索引是文件描述符号，通过文件描述符号索引到数组childpid中的子进程pid。通过这个方法，当传递文件指针并且调用pclose的时候，我们调用标准输入输出函数fileno来获取文件指针对应的文件描述符号，然后获取到waitpid所需要的子进程pid。因为对于一个指定的进程，可能会调用popen多次，所以我们动态分配childpid数组（在第一次调用popen的时候调用），数组的元素数目是可以拥有的最大文件描述符号的数目，这样可以容纳尽可能多的子进程。
	调用pipe和fork然后在每个进程中将特定的文件重新定向，这个过程类似我们之前做的。
	POSIX.1要求popen在子进程中关闭之前的popen函数调用打开的文件。我们通过遍历childpid数组并且关闭其中仍然打开的文件描述符号来做到这个。
	如果调用pclose的进程建立了SIGCHLD的信号处理函数会怎样？答案是从pclose中调用pclose将会返回EINTR错误。因为调用者允许捕捉这个信号（或者其他任何可能导致waitpid中断的信号），如果它被一个捕获的信号中断了，那么我们只是简单地再次调用waitpid(看代码即知，如果wait没错或者是信号中断的，那么就不会跳出while循环)。
	(这里根据以前的内容可知SIGCHLD在子进程结束的时候由内核自动产生，一般这个信号会被忽略，但是如果捕获这个信号，比较常见的做法是在其信号处理函数中调用了waitpid之类的函数获取其子进程状态。
	另外前面也说过，waitpid或wait行为如下：a.阻塞:如果进程的所有子进程正在运行的话。b.立即返回：这时候如果有一个子进程终止了并且它等待自己的终止状态被获取，那么会立即返回这个子进程的终止状态。c.立即返回并且设置错误码：这时候进程没有子进程会出现这种情况。)
	有一个需要注意的情况就是：当程序调用waitpid获取了通过popen建立的子进程的退出状态码，然后我们调用pclose的时候pclose里面的waitpid将会发现子进程不存在了，并且返回1且设置errno为ECHILD。这种情况的这个行为是POSIX.1要求的。
	有些早期的pclose在信号打断wait的时候会返回EINTR错误。当然，也有些版本忽略会阻塞或者在等待的时候信号SIGINT,SIGQUIT以及SIGHUP，这些都是POSIX.1中不允许的。
	popen不应该被一个设置了set-user-ID或者set-group-ID的程序调用。当执行命令的时候，popen做的工作等价如下：
	execl("/bin/sh", "sh", "-c", command, NULL);
	这个执行shell命令的时候会继承调用者的环境，通过set-ID文件模式赋予的提升的权限，非法用户可能会操作这个环境这样shell执行命令就可能是非期望的了。
	popen非常适合执行这样的功能：用它来执行一个简单的过滤，来转换运行的命令的输入或者输出。命令想要建立它自己的管道线的时候，也是这个情况。

	例子
	假设有一个应用程序向标准输出写提示符号并且从标准输入读取一行。通过popen，我们可以在应用程序和它的输入之前插入一个程序，用来转换输入。如下图(注意图中的filter program是使用popen打开的子进程)：
	使用popen转换输入：
	+parent-------+ popen pipe   +filter program--+
	|             |<-------------|stdout          |
	+-----stdout--+              +----stdin-------+
	            \                   ^
	             \prompt           /user input
	           +--v---------------/--+
	           |   user at terminal  |
	           +---------------------+

	转换的可以是例如路径扩展名称，或者提供一个历史的机制（记住之前输入的命令）。

	#include <ctype.h>
	int main(void)
	{
		int     c;
		while ((c = getchar()) != EOF) {
			if (isupper(c))
				c = tolower(c);
			if (putchar(c) == EOF)
				err_sys("output error");
			if (c == '\n')
				fflush(stdout);
		}
		exit(0);
	}
	上面的代码给出了一个简单的过滤程序列出了这个操作。过滤程序拷贝标准输入到标准输出，把任何的大写字母转换成小写的字母。我们后面讨论协作处理程序的时候会讨论为什么我们写入一个回车符号之后会刷新标准输出。

	我们把这个程序编译成为myuclc可执行文件，然后通过下面的代码程序调用popen来执行.
	#include <sys/wait.h>
	int main(void)
	{
	    char    line[MAXLINE];
	    FILE    *fpin;

	    if ((fpin = popen("myuclc", "r")) == NULL)
	        err_sys("popen error");
	    for ( ; ; ) {
	        fputs("prompt> ", stdout);
	        fflush(stdout);
	        if (fgets(line, MAXLINE, fpin) == NULL) /* read from pipe */
	            break;
	        if (fputs(line, stdout) == EOF)
	            err_sys("fputs error to pipe");
	    }
	    if (pclose(fpin) == -1)
	        err_sys("pclose error");
	    putchar('\n');
	    exit(0);
	}
	我们需要在写入prompt之后需要调用fflush，因为标准输出一般都是行缓冲的，同时prompt中并没有包含回车符号(所以我们要显式将它输出)。

	4)协作处理程序
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec4.html
	unix系统中的filter是一个程序，这个程序从标准输入读取数据并且写入到标准输出。Filter一般会以线性的方式连接到shell的管道线中。当生成filter的标准输入，以及从filter的标准输出读取数据的程序是同一个程序的时候，filter就变成了一个协作处理程序(coprocesses)(也就是被协作者输入给协作者，协作者处理之后再送回给被协作者)。
	Korn shell 提供协作处理程序;Bourne shell, Bourne-again shell，和C shell不提供将进程连接成为协作处理程序的方法。协作处理程序一般通过shell运行在后台，它的标准输入和输出一般通过管道连接到另外的程序上面。尽管初始化一个协作处理程序并将它的标准输入和输出连接到另外的进程上面的shell语法非常的奇怪，但是协作处理程序在c程序中还是非常有用的。
	popen为我们提供了一个单向的管道，可以到达另外进程的标准输入或者从其标准输出而来，通过协作处理程序，我们可以拥有到另外进程的两个双向管道，一个通向其标准输入，一个来自其标准输出。我们写它的标准输入，让它处理相应的数据，然后从它的标准输出中读取数据。

	例子
	这里给出了一个协作处理程序的例子。进程创建两个pipes，一个是协作处理程序的标准输入，另外一个是协作处理程序的标准输出，下图描述了这个结构：
      通过写它的标准输入以及读取它的标准输出来运行写作处理程序

	+parent-------------+                +child(coprocesses)--+
	|          fd1[1]   |<----pipe1------|  stdin             |
	|          fd2[0]   |-----pipe2----->|  stdout            |
	+-------------------+                +--------------------+
	下面一个简单的协作处理程序从它的标准输入读取两个数字，然后计算两个数字的和，然后将结果写入到它的标准输出中（一般的协作处理程序会做更多的工作，这里只是一个简单的例子，用来学习如何使用管道连接协作处理程序）。
	int main(void)
	{
	    int     n,  int1,  int2;
	    char    line[MAXLINE];
	    while ((n = read(STDIN_FILENO, line, MAXLINE)) > 0) {
	        line[n] = 0;        /* null terminate */
	        if (sscanf(line, "%d%d", &int1, &int2) == 2) {/*从标准输入读取两个整数*/
	            sprintf(line, "%d\n", int1 + int2);/*对输入进行计算处理*/
	            n = strlen(line);
	            if (write(STDOUT_FILENO, line, n) != n)
	                err_sys("write error");
	        } else {
	            if (write(STDOUT_FILENO, "invalid args\n", 13) != 13)/*将处理结果写入标准输出*/
	                err_sys("write error");
	        }
	    }
	    exit(0);
	}
	我们将这个程序编译，生成一个add2的可执行文件。

	下面代码的程序，在从标准输入读取两个数字之后，会启动这个add2为协作处理程序，然后把从协作处理程序得到的值写到它的标准输出。
	static void sig_pipe(int signo)
	{/*我们的信号处理程序*/
	    printf("SIGPIPE caught\n");
	    exit(1);
	}
	int main(void)
	{
	    int     n, fd1[2], fd2[2];
	    pid_t   pid;
	    char    line[MAXLINE];

	    if (signal(SIGPIPE, sig_pipe) == SIG_ERR)
	        err_sys("signal error");

	    if (pipe(fd1) < 0 || pipe(fd2) < 0)/*创建管道*/
	        err_sys("pipe error");

	    if ((pid = fork()) < 0) {
	        err_sys("fork error");
	    } else if (pid > 0) {
	        close(fd1[0]);
	        close(fd2[1]);
	        while (fgets(line, MAXLINE, stdin) != NULL) {/*父进程从标准输入读取数据*/
	            n = strlen(line);
	            if (write(fd1[1], line, n) != n)/*父进程将标准输入读取的数据写入到发送管道中*/
	                err_sys("write error to pipe");
	            if ((n = read(fd2[0], line, MAXLINE)) < 0)/*父进程从接收管道中读取数据*/
	                err_sys("read error from pipe");
	            if (n == 0) {
	                err_msg("child closed pipe");
	                break;
	            }
	            line[n] = 0;    /* null terminate */
	            if (fputs(line, stdout) == EOF)/*父进程将从接收管道读取的数据写入到标准输出中*/
	                err_sys("fputs error");
	        }
	        if (ferror(stdin))
	            err_sys("fgets error on stdin");
	        exit(0);
	    } else {                                  /* child */
	        close(fd1[1]);
	        close(fd2[0]);
	        if (fd1[0] != STDIN_FILENO) {
	            if (dup2(fd1[0], STDIN_FILENO) != STDIN_FILENO)/*子进程将标准输入重新定向到管道*/
	                err_sys("dup2 error to stdin");
	            close(fd1[0]);
	        }

	        if (fd2[1] != STDOUT_FILENO) {
	            if (dup2(fd2[1], STDOUT_FILENO) != STDOUT_FILENO)/*子进程将标准输出重新定向到管道*/
	                err_sys("dup2 error to stdout");
	            close(fd2[1]);
	        }
	        if (execl("./add2", "add2", (char *)0) < 0)/*子进程执行协作处理程序*/
	            err_sys("execl error");
	    }
	    exit(0);
	}
	这里，我们创建两个管道，然后父子进程关闭其无用的管道端。我们需要使用两个管道，一个用来作为协作处理程序的标准输入，一个用来做为协作处理程序的标准输出。子进程然后在启动协作处理程序之前调用dup2将管道描述符号重定向到标准输入和标准输出。
	如果我们编译并且运行上面的程序，那么它会正常工作。但是，如果我们在等待输入期间杀掉了add2协作处理程序然后输入了两个数字，这个时候会产生写管道没有读取端的信号（导致信号处理程序被调用）。
	之前说过并不是所有的系统的pipe函数都提供全双工的管道，后面我们给出了另外一个版本的例子，它使用一个单个的全双工管道代替两个半双工管道，这需要系统支持全双工管道。

	例子：
	在前面的add2协作处理程序中，我们使用了底层的I/O（unix的系统调用）:read和write。如果我们使用标准I/O库重新实现这个协作处理程序会怎样呢？下面的代码给出了这样的版本：
	int main(void)
	{
	    int     int1, int2;
	    char    line[MAXLINE];

	    while (fgets(line, MAXLINE, stdin) != NULL) {
	        if (sscanf(line, "%d%d", &int1, &int2) == 2) {
	            if (printf("%d\n", int1 + int2) == EOF)
	                err_sys("printf error");
	        } else {
	            if (printf("invalid args\n") == EOF)
	                err_sys("printf error");
	        }
	    }
	    exit(0);
	}
	如果我们使用上面的这段代码作为协作处理程序，当启动协作处理程序的时候，就不会工作了。因为，默认来说标准I/O库是有缓存的。当这段程序被启动的时候，第一个fgets使用标准I/O库分配一个缓存，使用已有的缓存类型，然后从标准输入（这个标准输入实际被重新定向到管道上了）中读取。因为标准输入已经被重新定向成为了一个管道，默认来说标准I/O库函数的缓存是"fully buffered"(也就是缓存满了才会flush),类似标准输出也会有同样的动作。这样，add2程序从它的标准输入上读取就会阻塞，而调用popen的程序从它的管道中读取（也就是add2的标准输出）的时候也会阻塞，最终导致了死锁。
	这里，我们可以控制运行的协作处理程序，我们可以在上面代码中的while循环之前加入如下的语句：
	if (setvbuf(stdin, NULL, _IOLBF, 0) != 0)
		err_sys("setvbuf error");
	if (setvbuf(stdout, NULL, _IOLBF, 0) != 0)
		err_sys("setvbuf error");
	这些语句导致fgets变成行缓存的了（输入一个完整的一行也就是包含回车的行），同时printf会再遇到一个换行符号的时候刷新输出。
	如果我们无法修改向管道进行输出的程序，那么就需要其他的技术了，例如，如果我们使用awk(一个文本处理工具)作为一个协作处理程序，用来替代这里的add2，那么只要写一个如下的脚本：
	#! /bin/awk -f
	{ print $1 + $2 }
	这样这个程序也不会正常的工作，原因和前面那段代码一样，因为它使用的是标准I/O的缓存了。但是这里，我们无法改变awk的工作方式（也就是说，除非我们有awk的代码，否则我们无法修改awk的代码，设置其缓存类型）。这个时候我们可以在启动协作处理程序（awk）的时候让它以为自己的标准输入和输出是一个终端，这样会导致协作处理程序中的标准I/O库函数使用行缓存来处理输入/输出流。类似类似我们使用setvbuf，我们使用伪终端来做这个工作，后面会讲到。

	5)FIFOs
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec5.html
	FIFOs有时被称作有名管道。Pipes只能用在祖先进程创建的pipe之后具有关系的进程之间的通信(不考虑后面将要讲述的基于流的挂载的管道)，而FIFOs可以用在无关进程之间的通信。
	前面我们已经看到过，管道其实是一种文件，其stat结构中的st_mode成员会标志该文件是管道，我们通过S_ISFIFO宏来对它进行测试。
	创建一个FIFO和创建一个文件类似，其实，其路径名是文件系统中存在的。
	#include <sys/stat.h>
	int mkfifo(const char *pathname, mode_t mode);
	返回：如果成功返回0，如果错误返回1。
	参数mode和open函数的mode参数一样。
	创建了FIFO之后，我们可以使用open函数打开它，一般的文件I/O函数(例如close,read,write,unlink等)对FIFO也是适用的。
	应用程序可以通过mknod函数来创建管道，但是POSIX.1中没有包含mknod函数，所以POSIX.1中引入了mkfifo函数，现在mknod被包含在XSI扩展中，在大多数系统上面，mkfifo调用mknod来创建管道。
	当打开一个FIFO的时候，非阻塞标记会(O_NONBLOCK)有一些影响：
	* 一般来说（O_NONBLOCK没有被指定），使用只读的open会导致阻塞，直到其他的进程打开FIFO用来写入；类似，使用只写的open也会导致阻塞，直到其他的进程打开FIFO用来读取。
	* 如果一个O_NONBLOCK被指定了，那么只读的open，将会立即返回。但是如果没有进程对FIFO打开进行读取的话，只写的open返回1并且设置errno为ENXIO
	和pipe一样，如果我们写一个没有进程读的管道，那么会产生SIGPIPE信号，如果最后一个写FIFO的进程关闭FIFO那么会为读FIFO的进程产生一个文件结束符号。
	多个进程写一个给定的FIFO是非常常见的。这样我们就不得不考虑一下写操作的原子性，防止多个进程的写相互干扰。和pipes类似，常量PIPE_BUF指定可以原子写的最大的数据量。
	FIFOs有两个用途：
	a)被shell命令使用将数据从一个管道线传递到另外一个管道线，同时不创建中间文件。
	b)做为一个客户服务程序之间的交互点，用来在客户程序和服务程序之间传输数据。
	我们会使用例子来进行描述。

	使用管道重定向输出流的例子
	FIFOs可以被用来重定向一系列shell命令的输出流。这个会防止将数据写入到一个中间文件中（类似pipe）。pipes只能用于在进程之间进行线性的连接，而FIFO有它的名称，所以可以用来进行非线性的连接。
	假设一个过程，需要处理一个过滤好的输入流两次，如图：

	                                         +--------------+
	                                   ----> | prog3        |
	                                --/      +--------------+
	              +------------+ --/
	input file--->| prog1      |
	              +------------+ --\         +--------------+
	                                ---\     | prog2        |
	                                    ---> +--------------+

	通过使用FIFO和UNIX的程序tee，我们可以不经过中间文件完成这个过程。（tee程序会将它的标准输入拷贝到它的标准输出以及命令行上指定的一个文件中）。
	mkfifo fifo1
	prog3 < fifo1 &
	prog1 < infile | tee fifo1 | prog2
	我们创建一个FIFO然后在后台启动prog3，从FIFO中读取。我们之后启动prog1然后使用tee将它的标准输入发送到FIFO和prog2中。如下图所示：

	                                                      +-------+     +------+
	                                                ----> | FIFO  |---->|prog3 |
	                                             --/      +-------+     +------+
	            +--------+     +------------+ --/
	input file->|prog1   |---->| tee        |
	            +--------+     +------------+ --\         +-------+
	                                             ---\     | prog2 |
	                                                 ---> +-------+
	一个客户服务使用FIFO进行通信的例子
	另外一个使用FIFOs的例子就是在客户和服务器模型之间进行通信。如果我们有一个连接了多个客户程序的服务，每个客户程序都会把自己的请求写入到服务创建的一个公共的FIFO中（这里的"well-known"表示我们使用的FIFO的路径名称是所有的client都知道了的）下面的图就表示了这个情况。

	                                          +---------------+
	                                          |     server    |
	                                          +-------^-------+
	                                                  |
	                                             read requests
	                                          +-------+-------+
	                                          | well-knownFIFO|
	                                          +--^----------^-+
	                                            /            \
	                                  write requests     write requests
	                                          /                \
	                                         /                  \
	                              +------------+               +-----------+
	                              |   client   |   ......      |  client   |
	                              +------------+               +-----------+

	因为对于一个FIFO有多个写入者，所以客户发送给server的请求需要小于PIPE_BUF字节，这样会客户之间的写操作互相干扰。
	使用这个FIFOs模型的问题在于服务端如何将请求发送回每个客户程序。这个时候单一的FIFO就无法使用了，因为每个客户都有自己的请求相应，但是每个客户却无法知道什么时候从FIFO中读取到它自己的请求相应。有一个解决的方法就是，每个客户在其请求中同时发送它自己的进程ID，服务会为每个客户创建单独的FIFO，创建的路径名称基于客户的进程ID。例如，服务可以创建一个名称为"/tmp/serv1.XXXXX"的FIFO，这里XXXXX就是客户程序的进程ID。下图描述了这个结构：

	                                          +---------------+
	                                          |     server    |
	                                        / +-------^-------+ \
	                              write replies       |         write replies
	                                      /      read requests    \
	                      +--------------v-+  +-------+-------+  +-v---------------+
	                      |client-FIFO     |  | well-knownFIFO|  | client-FIFO     |
	                      +---\------------+  +--^----------^-+  +-------------/---+
	                           \                /            \                /
	                            \     write requests     write requests      /
	                      read replies        /                \         read replies
	                              \          /                  \          /
	                              +v-----------+               +----------v+
	                              |   client   |   ......      |  client   |
	                              +------------+               +-----------+

	这样的方式会正确的工作，但是有一个缺点就是服务无法知道如何判断一个客户是否终止。这样会导致客户端的FIFOs留存在了文件系统当中。服务必须捕获SIGPIPE信号，因为可能客户发送请求之后，在读取相应之前就终止了，这样留下的相应的客户端FIFO就之后一个写进程(server)却没有读进程了（前面说过这个时候会产生SIGPIPE）。我们后面在讨论到基于流的管道的时候，会讨论解决这个问题的比较不错的算法。

	对于前面的结构，如果服务进程打开well-known的FIFO的时候使用的是read-only方式（也就是只从其中读取数据），那么每次当客户进程数目从1变成0的时候，服务进程都会从FIFO中读取到一个文件结尾符号（因为前面说过，最后一个写进程关闭管道的时候会在管道中写入一个文件结束符号）。为了防止这样的情况发生，服务进程采用了这样的方法：打开它的well-known FIFO的时候使用readwrite模式(本书本章中的一个练习提到过)。

	6)XSI IPC
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec6.html
	三种类型的XSI IPC：消息队列，信号量，和共享内存，有许多共同点。这里将讨论这些共同的特性，后面会依次讨论它们的各自的特性。
		XSI的IPC函数基于System V的IPC函数。这三种类型的IPC起源于1970s的一个被称作"Columbus UNIX"的内部AT&T的UNIX版本。后来这三种类型的IPC被添加到System V中。它们不使用文件系统的命名空间而是使用自己的标准的命名空间。
	我们应当知道（前面的表格中也说了）：消息队列，信号量和共享内存被定义为Single UNIX Specification的XSI扩展。
	标识和关键字
	内核中的每个IPC的结构(消息队列，信号量或者共享内存段)，通过一个非负的整数来引用。例如当发送或者从一个消息队列中接收消息的时候，我们所知道的就只是这个队列的标识。和文件描述符号不同，IPC的标识不是一个小的整数。实际上，当创建并且移走一个IPC结构的时候，相应的标识符号会连续地增加，知道它到达一个最大的正整数值，然后又回归到0。
	标识只是一个IPC对象的内部名字。协作进程需要一个外部名字策略以便能够使用IPC对象进行交互。为了实现这个目的，IPC对象和一个关键字进行关联，这个关键字的作用就像是一个外部的名字一样。
	当创建一个IPC结构的时候（通过调用msgget, semget, 或 shmget），必须指定一个关键字。关键字的类型是key_t，它是在头文件<sys/types.h>中被定义的一个长整数类型。这个关键字在内核里面被转换成一个标识。
	对于一个客户和服务，有许多种不同的方法来使用同一个IPC结构。
	a)服务可以通过指定一个IPC_PRIVATE的关键字来创建一个IPC结构，然后将返回的标识存储到一个地方（例如文件系统中）让客户能够获取到。关键字IPC_PRIVATE可以确保服务能够创建一个新的IPC结构。使用这个技术的缺点就是，服务进程需要通过文件系统操作来将整数标识写入到文件中，然后客户就可以获取到这个标识了。
	IPC_PRIVATE关键字也可以使用在父子关系的进程中，父进程通过指定IPC_PRIVATE创建一个新的IPC结构，然后返回的标识对于后来fork出来的子进程就是可用的了。子进程可以通过exec函数的参数，将这个标识符号传递给一个新启动的程序中。
	b)客户和服务可以通过一个共同的头文件来商定好一个定义的关键字。例如，服务之后通过指定这个关键字创建一个新的IPC结构。这个方法的一个问题就是，有可能这个关键字已经和某个其他的IPC结构关联了，在这个情况下，get函数（msgget,semget,或者shmget）返回一个错误。服务进程必须处理这个错误，删除已经存在的IPC结构，然后再重新创建一个。
	c)客户和服务进程可以商定好一个路径和project ID(这个project ID是一个介于0到255之间的字符)，然后调用函数ftok将这两个值转换成一个关键字。这个关键字然后在第2步(应该就是前面的头文件的方法)中被使用。ftok所提供的功能就只是从一个给定的路径名和project ID生成一个关键字。
	#include <sys/ipc.h>
	key_t ftok(const char *path, int id);
	返回：如果成功返回关键字，如果失败返回(key_t)-1。
	这里的path参数必须引用一个已经存在的文件名称，而参数id则只使用它的低8位来生成关键字。
	ftok创建的关键字，一般是通过path对应的文件的stat结构的st_dev和st_ino成员结合project ID，来进行生成的。如果指定两个不同的path，那么ftok通常会返回两个不同的关键字。然而由于i-node成员和关键字都是通过长整型来存储的，所以在创建关键字的时候必然会丢失一些信息（关于索引节点的唯一性的信息），这意味着如果两个不同的路径名，如果指定的project id是相同的话，也是有可能会产生同样值的关键字的。
	三个get函数（msgget,semget和shmget）都有两个类似的参数：一个关键字和一个整数标记。当一个新的IPC结构被创建（通常是服务进程创建）的时候，通常是由如下情况导致：指定的关键字应当是IPC_PRIVATE，或者是一个没有与任何其他特定IPC结构关联的关键字并且指定了IPC_CREAT标记。如果想要引用一个已经存在的队列（通常是客户进程引用），关键字必须要和创建该队列时候的关键字一样并且没有指定IPC_CREAT标记。
	需要注意的是，我们不可能通过IPC_PRIVATE关键字来引用一个已经存在的queue，因为这个特殊的关键字值会创建一个新的queue。为引用一个已经存在的使用关键字IPC_PRIVATE创建的queue，我们必须知道相应的表示，然后在其他的IPC调用中（例如msgsnd和msgrcv）使用那个标识，而不是通过get函数来获得标识。
	如果我们想要创建一个新的IPC结构变量，那么我们需要确保我们不会引用一个使用同样表示的已经存在的IPC结构变量，，我们必须指定设定了IPC_CREAT和IPC_EXCL位的标记。使用这个方法，当已经存在了那个IPC结构的时候，会导致返回一个EEXIST错误（这个情况就类似使用指定了O_CREAT和O_EXCL标记的open函数）。

	权限结构
	XSI的IPC结构和一个ipc_perm结构相关联，这个结构定义了权限和属主，并且至少包含了如下的成员：
	struct ipc_perm {
		uid_t  uid;  /* owner's effective user id */
		gid_t  gid;  /* owner's effective group id */
		uid_t  cuid; /* creator's effective user id */
		gid_t  cgid; /* creator's effective group id */
		mode_t mode; /* access modes */
		.
	};
	每种实现都包含了额外的成员，可以通过查看你系统上面的<sys/ipc.h>文件来了解完整的定义。
	当建立IPC的时候，所有的成员都会被初始化。之后，我们可以通过调用msgctl,semctl,或者shmctl来修改uid,gid,和mode成员。为了能够改变这些值，调用进程必须是IPC结构的创建者或者是超级用户。修改这些成员和给一个文件调用chown或者chmod类似。
	mode成员的值和<sys/stat.h>中定义的文件访问权限很类似，但是对于任何的IPC结构没有相应的执行权限。同时，消息队列和共享内存使用read和write但是信号量使用read和alter。下表展示的就是每种IPC形式的六个权限：
	┌──────────────────────┬──────┐
	│      Permission      │ Bit  │
	├──────────────────────┼──────┤
	│ user-read            │ 0400 │
	├──────────────────────┼──────┤
	│ user-write (alter)   │ 0200 │
	├──────────────────────┼──────┤
	│ group-read           │ 0040 │
	├──────────────────────┼──────┤
	│ group-write (alter)  │ 0020 │
	├──────────────────────┼──────┤
	│ other-read           │ 0004 │
	├──────────────────────┼──────┤
	│ other-write (alter)  │ 0002 │
	└──────────────────────┴──────┘
	有一些实现定义了一些常量来表示这些权限，但是这些都没有被Single UNIX Specification标准化。

	配置限制
	我们可以看到，所有三种形式的XSI IPC都有内部的限制。所有这些限制可以通过内核来进行配置，我们后面讲到每一种IPC的时候，将会对这些限制进行描述。
	每个平台提供了它自己的显示和修改特定限制的方法。FreeBSD 5.2.1,Linux 2.4.22,和Mac OS X 10.3提供了sysctl命令来查看和修改内核配置参数。Solaris 9可以通过修改文件/etc/system然后重新启动来修改内核的配置参数。
	在Linux上面，呢可以通过运行"ipcs -l"来查看IPC相关的限制。在FreeBSD上，相应的命令是"ipcs -T"。在Solaris上，你可以运行sysdef -i来查看可以调节的参数。

	优点和缺点
	XSI IPC的一个基本问题就是IPC结构是系统范围内的，没有一个引用计数。例如，如果我们创建了一个消息队列，将一些消息放到这个队列上面，然后终止进程，那么消息队列和它的内容并不会被删除。它们会保留在系统中，直到其它进程调用msgrcv或者msgctl进行特定的读取或删除，或者通过执行ipcrm命令，或者通过系统的重新启动。与pipe相比，pipe会在最后一个引用它的进程结束的时候完全地被移除。对于FIFO，尽管管道的名字在文件系统中保留着（以管道文件的形式），但是FIFO中保留的任何数据会在最后一个引用该FIFO的进程结束的时候被移走。
	另外一个XSI IPC的问题就是，这些IPC结构不是通过在文件系统中的名字被知道的。我们无法通过前面的函数来访问和修改它们。有许多系统调用(msgget,semop,shmat,等等)被添加到内核中以便支持这些IPC对象。我们无法通过ls命令来查看IPC对象，我们无法通过rm命令来删除它们，我们也无法通过chmod命令来修改它们的权限。然而，有两个命令"ipcs"和"ipcrm"被加入了进来，可以实现类似的功能。
	因为这些IPC不能使用文件描述符号，所以我们不能构对它们使用多I/O函数(select和poll函数)进行操作。这使得我们同时使用多个IPC结构或者通过文件或者设备I/O使用任何这些IPC结构变得非常的困难。例如，我们无法有一个服务进程不经过忙等待的循环方式等待消息被放到两个消息队列中的一个上面。
	还有更多关于有点和缺点的讨论或者争辩，这里就不一一列举了。同时有一个描述各种IPC特性的表格，这里也不列出了。具体参见参考资料。
	后面将会对三种IPC分别进行详细的讲解。

	7)消息队列
参考:http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec7.html
	消息队列是存放在内核中的消息的链表，通过消息队列标识进行标记。我们把消息队列称为队列，把它的标识称为队列标识。
	另外Single UNIX Specification有一个实时扩展的消息队列实现，这里对实时扩展不进行讨论。
	通过msgget一个新的队列会被创建或者一个已经存在的队列会被打开。新的消息通过msgsnd函数被添加到队列的尾部。每个消息有一个正的长整数类型字段，一个非负的长度，以及实际的数据字节（和长度相关的）。所有这些在消息被添加到队列中的时候通过msgsnd来指定。通过msgrcv可以从一个队列中接收消息。我们没有必要以先进先出的次序来获取消息。其实，我们可以基于消息的类型字段来获取消息。
	每个队列有如下的msqid_ds结构和它相关联：
	struct msqid_ds {
		struct ipc_perm  msg_perm;     /* see Section 15.6.2 */
		msgqnum_t        msg_qnum;     /* # of messages on queue */
		msglen_t         msg_qbytes;   /* max # of bytes on queue */
		pid_t            msg_lspid;    /* pid of last msgsnd() */
		pid_t            msg_lrpid;    /* pid of last msgrcv() */
		time_t           msg_stime;    /* last-msgsnd() time */
		time_t           msg_rtime;    /* last-msgrcv() time */
		time_t           msg_ctime;    /* last-change time */
		.
	};
	这个结构定义了当前的队列状态。其中的成员由Single UNIX Specification来定义，实现中还可以包含一些额外的没有在这个标准中定义的成员域。
	文中列出了一个表格用来展示影响队列的各种系统限制。这里就不给出了。有一点需要注意的是，有些限制可能会依赖其它的限制，例如Linux中消息队列中最大的队列数目和所有队列能够容纳的最大数据量会影响最大的消息量。（注意数据是被包含在消息量中的）另外，在Linux中，即使消息包含0个字节的数据，那么也会认为这个消息包含了一个字节的数据，这样来限制排入队列中的消息的数目。
	一般来说第一个函数应该是msgget，用来创建一个队列或者打开一个已经存在的队列。
	#include <sys/msg.h>
	int msgget(key_t key, int flag);
	返回值：如果成功返回队列ID，如果错误返回1。
	在前面，我们描述了将关键字转化为标识的一些规则，也讨论了创建一个队列或者引用一个已经存在的队列。当一个新的队列被创建的时候，msqid_ds结构的如下成员会被初始化。
	*ipc_perm结构如前面说的那样被初始化。这个结构的mode成员会被设置为相应的权限标志。这些权限标志的值前面也提到过。
	*msg_qnum,msg_lspid, msg_lrpid, msg_stime,和msg_rtime都会被设置为0。
	*msg_ctime被设置成当前的时间。
	*msg_qbytes 被设置成系统的限制。
	成功的时候，msgget返回非负的队列ID，这个被接下来的三个消息队列函数来使用。
	msgctl对队列进行各种操作，这个函数以及后面相应的信号量和共享内存的函数(semctl和shmctl)就像ioctl函数（它是通过不同参数，进行各种操作的函数，一般在编写驱动程序的时候用这个函数以及其参数来实现相应硬件的特定的功能）那样(所谓可以容纳各种杂乱操作的"垃圾"函数)。
	#include <sys/msg.h>
	int msgctl(int msqid, int cmd, struct msqid_ds *buf );
	返回：如果成功返回0，如果错误返回1。
	参数cmd用来指定对msqid相应的队列进行的操作,如下。
	IPC_STAT:表示获取队列的msqid_ds结构，并把它存放在buf所值的位置。
	IPC_SET:从buf所指的结构变量中拷贝如下的成员到队列相关的msqid_ds结构：msg_perm.uid, msg_perm.gid, msg_perm.mode, 和 msg_qbytes。这个命令只有当进程的有效用户ID等于msg_perm.cuid或者msg_perm.uid或者一个进程具有超级用户权限的时候才能够被执行。只有超级用户可以增加msg_qbytes的值。
	IPC_RMID:将消息队列中仍然存在的数据，以及消息队列本身从系统中移走。这个删除的操作是立即生效的。任何其他的进程如果仍然在使用这个消息队列，那么它将在下次尝试操作这个队列的时候获得一个EIDRM的错误。这个命令只有当进程的有效用户ID等于msg_perm.cuid或者msg_perm.uid或者一个进程具有超级用户权限的时候才能够被执行。
	后面我们将会看到，这三个命令(IPC_STAT, IPC_SET, 和 IPC_RMID)在信号量以及共享内存中也被提供了。

	数据通过调用msgsnd函数被放在消息队列中。
	#include <sys/msg.h>
	int msgsnd(int msqid, const void *ptr, size_t nbytes, int flag);
	返回值：如果成功返回0，如果错误返回1。
	如我们前面所提到的，每个消息由一个正的长整数，一个非负的长度(nbytes)，以及一个实际的数据(和前面nbytes长度相应)。消息会被放置在队列的尾部。
	ptr参数指向一个长整数，这个整数包含消息类型（正数），以及接下来紧跟着消息的数据。（如果nbytes为0那么没有消息数据）如果我们发送的最大的消息是512字节，我们可以定义如下的结构：
	struct mymesg {
		long  mtype;      /* 消息类型，正数 */
		char  mtext[512]; /* 消息数据，长度为nbytes */
	};
	然后让ptr参数指向mymesg结构。消息类型会在接收者以非先进先出方式接收数据的时候被使用。
	有些系统同时支持64位环境。这会影响长整数和指针类型的大小。例如：在64位的SPARC系统中，Solaris允许32位和64位的应用程序共存。如果一个32位的应用程序通过管道或者套接字和一个64位的应用程序交换这个结构的数据，那么就会出现问题。也就是说，一个32位应用程序可能会期望mtext成员从这个结构的第4个字节开始，而64位的应用程序会期望mtext成员从这个结构的第8个字节开始。这个时候，64位应用程序中的mtype成员的部分内容(即后4个字节)将会被32位应用程序当做mtext成员的部分内容，而32位应用程序的mtext成员的部分内容(即前4个字节)被64位应用程序当做mtype成员的部分内容。
	然而，这个问题在XSI的消息队列中不会发生。Solaris将32位版本的IPC系统调用用与64位版本的IPC系统调用不同的入口(应该是系统调用的中断入口)来进行实现。系统调用知道如何处理32位应用程序和64位应用程序之间的通信，并且特殊对待type成员防止与消息的数据部分相互干扰。唯一的潜在问题就是可能64位应用程序通过8字节的类型成员发送消息，而类型成员的值超过了32位应用程序能够用4字节表示的范围。这个时候，32位的应用程序将会看到一个被截断的类型成员。
	可以给flag指定IPC_NOWAIT值。这个效果类似文件I/O时候指定非阻塞标志。如果消息队列已经满了（或者是队列中消息的总数达到了系统的限制，或者是数据量的字节达到了系统的限制），那么指定IPC_NOWAIT将会导致msgsnd立即返回，错误为EAGAIN。如果IPC_NOWAIT没有被指定，那么我们会阻塞，一直到有空间可以容纳这个消息，或者消息队列从系统中被删除，或者捕获到一个信号并且信号处理函数返回。在第2个情况下，会返回一个EIDRM错误；在最后一个情况下，会返回EINTR错误。
	需要注意当不计考虑地删除一个消息队列时候，系统是如何处理这个情况的。因为每个消息队列中没有相应的引用计数（而对于打开的文件中却有引用计数），删除一个队列会导致使用这个队列的进程当下次对这个队列进行操作的时候，产生错误。信号量处理删除的方式也是这样。相反，当一个文件被删除的时候，文件的内容并没有被删除，直到最后一个打开的文件描述符号被删除。
	当msgsnd成功返回的时候，和消息队列相关的msqid_ds结构会被更新，通过msg_lspid来指明调用这个函数的进程ID，以及通过msg_stime指明调用这个函数的时间，还有通过msg_qnum来指明多了一个消息。

	如果从一个队列中接收一个消息，那么使用msgrcv函数。
	#include <sys/msg.h>
	ssize_t msgrcv(int msqid, void *ptr, size_t nbytes , long type, int flag);
	返回值：如果成功返回消息数据部分的大小，如果错误返回1。
	类似msgsnd，参数ptr指向一个长整类型(消息的类型字段存放在其中)后面接着一个存放实际数据的缓存。参数nbytes指定数据缓存的大小。如果返回的消息比nbytes大并且MSG_NOERROR已经被设置，那么消息会被截断（这个时候我们不会收到消息被截断的通知同时剩余的消息也会被忽略）。如果消息太大，并且这个MSG_NOERROR没有被设置，那么会返回E2BIG错误（同时消息会保留在队列中）。
	我们可以通过type参数指定我们想要什么类型的消息。
	type == 0:表示将会返回队列中的第一个消息。
	type > 0: 表示将会返回队列中消息类型的值等于type参数的第一个消息。
	type < 0:表示将会返回队列中第一个最小的消息的类型值，这个值小于或者等于type的绝对值。
	非0的type表示将会以非先进先出的次序读取消息。例如type可以表示一个优先权，应用程序可以给消息赋予相应的优先级。另外一个使用这个成员的地方就是让这个成员包含一个进程的ID，这在多个客户和一个服务进程使用单个消息队列进行通信的时候，会用到(只要进程ID适合长整数类型)。
	我们可以指定一个IPC_NOWAIT值给flag，这样可以使得这个操作成为非阻塞的操作，导致当队列中没有指定类型的消息的时候，msgrcv会立即返回-1并且设置errno为ENOMSG。如果没有指定IPC_NOWAIT，那么这个操作会一直阻塞，直到一个指定类型的消息可用，或者队列在系统中被删除（返回-1并且设置errno为EIDRM），或者捕获到一个信号并且信号处理函数返回（导致msgrcv返回1并且设置errno为EINTR）。
	当msgrcv成功的时候，内核会更新相应消息队列的msqid_ds结构变量，通过msg_lrpid表示最后调用这个函数的进程PID，通过msg_rtime表示调用的时间，通过msg_qnum表示队列中少了一个消息。

	消息队列和管道以及流的时间对比的例子
	我们可以通过消息队列或者全双工管道来实现客户和服务进程之间的双向通信。
	下面的表格给出了Solaris上面三种类型通信技术的时间对比：消息队列，基于流的管道，以及UNIX域套接字。测试程序创建一个IPC通道，调用fork然后由父进程向子进程发送200兆数据。通过调用100,000次msgsnd来发送数据，消息队列的消息长度为2000字节；还有通过100,000次调用write给基于流的管道和UNIX域的套接字，每次write的字节数目为2000字节。下面的时间以秒为单位。
	 对比的表格数据如下：
	┌─────────────────────┬──────┬────────┬───────┐
	│      Operation      │ User │ System │ Clock │
	├─────────────────────┼──────┼────────┼───────┤
	│ message queue       │ 0.57 │  3.63  │ 4.22  │
	├─────────────────────┼──────┼────────┼───────┤
	│ STREAMS pipe        │ 0.50 │  3.21  │ 3.71  │
	├─────────────────────┼──────┼────────┼───────┤
	│ UNIX domain socket  │ 0.43 │  4.45  │ 5.59  │
	└─────────────────────┴──────┴────────┴───────┘
	这些数据给我们展示的结果表示，本来想要提供更高速度的消息队列，其实它的速度没有其他形式的IPC的速度快（实际上基于流的管道的速度比消息队列还快）。（当实现消息队列之后，其他形式的IPC可用的只有半双工的管道???）当我们考虑到前面节提到的消息队列的优点和缺点问题的时候，我们得到这样一个结论：在新的应用程序中，我们不应当使用消息队列了。

	8)信号量
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec8.html
	信号量和我们前面提到的IPC不太一样，它是一个计数器，用来提供在多个进程之间共享数据的访问。
	Single UNIX Specification 有一个对信号量的实时扩展，这里不对它进行讨论。
	为了获得一个共享的资源，进程需要做如下的工作：
	a)对控制资源的信号量进行测试。
	b)如果信号量的值是整数，那么进程可以对共享资源进行访问，这时候将把信号量的值减少1，表示使用了一个单位的资源。
	c)如果信号量的值大于0，那么进程睡眠直到信号量大于0，然后进程醒来执行步骤1。
	如果一个进程操作完信号量控制的共享数据，那么将会给信号量加1，如果有其他进程由于等待信号量而处于睡眠状态，那么这些进程将会被唤醒。
	为了正确地执行信号量，信号量值的测试和减少操作必须是一个原子操作。因此，信号量一般在内核中实现。
	有一个叫二进制的比较通用的信号量，这个信号量控制一个单一的资源，它的值被初始化为1。一般来说，信号量可以被初始化成为任何正数，数值表示可用的共享资源的单元数目。
	XSI的信号量比这复杂多了，有三个特性导致了这样的复杂性：
	a) 信号量并不简单地是一个单个的非负值。相反，我们将信号量定义成了包含一个或者多个信号量值的集合。当我们创建了一个信号量的时候，我们指定集合中值的数目。
	b) 信号量的创建(semget)是和它的初始化(semctl)相独立的。这个缺点比较致命，因为我们不能创建一个信号量集合同时初始化集合中的所有值。
	c)由于所有形式的XSI IPC即使在没有进程使用它们的时候也会保持存在，所以我们可能会担心一个应用程序没有释放分配给它的信号量就终止了。后面我们讨论的undo特性用来处理这种情况。
	内核为每一个信号量集合维持一个semid_ds数据结构，如下：
	struct semid_ds {
		struct ipc_perm  sem_perm;  /* see Section 15.6.2 */
		unsigned short   sem_nsems; /* # of semaphores in set */
		time_t           sem_otime; /* last-semop() time */
		time_t           sem_ctime; /* last-change time */
		.
	};
	以上是Single UNIX Specification标准定义的一些成员，具体实现还可以定义其他的成员。
	每个信号量由至少有以下成员的匿名结构体所表示：
	struct {
		unsigned short  semval;   /* semaphore value, always >= 0 */
		pid_t           sempid;   /* pid for last operation */
		unsigned short  semncnt;  /* # processes awaiting semval>curval */
		unsigned short  semzcnt;  /* # processes awaiting semval==0 */
		.
	};
	对于信号量集合的系统限制这里就不给出了，具体参见参考资料。

	首先调用semget获得一个信号量ID。
	#include <sys/sem.h>
	int semget(key_t key, int nsems, int flag);
	返回值：如果成功返回信号量ID，如果错误返回1。
	前面我们讨论了将一个关键字转换成标识的方法，以及创建一个新的信号量集合和对已经存在的信号量集合的引用。当创建一个新的信号量集合的时候，semid_ds结构变量的如下成员将会被初始化。
	*ipc_perm结构如同前面描述的那样被初始化(即所有的成员都会被初始化)。结构的mode成员将会被设置成相应的flag权限位。
	* sem_otime 被设置成0。
	* sem_ctime 被设置成当前时间。
	* sem_nsems 被设置成nsems。
	集合中的信号量的数目用nsems进行表示。如果一个新的集合被创建（一般这个集合都是被服务进程创建），我们必须指定nsems;如果我们只是引用一个已经存在的集合（一般集合被客户进程引用），我们可以指定nsems为0。

	semctl函数用来进行各种类型的信号量操作。
	#include <sys/sem.h>
	int semctl(int semid, int semnum, int  cmd, ... /* union semun arg */);
	返回值：参见后面。
	第4个参数是可选的，它取决于请求的命令，如果存在，那么这个参数的类型是semun，这是一个各种命令的参数的联合。
	union semun {
		int              val;    /* for SETVAL */
		struct semid_ds *buf;    /* for IPC_STAT and IPC_SET */
		unsigned short  *array;  /* for GETALL and SETALL */
	};
	我们需要注意的是，这个可选的参数是一个实际的联合变量，而不是一个指向联合变量的指针。
	参数cmd指定了如下的10个命令，这些命令对semid相应的集合进行操作。有5各命令使用semnum指定集合中的一个成员以引用特定的信号量值。semnum的范围是[0,nsems-1]。
	IPC_STAT 获取集合相应的semid_ds结构，把它存放在第4个参数arg.buf中。
	IPC_SET 设置和集合相关联的semid_ds结构变量的sem_perm.uid, sem_perm.gid,和sem_perm.mode成员，设置的值来自arg.buf。这个命令的执行进程的有效用户id必续和sem_perm.cuid或者sem_perm.uid相等，或者执行这个命令的进程是具有超级用户权限的。
	IPC_RMID 从系统中删除信号量集合。删除的动作立即生效。任何使用这个信号量的进程再次操作信号量的时候将会得到EIDRM错误。这个命令的执行进程的有效用户id必续和sem_perm.cuid或者sem_perm.uid相等，或者执行这个命令的进程是具有超级用户权限的。
	GETVAL 返回semnum对应的信号量的信号量值。
	SETVAL 设置semnum所对应的信号量的值。这个值通过arg.val来进行指定。
	GETPID 返回semnum对应的信号量的sempid成员。
	GETNCNT 返回semnum对应的信号量的semncnt成员。
	GETZCNT 返回semnum对应的信号量的semzcnt成员。
	GETALL 获取集合中的所有信号量的值。这些值被存放在arg.array所指向的数组中。
	SETALL 设置集合中的所有信号量值，这些值来自arg.array数组。

	函数semop会原子性地对一个信号量集合执行数组中指定的一系列操作。
	#include <sys/sem.h>
	int semop(int semid, struct sembuf semoparray[], size_t nops);
	返回值：如果成功返回0，如果错误返回1。
	semoparray参数是一个指向信号量操作的数组的指针，其元素的数据结构如下：
	struct sembuf {
		unsigned short  sem_num;  /* member # in set (0, 1, ..., nsems-1) */
		short           sem_op;   /* operation (negative, 0, or positive) */
		short           sem_flg;  /* IPC_NOWAIT, SEM_UNDO */
	};
	nops参数指定操作数组中元素的数目。
	对集合中的每个成员的操作通过相应的sem_op值来进行指定。这个值可以是负数，0，或者是正数。（在下面的讨论中，我们会引用到信号量的"undo"标记，这个标记相应于sem_flg成员中的SEM_UNDO比特位）
	I. 最简单的情况是sem_op是正数。这个情况相应于进程所返回的资源的数目。sem_op的值会被添加到信号量的值中。如果undo标记被指定了，那么会从这个进程的信号量调整值减去sem_op。
	II. 如果sem_op是负数，那么表示我们想要获取信号量控制的资源。
	如果信号量的值大于或者等于sem_op的绝对值（资源可用），那么会将信号量的值减去sem_op的绝对值。这保证信号量的结果值大于或者等于0。如果undo标记被指定，那么sem_op的绝对值也会被加到这个进程的信号量调整值中。
	如果信号量的值比sem_op的绝对值小（资源不可用），那么会发生如下的情况：
	a. 如果IPC_NOWAIT被指定了，那么semop会返回一个EAGAIN错误。
	b. 如果IPC_NOWAIT没有被指定，那么这个信号量的semncnt值会增加（因为调用者将要睡觉），然后调用者会挂起直到如下的情况发生。
	a.1. 信号量的值变成了大于或者等于sem_op的绝对值的时候（也就是说其他的进程释放了一些资源）。信号量的semncnt的值会被减少（因为调用进程正在进行等待），同时sem_op的绝对值会被从信号量的值中被减去。如果undo标记被指定，那么sem_op的绝对值也会被加到这个进程的信号量调整值上。
	a.2. 信号量被从系统中移除的时候。这个时候，函数返回一个EIDRM错误。
	a.3. 进程捕获到了一个信号，并且信号处理函数返回。这个情况，信号量的semncnt的值会被减少（因为调用进程不会再进行等待），并且函数返回一个EINTR错误。
	III. 如果sem_op的值是0，这表示调用进程想要等待，一直到信号量的值变成为0。
	如果信号量的值当前是0，那么函数会立即返回。
	如果信号量的值为非0，那么会根据如下情况进行处理：
	a. 如果IPC_NOWAIT被指定了，那么返回错误EAGAIN。
	b. 如果没有指定IPC_NOWAIT，那么信号量的semzcnt值会被增加（因为调用这将要进行睡眠），同时调用进程挂起，直到如下的情况发生。
	a.1. 信号量的值变成了0,信号量的semncnt的值会被减少（因为调用进程正在进行等待）。
	a.2. 信号量被从系统中移除的时候。这个时候，函数返回一个EIDRM错误。
	a.3. 进程捕获到了一个信号，并且信号处理函数返回。这个情况，信号量的semncnt的值会被减少（因为调用进程不会再进行等待），并且函数返回一个EINTR错误。
	semop函数的操作是原子性质的，要么数组中的操作全部被做，要么一个也不做。

	在退出时候对信号量的调整
	我们前面说过，如果一个进程通过信号量分配了资源，那么当进程结束的时候，可能会出现问题。当我们为信号量操作指定SEM_UNDO标记并且我们分配一个资源（sem_op值小于0），内核会记住我们给那个信号量分配了多少资源（sem_op的绝对值）。当进程结束的时候，无论是主动的还是非主动地结束，内核都会检查这个进程是否需要调整信号量，如果需要，将会对信号量进行相应的调整。
	如果我们通过SETVAL或者SETALL命令调用semctl设置信号量的值，那么那个信号量在所有进程的的调整值都被设置成0。

	信号量和记录锁的时间对比的例子
	如果我们在多个进程之间共享一个单个的资源，我们可以使用信号量或者记录锁。
	通过信号量技术，我们创建了一个只有一个信号量成员的信号量集合，并且将这个成员信号量的值初始化为1。分配资源的时候，我们调用semop函数，其中的sem_op值为-1;释放资源的时候，我们执行同样的函数但是其中的sem_op的值为+1。我们也可以为每一个操作指定SEM_UNDO，以处理进程结束而没有释放资源的情况。
	通过记录锁的技术，我们创建一个空的文件，然后将文件的第一个字节做为锁住的字节（不一定非得存在）。当分配资源的时候，我们获取一个在这个字节上面的写锁；释放资源的时候，我们将这个字节解锁。记录锁的特性可以保证如果一个进程在持有锁的时候结束了，那么这个锁会自动被内核释放。
	下面的表格中，给出了Linux上面两个技术的时间对比情况。每种情况下，资源被分配和释放100,000此。通过三个不同的进程同时进行。表中的时间是所有三个进程的总共秒数。
	时间对比的表格
	┌──────────────────────────┬──────┬────────┬───────┐
	│        Operation         │ User │ System │ Clock │
	├──────────────────────────┼──────┼────────┼───────┤
	│ semaphores with undo     │ 0.38 │  0.48  │ 0.86  │
	├──────────────────────────┼──────┼────────┼───────┤
	│ advisory record locking  │ 0.41 │  0.95  │ 1.36  │
	└──────────────────────────┴──────┴────────┴───────┘
	在Linux上面，使用记录锁的时间会比信号量锁的时间多60%。
	尽管记录锁比信号量锁要慢，如果我们只是对一个单个的资源加锁（例如共享内存段）并且不需要XSI信号量提供的高级功能的化，我们还是喜欢使用记录锁。原因就是记录锁非常容易被使用，并且系统会自动处理进程结束的时候的资源释放等问题。
	9)共享内存
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec9.html
	共享内存允许两个或者更多的进程共享一块指定区域的内存。这个是最快的IPC，因为数据不需要在客户和服务进程之间进行拷贝了。共享内存唯一一个需要注意的地方就是同步多个进程访问共享内存。如果服务进程正在将数据放到共享内存区域，那么客户进程不应当在服务进程做完之前访问这个共享内存中的数据。一般来说，使用信号量来同步共享内存的访问（但是前面我们也看到了，记录锁也行）。
	Single UNIX Specification在共享内存对象的实时扩展选项中包含一系列的访问共享内存的接口集合，但是这里我们将部讨论实时方面的扩展。
	内核对于每个共享内存段都维护一个至少包含如下成员的数据结构：
	struct shmid_ds {
		struct ipc_perm  shm_perm;    /* see Section 15.6.2 */
		size_t           shm_segsz;   /* size of segment in bytes */
		pid_t            shm_lpid;    /* pid of last shmop() */
		pid_t            shm_cpid;    /* pid of creator */
		shmatt_t         shm_nattch;  /* number of current attaches */
		time_t           shm_atime;   /* last-attach time */
		time_t           shm_dtime;   /* last-detach time */
		time_t           shm_ctime;   /* last-change time */
		.
	};
	(其他的实现可以添加其他的额外成员)
	类型shmatt_t被定义成一个无符号的整数，其大小至少和unsigned short那么大。文中给出了影响共享内存的系统限制。这里就不列举了。
	一般首先调用的函数是shmget，用来获得共享内存标识。
	#include <sys/shm.h>
	int shmget(key_t key, size_t size, int flag);
	返回值：如果成功，返回共享内存的ID，如果错误返回1。
	前面我们讨论了将一个关键字转换成标识的方法，以及创建一个新的共享内存段和对已经存在的共享内存段的引用。当创建一个新的共享内存段的时候，shmid_ds结构变量的如下成员将会被初始化。
	*ipc_perm结构如同前面描述的那样被初始化(即所有的成员都会被初始化)。结构的mode成员将会被设置成相应的flag权限位。
	* shm_lpid, shm_nattach, shm_atime, 和 shm_dtime 都被设置成0.
	* shm_ctime 被设置成当前时间。
	* 被设置成要求的大小。
	size参数表示共享内存段的字节大小数目。具体的实现经常会将大小向上圆整成系统页大小的整数倍，但是如果应用程序如果指定的大小值不是系统页的整数倍的话，那么最后一页剩余的那个部分是不可用的。如果创建一个新的共享内存段的时候(一般都由服务进程创建)，我们必须指定它的size参数。如果我们引用一个已经存在的共享内存段（一般都由客户进程引用），我们可以指定size参数为0。如果创建一个新的共享内存段，那么这个新创建的共享内存段中的内容被初始化成0。

	shmctl函数用来处理各种类型的共享内存操作。
	#include <sys/shm.h>
	int shmctl(int shmid, int cmd, struct shmid_ds *buf);
	返回值：如果成功，返回OK，如果错误返回1。
	cmd参数指定了如下的五个命令，这五个命令用来操作shmid所指定的共享内存段。
	IPC_STAT 获取共享内存段的shmid_ds结构，并将它存放在buf所指向的数据结构指针中。
	IPC_SET 根据buf指向的数据结构，设置共享内存段相应的shmid_ds结构相关的如下三个成员：shm_perm.uid, shm_perm.gid, 和 shm_perm.mode。这个命令可以被执行的前提是：进程的有效用户ID等于shm_perm.cuid或者shm_perm.uid，或者进程具有超级用户权限。
	IPC_RMID 从系统中删除共享内存段。因为有一个维护共享内存段的附加计数值(shmid_ds结构变量中的shm_nattch成员)，共享内存段不会被删除，这个状态一直维持到最后一个使用这个共享内存段的进程终止，或者断开和它的连接。无论这段内存是否仍然在被使用，这个共享内存段的标识会被立即删除，这样就无法通过shmat函数将这段内存再次附加了。这个命令可以被执行的前提是：进程的有效用户ID等于shm_perm.cuid或者shm_perm.uid，或者进程具有超级用户权限。
	Linux和Solaris还提供了两个命令，它们不属于Single UNIX Specification的一个部分。
	SHM_LOCK 锁住内存中的共享内存段。这个命令只能被超级用户执行。
	SHM_UNLOCK 解锁共享内存段。这个命令只能被超级用户执行。

	当创建了一个共享内存段的时候，进程可以通过调用shmat来将这个共享内存段附加到自己的地址空间上面。
	#include <sys/shm.h>
	void *shmat(int shmid, const void *addr, int flag);
	返回值：如果成功返回指向共享内存段的指针，如果错误返回1。
	共享内存段所附加的在调用进程中的地址取决于参数addr以及在flag中是否指定了SHM_RND。
	* 如果addr是0，那么共享内存段会被附加到内核所选择的第一个可用的地址。建议这样做。
	* 如果addr是非空的并且没有指定SHM_RND，那么共享内存段会被附加到addr所指定的地址上面。
	* 如果addr非空，并且SHM_RND被指定了，那么共享内存段会被附加到地址(addr - addr mod SHMLBA)上面。SHM_RND命令表示取整。SHMLBA表示低地址界限倍数，一般它为2的幂。这个运算会导致地址被取整到下一个SHMLBA倍数了。
	除非我们只在一种硬件类型上面运行应用程序（目前这个情况是不可能的），我们不应当指定共享内存段被附加的地址。相反我们应当指定addr为0以让系统自己选择地址。
	如果SHM_RDONLY位被在flag中指定了，那么共享内存段将会以只读的方式被附加。否则共享内存段会以读写的方式被附加。
	shmat返回的就是被附加的共享内存段的地址，或者如果错误返回1。如果shmat成功，那么内核会增加和共享内存段相关联的shmid_ds中的shm_nattch计数。

	当我们使用完共享内存段之后，我们调用shmdt将其断开。注意：这不会将共享内存标识以及它相关的数据结构从系统中移除。标识会一直存在，直到有进程（通常为服务进程）特意地通过调用IPC_RMID命令的shmctl将它移除。
	#include <sys/shm.h>
	int shmdt(void *addr);
	Returns: 0 if OK, 1 on error
	返回值：如果成功，返回0，如果错误返回1。
	addr参数就是之前调用shmat返回的值。如果成功，那么shmdt将会减少相关的shmid_ds结构变量的shm_nattch计数成员变量。

	举例
	不同的内核通过传入shmat参数0来附加地址段返回的地址依赖于系统。下面的代码展示了一个例子：
	#include <sys/shm.h>
	#define ARRAY_SIZE  40000
	#define MALLOC_SIZE 100000
	#define SHM_SIZE    100000
	#define SHM_MODE    0600    /* 用户 读/写 */

	char    array[ARRAY_SIZE];  /* 非初始化的bss数据段 */
	int main(void)
	{
	    int     shmid;
	    char    *ptr, *shmptr;
		/*打印非初始化bss数据段（全局变量数组）地址*/
	    printf("array[] from %lx to %lx\n", (unsigned long)&array[0], (unsigned long)&array[ARRAY_SIZE]);
		/*打印堆栈局部变量地址*/
	    printf("stack around %lx\n", (unsigned long)&shmid);

	    if ((ptr = malloc(MALLOC_SIZE)) == NULL)
	        err_sys("malloc error");
		/*打印堆内存地址*/
	    printf("malloced from %lx to %lx\n", (unsigned long)ptr, (unsigned long)ptr+MALLOC_SIZE);

	    if ((shmid = shmget(IPC_PRIVATE, SHM_SIZE, SHM_MODE)) < 0)
	        err_sys("shmget error");
	    if ((shmptr = shmat(shmid, 0, 0)) == (void *)-1)
	        err_sys("shmat error");
		/*打印共享内存地址*/
	    printf("shared memory attached from %lx to %lx\n", (unsigned long)shmptr, (unsigned long)shmptr+SHM_SIZE);

	    if (shmctl(shmid, IPC_RMID, 0) < 0)
	        err_sys("shmctl error");

	    exit(0);
	}


	在基于intel的linux系统上面运行这个程序，输入输出如下：
	$ ./a.out
	array[] from 804a080 to 8053cc0
	stack around bffff9e4
	malloced from 8053cc8 to 806c368
	shared memory attached from 40162000 to 4017a6a0

	下图展示了这个内存布局，和我们前面说过的类似。并且注意，共享内存段放在堆栈下面。


	                        +----------------------+ \
	           high address |                      |  \Command Line arguments
	                        |                      |  /And environment variables.
	                        +----------------------+ /
	                        |    Stack             |<-----0xbffff9e4
	                        |                      |
	                        |                      |
	                        +----------------------+
	                        |   Shared Memory      |<----0x4017a6a0 \ Shared memory of
	                        |                      |<----0x40162000 / 100,000 bytes.
	                        +----------------------+
	                        |                      |
	                        |                      |<----0x0806c368 \ Malloc of
	                        |    Heap              |<----0x08053cc8 / 100,000 bytes.
	                        +----------------------+
	                        | uninitialized data   |<----0x08053cc0 \ array[] of
	                        |    (bss)             |<----0x0804a080 / 40,000 bytes.
	                        +----------------------+
	                        |                      |
	                        |   initialized data   |
	                        +----------------------+
	                        |                      |
	                        |        text          |
	           low address  +----------------------+

	使用mmap将文件内容映射到地址空间上面和使用XSI IPC函数附加共享内存段的地址的原理类似。不同的主要是，mmap映射的内容由文件来存放，而共享内存映射的内容没有相应的文件。

	举例：关于/dev/zero的内存映射
	共享内存可以用于不相关的内存之间，如果内存之间是相关的，那么我们可使用其它的技术。
	下面讲述的方法可以用于FreeBSD 5.2.1, Linux 2.4.22, 和 Solaris 9，而Mac OS X 10.3目前不支持将字符设备映射到进程地址空间。
	设备/dev/zero在被读取的时候会提供无限个0。这个设备也接收任何写入到它的数据，但是它会忽略数据。我们在IPC中利用了它在内存映射的时候的一个特性。
	* 一个匿名内存区域将会被创建，它的大小为mmap的第2个参数，并且向上取整为最近的系统页大小。
	* 内存区域会被初始化为0。
	* 如果一个祖先进程指定了MAP_SHARED标记的mmap那么多个进程可以共享这个内存区域。

	下面的程序展示了使用这个设备的方法。
	#include <fcntl.h>
	#include <sys/mman.h>

	#define NLOOPS       1000
	#define SIZE         sizeof(long)     /* 共享内存区域大小 */

	static int update(long *ptr)
	{
	    return((*ptr)++);    /* 返回增加之前的值 */
	}

	int main(void)
	{
	    int     fd, i, counter;
	    pid_t   pid;
	    void    *area;

	    if ((fd = open("/dev/zero", O_RDWR)) < 0)
	        err_sys("open error");
	    if ((area = mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)) == MAP_FAILED)
	        err_sys("mmap error");
	    close(fd);      /* 映射之后关闭/dev/zero */

	    TELL_WAIT();

	    if ((pid = fork()) < 0) {
	        err_sys("fork error");
	    } else if (pid > 0) {           /* 父进程 */
	        for (i = 0; i < NLOOPS; i += 2) {
	            if ((counter = update((long *)area)) != i)
	                err_quit("parent: expected %d, got %d", i, counter);

	            TELL_CHILD(pid);
	            WAIT_CHILD();
	        }
	    } else {                         /* 子进程 */
	        for (i = 1; i < NLOOPS + 1; i += 2) {
	            WAIT_PARENT();

	            if ((counter = update((long *)area)) != i)
	                err_quit("child: expected %d, got %d", i, counter);

	            TELL_PARENT(getppid());
	        }
	    }

	    exit(0);
	}
	程序打开一个/dev/zero设备，然后调用mmap，指定了一个长整数类型的大小。需要注意的是，当区域被映射的时候，我们可以关闭设备。进程然后创建一个子进程。因为标记MAP_SHARED已经被指定，所以向内存映射的区域写的内容会被其他的进程看到。如果我们指定MAP_PRIVATE的话，这个例子就不会工作了。
	父子进程然后交替运行，使用前面的同步函数增加一个共享内存区域的长整数。内存映射区域被mmap初始化为0。父进程把它增加到1，然后子进程把它增加到2，然后父进程把它增加到3，等等。
	使用/dev/zero的方式，其优点在于，在我们使用mmap创建映射的内存区域的时候，实际的文件不需要存在。将/dev/zero映射会自动创建一个指定大小的映射内存区域。使用这个技术的缺点就是，它只能工作在相关的进程之间。可能使用线程会更加简单和高效。无论使用什么方式，我们都必须使用同步的机制来控制访问的数据。

	匿名内存映射的例子
	许多实现提供匿名映射的功能，类似/dev/zero具有的特性。为了使用这个功能，我们指定mmap的MAP_ANON标记，并且指定文件描述符号为-1。返回的区域是匿名的（因为它没有通过文件描述符号和任何一个路径关联），并且会创建一个可以被子进程共享的内存映射区域。
	匿名内存映射在本书的四个平台上面都有支持。需要注意的是，Linux为这个功能定义了MAP_ANONYMOUS标记，但是为了便于程序的可移植特性，定义MAP_ANON标记为同样的值。
	我们可以做如下三个修改将前面的例子转化成使用这个特性：a)删除将/dev/zero打开的语句。b)删除将fd关闭的语句。c)修改mmap的调用如下：
	if ((area = mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_ANON | MAP_SHARED, -1, 0)) == MAP_FAILED)
	在这个调用中，我们指定MAP_ANON标记，并且设置文件描述符号为-1。剩下的部分没有变化。

	最后两例子，展示了在相关的进程之间进行内存的共享。如果共享内存在无关的进程之间进行，那么有两个可选的方法。应用程序可以使用XSI的共享内存函数，或者他们可以使用带有MAP_SHARED标记的mmap函数，将同一个文件映射到它们的地址空间。

	10)客户服务特性
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch15lev1sec10.html
	我们来详细看一下客户和服务进程的特性，它们被所使用的各种IPC所影响。最简单的关系就是客户进程调用fork执行服务进程。可以在fork之前建立两个半双工管道，以便可以在两个方向传输数据(类似下图)。服务程序被设置成具有set-user-id权限，这样它会有特殊的权限。我们也可以查看客户进程的real user id来判断客户进程的real user id(执行exec并不会改变real user id)。

	+parent-------------+                +child(coprocesses)--+
	|          fd1[1]   |<----pipe1------|  stdin             |
	|          fd2[0]   |-----pipe2----->|  stdout            |
	+-------------------+                +--------------------+

	通过这个结构，我们建立了一个打开的服务者进程。（我们以后会给出这个客户服务的实现）服务进程为客户进程打开文件而不是客户进程调用open函数。通过这个方式，可以添加额外检查的比user/group/other更高权限的的权限。我们假设服务进程是set-user-id程序。这样可以给它额外的权限（可能就是root权限）。这个服务进程使用客户进程的real user id来确定是否让客户进程访问请求的文件。通过这个方式，我们可以建立一个服务进程，这个服务进程可以让特定的用户具有他们一般情况下没有的权限。
	在这个例子，因为服务进程是父进程的一个子进程，服务进程所能够做的就是将文件的内容传递回父进程。虽然这个在普通文件的时候工作的很好，但是它不能用于特殊设备文件。例如，我们想让服务进程打开一个指定的文件，并且将文件描述符号传递回去。然而，一个父进程可以将一个打开的文件描述符号传递给子进程，但是一个子进程不能构将一个文件描述符号传递给父进程（除非使用一个特殊的编程技术，后面我们会说到）。

	我们展示了下面的图中显示的服务类型。这个服务进程是一个守护进程，通过某种形式的IPC和所有的客户进程相连接。我们不能在这种类型中使用客户服务模型。需要一个有名的IPC，例如FIFOs或者消息队列。通过FIFOs，我们可以看到如果服务进程想要把数据发送回客户进程，那么需要为这个客户进程创建一个额外的管道。如果客户服务程序发送的数据只是从客户进程发送到服务进程中，那么一个单一的公共FIFO就足够了。System V的行打印就使用这种形式的模型。客户程序是lp命令，服务进程是lpsched守护进程。因为数据只是从客户向服务进程发送，所以只使用一个单一的FIFO。
	                                          +---------------+
	                                          |     server    |
	                                        / +-------^-------+ \
	                              write replies       |         write replies
	                                      /      read requests    \
	                      +--------------v-+  +-------+-------+  +-v---------------+
	                      |client-FIFO     |  | well-knownFIFO|  | client-FIFO     |
	                      +---\------------+  +--^----------^-+  +-------------/---+
	                           \                /            \                /
	                            \     write requests     write requests      /
	                      read replies        /                \         read replies
	                              \          /                  \          /
	                              +v-----------+               +----------v+
	                              |   client   |   ......      |  client   |
	                              +------------+               +-----------+

	通过消息队列，有多种方法：
	*服务进程和所有的客户进程使用一个消息队列。通过消息的type字段来标识消息的接收者。例如，客户进程发送一个type类型为1的消息请求给服务进程，请求数据里面包含客户的进程ID。服务进程接收到请求之后，可以通过接收到的进程ID，把客户进程ID填入到消息type中，反馈消息给客户进程。这样，服务进程只接收type字段为1的消息(通过msgrcv的第4个参数)，客户进程只接收type为它自己进程ID的消息。
	*另外，每个客户进程还可以使用它们自己单独的消息队列。在发送第一条请求之前，每个客户先使用IPC_PRIVATE创建好它自己的消息队列。而服务进程本身有一个被所有客户进程知道的公共的消息队列。客户进程将第一条请求发送给服务进程的公共队列中，请求中包含了客户进程自己创建的消息队列的队列ID，服务进程接收到客户的第一个请求之后，就可以根据请求中的队列ID，开始通过客户进程自己的消息队列（而不再是公共的消息队列了）和客户进程之间开始交互了。
	使用这个方法的一个问题就是，每个客户进程的消息队列中只有一条消息（发给服务进程的请求或者从服务进程发送回来的反馈），这对系统资源是一个浪费，我们可以使用FIFO来替代；另外一个问题就是服务进程需要从多个消息队列中读取消息，而对于消息队列，却没有类似select或者poll的函数。
	以上两种使用消息队列的方法，都可以用共享内存或者同步机制（记录锁或者信号量）来替代。

	这个客户服务类型关系（服务进程和客户进程之间没有直系关系）的问题出现在服务进程精确辨别客户进程的上面。除非服务进程执行一个非特别的操作，否则服务进程就需要知道客户进程是谁。这可能要求服务进程是一个set-user-ID程序。尽管这些IPC机制都通过内核，但是并没有一个可用的方法让内核可以分辨出消息的发送者。
	通过消息队列，如果在客户和服务进程之间使用一个单一的队列（这样只有一个消息在一个时间中在队列中），那么消息队列的msg_lspid成员包含了其他进程的进程ID。但是当写服务进程的时候，我们需要知道客户进程的有效用户ID而不是进程ID。目前没有一个可以移植的方法可以通过一个指定的进程ID获得相应的有效用户ID(虽然内核将两个值都保存在了进程表中，但是除非我们搜索内核的内存，否则我们没有办法通过其中的一个来获取另外一个值)。
	我们将会使用后面讲述的一个技术来让服务进程辨别客户进程。我们也可以使用FIFOs,消息队列，信号量，或者共享内存来实现。下面的描述，假设使用的是FIFOs，就像前面那个图形中的那样。客户必须创建它自己的FIFO，然后设置文件访问权限为只读只写。我们假设服务进程具有超级用户权限（否则它可能不会关心客户进程的真实身份），这样服务进程也可以对这个FIFO进行读写。当服务进程接收到客户发送到服务进程的公共FIFO上面的第一个请求的时候（请求必须包含客户的FIFO的标识），服务进程调用stat或者fstat对客户相关的FIFO进行操作。服务进程假设客户进程的有效用户ID就是管道的属主（就是stat结构的st_uid成员），服务进程只验证用户读和用户写权限是否激活。另外，服务进程应该也查看相应的FIFO的三个时间（stat结构变量的st_atime,st_mtime,和st_ctime成员）来验证它们是最近的。如果一个非法用户可以用其它认创建一个FIFO，并且设置了文件的读写权限，那么系统就是不安全的。
	如果使用XSI的IPC实现这个技术，那么使用前面我们说过的和消息队列，信号量和共享内存相关的ipc_perm结构来辨别创建IPC消息通信结构的创建者（通过cuid和cgid成员）。和使用FIFOs类似，服务进程需要客户进程创建IPC结构，并且设置访问权限为只读只写。和IPC结构相关的时间信息也应当被服务进程验证，以便可以保证是最新的（IPC结构除非被显示地删除，否则它们会一直存在）。
	我们后面将会看到一个更好的方法来做这个验证，就是让内核提供客户进程的有效用户ID以及有效用户组ID。这个在文件描述符号在进程之间传递的时候，通过STREAMS子系统来做。

	11)总结
	我们详细讲解了内部进程通信技术：pipes,有名管道(FIFOs)，和三种XSI的通用IPC技术（消息队列，信号量，和共享内存）。信号量实际上是一种同步机制，并不是真正的IPC机制，它一般用来同步共享资源的访问，例如共享内存段。通过pipes，我们看到了popen函数的实现，协作处理进程，以及使用标准输入输出库时候缓存时候遇到的问题。
	在对比了消息队列和全双工管道，信号量和记录锁的时间之后，我们可以得到如下建议：应该学习管道(pipes)和有名管道(FIFOs)，因为这两种基本的技术在许多的应用程序中工作的效率还是非常高的。避免在新的应用程序中使用消息队列和信号量，可以使用全双工管道和记录锁来替代，因为它们使用起来要简单得多。尽管使用mmap函数也能实现类似共享内存的功能，但是共享内存还是有它的作用的。
	在后面，我们将会看到网络的IPC技术，这允许进程之间跨越不同的机器进行通信。

*网络通信
==========================
	1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec1.html
	在前面的章节，我们查看了pipes,FIFOs,消息队列，信号量，和共享内存这些unix提供的经典的IPC方式。这些机制允许运行在同一台机器上面的进程之间相互通信。本部分内容将会介绍在不同机器上运行的进程之间的通信（通过一个公共的网络），即网络通信。
	本部分内容中我们讨论网络IPC的套接字接口，通过这个接口，进程可以和本地或者别的机器上面的进程进行通信。这也是套接字的一个目的，无论在同一个机器还是不同的机器上面通信都使用同一套接口。尽管可以使用套接字通过不同的网络协议实现通信，这里我们将范围限制在Tcp/Ip协议上面，这也是因特网上事实的标准。
	POSIX.1上面定义的套接字API是基于4.4BSD的。尽管随着时间的逝去，接口有了些许的变化，但是当前的套接字接口和之前被引入的早期的原来的1980年的4.2BSD的套接字接口还是非常类似的。
	本部分内容只对套接字进行了简单的介绍，更详细的资料请参见其他资料。

	2)套接字描述符
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec2.html
	套接字是一个通信端点。和在unix系统上面使用文件描述符号访问文件类似，应用程序可以使用套接字描述符号访问套接字。套接字描述符号在unix系统中使用文件描述符号实现。实际上，有许多可以用来处理文件描述符号的函数，例如read和write都可以用在套接字描述符号上面。
	为了创建一个套接字，我们需要调用socket函数。
	#include <sys/socket.h>
	int socket(int domain, int type, int protocol);
	返回：如果成功返回文件（套接字）描述符号，如果错误返回1。
	domain参数决定通信的特性，包含地址格式（后面会详细说明）。下表列出来了POSIX.1所指定的domain。常量以AF_（address family）开始因为每个domain有它自己用来表示地址的格式。
	套接字通信domain
	┌───────────┬───────────────────────┐
	│  Domain   │      Description      │
	├───────────┼───────────────────────┤
	│ AF_INET   │ IPv4 Internet domain  │
	├───────────┼───────────────────────┤
	│ AF_INET6  │ IPv6 Internet domain  │
	├───────────┼───────────────────────┤
	│ AF_UNIX   │ UNIX domain           │
	├───────────┼───────────────────────┤
	│ AF_UNSPEC │ unspecified           │
	└───────────┴───────────────────────┘
	我们在后面讨论unix domain(unix 域)。大多数系统也定义了AF_LOCAL域，它是AF_UNIX的别名。AF_UNSPEC域是一个占位符号，表示“任何”域。历史上，有写平台支持额外的网络协议，例如AF_IPX网络协议族，但是相应于这些协议的domain常量并没有在POSIX.1标准中定义。
	type参数定义了套接字的类型，进而定义了通信的特性。下表列出了POSIX.1中指定的套接字类型。但是有些实现可以支持额外的类型。
	套接字类型
	┌────────────────┬──────────────────────────────────────────────────────────────────────┐
	│      Type      │                             Description                              │
	├────────────────┼──────────────────────────────────────────────────────────────────────┤
	│ SOCK_DGRAM     │ fixed-length, connectionless, unreliable messages                    │
	├────────────────┼──────────────────────────────────────────────────────────────────────┤
	│ SOCK_RAW       │ datagram interface to IP (optional in POSIX.1)                       │
	├────────────────┼──────────────────────────────────────────────────────────────────────┤
	│ SOCK_SEQPACKET │ fixed-length, sequenced, reliable, connection-oriented messages      │
	├────────────────┼──────────────────────────────────────────────────────────────────────┤
	│ SOCK_STREAM    │ sequenced, reliable, bidirectional, connection-oriented byte streams │
	└────────────────┴──────────────────────────────────────────────────────────────────────┘
	protocol参数一般是0，用来为给定的domain和type选定默认的协议。当多个协议都支持同样的domain和type的时候，我们可以使用protocol参数选择一个特定的协议。在AF_INET通信domain中默认的SOCK_STREAM套接字协议是TCP(传输控制协议)，在AF_INET通信domain中默认的SOCK_DGRAM套接字协议是UDP(用户数据报协议)。
	在数据报(SOCK_DGRAM)接口中，通信双方不需要存在一个逻辑的链接。你所需要做的就只是发送一个指定好了另外一端使用的地址的消息。
	一个数据报因此提供了一个无连接服务。一个比特流(SOCK_STREAM)在另外一个方面要求，交换数据之前，你需要在你的套接字和另一方的套接字之间设置一个逻辑的链接。
	数据报是一个自包含的消息。发送数据报和给别人发送邮件类似。你可以发送许多信件，但是你不能保证接收的次序，并且同时有些也会可能丢失。每个信件包含接收者的地址，这样每个信都和其他信相互独立。每个信甚至可以发送到不同的接收者。
	相反，如果使用面向连接的协议，通信双方就像打电话。首先你需要建立一个连接用来打电话，但是建立连接之后，你就可以直接和对方通话了。连接是一个点对点的通信信道，你可以在其上说话，但是你的话语并不包含任何地址信息，就好象有一个点对点的虚拟连接联系这通话双方，连接本身就代表了特定的收发地址。
	经过SOCK_STREAM套接字，应用程序不用知道消息边界，因为套接字提供了一个字节流服务。也就是说当我们从一个socket中读取数据的时候，读取返回的数据数目可能和发送数据给我们的进程写入的字节数目不一样。我们将会获得发送给我们的任何东西，但是它们可能需要多个函数调用。
	SOCK_SEQPACKET套接字类似SOCK_STREAM套接字，不同的是我们获得的是一个基于消息的服务而不是基于字节流的服务。也就是说，从SOCK_SEQPACKET接收到的数据量和写入的数据量相同。流控制传输协议(SCTP)提供了在因特网的domain的顺序包协议。
	SOCK_RAW套接字提供一个直接面向底层网络层的数据报接口（在因特网的domain中叫做IP）。因为没有考虑传输协议（例如TCP和UDP），应用程序在使用这个接口的时候，需要建立他们自己的协议头。为了创建一个raw socket(原始套接字)，需要具有超级用户权限，这样可以防止非法应用程序创建一个破坏安全机制的包。
	调用socket函数和调用open函数类似。两者都获得一个文件描述符号，可以用来进行I/O。当你操作完了文件描述符号的时候，你可以调用close断开和文件或者套接字的连接，释放文件描述符号以便以后可以再次利用。
	尽管套接字描述符号实际上是一个文件描述符号，但是却不能使用所有以操作文件描述符号为参数的函数来操作套接字描述符号。参考资料中就列出了这些函数。由于篇幅，这里就不详细列出了，具体可以参见参考资料。例如，lseek就无法作用于套接字，因为套接字不接受文件偏移的概念。
	套接字的通信是双工的，我们可以使用shutdown函数来关闭对套接字的I/O。
	#include <sys/socket.h>
	int shutdown (int sockfd, int how);
	返回值：如果成功，返回0；如果出错，返回1。
	如果参数how是SHUT_RD，那么就无法从套接字里面读取数据。如果how参数是SHUT_WR，那么我们无法使用套接字来传输数据。我们可以使用SHUT_RDWR来禁止发送和接收数据。
	既然我们可以对一个套接字进行close那么为什么还需要shutdown呢？这有许多的原因。首先，close将会只在最后一个引用的进程关闭的时候才会关闭网络末端。这也意味着，如果我们复制了套接字（例如通过dup），那么套接字只有在最后一个引用它的文件描述符号关闭的时候才会被释放。shutdown函数允许我们不用考虑有几个进程引用文件描述符号，就可以释放套接字。另外，有时候使用shutdown来关闭一个方向的连接也非常的方便。例如，我们想要关闭一个socket的写入，但是我们还想让我们正在通信的进程可以在我们传输完数据的时候可以进行处理，同时也允许我们使用套接字来接收进程发送给我们的数据。

	3)寻址
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec3.html
	在前面的小节里面，我们学到了如何创建和销毁一个套接字。在我们使用套接字之前，我们需要知道如何定位到我们交互的进程。定位我们需要通信的进程，有两个部分，一个是我们想要连接的计算机的网络地址，一个是用来定位具体进程的计算机上面的服务。

	*字节顺序
	当和同一个计算机上面的进程进行通信的时候，我们不用担心字节顺序。字节顺序是处理器的特性，用来表示在一个大的数据类型中字节如何进行排序，例如整数。下面的图示表示了32位整数是如何进行排序的。
	32位整数的字节顺序
	big-endian:
	+---------------------------------+
	|   n   |  n+1   |  n+2  |  n+3   |
	+---------------------------------+
	MSB                           LSB

	little-endian:
	+---------------------------------+
	|  n+3  |  n+2   |  n+1  |   n    |
	+---------------------------------+
	MSB                           LSB

	如果处理器结构支持big-endian字节序，那么高字节地址出现在低位字节(LSB)。Little-endian字节顺序相反，高位字节内容(MSB)出现在左面，而低位字节内容出现在右面。因此，如果我们想要指定一个32位整数值为0x04030201，最高位字节包含4，最低位字节包含1，并且并不考虑字节次序。如果我们将这个整数的地址当做字符地址赋给一个字符指针cp，那么我们将会看到字节顺序的不同。在little-endian的处理器上面，cp[0]会引用最低位字节值1，cp[3]会引用最高位字节值4；而在big-endian处理器上面，cp[0]的值为4即最高字节，cp[3]包含1即最低字节位。下图给出了本文中四个平台的字节次序。
	测试平台的字节次序
	┌──────────────────┬─────────────────────────┬───────────────┐
	│ Operating system │ Processor architecture  │ Byte order    │
	├──────────────────┼─────────────────────────┼───────────────┤
	│ FreeBSD 5.2.1    │ Intel Pentium           │ little-endian │
	├──────────────────┼─────────────────────────┼───────────────┤
	│ Linux 2.4.22     │ Intel Pentium           │ little-endian │
	├──────────────────┼─────────────────────────┼───────────────┤
	│ Mac OS X 10.3    │ PowerPC                 │ big-endian    │
	├──────────────────┼─────────────────────────┼───────────────┤
	│ Solaris 9        │ Sun SPARC               │ big-endian    │
	└──────────────────┴─────────────────────────┴───────────────┘
	另外有些处理器还可以配置成两种字节顺序都可以支持。
	网络协议会指定一个字节次序，这样不同的计算机系统之间可以交换消息的信息而不用在意字节次序了。TCP/IP协议套件使用big-endian字节次序，字节次序在应用程序交换格式化数据的时候是可见的。通过TCP/IP，地址以网络字节次序表示，所以有时应用程序需要在网络字节次序和处理器字节次序之间进行转换。例如，在打印一个可读的地址的时候这个就很常见。

	有四个函数可以用于TCP/IP应用程序当中，在处理器字节次序和网络字节次序之间进行转换。
	#include <arpa/inet.h>
	uint32_t htonl(uint32_t hostint32);
	返回一个以网络字节顺序表示的32位整数。

	uint16_t htons(uint16_t hostint16);
	返回一个以网络字节顺序表示的16位整数。

	uint32_t ntohl(uint32_t netint32);
	返回一个以主机字节次序表示的32位整数。

	uint16_t ntohs(uint16_t netint16);
	返回一个以主机字节次序表示的16位整数。

	字符'h'表示"host"字节次序，字符'n'表示"network"字节次序。字符'l'表示"long"(也就是4个字节)整数，字符's'表示"short"(也就是两个字节)整数。这四个函数定义在<prpa/inet.h>中，有些老的系统中把它们放在<netinet/in.h>中。
	(据说，这里inet表示网络层向上暴露的接口，neti表示网络层向下链路层暴露的接口)

	*地址格式
	一个地址可以用来标识一个特定通信域中的套接字端。为特定的域指定特定的地址格式，这样不同的地址格式可以被传递到socket相关的函数中去。地址被强制转换成通用的sockaddr数据结构:
	struct sockaddr {
		sa_family_t   sa_family;   /* address family 例如AF_INET*/
		char          sa_data[];   /* variable-length address */
		.
	};
	实现上可以添加额外的数据成员，还可以定义sa_data[]成员的大小，例如，在linux系统上面，结构体定义如下：
	struct sockaddr {
		sa_family_t  sa_family;     /* address family */
		char         sa_data[14];   /* variable-length address */
	};
	FreeBSD结构定义如下：
	struct sockaddr {
		unsigned char  sa_len;        /* total length */
		sa_family_t    sa_family;     /* address family */
		char           sa_data[14];   /* variable-length address */
	};

	因特网地址定义在<netinet/in.h>中。在IPv4因特网域(AF_INET)，套接字地址使用结构sockaddr_in来表示:
	struct in_addr {
		in_addr_t       s_addr;       /* IPv4 address */
	};
	struct sockaddr_in {
		sa_family_t    sin_family;   /* address family */
		in_port_t      sin_port;     /* port number */
		struct in_addr sin_addr;     /* IPv4 address */
	};
	in_port_t数据类型被定义成uint16_t。in_addr_t数据类型被定义成uint32_t类型。这些整数数据类型指定了数据类型中的位号码，并且定义在<stdint.h>中。

	和AF_INET域相比较，IPv6因特网域(AF_INET6)套接字地址使用sockaddr_in6结构来表示：
	struct in6_addr {
		uint8_t        s6_addr[16];     /* IPv6 address */
	};
	struct sockaddr_in6 {
		sa_family_t     sin6_family;     /* address family */
		in_port_t       sin6_port;       /* port number */
		uint32_t        sin6_flowinfo;   /* traffic class and flow info */
		struct in6_addr sin6_addr;       /* IPv6 address */
		uint32_t        sin6_scope_id;   /* set of interfaces for scope */
	};

	下面是Single UNIX Specification要求定义的。不同的实现可以自由添加额外的成员。例如，在Linux上面，sockaddr_in数据结构被定义成如下：
	   struct sockaddr_in {
	     sa_family_t     sin_family;     /* address family */
	     in_port_t       sin_port;       /* port number */
	     struct in_addr  sin_addr;       /* IPv4 address */
	     unsigned char   sin_zero[8];    /* filler */
	   };
	这里，sin_zero成员是一个过滤域，应当被设置成全0。

	需要注意的是，尽管sockaddr_in和sockaddr_in6结构非常的不一样，但是他们都被强制转换成sockaddr数据结构并传递给socket函数。在后面，我们将会看到UNIX域套接字和两种因特网域套接字的地址格式都不一样。

	有时候我们需要以人可以阅读而不是计算机阅读的格式打印一个地址。BSD的网络软件包含inet_addr和inetntoa函数，用来在二进制的地址格式和点分十进制的字符串地址格式（a.b.c.d）之间进行转换。这些函数只能在IPv4地址上进行工作。有两个新的函数inet_ntop和inet_pton可以提供类似的功能，它们能够支持IPv4和IPv6地址格式。
	#include <arpa/inet.h>
	const char *inet_ntop(int domain, const void *restrict addr, char *restrict str, socklen_t size);
	返回值：成功的时候指向地址字符串的指针，错误的时候返回空。

	int inet_pton(int domain, const char *restrict str, void *restrict addr);
	返回值：成功的时候返回1，如果格式非法则返回0，如果错误则返回1。(费解???)

	inetntop函数可以将一个以网络字节次序的二进制质地转换成文本字符串;inet_pton将一个文本字符串转化成二进制的以网络字节次序表示的地址。这里，domain参数只能成传递两个值：AF_INET和AF_INET6。
	对于inet_ntop，size参数指定str缓存的大小（用来容纳字符串）。有两个常量：INET_ADDRSTRLEN可以有足够的空间容纳一个IPv4的地址，INET6_ADDRSTRLEN可以有足够的空间容纳一个IPv6的地址。对于inet_pton，addr缓存需要有足够的的空间，如果domain是AF_INET那么可以容纳一个32位的地址，如果domain是AF_INET6那么可以容纳一个128位的地址。

	*地址查询
	理想情况，一个应用程序不用知道套接字地址的内部结构。如果一个应用程序简单地把套接字地址作为sockaddr结构传递并且不依赖任何协议相关特性，那么应用程序就可以在提供同样类型服务的不同协议上面工作。
	以前BSD网络软件提供了访问各种网络配置信息的接口。在前面我们简单讨论了网络数据文件以及用来访问它们的函数。在这个章节，我们用一个更详细的方式来讨论它们并且介绍一些新的查询地址信息的函数。
	这些函数返回的网络地址信息可以被保存在许多的地方。它们可以被保存在静态的文件中（例如/etc/hosts,/etc/services等）；或者他们可以一个命名服务来管理，例如DNS(Domain Name System)或者NIS(Network Information Service)。我们不用考虑这些信息存放在哪里，我们可以使用同样的函数来访问它们。

	调用gethostent可以知道一个给定的计算机系统的hosts结构。
	#include <netdb.h>
	struct hostent *gethostent(void);
	返回：如果成功，返回一个指针，如果错误返回NULL。
	void sethostent(int stayopen);
	void endhostent(void);
	如果主机数据库文件没有被打开，那么gethostent将会打开它。gethostent函数返回文件中的下一条entry。sethostent函数会打开文件，或者如果文件已经打开，那么就重新回到文件的开始。endhostent函数关闭文件。
	当gethostent返回的时候，我们获取到一个指向hostent结构的指针，这个指针可能会指向一个静态数据缓存，这个静态数据缓存在每次调用gethostent的时候都会被覆盖。hostent结构的定义至少有以下几个成员：
	struct hostent {
		char   *h_name;       /* name of host */
		char  **h_aliases;    /* pointer to alternate host name array */
		int     h_addrtype;   /* address type */
		int     h_length;     /* length in bytes of address */
		char  **h_addr_list;  /* pointer to array of network addresses */
		.
	};
	返回的地址使用网络字节次序表示。
	有两个额外的函数gethostbyname和gethostbyaddr以前被包含在hostent函数中，但是现在它们将会被作废。我们马上就会看到可以替代他们的东西了。

	我们可以使用一些类似的接口获得网络名称以及代号。
	#include <netdb.h>
	struct netent *getnetbyaddr(uint32_t net, int type);
	struct netent *getnetbyname(const char *name);
	struct netent *getnetent(void);
	以上函数返回：如果成功返回指针，如果错误返回NULL。
	void setnetent(int stayopen);
	void endnetent(void);
	netent结构至少包含如下成员：
	struct netent {
		char     *n_name;      /* network name */
		char    **n_aliases;   /* alternate network name array pointer */
		int       n_addrtype;  /* address type */
		uint32_t  n_net;       /* network number */
		.
	};
	网络号码(n_net)以网络字节次序表示。地址类型是某一个地址常量（例如AF_INET）。

	我们可以通过如下的函数在协议名称和号码之间进行映射。
	#include <netdb.h>
	struct protoent *getprotobyname(const char *name);
	struct protoent *getprotobynumber(int proto);
	struct protoent *getprotoent(void);
	以上函数返回：如果成功返回指针，如果错误返回NULL。
	void setprotoent(int stayopen);
	void endprotoent(void);
	通过POSIX.1定义的protoent结构至少应当包含如下成员：
	struct protoent {
		char   *p_name;     /* protocol name */
		char  **p_aliases;  /* pointer to alternate protocol name array */
		int     p_proto;    /* protocol number */
		.
	};

	服务通过地址部分的端口号码部分来表示。每个服务提供一个公共的端口号码。我们可以通过getservbyname函数将一个服务名称映射成一个端口，通过getservbyport函数将一个端口映射成一个服务名称，或者通过getservent函数顺序扫描服务数据库。
	#include <netdb.h>
	struct servent *getservbyname(const char *name, const char *proto);
	struct servent *getservbyport(int port, const char *proto);
	struct servent *getservent(void);
	以上返回：如果成功返回指针，如果错误返回NULL。
	void setservent(int stayopen);
	void endservent(void);
	servent结构的定义至少包含如下的成员:
	struct servent {
		char   *s_name;      /* service name */
		char  **s_aliases;   /* pointer to alternate service name array */
		int     s_port;      /* port number */
		char   *s_proto;     /* name of protocol */
		.
	};

	POSIX.1定义了一些新的函数可以让一个应用程序将一个主机名称和服务名称映射成一个地址，以及进行相反的映射。这些函数替代了原来的gethostbyname和gethostbyaddr函数。
	getaddrinfo函数允许我们将一个主机名称和服务名称映射成一个地址。
	#include <sys/socket.h>
	#include <netdb.h>
	int getaddrinfo(const char *restrict host, const char *restrict service,
					const struct addrinfo *restrict hint, struct addrinfo **restrict res);
	返回值：如果成功返回0，如果错误返回非0的错误代码。
	void freeaddrinfo(struct addrinfo *ai);
	我们需要提供主机名称，服务名称，或者两者都提供。如果我们只提供一个名称，那么另外一个应该是空指针。主机名称可以是一个节点名称，或者点分十进制表示的主机地址。
	getaddrinfo函数返回一个addrinfo结构的链表。我们可以使用freeaddrinfo将一个或者多个这些结构释放，这取决于有多少个这个结构通过ai_next成员被链接。
	addrinfo结构的定义，至少包含如下的成员：
	struct addrinfo {
		int               ai_flags;       /* customize behavior */
		int               ai_family;      /* address family */
		int               ai_socktype;    /* socket type */
		int               ai_protocol;    /* protocol */
		socklen_t         ai_addrlen;     /* length in bytes of address */
		struct sockaddr  *ai_addr;        /* address */
		char             *ai_canonname;   /* canonical name of host */
		struct addrinfo  *ai_next;        /* next in list */
		.
	};
	我们可以提供一个可选的hint(参见getaddrinfo函数的参数)来符合特定的标准。这个hint是一个模板，它只使用ai_family，ai_flags,以及ai_socktype成员，用来过滤地址。剩下的整数成员必须被设置成0，并且指针成员被设置为空。下表列出了对于ai_flags成员我们可以使用的flags，以便定制地址和名称的处理方式。
	addrinfo结构的flags
	┌────────────────┬────────────────────────────────────────────────────────────┐
	│      Flag      │                                 Description                │
	├────────────────┼────────────────────────────────────────────────────────────┤
	│ AI_ADDRCONFIG  │ 请求配置的是哪种地址类型（IPv4或者IPv6)。                  │
	├────────────────┼────────────────────────────────────────────────────────────┤
	│ AI_ALL         │ 对IPv4和IPv6地址都进行查找（只和AI_V$MAPPED一块使用)。     │
	├────────────────┼────────────────────────────────────────────────────────────┤
	│ AI_CANONNAME   │ 请求一个正式的名称（和别名相对）。                         │
	├────────────────┼────────────────────────────────────────────────────────────┤
	│ AI_NUMERICHOST │ 以数字形式返回主机地址。                                   │
	├────────────────┼────────────────────────────────────────────────────────────┤
	│ AI_NUMERICSERV │ 将服务作为端口号码返回。                                   │
	├────────────────┼────────────────────────────────────────────────────────────┤
	│ AI_PASSIVE     │ 绑定套接字地址以便侦听。                                   │
	├────────────────┼────────────────────────────────────────────────────────────┤
	│ AI_V4MAPPED    │ 如果没有发现IPv6地址，那么返回以IPv6格式映射的IPv4地址。   │
	└────────────────┴────────────────────────────────────────────────────────────┘

	如果getaddrinfo失败，那么我们不能使用perror或者strerror来生成错误消息。相反，我们需要调用gai_strerror来将返回的错误号码转化成错误消息。
	#include <netdb.h>
	const char *gai_strerror(int error);
	返回：一个描述错误的指向字符串的指针。

	getnameinfo函数会将一个地址转化成一个主机和服务名称。
	#include <sys/socket.h>
	#include <netdb.h>
	int getnameinfo(const struct sockaddr *restrict addr, socklen_t alen, char *restrict host,
	                socklen_t hostlen, char *restrict service, socklen_t servlen, unsigned int flags);
	返回：如果成功返回0，如果错误返回非0值。
	套接字地址(addr)被转化成一个主机名称和服务名称。如果host非空，那么它指向一个用来存放主机名称的长度为hostlen字节的缓存。类似地，如果service非空，那么它指向一个用来存放服务名称的长度为servlen字节的缓存。
	参数flags会给我们指定对这个转换进行的方式。下面的表格列举出来支持的flags。
	getnameinfo函数的标记
	┌────────────────┬────────────────────────────────────────────────────────────────┐
	│      Flag      │                                         Description            │
	├────────────────┼────────────────────────────────────────────────────────────────┤
	│ NI_DGRAM       │ 服务基于数据报而不是流。                                       │
	├────────────────┼────────────────────────────────────────────────────────────────┤
	│ NI_NAMEREQD    │ 如果没有找到主机名称，那么将这个作为错误对待。                 │
	├────────────────┼────────────────────────────────────────────────────────────────┤
	│ NI_NOFQDN      │ 只返回本地主机整个域名称的节点名称部分。                       │
	├────────────────┼────────────────────────────────────────────────────────────────┤
	│ NI_NUMERICHOST │ 返回数字形式表示的主机地址而不是名字形式。                     │
	├────────────────┼────────────────────────────────────────────────────────────────┤
	│ NI_NUMERICSERV │ 返回数字形式的服务地址（例如端口号码），而不是名字的形式。     │
	└────────────────┴────────────────────────────────────────────────────────────────┘

	举例：
	下面的程序列举getaddrinfo函数的使用。
	打印主机和服务信息的例子：
	#include "apue.h"//本书中一些预先定义好的自定义函数以及需要的头文件都在这里。
	#include <netdb.h>
	#include <arpa/inet.h>
	#if defined(BSD) || defined(MACOS)
	#include <sys/socket.h>
	#include <netinet/in.h>
	#endif

	void print_family(struct addrinfo *aip)
	{
	    printf(" family ");
	    switch (aip->ai_family) {
	    case AF_INET:
	        printf("inet");
	        break;
	    case AF_INET6:
	        printf("inet6");
	        break;
	    case AF_UNIX:
	        printf("unix");
	        break;
	    case AF_UNSPEC:
	        printf("unspecified");
	        break;
	    default:
	        printf("unknown");
	    }

	}
	void print_type(struct addrinfo *aip)
	{
	    printf(" type ");
	    switch (aip->ai_socktype) {
	    case SOCK_STREAM:
	        printf("stream");
	        break;
	    case SOCK_DGRAM:
	        printf("datagram");
	        break;
	    case SOCK_SEQPACKET:
	        printf("seqpacket");
	        break;
	    case SOCK_RAW:
	        printf("raw");
	        break;
	    default:
	        printf("unknown (%d)", aip->ai_socktype);
	    }
	}

	void print_protocol(struct addrinfo *aip)
	{
	    printf(" protocol ");
	    switch (aip->ai_protocol) {
	    case 0:
	        printf("default");
	        break;
	    case IPPROTO_TCP:
	        printf("TCP");
	        break;
	    case IPPROTO_UDP:
	        printf("UDP");
	        break;
	    case IPPROTO_RAW:
	        printf("raw");
	        break;
	    default:
	        printf("unknown (%d)", aip->ai_protocol);
	    }
	}

	void print_flags(struct addrinfo *aip)
	{
	    printf("flags");
	    if (aip->ai_flags == 0) {
	        printf(" 0");

	    } else {
	        if (aip->ai_flags & AI_PASSIVE)
	            printf(" passive");
	        if (aip->ai_flags & AI_CANONNAME)
	            printf(" canon");
	        if (aip->ai_flags & AI_NUMERICHOST)
	            printf(" numhost");
	#if defined(AI_NUMERICSERV)
	        if (aip->ai_flags & AI_NUMERICSERV)
	            printf(" numserv");
	#endif
	#if defined(AI_V4MAPPED)
	        if (aip->ai_flags & AI_V4MAPPED)
	            printf(" v4mapped");
	#endif
	#if defined(AI_ALL)
	        if (aip->ai_flags & AI_ALL)
	            printf(" all");
	#endif
	    }
	}
	int main(int argc, char *argv[])
	{
	    struct addrinfo     *ailist, *aip;
	    struct addrinfo     hint;
	    struct sockaddr_in  *sinp;
	    const char          *addr;
	    int                 err;
	    char                abuf[INET_ADDRSTRLEN];

	    if (argc != 3)
	        err_quit("usage: %s nodename service", argv[0]);
	    hint.ai_flags = AI_CANONNAME;
	    hint.ai_family = 0;
	    hint.ai_socktype = 0;
	    hint.ai_protocol = 0;
	    hint.ai_addrlen = 0;
	    hint.ai_canonname = NULL;
	    hint.ai_addr = NULL;
	    hint.ai_next = NULL;
	    if ((err = getaddrinfo(argv[1], argv[2], &hint, &ailist)) != 0)
	        err_quit("getaddrinfo error: %s", gai_strerror(err));
	    for (aip = ailist; aip != NULL; aip = aip->ai_next) {
	        print_flags(aip);
	        print_family(aip);
	        print_type(aip);
	        print_protocol(aip);
	        printf("\n\thost %s", aip->ai_canonname?aip->ai_canonname:"-");
	        if (aip->ai_family == AF_INET) {

	           sinp = (struct sockaddr_in *)aip->ai_addr;
	           addr = inet_ntop(AF_INET, &sinp->sin_addr, abuf,
	               INET_ADDRSTRLEN);
	           printf(" address %s", addr?addr:"unknown");
	           printf(" port %d", ntohs(sinp->sin_port));
	        }
	        printf("\n");
	    }
	    exit(0);
	}

	这个程序列举了getaddrinfo函数的使用。如果这个主机上面有多个协议支持给定的协议，那么程序将会打印更多的条目。在这个例子里，我们只打印工作在IPv4下的协议（ai_family等于AF_INET）的地址信息。如果我们想要限制输出为AF_INET协议族，那么我们应当设置hint中的ai_family成员。
	当我们在某一个系统下面运行这个程序的时候，我们得到如下类似的输出：
	$ ./a.out harry nfs
	flags canon family inet type stream protocol TCP
	 host harry address 192.168.1.105 port 2049
	flags canon family inet type datagram protocol UDP
	 host harry address 192.168.1.105 port 2049

	*将地址和套接字进行关联
	客户的套接字关联的地址并不是重点，我们可以让系统选择一个默认的地址。但是对于一个服务器，我们需要将一个公共的地址和服务器的套接字相关联，这样客户的请求将会到达。客户需要一个方式来发现这个地址，以便连接服务器，最简单的方式就是服务器保存一个地址并且将它注册到/etc/services中或者一个名字管理服务上。
	我们使用bind函数来将一个地址和一个socket相互关联。
	#include <sys/socket.h>
	int bind(int sockfd, const struct sockaddr *addr, socklen_t len);
	返回值：如果成功返回0，如果错误，返回1。
	对于我们能够使用的地址，有一些限制：
	a)我们指定的地址必须对于进程所运行的机器来说是合法的：我们不能指定一个属于其他机器的地址。
	b)地址必须和我们创建套接字时候使用的地址族的格式相匹配。
	c)地址中的端口号码，不能小于1024，除非进程具有特殊的权限（也就是，超级用户权限）。
	d)尽管有些协议支持多个绑定，一般来说也只有一个套接字端绑定到一个给定的地址上面。
	对于因特网域，如果我们指定特殊的IP地址（INADDR_ANY），套接字端将会被绑定到系统所有的网络接口上面。这也就是说，我们可以接收任何来自安装到系统上面的网络接口卡上面的包。我们在后面将会看到，如果我们调用connect或者listen的时候没有将地址绑定到socket上面，那么系统将会选择一个地址，并且把它绑定到我们的套接字上。

	我们可以使用getsockname函数来获取绑定到一个套接字上面的地址。
	#include <sys/socket.h>
	int getsockname(int sockfd, struct sockaddr *restrict addr, socklen_t *restrict alenp);
	返回：如果成功返回0，如果错误返回1。
	在调用getsockname之前，我们将alenp设置为指向一个整数，整数的内容包含sockaddr结构的缓存的大小。在返回的时候，整数被设置成返回的地址的大小。如果地址不适合提供的缓存，那么地址会被截断。如果当前没有地址绑定在套接字上面，那么结果是不确定的。

	如果套接字被连接到了一个对等的节点上面，我们可以通过调用getpeername函数来获得对等节点的地址。
	#include <sys/socket.h>
	int getpeername(int sockfd, struct sockaddr *restrict addr, socklen_t *restrict alenp);
	返回：如果成功返回0，如果错误返回1。
	除了返回一个对等节点的地址之外，getpeername函数和getsockname函数都一样。

	4)建立连接
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec4.html
	如果我们处理一个面向连接的网络服务（SOCK_STREAM或者SOCK_SEQPACKET），那么在我们可以交换数据之前，我们需要创建一个连接，这个连接在请求服务的进程的套接字（客户端）以及提供服务的进程（服务端）之间建立。我们使用connect函数创建一个连接。
	#include <sys/socket.h>
	int connect(int sockfd, const struct sockaddr *addr, socklen_t len);
	返回：如果成功返回0，如果错误返回1。
	我们使用connect函数指定的地址，是我们想要通信的服务器的地址。如果sockfd没有绑定到一个地址上面，那么connect将会为调用者绑定到一个默认的地址上面。
	当我们尝试连接到一个服务器的时候，连接的请求可能会因为一些原因而失败。我们尝试连接的机器必须是启动并且是运行的。服务必须被绑定到我们尝试连接的地址上面，并且服务器的提交连接队列中也必须要有空间（我们会在后面简单对此进行介绍）。因此，应用程序必须能够处理由于临时的条件引起的连接错误的返回。

	例子
	下面的例子给处了一个处理临时连接错误的一个方法。这个在一个负载很高的服务器上面很容易发生。
	#include "apue.h"//一些必要的自定义函数和文件的包含
	#include <sys/socket.h>
	#define MAXSLEEP 128
	int connect_retry(int sockfd, const struct sockaddr *addr, socklen_t alen)
	{
	    int nsec;

	    /*
	     * 尝试使用指数回退方法进行连接。
	     */
	    for (nsec = 1; nsec <= MAXSLEEP; nsec <<= 1) {
	        if (connect(sockfd, addr, alen) == 0) {
	            /*
	             * 接受连接。
	             */
	            return(0);
	        }

	        /*
	         * 再次尝试连接之前的延迟。
	         */
	        if (nsec <= MAXSLEEP/2)
	            sleep(nsec);
	    }
	    return(-1);
	}
	这个函数展示了一种叫做指数回退的算法。如果调用connect失败了，那么进程会进入睡眠一小段时间，然后继续尝试，同时会在每次循环的时候增加延迟时间，一直增加到2分钟。

	如果套接字是非阻塞模式，那么在无法建立连接的时候connect将会返回，并且设置errno为EINPROGRESS。应用程序可以使用pool或者select来确定哪个文件描述符可写。这个时候，连接完成。
	connect函数也可以用做无连接的网络服务（ SOCK_DGRAM）。这看起来似乎有点冲突，但是实际上是一种优化。如果我们使用SOCK_DGRAM套接字调用connect，那么我们发送的所有消息的目标地址被设置成我们在connect调用中的地址，这样我们就不用在每次发送消息的时候都提供一个地址了。另外，我们将会只从我们指定的地址处接收数据报。

	服务器通过调用listen函数来准备接收connect请求。
	#include <sys/socket.h>
	int listen(int sockfd, int backlog);
	返回：如果成功返回0，如果错误返回1。

	参数backlog给系统提供了一个提示，提示代表进程要排队的没有完成的连接请求的数目。实际的值取决与系统，但是上限通过<sys/socket.h>中的SOMAXCONN来进行指定。
	在Solaris中<sys/socket.h>中的SOMAXCONN值被忽略。特定的最大值取决于系统的实现。对于TCP来说，默认的值为128。
	当队列满的时候，系统将会拒绝额外的connect请求。所以，backlog值必须基于期望的服务器负载以及接受连接请求并启动服务的进程的数目。

	当服务进程调用listen的时候，使用的套接字可以接受连接请求。我们使用accept函数来接收连接请求，然后将它转化成一个连接。
	#include <sys/socket.h>
	int accept(int sockfd, struct sockaddr *restrict addr, socklen_t *restrict len);
	返回：如果成功返回套接字文件描述符号，如果失败返回错误。
	accept函数返回一个套接字文件描述符号，这个文件描述符号连接到客户服务进程，被称作一个连接。新的套接字描述符号具有和原始套接字(sockfd)同样的套接字类型以及地址族。传递给accept函数的原始套接字并不和连接有关联，但是仍然可以接收额外的连接请求。
	如果我们不关心客户端是什么，那么我们可以设置addr和len参数为NULL。否则，在调用accept之前，我们需要设置addr参数为一个足够大的可以容纳地址的缓存，同时设置参数len（一个整数指针）为一个整数的地址。返回的时候，accept将会填充客户的地址到缓存，同时更新整数指针所指向的整数以反应地址的大小。
	如果没有提交连接请求，那么accept将会阻塞直到来到一个连接请求。如果sockfd是非阻塞的模式，那么accept将会返回1并且设置errno为EAGAIN或者EWOULDBLOCk。
	本文中讨论的所有的四个平台将EAGAIN定义为和EWOULDBLOCK一样。
	如果一个服务进程调用accept并且目前没有连接请求，这个时候服务进程将会阻塞直到一个请求来到。另外，服务进程也可以使用poll或者select来等待连接请求的到来，这个时候一个具有提交连接请求的套接字将会可读。

	例子
	下面的代码展示了一个我们可以使用的函数分配和初始化一个服务进程使用的套接字。
	我们将会看到TCP对于地址重新利用有一些奇怪的规则，使得这个例子不够完整。后面会给出通过了这些规则的解决本版本的主要问题的这个函数。

	初始化服务进程使用的套接字端
	#include "apue.h"
	#include <errno.h>
	#include <sys/socket.h>
	int initserver(int type, const struct sockaddr *addr, socklen_t alen, int qlen)
	{
	    int fd;
	    int err = 0;

	    if ((fd = socket(addr->sa_family, type, 0)) < 0)
	        return(-1);
	    if (bind(fd, addr, alen) < 0) {
	        err = errno;
	        goto errout;
	    }
	    if (type == SOCK_STREAM || type == SOCK_SEQPACKET) {
	        if (listen(fd, qlen) < 0) {
	            err = errno;
	            goto errout;
	        }
	    }
	    return(fd);

	errout:
	    close(fd);
	    errno = err;
	    return(-1);
	}

	5)数据传输
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec5.html
	由于socket末端使用文件描述符号来替代，当被连接起来的时候，我们就可以使用read和write来和socket进行通信了。需要记住的是如果我们使用connect函数的时候设置了默认的通信对等端，那么数据报的socket可以被认为是连接好了的。使用read和write与套接字描述符号进行通信是非常有意义的，因为它以为着我们可以把套接字描述符号传递给本来是用来操作本地文件的函数。我们也可以把套接字描述符号传递给子进程，子进程执行exec另外一个程序而那个程序却不用知道关于套接字的信息。
	尽管我们能够使用read和write交换数据，但是这也只是我们使用这两个函数所能做的所有的事情了。如果我们想要指定选项，从多个客户端接受包，或者发送带外的数据，我们需要使用六个特定的sockt函数来进行数据传输。

	有三个函数用来发送数据，同时也有三个函数用来接收数据。首先我们来看看发送数据的函数。
	最简单的就是send，它和write的功能类似，但是允许我们指定标记来改变我们看待被传输的数据的方式。
	#include <sys/socket.h>
	ssize_t send(int sockfd, const void *buf, size_t nbytes, int flags);
	返回：如果成功那么返回发送的字节数目，如果错误则返回1。
	和write类似，套接字使用send的时候需要被连接。buf和nbytes参数和write中相应的参数的含义一样。
	和write不同的是，send支持第四个参数flags。Single UNIX Specification定义了两个参数，但是一般实现都会定义一些额外的参数。大致如下面列出的，具体哪个系统支持，请参见参考资料，详细这里就不一一列举了。
	MSG_DONTROUTE 不在本地网络之外对包进行路由。
	MSG_DONTWAIT 打开非阻塞操作（与使用O_NONBLOCK等价）。
	MSG_EOR 如果协议支持，那么这个表示记录的结尾。
	MSG_OOB 如果协议支持，那么发送带外数据。
	如果send返回成功，并不意味这另一端的进程接收到了数据。所有我们能够保证的只是：当send成功的时候，数据被发送到网络中了，并且没有错误。
	对于一个支持消息边界的协议，如果我们尝试发送一个单个的消息，这个消息的大小比协议支持的最大大小要大，那么send将会返回失败并且设置errno为EMSGSIZE。对于一个字节流协议，send将会阻塞，直到整个数据都被传输完毕。

	sendto函数和send函数类似。不同的是，sendto允许我们指定一个无连接套接字使用的目标地址。
	#include <sys/socket.h>
	ssize_t sendto(int sockfd, const void *buf, size_t nbytes, int flags, const struct sockaddr *destaddr,
					 socklen_t destlen);
	返回：如果成功返回字节数目，如果错误返回1。
	使用面向连接的套接字，目标地址被忽略，因为目标已经隐含在了连接中。使用无连接的套接字，如果我们不首先通过connect函数设置目标地址，那么我们就无法使用send发送，所以sendto函数给了我们一个可以选择的方法来发送消息。

	我们有不只一种方法通过套接字传输数据。我们可以调用sendmsg，通过msghdr结构指定用来传输数据的多个缓存，这个和使用writev函数有点类似。
	#include <sys/socket.h>
	ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
	返回：如果成功，返回发送的字节数目，如果错误返回1。
	POSIX.1定义msghdr结构至少包含如下成员：
	struct msghdr {
		void          *msg_name;         /* optional address */
		socklen_t      msg_namelen;      /* address size in bytes */
		struct iovec  *msg_iov;          /* array of I/O buffers */
		int            msg_iovlen;       /* number of elements in array */
		void          *msg_control;      /* ancillary data */
		socklen_t      msg_controllen;   /* number of ancillary bytes */
		int            msg_flags;        /* flags for received message */
		.
		.
		.
	};
	对于msg_iov成员，我们前面看见过iovec结构，我们将在后面看到辅助数据的使用。

	函数recv和read函数类似，但是允许我们指定一些如何接收数据的控制选项。
	#include <sys/socket.h>
	ssize_t recv(int sockfd, void *buf, size_t nbytes, int flags);
	返回：返回消息的字节长度，如果没有消息返回0并且对等端做顺序的shutdown(???)，或者如果错误返回1。
	传递给recv的flags参数通过一个表格的形式进行列出，其中只有三个是Single UNIX Specification定义的。这里只给出一个大致的列举，具体那个实现支持它们，请参见参考资料。
	┌─────────────┬─────────────────────────────────────────────────┬
	│    Flag     │                   Description                   │
	│             │                                                 │
	├─────────────┼─────────────────────────────────────────────────┼
	│ MSG_OOB     │ 如果协议支持，那么获取带外数据。                │
	├─────────────┼─────────────────────────────────────────────────┼
	│ MSG_PEEK    │ 返回包内容但是不会消耗包。                      │
	├─────────────┼─────────────────────────────────────────────────┼
	│ MSG_TRUNC   │ 返回一个包的实际长度，即使它被截断了。          │
	├─────────────┼─────────────────────────────────────────────────┼
	│ MSG_WAITALL │ 等待，直到所有数据可用(只对SOCK_STREAM)         │
	└─────────────┴─────────────────────────────────────────────────┴
	当我们指定MSG_PEEK标记的时候，我们可以查看下一次将要读取的数据而不用消耗实际的数据（也就是说数据不会在被看到之后被清除掉）。下次调用read或者recv相关的函数的时候，将会返回我们这里查看到的数据。
	通过使用SOCK_STREAM套接字，我们可以接收比我们请求少的数据。MSG_WAITALL标记会阻止这个现象发生，不让recv返回直至所有请求的数据被接收到。对于SOCK_DGRAM和SOCK_SEQPACKET套接字，MSG_WAITALL标记对它们的行为没有区别，因为这些基于消息的套接字类型在单个读取的时候已经返回了整个的消息。
	如果发送者调用了shutdown函数来结束数据的传输，或者如果网络协议默认支持依次shutdown并且发送者关闭了套接字，那么recv将会在我们已经接收到所有的数据的时候返回0。

	如果我们对发送者是谁很感兴趣，那么我们可以使用recvfrom来获得数据得以发送的源地址。
	#include <sys/socket.h>
	ssize_t recvfrom(int sockfd, void *restrict buf, size_t len, int flags, struct sockaddr *restrict addr,
	                 socklen_t *restrict addrlen);
	返回：会返回消息的字节长度，如果没有消息返回0并且对等端会顺序调用shutdown，或者如果错误返回1。
	如果addr参数非空，它将会包含发送数据所来自的套接字末端地址。当调用recvfrom的时候，我们需要设置addrlen参数指向一个整数，这个整数用来包含addr参数所指向的套接字缓存的字节大小。当返回的时候，这个整数会被设置成实际字节的大小。
	因为通过这个函数我们可以获取发送者的地址，recvfrom实际和无连接的套接字一块使用。否则，recvfrom表现的行为和recv一样。

	和readv类似地如果想要接收数据到多个缓存，或者我们想要接收辅助的数据，我们可以使用recvmsg。
	#include <sys/socket.h>
	ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);
	返回：消息的字节长度，如果没有消息返回0并且对等端允许调用shutdown，或者如果错误返回1。
	recvmsg函数使用msghdr结构（我们看到sendmsg中使用了）指定接收数据的输入缓存。我们可以设置flags参数来更改默认的recvmsg行为。返回的时候，msghdr结构的msg_flags成员会被设置，以表示接收数据的各种特性(msg_flags成员在进入recvmsg的时候被忽略)。对于recvmsg返回的可能值，在下面的表格中列出来了。后面会对recvmsg函数的使用举一个例子。
	┌──────────────┬────────────────────────────────────┬
	│     Flag     │            Description             │
	│              │                                    │
	├──────────────┼────────────────────────────────────┼
	│ MSG_CTRUNC   │ 控制数据被截断。                   │
	├──────────────┼────────────────────────────────────┼
	│ MSG_DONTWAIT │ recvmsg 以一种非阻塞的模式被调用。 │
	├──────────────┼────────────────────────────────────┼
	│ MSG_EOR      │ 返回接收的记录结尾。               │
	├──────────────┼────────────────────────────────────┼
	│ MSG_OOB      │ 接收带外数据。                     │
	├──────────────┼────────────────────────────────────┼
	│ MSG_TRUNC    │ 截断正常数据。                     │
	└──────────────┴────────────────────────────────────┴


	*面向连接的客户端的例子
	下面的程序，显示了一个客户的命令，这个命令和服务进行通信，从系统的uptime命令获取输出。我们将这个服务称作"remote uptime"(或简称"ruptime")。
	这个程序连接服务器，读取服务器发送的字符串，然后打印字符串到标准输出。因为我们使用SOCK_STREAM套接字，我们不能保证我们会在一个recv调用中读取整个字符串，所以我们使用一个循环进行调用，直到它返回0。
	#include <netdb.h>
	#include <errno.h>
	#include <sys/socket.h>
	#define MAXADDRLEN  256
	#define BUFLEN      128
	extern int connect_retry(int, const struct sockaddr *, socklen_t);
	void print_uptime(int sockfd)
	{
	    int     n;
	    char    buf[BUFLEN];

	    while ((n = recv(sockfd, buf, BUFLEN, 0)) > 0)
	        write(STDOUT_FILENO, buf, n);
	    if (n < 0)
	        err_sys("recv error");
	}

	int main(int argc, char *argv[])
	{
	    struct addrinfo *ailist, *aip;
	    struct addrinfo hint;
	    int             sockfd, err;

	    if (argc != 2)
	        err_quit("usage: ruptime hostname");
	    hint.ai_flags = 0;
	    hint.ai_family = 0;
	    hint.ai_socktype = SOCK_STREAM;
	    hint.ai_protocol = 0;
	    hint.ai_addrlen = 0;
	    hint.ai_canonname = NULL;
	    hint.ai_addr = NULL;
	    hint.ai_next = NULL;
	    if ((err = getaddrinfo(argv[1], "ruptime", &hint, &ailist)) != 0)
	        err_quit("getaddrinfo error: %s", gai_strerror(err));
	    for (aip = ailist; aip != NULL; aip = aip->ai_next) {
	        if ((sockfd = socket(aip->ai_family, SOCK_STREAM, 0)) < 0)
	            err = errno;
	        if (connect_retry(sockfd, aip->ai_addr, aip->ai_addrlen) < 0) {
	            err = errno;
	        } else {
	            print_uptime(sockfd);
	            exit(0);
	        }
	    }
	    fprintf(stderr, "can't connect to %s: %s\n", argv[1],
	      strerror(err));
	    exit(1);
	}

	如果服务进程支持多个网络接口或者多个网络协议，getaddrinfo函数可能返回多个候选地址。我们一次对每个进行尝试，当找到一个允许我们连接的服务的时候为止。我们使用前面自定义的connect_retry函数来建立和服务器之间的连接。

	*面向连接的服务端的例子
	下面的程序给出了提供前面客户端的uptime的服务输出程序。
	#include <netdb.h>
	#include <errno.h>
	#include <syslog.h>
	#include <sys/socket.h>

	#define BUFLEN  128
	#define QLEN 10

	#ifndef HOST_NAME_MAX
	#define HOST_NAME_MAX 256
	#endif

	extern int initserver(int, struct sockaddr *, socklen_t, int);

	void serve(int sockfd)
	{
	    int     clfd;
	    FILE    *fp;
	    char    buf[BUFLEN];

	    for (;;) {
	        clfd = accept(sockfd, NULL, NULL);
	        if (clfd < 0) {
	            syslog(LOG_ERR, "ruptimed: accept error: %s",
	              strerror(errno));
	            exit(1);
	        }
	        if ((fp = popen("/usr/bin/uptime", "r")) == NULL) {
	            sprintf(buf, "error: %s\n", strerror(errno));
	            send(clfd, buf, strlen(buf), 0);
	        } else {
	            while (fgets(buf, BUFLEN, fp) != NULL)
	                send(clfd, buf, strlen(buf), 0);
	            pclose(fp);
	        }
	        close(clfd);
	    }
	}

	int main(int argc, char *argv[])
	{
	    struct addrinfo *ailist, *aip;
	    struct addrinfo hint;
	    int             sockfd, err, n;
	    char            *host;

	    if (argc != 1)
	        err_quit("usage: ruptimed");
	#ifdef _SC_HOST_NAME_MAX
	    n = sysconf(_SC_HOST_NAME_MAX);
	    if (n < 0)  /* best guess */
	#endif
	        n = HOST_NAME_MAX;
	    host = malloc(n);
	    if (host == NULL)
	        err_sys("malloc error");
	    if (gethostname(host, n) < 0)
	        err_sys("gethostname error");
	    daemonize("ruptimed");
	    hint.ai_flags = AI_CANONNAME;
	    hint.ai_family = 0;
	    hint.ai_socktype = SOCK_STREAM;
	    hint.ai_protocol = 0;
	    hint.ai_addrlen = 0;
	    hint.ai_canonname = NULL;
	    hint.ai_addr = NULL;
	    hint.ai_next = NULL;
	    if ((err = getaddrinfo(host, "ruptime", &hint, &ailist)) != 0) {
	        syslog(LOG_ERR, "ruptimed: getaddrinfo error: %s",
	          gai_strerror(err));
	        exit(1);
	    }
	    for (aip = ailist; aip != NULL; aip = aip->ai_next) {
	        if ((sockfd = initserver(SOCK_STREAM, aip->ai_addr,
	          aip->ai_addrlen, QLEN)) >= 0) {
	            serve(sockfd);
	            exit(0);
	        }
	    }
	    exit(1);
	}

	为了获取地址，服务进程需要获取它所运行的主机的名称。有些系统没有定义_SC_HOST_NAME_MAX常量，所以我们使用HOST_NAME_MAX。如果系统没有定义HOST_NAME_MAX那么我们自己定义它。POSIX.1指明了主机名称的最小值为255字节（不包含结束符号），所以我们定义HOST_NAME_MAX为256字节以便能够包含结束符号。
	服务进程调用gethostname来得到主机的名称，同时查看用于remote uptime服务的地址。可能会返回多个地址，但是我们只是选择第一个来建立套接字末端。
	我们使用前面自己定义的initserver函数来初始化等待连接请求到达处的套接字末端（实际上，我们使用另外一个版本，具体还是参见参考资料吧）。

	例子：另外一个可选的面向连接的服务进程
	之前我们说过使用文件描述符号可以访问套接字，这一点非常重要，因为这样程序在网络环境下不用了解关于网络相关的信息。下面的程序就展示了这一点。不是读取uptime命令的标准输出并且将它发送到客户端，而是服务进程让uptime命令的标准输出和标准错误输出变成连接到客户端的套接字。
	#include <netdb.h>
	#include <errno.h>
	#include <syslog.h>
	#include <fcntl.h>
	#include <sys/socket.h>
	#include <sys/wait.h>

	#define QLEN 10

	#ifndef HOST_NAME_MAX
	#define HOST_NAME_MAX 256
	#endif

	extern int initserver(int, struct sockaddr *, socklen_t, int);

	void serve(int sockfd)
	{
	    int     clfd, status;
	    pid_t   pid;

	    for (;;) {
	        clfd = accept(sockfd, NULL, NULL);
	        if (clfd < 0) {
	            syslog(LOG_ERR, "ruptimed: accept error: %s",
	              strerror(errno));
	            exit(1);
	        }
	        if ((pid = fork()) < 0) {
	            syslog(LOG_ERR, "ruptimed: fork error: %s",
	              strerror(errno));
	            exit(1);
	        } else if (pid == 0) {  /* 子进程 */
	            /* 父进程调用daemonize函数，这样STDIN_FILENO，STDOUT_FILENO，和STDERR_FILENO被打开到/dev/null。
	             * 因此，不需要通过检查clfd是否等于这些值之一来对调用close进行保护。
	             */
	            if (dup2(clfd, STDOUT_FILENO) != STDOUT_FILENO ||
	              dup2(clfd, STDERR_FILENO) != STDERR_FILENO) {
	                syslog(LOG_ERR, "ruptimed: unexpected error");
	                exit(1);
	            }
	            close(clfd);
	            execl("/usr/bin/uptime", "uptime", (char *)0);
	            syslog(LOG_ERR, "ruptimed: unexpected return from exec: %s",
	              strerror(errno));
	        } else {        /* 父进程 */
	            close(clfd);
	            waitpid(pid, &status, 0);
	        }
	    }
	}

	int main(int argc, char *argv[])
	{
	    struct addrinfo *ailist, *aip;
	    struct addrinfo hint;
	    int             sockfd, err, n;
	    char            *host;

	    if (argc != 1)
	        err_quit("usage: ruptimed");
	#ifdef _SC_HOST_NAME_MAX
	    n = sysconf(_SC_HOST_NAME_MAX);
	    if (n < 0)  /* best guess */
	#endif
	        n = HOST_NAME_MAX;
	    host = malloc(n);
	    if (host == NULL)
	        err_sys("malloc error");
	    if (gethostname(host, n) < 0)
	        err_sys("gethostname error");
	    daemonize("ruptimed");
	    hint.ai_flags = AI_CANONNAME;
	    hint.ai_family = 0;
	    hint.ai_socktype = SOCK_STREAM;
	    hint.ai_protocol = 0;
	    hint.ai_addrlen = 0;
	    hint.ai_canonname = NULL;
	    hint.ai_addr = NULL;
	    hint.ai_next = NULL;
	    if ((err = getaddrinfo(host, "ruptime", &hint, &ailist)) != 0) {
	        syslog(LOG_ERR, "ruptimed: getaddrinfo error: %s",
	          gai_strerror(err));
	        exit(1);
	    }
	    for (aip = ailist; aip != NULL; aip = aip->ai_next) {
	        if ((sockfd = initserver(SOCK_STREAM, aip->ai_addr,
	          aip->ai_addrlen, QLEN)) >= 0) {
	            serve(sockfd);
	            exit(0);
	        }
	    }
	    exit(1);
	}


	不是使用popen来运行uptime命令以及从连接到命令标准输出的管道上面读取输出，我们使用fork创建子进程并且之后使用dup2来让子进程的STDIN_FILENO打开到/dev/null，STDOUT_FILENO和STDERR_FILENO打开到套接字的末端。当我们执行uptime命令的时候，命令向标准输出写，因为标准输出连接到了套接字，数据会被发送会ruptime的客户端命令。
	父进程可以安全地关闭连接到客户端的文件描述符号，因为子进程仍旧打开着它。父进程在继续之前等待子进程完成，这样子进程不会变成僵尸进程。因为uptime命令不会占用太多的时间，所以父进程可以在接收下一条请求之前等待字进程退出。但是如果子进程执行过长的时间的化，可能这个方法就不那么好用了。
	前面的例子使用的是面向连接的套接字。但是我们如何选择合适的类型？什么时候我们使用面向连接的套接字，什么时候我们使用无连接的套接字？这个打开取决于我们需要做多少工作以及我们可以容忍多少的错误。
	对于一个无连接的套接字，对数据包到达的次序没有太多的要求，所以如果我们不能将我们所有的数据放到一个包中，我们就需要考虑次序的问题，包的最大长度是通信协议的特性。另外，对于无连接的套接字，可能会出现丢包的情况。如果我们的应用程序不能容忍丢包的情况，那么我们应该使用面向连接的套接字。
	容忍包的丢失以为着我们可以有两个选择。如果我们使用可靠的通信方式，那么我们需要给我们的包进行编号，当我们检测到包的丢失的时候可以请求重新传送。由于一个包可能会延迟导致好象是丢失了，但是在我们再次请求传输的时候又出现了，所以我们也应当可以辨别重复的包然后忽略它们。
	另外一个选择就是我们可以重新尝试命令来处理错误。对于一个简单的应用程序，这个就足够了，但是对于一个复杂的应用程序，它并不一定可行。所以，一般来说这时候我们最好使用面向连接的套接字服务。
	使用面向连接的套接字的缺点就是，我们在建立连接的时候需要做更多的工作和时间，并且每个连接都会消耗更多的操作系统资源。

	无连接客户的例子
	下面的程序就是使用数据包接口的uptime客户端程序。
	#include <netdb.h>
	#include <errno.h>
	#include <sys/socket.h>

	#define BUFLEN      128
	#define TIMEOUT     20

	void sigalrm(int signo)
	{
	}

	void print_uptime(int sockfd, struct addrinfo *aip)
	{
	    int     n;
	    char    buf[BUFLEN];

	    buf[0] = 0;
	    if (sendto(sockfd, buf, 1, 0, aip->ai_addr, aip->ai_addrlen) < 0)
	        err_sys("sendto error");
	    alarm(TIMEOUT);
	    if ((n = recvfrom(sockfd, buf, BUFLEN, 0, NULL, NULL)) < 0) {
	        if (errno != EINTR)
	            alarm(0);
	        err_sys("recv error");
	    }
	    alarm(0);
	    write(STDOUT_FILENO, buf, n);
	}
	int main(int argc, char *argv[])
	{
	    struct addrinfo     *ailist, *aip;
	    struct addrinfo      hint;
	    int                  sockfd, err;
	    struct sigaction     sa;

	    if (argc != 2)
	        err_quit("usage: ruptime hostname");
	    sa.sa_handler = sigalrm;
	    sa.sa_flags = 0;
	    sigemptyset(&sa.sa_mask);
	    if (sigaction(SIGALRM, &sa, NULL) < 0)
	        err_sys("sigaction error");
	    hint.ai_flags = 0;
	    hint.ai_family = 0;
	    hint.ai_socktype = SOCK_DGRAM;
	    hint.ai_protocol = 0;
	    hint.ai_addrlen = 0;
	    hint.ai_canonname = NULL;
	    hint.ai_addr = NULL;
	    hint.ai_next = NULL;
	    if ((err = getaddrinfo(argv[1], "ruptime", &hint, &ailist)) != 0)
	        err_quit("getaddrinfo error: %s", gai_strerror(err));

	    for (aip = ailist; aip != NULL; aip = aip->ai_next) {
	        if ((sockfd = socket(aip->ai_family, SOCK_DGRAM, 0)) < 0) {
	            err = errno;
	        } else {
	            print_uptime(sockfd, aip);
	            exit(0);
	        }
	     }

	     fprintf(stderr, "can't contact %s: %s\n", argv[1], strerror(err));
	     exit(1);
	}
	基于数据包的客户端的main函数和面向连接的客户端类似，只是安装了一个SIGALARM的信号处理函数。我们使用alarm函数防止recvfrom函数调用导致无限的阻塞。
	使用面向连接的协议，我们需要在交换数据之前连接到服务端。这个连接请求就已经足够让服务端确定它需要给客户提供什么样子的服务。但是，在基于数据包的协议中，我们需要一个方法来通知服务端我们需要它为我们提供服务。在这个例子中，我们只是简单地给服务端发送一个一个字节长度的消息，服务端可以接收到它，从数据包中获得我们的地址，然后使用这个地址来发送相应信息。如果服务端提供了多个服务，我们使用这个请求消息来识别我们需要的服务，但是由于服务端只做一件事情，这一个字节消息的内容无关紧要。
	如果服务端没有运行，客户端将会在调用recvfrom的地方无限阻塞下去。在面向连接的例子里面，connect调用将会在服务端没有运行的时候调用失败。为了避免无限的阻塞，我们在调用recvfrom之前设置alarm。

	无连接服务的例子
	下面的程序是数据报版本的uptime服务的例子。

	通过数据报提供系统uptime的server
	#include "apue.h"
	#include <netdb.h>
	#include <errno.h>
	#include <syslog.h>
	#include <sys/socket.h>

	#define BUFLEN      128
	#define MAXADDRLEN  256

	#ifndef HOST_NAME_MAX
	#define HOST_NAME_MAX 256
	#endif

	extern int initserver(int, struct sockaddr *, socklen_t, int);

	void serve(int sockfd)
	{
	    int         n;
	    socklen_t   alen;
	    FILE        *fp;
	    char        buf[BUFLEN];
	    char        abuf[MAXADDRLEN];

	    for (;;) {
	        alen = MAXADDRLEN;
	        if ((n = recvfrom(sockfd, buf, BUFLEN, 0, (struct sockaddr *)abuf, &alen)) < 0) {
	            syslog(LOG_ERR, "ruptimed: recvfrom error: %s", strerror(errno));
	            exit(1);
	        }
	        if ((fp = popen("/usr/bin/uptime", "r")) == NULL) {
	            sprintf(buf, "error: %s\n", strerror(errno));
	            sendto(sockfd, buf, strlen(buf), 0, (struct sockaddr *)abuf, alen);
	        } else {
	            if (fgets(buf, BUFLEN, fp) != NULL)
	                sendto(sockfd, buf, strlen(buf), 0, (struct sockaddr *)abuf, alen);
	            pclose(fp);
	        }

	    }

	}

	int main(int argc, char *argv[])
	{
	    struct addrinfo *ailist, *aip;
	    struct addrinfo hint;
	    int             sockfd, err, n;
	    char            *host;

	    if (argc != 1)
	        err_quit("usage: ruptimed");
	#ifdef _SC_HOST_NAME_MAX
	    n = sysconf(_SC_HOST_NAME_MAX);
	    if (n < 0)  /* best guess */
	#endif
	        n = HOST_NAME_MAX;
	    host = malloc(n);
	    if (host == NULL)
	        err_sys("malloc error");
	    if (gethostname(host, n) < 0)
	        err_sys("gethostname error");
	    daemonize("ruptimed");
	    hint.ai_flags = AI_CANONNAME;
	    hint.ai_family = 0;
	    hint.ai_socktype = SOCK_DGRAM;
	    hint.ai_protocol = 0;
	    hint.ai_addrlen = 0;
	    hint.ai_canonname = NULL;
	    hint.ai_addr = NULL;
	    hint.ai_next = NULL;
	    if ((err = getaddrinfo(host, "ruptime", &hint, &ailist)) != 0) {
	        syslog(LOG_ERR, "ruptimed: getaddrinfo error: %s",
	          gai_strerror(err));
	        exit(1);
	    }
	    for (aip = ailist; aip != NULL; aip = aip->ai_next) {
	        if ((sockfd = initserver(SOCK_DGRAM, aip->ai_addr,
	          aip->ai_addrlen, 0)) >= 0) {
	            serve(sockfd);
	            exit(0);
	        }
	    }
	    exit(1);
	}
	服务端阻塞在recvfrom等待服务请求，当一个请求到来的时候，我们保存请求的地址并且使用popen来执行uptime命令。我们使用sendto函数将输出发送回客户端，这时候的目标地址是被设置成了请求者的地址。

	6)套接字选项
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec6.html
	套接字机制提供了两个套接字选项接口来控制套接字的行为。一个接口用来设置选项，另外一个接口用来允许我们请求选项的状态。我们可以获得以及设置三种类型的选项。
	1.通用选项，可以工作在所有的套接字类型。
	2.在套接字层次上面进行管理的选项，但是依赖底部协议的支持。
	3.和每个协议相关的协议选项。
	Single UNIX Specification 只定义了套接字层的选项（上面所提到的前面两项）

	我们可以通过setsockopt函数来设置套接字选项。
	#include <sys/socket.h>
	int setsockopt(int sockfd, int level, int option, const void *val, socklen_t len);
	返回：如果成功返回0，如果错误返回1。
	参数level用来分辨option所应用的协议。如果option是通用套接字层次的选项，那么level设置成SOL_SOCKET。否则level设置成控制option的协议号。例如IPPROTO_TCP用于TCP选项，以及IPPROTO_IP用于IP选项。下面的表中就列出了Single UNIX Specification定义的通用的套接字层次的选项。
	┌───────────────┬──────────────────────┬─────────────────────────────────────────────────────┐
	│    Option     │ Type of val argument │                             Description             │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_ACCEPTCONN │ int                  │ 返回套接字是否激活用于侦听（只用于getsockopt）。    │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_BROADCAST  │ int                  │ 如果*val非0那么广播数据报。                         │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_DEBUG      │ int                  │ 如果*val非0那么激活网络驱动的调试。                 │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_DONTROUTE  │ int                  │ 如果*val非0，那么忽略通常的路由。                   │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_ERROR      │ int                  │ 返回并且清除提交的套接字错误（只用于getsockopt）。  │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_KEEPALIVE  │ int                  │ 如果*val非0，那么激活定期活动的消息。               │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_LINGER     │ struct linger        │ 如果有未发送的消息存在以及套接字关闭，那么做延迟。  │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_OOBINLINE  │ int                  │ 如果*val非0，那么将带外数据嵌入到正常数据中。       │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_RCVBUF     │ int                  │ 接收缓存的字节大小。                                │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_RCVLOWAT   │ int                  │ receive调用返回的最小数据字节。                     │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_RCVTIMEO   │ struct timeval       │ 套接字receive调用的超时值。                         │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_REUSEADDR  │ int                  │ 如果*val非0，那么重复使用bind的地址。               │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_SNDBUF     │ int                  │ send缓存中的字节大小。                              │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_SNDLOWAT   │ int                  │ 一次send调用传输的最小数据字节量。                  │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_SNDTIMEO   │ struct timeval       │ 一个套接字send调用的超时值。                        │
	├───────────────┼──────────────────────┼─────────────────────────────────────────────────────┤
	│ SO_TYPE       │ int                  │ 辨别套接字类型（只在getsockopt中）。                │
	└───────────────┴──────────────────────┴─────────────────────────────────────────────────────┘
	参数val指向一个数据结构或者整数，这取决于option。有些选项是on/off开关。 如果这个整数非0，那么option被激活。如果这个整数是0，那么option不被激活。len参数指定val指向的对象的大小。

	我们可以通过函数getsockopt来获取当前option的值。
	#include <sys/socket.h>
	int getsockopt(int sockfd, int level, int option, void *restrict val, socklen_t *restrict lenp);
	返回：如果成功返回0，如果错误返回1。
	注意lenp参数是一个指向整数的指针。在调用getsockopt之前，我们设置整数为option被拷贝的缓存的大小，如果实际的option大小比这个大小大，那么option就会被截断。如果实际的option大小比size小或者同样大，那么整数会在返回的时候被更新成实际的大小。

	例子
	前面的(initserver)函数当服务进程终止的时候操作失败，然后我们尝试立即重新启动。一般来说，TCP的实现会会阻止我们将同样一个地址绑定，除非超时。SO_REUSEADDR的套接字选项允许我们忽略这个限制，下面的代码就展示了这个特性。

	为了激活SO_REUSEADDR选项，我们设置整数为一个非0的值然后将整数的地址做为val参数传递给setsockopt函数。我们设置len参数为一个表示整数的大小，来表示val所指向的对象的大小。

	服务进程使用地址重用初始化一个将要被使用的套接字末端
	#include "apue.h"
	#include <errno.h>
	#include <sys/socket.h>
	int initserver(int type, const struct sockaddr *addr, socklen_t alen, int qlen)
	{
	    int fd, err;
	    int reuse = 1;

	    if ((fd = socket(addr->sa_family, type, 0)) < 0)
	        return(-1);
	    if (setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &reuse, sizeof(int)) < 0) {
	        err = errno;
	        goto errout;
	    }
	    if (bind(fd, addr, alen) < 0) {
	        err = errno;
	        goto errout;
	    }
	    if (type == SOCK_STREAM || type == SOCK_SEQPACKET) {
	        if (listen(fd, qlen) < 0) {
	            err = errno;
	            goto errout;
	        }
	    }
	    return(fd);

	errout:
	    close(fd);
	    errno = err;
	    return(-1);
	}

	7)带外数据
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec7.html
	带外数据是一个被一些通信协议支持的可选的特性，它允许比普通数据优先级高的数据被传送。带外数据会被优先任何已经排队的待传输的数据被传送。TCP支持带外数据，但是UDP不支持。TCP对带外数据的实现，会在很大的程度上影响用于带外数据的套接字接口。
	TCP将带外数据看作"紧急（urgent）"数据。TCP只支持单个字节的紧急数据，但是允许紧急数据通过普通的数据发送机制在带外发送。为了生成紧急数据，我们指定任意三个send函数的MSG_OOB标记，如果我们发送具有MSG_OOB标记的数据大于一个字节，那么最后一个字节将会被当做紧急数据。
	当接收到紧急数据的时候，如果我们做了这个套接字的相关信号产生处理，那么会发送给我们SIGURG信号。前面我们可以看到，我们可以使用F_SETOWN命令fcntl函数设置一个套接字的属主。如果fcntl函数的第三个参数是整数，它指定一个进程ID，如果它是一个不是-1的负数，那么表示一个进程组ID。因此，我们可以通过调用如下函数，来让我们的应用程序接收信号：
	fcntl(sockfd, F_SETOWN, pid);
	F_GETOWN命令可以用来获取当前的套接字的属主。类似F_SETOWN命令，一个负数值表示进程组ID，一个正数值代表一个进程ID，所以如下调用：
	owner = fcntl(sockfd, F_GETOWN, 0);
	将会返回一个owner值，如果它是正数，则表示被配置的接收从套接字信号的进程ID；如果它是负数，则其绝对值表示从套接字接收信号的进程组ID。

	TCP支持紧急标记的提示：就是紧急数据在普通数据流中出现的点。如果我们使用SO_OOBINLINE套接字选项，那么我们可以选择和普通数据在一起来接收紧急数据（费解?????）。为了能够辨别出我们已经到达了紧急标记点，我们使用sockatmark函数。
	#include <sys/socket.h>
	int sockatmark(int sockfd);
	返回：如果到达了标记，那么返回1，如果没有到达标记那么返回0，如果出现了错误，那么返回1。
	当下一个将要被读取的字节就是紧急数据标记的地方的时候，sockatmark将会返回1。
	当带外数据在套接字读取队列中存在的时候，select函数将会返回这个文件描述符号，就像发生了提交的例外情况一样。我们可以选择连同普通数据一起来接收紧急数据，或者我们可以使用某个recv函数的MSG_OOB标记来在其他任何队列数据之前接收紧急数据。TCP会为一个字节的紧急数据排队，如果在我们接收到当前的紧急数据之前有另外的紧急数据到达，那么当前存在的紧急数据将会被忽略。

	8)非阻塞和异步I/O
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec8.html
	一般来说recv函数将会在数据没有立即到达的时候阻塞。类似地，send函数将会在套接字用于发送的输出队列没有足够空间的时候阻塞。这个行为会在套接字处于非阻塞的模式的时候有所改变。这个时候，这些函数将会失败，并且设置errno为EWOULDBLOCK或者EAGAIN。当发生这个情况的时候，我们可以使用poll或者select函数来对我们能够发送或者接收数据时候进行处理。
	Single UNIX Specification的实时扩展包含对通用的异步I/O机制的支持。套接字机制有它自己的处理异步I/O的方法，但是这个并没有在Single UNIX Specification中被标准化。有些文章将经典的基于套接字的异步I/O机制称为"基于信号的I/O"，以和实时扩展的异步I/O机制进行区别。
	使用基于套接字的异步I/O，我们可以设置在我们能够读取数据或者套接字的写队列中有空间的时候被发送SIGIO信号。激活异步I/O是一个两步的过程：
	a.建立套接字属主，这样信号可以被发送到合适的进程。
	b.通知套接字，我们想要它在I/O操作没有阻塞的时候给我们发送信号。
	我们可以以三种方式完成第一个步骤：
	a. 使用fcntl函数的F_SETOWN命令。
	b. 使用ioctl函数的FIOSETOWN命令。
	c. 使用ioctl函数的SIOCSPGRP命令。
	我们有两个选择可以完成第二个步骤：
	1.使用fcntl函数的F_SETFL命令并且激活文件的O_ASYNC标记。
	2.使用ioctl函数的FIOASYNC命令。
	对于上面的那些命令，有一些但是它们并不是通用的。具体这些套接字异步I/O管理命令在那个系统上支持，请参考参考资料中的一个表格，这里面就不列举出来了。

	9)总结：
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch16lev1sec9.html
	在本章，我们看到了允许进程像在本地机器一样与其他机器上的进程进行通信的进程通信机制。我们讨论了套接字末端如何被命名，以及我们在和服务端进行通信的时候怎样能够发现相应的地址信息。
	我们展示了使用无连接方式（也就是基于数据报的方式）的套接字和面向连接的套接字的例子。我们也简要地讨论了异步和非阻塞的套接字I/O以及用来管理套接字选项的接口。
	在下一个章节中，我们将要看到一些高级的IPC内容，包含我们如何使用套接字在运行在同一台机器上面的进程之间传递文件描述符号。

*高级进程通信
==========================
	1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch17lev1sec1.html
	在前面的两章，我们介绍了各种类型的进程通信，包括管道和套接字。在这一个章节我们将会看到两个高级的通信方式：基于流管道的IPC以及Unix域套接字，以及我们可以对它们进行怎样的操作。通过这些形式的IPC，我们可以将打开的文件描述符号在进程之间进行传递，服务进程可以将名称和这些文件描述符号进行关联，客户进程可以使用这些名称和服务进程之间进行通信。我们也会看到，操作系统如何为每一个客户进程提供单一的IPC通道。

	2)基于流的管道
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch17lev1sec2.html
	基于流的管道（简称“流管道”即stream pipe），是一个全双工的管道，父子进程之间通过单一的管道就可以进行双向的通信。
	前面已经说过，Solaris系统支持stream pipes，而linux上面可以通过一个可选的软件包来提供这样的功能。
	下图用两种方式展示了stream pipes:

	    +-----User Process----+                         +---User Process-----+
	    |                     |                         |                    |
	    |  fd[0]      fd[1]   |                         |fd[0]          fd[1]|
	    +----^----------^-----+                         +-^---------------^--+
	          \        /                                  |               |
	           --------                             +-----|---------------|------+
	                                                |     +->Stream Pipe<-+      |
	                                                +-----------Kernel-----------+

	如果我们深入到Stream pipe内部，我们将会看到两个stream头部，每一个写队列(WQ)指向另外一个读队列(RQ)。对一端写入数据，将会放到另外一端读取队列的消息中去。

	                      Stream pipe 的内部

	            +---------+                   +---------+
	            | +----+  |                   |  +----+ |
	            | | WQ |---------\    /----------| WQ | |
	            | +----+  |       \  /        |  +----+ |
	      fd[0] |         |        \/         |         | fd[1]
	            | +----+  |        /\         |  +----+ |
	            | | RQ |<---------/  \---------->| RQ | |
	            | +----+  |                   |  +----+ |
	            +---------+                   +---------+
	           Stream head                     Stream head


	由于Stream pipe是一个流，我们可以将streams模块推送到管道的任何一段来处理写入管道的数据，后面会给出相应的图形。但是如果我们将一个模块推送到一端，我们不能从另外一端将它弹出来。如果我们想要移走它，那么我们需要从推送它的那一端将它移走。

	                      含有Module的Stream pipe 的内部

	            +---------+          +---------+                          +---------+
	            | +----+  |          |  +----+ |                          |  +----+ |
	            | | WQ |--------------->| WQ |--------\    /-----------------| WQ | |
	            | +----+  |          |  +----+ |       \  /               |  +----+ |
	      fd[0] |         |          |         |        \/                |         | fd[1]
	            | +----+  |          |  +----+ |        /\                |  +----+ |
	            | | RQ |<-------------- | RQ |<---------  ------------------>| RQ | |
	            | +----+  |          |  +----+ |                          |  +----+ |
	            +---------+          +---------+                          +---------+
	           Stream head             module                              Stream head
	假设我们没有做任何事情，例如推送一个模块。一个stream pipe的表现好象是一个无stream的pipe，当然它还是支持streamio(7)中所说的多数的STREAMS的ioctl命令的。在后面的章节中，我们将会看到一个例子，这个了例子展示了当我们在文件系统中给定一个管道名称的时候，通过向streams pipe推送一个模块来提供唯一的连接。

	举例
	这里对前面的协作处理程序使用单个的streams pipe做了一个重新的实现。下面的代码给出了新的main函数，而add2协作处理程序和前面的一样。我们调用了一个新的函数s_pipe来创建一个单一的streams pipe（我们马上会给出这个函数的stream pipes和unix domain sockets两种实现）。

	通过streams pipe来调用add2程序的例子
	#include "apue.h"
	static void sig_pipe(int);      /* our signal handler */

	int main(void)
	{
	    int     n;
	    int     fd[2];
	    pid_t   pid;
	    char    line[MAXLINE];

	    if (signal(SIGPIPE, sig_pipe) == SIG_ERR)
	        err_sys("signal error");

	    if (s_pipe(fd) < 0)         /* need only a single stream pipe */
	        err_sys("pipe error");
	    if ((pid = fork()) < 0) {
	        err_sys("fork error");
	    } else if (pid > 0) {                           /* parent */
	        close(fd[1]);
	        while (fgets(line, MAXLINE, stdin) != NULL) {
	            n = strlen(line);
	            if (write(fd[0], line, n) != n)
	                err_sys("write error to pipe");
	            if ((n = read(fd[0], line, MAXLINE)) < 0)
	                err_sys("read error from pipe");
	            if (n == 0) {
	                err_msg("child closed pipe");
	                break;
	            }
	            line[n] = 0; /* null terminate */
	            if (fputs(line, stdout) == EOF)
	                err_sys("fputs error");
	        }
	        if (ferror(stdin))
	            err_sys("fgets error on stdin");
	        exit(0);
	    } else {                                    /* child */
	        close(fd[0]);
	        if (fd[1] != STDIN_FILENO &&
	          dup2(fd[1], STDIN_FILENO) != STDIN_FILENO)
	            err_sys("dup2 error to stdin");
	        if (fd[1] != STDOUT_FILENO &&
	          dup2(fd[1], STDOUT_FILENO) != STDOUT_FILENO)
	               err_sys("dup2 error to stdout");
	        if (execl("./add2", "add2", (char *)0) < 0)
	            err_sys("execl error");
	    }
	    exit(0);
	}
	static void sig_pipe(int signo)
	{
	    printf("SIGPIPE caught\n");
	    exit(1);
	}


	父进程只使用fd[0]进行读写（向fd[0]写的内容反应到fd[1]中，从fd[0]读取的内容来自fd[1]），子进程只使用fd[1]进行读写。因为streams pipe的每个末端都是全双工的，所以父进程只是读取和写入fd[0];子进程将标准输入输出复制到fd[1]，达到对fd[1]进行读写的目的（之前是使用了两个半双工管道对应两对文件描述符号，这里只使用一个管道对应一对文件描述符号）。下面的图就展示了结果文件描述符号的情况。注意这里的例子也可以使用不基于流的全双关工的pipes来实现，因为这个例子没有使用任何关于流的特性。
	前面说过FreeBSD支持全双工pipes，但是这样的pipes不是基于流机制的。
	                    协作处理程序中的文件描述符号布局
	               Parent                            Child(coprocess)
	            +----------+                         +--------------+
	            |          |        /--------------->|  stdin       |
	            |    fd[0] <-------|---------------->|  fd[1]       |
	            |          |        \--------------->|  stdout      |
	            +----------+                         +--------------+

	我们定义的s_pipe和标准的pipe函数类似。两个函数使用接收同样的参数，但是s_pipe返回的文件描述符号以读和写的方式打开。

	基于流的s_pipe函数的例子
	下面的代码展示了基于流的s_pipe函数的实现。这个实现只是调用了标准的pipe函数，创建全双工的管道。
	#include "apue.h"
	/*
	 * Returns a STREAMS-based pipe, with the two file descriptors
	 * returned in fd[0] and fd[1].
	 */
	int s_pipe(int fd[2])
	{
	    return(pipe(fd));
	}

	有名stream pipes
	一般来说，pipes只能在亲戚进程之间使用，一般是子进程从它们的父进程将pipes继承过来。前面我们看到过非相关进程可以使用FIFOs进行通信，但是这个只提供了单向的通信路径。streams机制为进程提供了一个方法，通过这个方法，进程可以给定文件系统中的一个pipe名字，这解决了单向的FIFOs问题。
	我们可以使用fattach函数为Streamspipe提供一个文件系统中的名字。
	#include <stropts.h>
	int fattach(int filedes, const char *path);
	返回：如果成功返回0，如果错误返回1。
	参数path必须引用一个已经存在的文件名称，并且调用的进程必须拥有这个文件并且具有对这个文件的写权限，或者以超级用户的身份运行。
	一旦一个streams pipe被附加到一个文件系统上面的名称上面，那么相应的文件就变得不可访问了。任何打开这个名称的进程将获得相应的pipe的访问而不是那个文件。任何在pipe附加到该文件之前就打开这个文件的进程仍然可以继续对这个文件进行访问。实际上，这些进程一般不会知道现在这个名称正在引用一个不同的文件。
	下图展示了一个附加到路径/tmp/pipe上面的pipe。这个pipe只有一个端被附加到文件系统上面的名字上面，另外一个端用来和打开这个被附加的文件的进程进行通信。尽管可以这样将任何类型的流文件描述符号附加到一个文件系统上面的名字上面，但是fattach函数一般用来为一个stream pipe提供一个名字而使用。

	                           挂载到一个文件系统中的名字上面的pipe
	          +------------------+
	          |  user process    |
	          +--------------^---+
	                          \
	                           \
	                            v
	                        +------------------+             +------------------+
	                        |   stream head    |             |   stream head    | /tmp/pipe
	                        +------------^-----+             +---^--------------+
	                                      \         pipe        /
	                                       ---------------------


	一个进程可以调用fdetach来取消一个streams file和一个文件系统中文件名称之间的关联。
	#include <stropts.h>
	int fdetach(const char *path);
	返回：如果成功返回0，如果错误返回1。
	在调用fdetach之后，任何通过打开这个路径访问相应的streams pipe的进程还是会仍然继续对这个stream进行访问，但是之后对这个路径打开进行访问的进程将会访问到这个路径对应的文件系统中的原始的文件。

	*单一连接
	尽管我们可以将一个stream pipe的末端附加到文件系统上面的一个路径名字上面，我们在多个客户进程使用有名的streams pipe和服务进程进行通信的时候还是会遇到问题。来自一个客户进程的数据可能会干扰另外一个写入管道的客户进程的数据。尽管我们可以保证客户进程写的数据量少于PIPE_BUF字节这样写操作就是原子的了，我们没有办法向一个特定的客户进程反馈并且保证就是那个客户进程读取到了消息。因为有许多进程读取同一个管道，我们无法控制那个进程实际读取我们发送的数据。
	connld的stream module解决了这个问题。在将一个streams pipe附加到一个文件系统中的名字之前，服务进程可以首先将一个connld 模块推送到被附加的管道的末端。这样如下图所示：

	                              为单一连接设置connld
	  +-----------------+                                           +-----------------+
	  | server process  |                                           | client process  |
	  +-----------^-----+                                           +-^---------------+
	               \                                                 .
	                \                                /tmp/pipe      .
	                +v--------------+                +-------------v+
	                | stream head   |                | stream head  |
	                +--------^------+                +------^-------+
	                         |                              |
	                         |                              |
	                         \                      +-------v------+
	                          \                     |   CONNLD     |
	                           \                    +------^-------+
	                            \      pipe                |
	                             --------------------------+

	在上面的图中，服务进程附加pipe的一个末端到/tmp/pipe上面，这里我们用虚线表示客户进程（client process）正在打开一个附加的streams pipe。一旦打开过程完毕了，那么我们就有了下图所示的情况：

	                                      使用connld创建单一连接
	                   +----------------+                          +---------------+
	                   | server process |                          | client process|
	                   +-^-------------^+                          +--------------^+
	                    /               \                                          \
	                   /       /tmp/pipe ----------------\                          \
	   +--------------v-+      +---------------+         +v-------------+          +-v-----------+
	   |  stream head   |      |  stream head  |         |  stream head |          |  stream head|
	   +--------^-------+      +-------^-------+         +---------^----+          +------^------+
	            |                      |                            \      pipe          /
	            \                      |                             --------------------
	             \             +-------v-------+
	              \            |   CONNLD      |
	               \           +-------^-------+
	                \       pipe       |
	                 ------------------+

	客户进程不会为它打开的管道末端接收一个打开的文件描述符号。相反，操作系统创建一个新的管道然后返回给客户进程一个新的管道末端做为打开/tmp/pipe的结果。系统发送新管道的另外一个端给服务进程,发送的方式是通过将它的文件描述符号在已经存在的附加了文件的的管道上进行传输，这样就会导致在客户进程和服务进程上面只有一个单一的连接了。我们将会在后面看到使用stream pipes传输文件描述符号的机制。
	fattach函数构建在mount系统调用之上，这个工具被当做被挂载了的streams。被挂载了的streams和connld模块的这些机制后来被SVR4纳入。

	我们接下来开发三个函数，这些函数可以用来在非继承的进程之间创建单一的连接。这些函数模拟之前讲过的面向连接的套接字函数。我们使用streams pipes来做其底下的通信机制，后面我们会看到也可以使用UNIX domain sockets来实现这些函数。
	#include "apue.h"
	int serv_listen(const char *name);
	返回：如果成功返回侦听的文件描述符号，如果错误返回负数。
	int serv_accept(int listenfd, uid_t *uidptr);
	返回：如果成功返回新的文件描述符号，如果错误返回负数。
	int cli_conn(const char *name);
	返回：如果成功返回文件描述符号，如果错误返回负数。

	函数serv_listen在服务进程侦听客户进程向公共名称（文件系统中的路径）发送连接请求的时候，可以用于服务进程。客户进程将会在他们想要连接服务进程的时候使用这个名称。返回值就是streams pipe的服务端。代码如下：
	#include "apue.h"
	#include <fcntl.h>
	#include <stropts.h>

	/* pipe permissions: user rw, group rw, others rw */
	#define FIFO_MODE (S_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP|S_IROTH|S_IWOTH)

	/*
	 * Establish an endpoint to listen for connect requests.
	 * Returns fd if all OK, <0 on error
	 */
	int serv_listen(const char *name)
	{
	   int     tempfd;
	   int     fd[2];

	   /*
	    * Create a file: mount point for fattach().
	    */
	   unlink(name);
	   if ((tempfd = creat(name, FIFO_MODE)) < 0)
	       return(-1);
	   if (close(tempfd) < 0)
	       return(-2);
	   if (pipe(fd) < 0)
	       return(-3);
	   /*
	    * Push connld & fattach() on fd[1].
	    */
	   if (ioctl(fd[1], I_PUSH, "connld") < 0) {
	       close(fd[0]);
	       close(fd[1]);
	       return(-4);
	   }
	   if (fattach(fd[1], name) < 0) {
	       close(fd[0]);
	       close(fd[1]);
	       return(-5);
	   }
	   close(fd[1]); /* fattach holds this end open */

	   return(fd[0]); /* fd[0] is where client connections arrive */
	}

	服务端使用serv_accept函数等待客户连接请求到达。当请求到达的时候，系统会自动创建一个新的streams pipe，然后这个函数返回一个末端给服务进程。另外，客户进程的有效用户ID被存放在uidptr指向的内存。代码如下：
	#include "apue.h"
	#include <stropts.h>

	/*
	 * Wait for a client connection to arrive, and accept it.
	 * We also obtain the client's user ID.
	 * Returns new fd if all OK, <0 on error.
	 */
	int serv_accept(int listenfd, uid_t *uidptr)
	{
	    struct strrecvfd    recvfd;
	    if (ioctl(listenfd, I_RECVFD, &recvfd) < 0)
	        return(-1);     /* could be EINTR if signal caught */
	    if (uidptr != NULL)
	        *uidptr = recvfd.uid;   /* effective uid of caller */
	    return(recvfd.fd);  /* return the new descriptor */
	}

	一个客户调用cli_conn来连接到服务器。name参数指定的名称必须和服务端serv_listen中指定的名称一样。返回的时候，客户进程得到一个连接到服务端的连接。代码如下：
	#include "apue.h"
	#include <fcntl.h>
	#include <stropts.h>

	/*
	 * Create a client endpoint and connect to a server.
	 * Returns fd if all OK, <0 on error.
	 */
	int cli_conn(const char *name)
	{
	    int     fd;

	    /* open the mounted stream */
	    if ((fd = open(name, O_RDWR)) < 0)
	        return(-1);
	    if (isastream(fd) == 0) {
	        close(fd);
	        return(-2);
	    }
	    return(fd);
	}

	我们仔细检测返回的文件描述符号是否引用了一个streams设备，以防服务进程没有启动但是这个文件名称仍然在文件系统中存在着。后面我们将会看到这三个函数是怎样被使用的。

	3)Unix域套接字
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch17lev1sec3.html
	UNIX域套接字用于和运行在同一台机器上面的进程进行通信。尽管因特网域的套接字也可以用于同样的目的，但是UNIX域的套接字的效率更高。UNIX域的套接字只拷贝数据，它门没有对协议的相关处理，没有网络头的添加和移除，没有校验和的计算，没有顺序号码的生成，也没有对发送的确认。

	UNIX域套接字同时提供了流和数据报的接口。但是UNIX域数据报服务是可靠的，消息不会丢失也不会乱序。UNIX域套接字类似套接字和pipes的综合。你可以使用面向网络的套接字接口来使用它们或者你也可以使用socketpair函数创建一对匿名的，连接的UNIX域套接字。
	#include <sys/socket.h>
	int socketpair(int domain, int type, int protocol, int sockfd[2]);
	返回：如果成功返回0，如果错误返回1。
	尽管这个接口足够通用可以允许socketpair在任何域中使用，但是操作系统一般只支持对UNIX域的支持。

	使用UNIX域套接字的s_pipe函数的例子
	下面的代码展示了基于套接字的s_pipe函数实现。这个函数创建一对面向连接的UNIX域流的套接字。
	有些基于BSD的系统使用UNIX 域套接字来实现管道，但是当pipe被调用的时候，管道第一个描述符号的读端以及第二个描述符号的写端都是关闭的。为了获得一个全双工的管道，我们必须直接调用socketpair。
	#include "apue.h"
	#include <sys/socket.h>

	/*
	 * Returns a full-duplex "stream" pipe (a UNIX domain socket)
	 * with the two file descriptors returned in fd[0] and fd[1].
	 */
	int s_pipe(int fd[2])
	{
	    return(socketpair(AF_UNIX, SOCK_STREAM, 0, fd));
	}


	有名的UNIX域套接字
	尽管socketpair函数创建了互相连接的套接字，但是它们并没有名字。也就是说，它们不能通过没有亲属关系的进程被访问到。在前面，我们学到了如何将一个地址绑定到一个因特网的套接字上面。如同因特网的套接字一样，UNIX域套接字可以有名称并且用来做为某些服务的通知。然而，UNIX域的套接字和因特网的套接字有所不同。

	在前面我们知道，套接字的地址格式对于每个系统实现来说有所不同。一个用于UNIX域套接字的地址可以使用sockaddr_un结构来进行表示。在Linux 2.4.22和Solaris 9中，sockaddr_un结构如下，并定义在<sys/un.h>中：
	struct sockaddr_un {
		sa_family_t sun_family;      /* AF_UNIX */
		char        sun_path[108];   /* pathname */
	};

	在FreeBSD 5.2.1和Mac OS X 10.3中，sockaddr_un结构的定义如下：
	struct sockaddr_un {
		unsigned char  sun_len;         /* length including null */
		sa_family_t    sun_family;      /* AF_UNIX */
		char           sun_path[104];   /* pathname */
	};
	sockaddr_un结构中的sun_path成员包含了一个路径。当我们将一个地址绑定到一个UNIX域的套接字上面的时候，系统以同样的名字创建了一个S_IFSOCK类型的文件。这个文件只用来通知客户程序套接字的名称。这个文件不能被打开只能用于应用程序之间的通信。
	如果这个文件在我们想要绑定同样名称的地址的时候已经存在了，这个绑定的请求将会失败。当我们关闭套接字的时候，文件不会被自动地删除，所以我们需要确保当我们程序退出的时候将这个文件unlink。

	例子
	后面的代码展示了绑定一个地址到UNIX域套接字的例子。
	#include "apue.h"
	#include <sys/socket.h>
	#include <sys/un.h>
	int main(void)
	{
	    int fd, size;
	    struct sockaddr_un un;

	    un.sun_family = AF_UNIX;
	    strcpy(un.sun_path, "foo.socket");
	    if ((fd = socket(AF_UNIX, SOCK_STREAM, 0)) < 0)
	        err_sys("socket failed");
	    size = offsetof(struct sockaddr_un, sun_path) + strlen(un.sun_path);
	    if (bind(fd, (struct sockaddr *)&un, size) < 0)
	        err_sys("bind failed");
	    printf("UNIX domain socket bound\n");
	    exit(0);
	}

	当我们运行这个程序的时候，绑定请求成功，但是如果我们再次运行这个程序，我们会得到一个错误。因为，这个文件已经存在了，如果我们不删除这个文件那么这个程序不会再次成功运行。
	$ ./a.out                                       run the program
	UNIX domain socket bound
	$ ls -l foo.socket                              look at the socket file
	srwxrwxr-x 1 sar        0 Aug 22 12:43 foo.socket
	$ ./a.out                                       try to run the program again
	bind failed: Address already in use
	$ rm foo.socket                                 remove the socket file
	$ ./a.out                                       run the program a third time
	UNIX domain socket bound                        now it succeeds

	这里，我们确定bind的地址的大小的方法是使用offsetof函数来确定sun_path成员的偏移再加上其大小，并没有包含其中的NULL字符串结束字节。因为不同的系统实现sun_path成员前面都有什么是不一样的，我们使用<stddef.h>中的offsetof宏来从结构的最开始进行计算。这个offsetof宏的定义如下：
	#define offsetof(TYPE, MEMBER) ((int)&((TYPE *)0)->MEMBER)
	这个表达式会计算一个整数，这个整数代表一个成员的起始地址，并且假定整个结构的起始地址是0。

	*单向连接
	服务进程可以使用标准的bind,listen和accept函数来管理unix域到客户进程的单一连接。客户进程使用connect来和服务进程进行连接；在服务进程接收到了connect请求之后，在客户和服务进程之间就存在了一条单一的连接。这样的操作和前面我们在因特网套接字中的两个例子类似。
	下面出一个使用unix域套接字的serv_listen函数：

	unix域套接字的serv_listen函数
	#include "apue.h"
	#include <sys/socket.h>
	#include <sys/un.h>
	#include <errno.h>
	#define QLEN 10
	/*
	 * Create a server endpoint of a connection.
	 * Returns fd if all OK, <0 on error.
	 */
	int serv_listen(const char *name)
	{
	    int                 fd, len, err, rval;
	    struct sockaddr_un  un;

	    /* create a UNIX domain stream socket */
	    if ((fd = socket(AF_UNIX, SOCK_STREAM, 0)) < 0)
	       return(-1);
	    unlink(name);   /* in case it already exists */

	    /* fill in socket address structure */
	    memset(&un, 0, sizeof(un));
	    un.sun_family = AF_UNIX;
	    strcpy(un.sun_path, name);
	    len = offsetof(struct sockaddr_un, sun_path) + strlen(name);

	    /* bind the name to the descriptor */
	    if (bind(fd, (struct sockaddr *)&un, len) < 0) {
	        rval = -2;
	        goto errout;
	    }
	    if (listen(fd, QLEN) < 0) { /* tell kernel we're a server */
	        rval = -3;
	        goto errout;
	    }
	    return(fd);

	errout:
	    err = errno;
	    close(fd);
	    errno = err;
	    return(rval);
	}
	首先，我们调用socket创建一个unix域的套接字。然后我们用一个已知的名字填充sockaddr_un结构(这个结构做为bind的参数)以便绑定给套接字。注意在一些平台上面我们不需要设定sun_len成员，因为操作系统通过传给bind函数的地址长度会为我们设置这个成员。
	最后，我们调用listen函数来告诉内核，进程将作为一个服务进程，等待来自客户进程的连接。当客户的连接请求到达的时候，服务进程再调用serv_accept函数。如下：

	unix域套接字的serv_accept函数
	#include "apue.h"
	#include <sys/socket.h>
	#include <sys/un.h>
	#include <time.h>
	#include <errno.h>

	#define STALE   30  /* client's name can't be older than this (sec) */

	/*
	 * Wait for a client connection to arrive, and accept it.
	 * We also obtain the client's user ID from the pathname
	 * that it must bind before calling us.
	 * Returns new fd if all OK, <0 on error
	 */
	int serv_accept(int listenfd, uid_t *uidptr)
	{
	    int                 clifd, len, err, rval;
	    time_t              staletime;
	    struct sockaddr_un  un;
	    struct stat         statbuf;

	    len = sizeof(un);
	    if ((clifd = accept(listenfd, (struct sockaddr *)&un, &len)) < 0)
	        return(-1);     /* often errno=EINTR, if signal caught */

	    /* obtain the client's uid from its calling address */
	    len -= offsetof(struct sockaddr_un, sun_path); /* len of pathname */
	    un.sun_path[len] = 0;           /* null terminate */

	    if (stat(un.sun_path, &statbuf) < 0) {
	        rval = -2;
	        goto errout;
	    }
	#ifdef S_ISSOCK     /* not defined for SVR4 */
	    if (S_ISSOCK(statbuf.st_mode) == 0) {
	        rval = -3;      /* not a socket */
	        goto errout;
	    }
	#endif
	    if ((statbuf.st_mode & (S_IRWXG | S_IRWXO)) ||
	        (statbuf.st_mode & S_IRWXU) != S_IRWXU) {
	          rval = -4;     /* is not rwx------ */
	          goto errout;
	    }

	    staletime = time(NULL) - STALE;
	    if (statbuf.st_atime < staletime ||
	        statbuf.st_ctime < staletime ||
	        statbuf.st_mtime < staletime) {
	          rval = -5;    /* i-node is too old */
	          goto errout;
	    }
	    if (uidptr != NULL)
	        *uidptr = statbuf.st_uid;   /* return uid of caller */
	    unlink(un.sun_path);        /* we're done with pathname now */
	    return(clifd);

	errout:
	    err = errno;
	    close(clifd);
	    errno = err;
	    return(rval);
	}

	服务进程阻塞在accept调用上面，等待客户进程调用cli_conn。当accept返回的时候，它的返回值是连接到客户进程的一个新的文件描述符号（这个和connld模块对STREAMS子系统所做的一样）。另外，客户端赋值到它的套接字上面的路径名称（这个名称包含客户进程的进程ID）也会在accept中，通过第二个参数（指向sockaddr_un结构的指针）被返回(参见下面的cli_conn)。我们给这个路径名称赋值一个null结束符号，然后调用stat。这样我们检测路径名称确实是一个套接字并且权限只允许用户读，写，执行。我们也会检查和套接字相关的时间不会超过30秒。
	如果所有这三项检测成功，我们假定客户进程的标识（它的有效用户ID）就是套接字的属主。尽管检测不是很完美，但是这也是我们在目前的系统上面可以做的最好的了（若内核返回有效用户ID给accept，就像ioctl的I_RECVFD命令那样，这会更好）。

	客户进程通过调用cli_conn函数初始化到服务器的连接。
	用于unix 域套接字的cli_conn函数
	#include "apue.h"
	#include <sys/socket.h>
	#include <sys/un.h>
	#include <errno.h>

	#define CLI_PATH    "/var/tmp/"      /* +5 for pid = 14 chars */
	#define CLI_PERM    S_IRWXU          /* rwx for user only */

	/*
	 * Create a client endpoint and connect to a server.
	 * Returns fd if all OK, <0 on error.
	 */
	int cli_conn(const char *name)
	{
	    int                fd, len, err, rval;
	    struct sockaddr_un un;

	    /* create a UNIX domain stream socket */
	    if ((fd = socket(AF_UNIX, SOCK_STREAM, 0)) < 0)
	        return(-1);

	    /* fill socket address structure with our address */
	    memset(&un, 0, sizeof(un));
	    un.sun_family = AF_UNIX;
	    sprintf(un.sun_path, "%s%05d", CLI_PATH, getpid());
	    len = offsetof(struct sockaddr_un, sun_path) + strlen(un.sun_path);

	    unlink(un.sun_path);        /* in case it already exists */
	    if (bind(fd, (struct sockaddr *)&un, len) < 0) {
	        rval = -2;
	        goto errout;
	    }
	    if (chmod(un.sun_path, CLI_PERM) < 0) {
	        rval = -3;
	        goto errout;
	    }
	    /* fill socket address structure with server's address */
	    memset(&un, 0, sizeof(un));
	    un.sun_family = AF_UNIX;
	    strcpy(un.sun_path, name);
	    len = offsetof(struct sockaddr_un, sun_path) + strlen(name);
	    if (connect(fd, (struct sockaddr *)&un, len) < 0) {
	        rval = -4;
	        goto errout;
	    }
	    return(fd);

	errout:
	    err = errno;
	    close(fd);
	    errno = err;
	    return(rval);
	}

	我们调用socket函数创建客户端的unixt域套接字，然后我们使用一个客户端指定的名字填充一个sockaddr_un结构。
	我们不会让系统为我们选择一个默认的地址，因为服务器无法将一个客户进程和另外一个客户进程相区别。我们所作的是将我们自己的地址绑定，这一步我们通常在开发一个使用套接字的应用程序的时候不会使用。
	我们绑定的路径的最后5个字符来自客户进程的进程ID。我们调用unlink，防止路径已经存在。然后我们调用bind为客户端的套接字指定一个名称。这样会在文件系统中创建一个和绑定的路径名称一样的套接字文件(注意，bind会创建文件)。我们调用chmod来关闭除了用户读、写、执行之外的所有权限。在serv_accept中，服务进程检查这些权限以及套接字的用户ID来验证客户进程的标识。
	我们然后填充另外一个sockaddr_un结构，这时候使用服务进程的公共名称。最后，我们调用connect函数向服务进程发起连接请求。


	4)传递文件描述符号
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch17lev1sec4.html
	在进程之间传递打开的文件描述符号这个功能非常强大。它可以使得客户服务程序具有不同的设计方案。它允许一个进程（一般这个进程都是服务进程）去做打开一个文件的所有工作（包括将网络名称转换为网络地址，向modem拨号，协商文件锁，等等），然后简单地向调用进程传递回去一个文件描述符号，这个文件符号可以用于输入输出函数。所有打开文件的细节工作在客户进程端来看都是被隐藏了的。
	我们必须对“传递一个打开的文件描述符号”这个词语非常了解。在最开始的时候，我们展示过两个进程打开同样一个文件的情况，尽管这两个进程共享同样的v-node，但是每一个进程有它自己的文件表项。
	当我们在进程之间传递打开的文件描述符号的时候，我们想要两个进程之间共享同一个文件表项，如下图所示：

	                从上面的进程打开的文件传递到底下的进程

	  +-process table entry--+
	  |     fd     file      |
	  |    +flags+-pointer-+ |
	  |fd0 |-----|---------| |
	  |fd1 |-----|---------| |   ---->+file table---------+
	  |fd2 |-----|---------| |  /  -->| file status flags |
	  |fd3 |-----|---------|----  /   +-------------------+
	  |    |    ......     | |   /    | current offset    |
	  |    +---------------+ |   |    +-------------------+
	  |                      |   |    | v-node pointer    |------> +-v-node table---+
	  +----------------------+   |    +-------------------+        |    v-node      |
	                             |                                 |   information  |
	                             |                                 +----------------+
	  +-process table entry--+   |                                 |    i-node      |
	  |     fd     file      |   |                                 |   information  |
	  |    +flags+-pointer-+ |  /                                  +_.............._+
	  |fd0 |-----|---------| | /                                   |    current     |
	  |fd1 |-----|---------| |/                                    |   file size    |
	  |fd2 |-----|---------| /                                     +----------------+
	  |fd3 |-----|---------|/|
	  |fd4 |-----|---------| |
	  |    |    ......     | |
	  |    +---------------+ |
	  |                      |
	  |                      |
	  +----------------------+
	从技术来看，我们将一个指向文件表的指针从一个进程传递给另外一个进程。这个指针被分配给接收进程的第一个可用的文件描述符号。（也就是说，我们传递一个打开的文件描述符号，但是文件描述符号的号码在两个进程中并不一定一样，上图就是一个很明显的例子）两个进程共享一个打开的文件表实际就是调用fork的时候发生的事情(可以参见前面讲述fork时候一个描述fork之后父子之间共享打开文件的图)。
	当一个文件描述符号从一个进程被传递到另外一个进程的时候，发送进程在传递完了文件描述符号之后会关闭掉文件描述符号。发送进程关闭文件描述符号并不会真的关闭掉文件或者设备，因为文件描述符号对于接收进程来说仍然是打开的（即便接受进程没有特地接收文件描述符号）。
	我们定义如下的三个函数来发送和接收文件描述符号，在本节的后面，我们将会展示对于流和套接字的这三个函数的代码。
	#include "apue.h"
	int send_fd(int fd, int fd_to_send);
	int send_err(int fd, int status, const char *errmsg);
	两者返回：如果成功返回0，如果错误返回1。

	int recv_fd(int fd, ssize_t (*userfunc)(int, const void *, size_t));
	返回：如果成功返回文件描述符号，如果错误返回负数。

	如果进程（通常是服务进程）想要发送文件描述符号给另外一个进程，那么调用send_fd或者send_err。进程（通常客户进程）如果等待接收文件描述符号则调用recv_fd。
	函数send_fd通过fd代表的unix域的套接字或者stream pipe来发送文件描述符号"fd_to_send"。
	我们将要使用s-pipe来引用双向的通信通道，这个通道可以采用streams pipe或者unix域套接字实现。
	send_err函数使用fd发送errmsg，并且fd后面接着的status状态值必须在范围1到255之间。
	客户进程调用recv_fd来接收一个文件描述符号。如果所有的过程成功（发送者调用send_fd），那么会返回一个非负数的文件描述符号作为函数的返回值。否则，返回值表示send_err发出的状态(在1到-255区间之间的负数)。另外，如果服务进程发送一个错误的消息，那么客户进程的userfunc函数将会被调用来处理这个消息。userfunc函数的第一个参数是STDERR_FILENO，后面接着的是指向错误消息的指针以及它的长度。userfunc函数的返回值就是写入的字节数目或者表示错误时候的负数。一般来说客户进程会指定一个常用的write函数作为userfunc。
	我们自己实现了一个这三个函数所使用的协议：为了发送一个文件描述符号，send_fd发送两个字节的0，后面接着实际的文件描述符号。为了发送一个错误，send_err发送错误消息errmsg，后面接着一个字节的0，然后是状态字节的绝对值（从1到255）。函数recv_fd读取s-pipe上面的所有内容直到它遇到一个null字节，任何此刻读取到的字符都会被传递到调用者的userfunc中。recv_fd的下一个字节就是状态字节，如果状态字节是0，那么会传递一个文件描述符号；否则不会接收到文件描述符号（因为基于前面send_fd的协议，如果发送文件描述符号，那么开始0实际就是null，所以相当于一个"空字符串+0+描述符号"；而不发送文件描述符号相当于"错误消息字符串+状态绝对值"）。
	函数send_err在写错误消息到s-pipe之后调用send_fd函数。如下所示：
	send_err函数
	#include "apue.h"
	/*
	 * Used when we had planned to send an fd using send_fd(),
	 * but encountered an error instead. We send the error back
	 * using the send_fd()/recv_fd() protocol.
	 */
	int send_err(int fd, int errcode, const char *msg)
	{
	    int     n;

	    if ((n = strlen(msg)) > 0)
	        if (writen(fd, msg, n) != n)    /* send the error message */
	            return(-1);

	    if (errcode >= 0)
	        errcode = -1;   /* must be negative */

	    if (send_fd(fd, errcode) < 0)
	        return(-1);

	    return(0);
	}


	下面将看到函数send_fd和recv_fd函数的实现。

	*将文件描述符号通过基于流的管道进行传递。
	文件描述符号用两个ioctl命令：I_SENDFD和I_RECVFD，通过streams pipes被交换。发送一个文件描述符号的时候我们设置ioctl的第三个参数为实际的文件描述符号。代码如下：
	对于streams pipes的send_fd函数
	#include "apue.h"
	#include <stropts.h>

	/*
	 * Pass a file descriptor to another process.
	 * If fd<0, then -fd is sent back instead as the error status.
	 */
	int send_fd(int fd, int fd_to_send)
	{
	    char    buf[2];     /* send_fd()/recv_fd() 2-byte protocol */

	    buf[0] = 0;         /* null byte flag to recv_fd() */
	    if (fd_to_send < 0) {
	        buf[1] = -fd_to_send;   /* nonzero status means error */
	        if (buf[1] == 0)
	            buf[1] = 1; /* -256, etc. would screw up protocol */
	    } else {
	        buf[1] = 0;     /* zero status means OK */
	    }

	    if (write(fd, buf, 2) != 2)
	        return(-1);
	    if (fd_to_send >= 0)
	        if (ioctl(fd, I_SENDFD, fd_to_send) < 0)
	            return(-1);
	    return(0);
	}

	当我们接收一个文件描述符号的时候，ioctl的第3个参数是一个如下strrecvfd结构的指针：
	struct strrecvfd {
		int    fd;       /* new descriptor */
		uid_t  uid;      /* effective user ID of sender */
		gid_t  gid;      /* effective group ID of sender */
		char   fill[8];
	};
	recv_fd函数从streams pipe中读取信息，直到2字节协议的第一个字节被接收（null字节）。当我们通过I_RECVFD的ioctl命令请求的时候，流头部的读取队列的下一条消息必须是来自I_SENDFD调用的文件描述符号，或者我们获得一个错误。函数代码如下所示：
	    streams pipe的recv_fd函数
	#include "apue.h"
	#include <stropts.h>

	/*
	 * Receive a file descriptor from another process (a server).
	 * In addition, any data received from the server is passed
	 * to (*userfunc)(STDERR_FILENO, buf, nbytes). We have a
	 * 2-byte protocol for receiving the fd from send_fd().
	 */
	int recv_fd(int fd, ssize_t (*userfunc)(int, const void *, size_t))
	{
	    int                 newfd, nread, flag, status;
	    char                *ptr;
	    char                buf[MAXLINE];
	    struct strbuf       dat;
	    struct strrecvfd    recvfd;

	    status = -1;
	    for ( ; ; ) {
	        dat.buf = buf;
	        dat.maxlen = MAXLINE;
	        flag = 0;
	        if (getmsg(fd, NULL, &dat, &flag) < 0)
	            err_sys("getmsg error");
	        nread = dat.len;
	        if (nread == 0) {
	            err_ret("connection closed by server");
	            return(-1);
	        }
	        /*
	         * See if this is the final data with null & status.
	         * Null must be next to last byte of buffer, status
	         * byte is last byte. Zero status means there must
	         * be a file descriptor to receive.
	         */
	        for (ptr = buf; ptr < &buf[nread]; ) {
	            if (*ptr++ == 0) {
	                if (ptr != &buf[nread-1])
	                    err_dump("message format error");
	                 status = *ptr & 0xFF;   /* prevent sign extension */
	                 if (status == 0) {
	                     if (ioctl(fd, I_RECVFD, &recvfd) < 0)
	                         return(-1);
	                     newfd = recvfd.fd;  /* new descriptor */
	                 } else {
	                     newfd = -status;
	                 }
	                 nread -= 2;
	            }
	        }
	        if (nread > 0)
	            if ((*userfunc)(STDERR_FILENO, buf, nread) != nread)
	                 return(-1);

	        if (status >= 0)    /* final data has arrived */
	            return(newfd);  /* descriptor, or -status */
	    }
	}

	将文件描述符号通过unix域套接字进行传输
	为了使用unix域套接字传递文件描述符号，我们调用sendmsg(2)和recvmsg(2)函数。两个函数会接收一个指向msghdr结构的指针，这个结构包含了我们想要接收和发送的所有信息。下面的定义就和你的系统上面的结构类似：
	struct msghdr {
		void         *msg_name;        /* optional address */
		socklen_t     msg_namelen;     /* address size in bytes */
		struct iovec *msg_iov;         /* array of I/O buffers */
		int           msg_iovlen;      /* number of elements in array */
		void         *msg_control;     /* ancillary data */
		socklen_t     msg_controllen;  /* number of ancillary bytes */
		int           msg_flags;       /* flags for received message */
	};
	前两个成员用于在网络连接上面发送数据包，在每个数据包中可以指定目标地址。下两个元素允许我们指定一个数组缓存（分散读和聚集写），和我们前面描述的readv与writev函数类似。msg_flags域包含了描述消息接收的标记，前面谈到recvmsg的消息标记的时候对此进行过说明。
	两个用来处理传递和接收的控制信息的成员，msg_control域指向cmsghdr（控制消息头部）结构，msg_controllen域包含控制信息的字节数目。
	struct cmsghdr  {
		socklen_t   cmsg_len;    /* data byte count, including header */
		int         cmsg_level;  /* originating protocol */
		int         cmsg_type;   /* protocol-specific type */
		/* followed by the actual control message data */
	};
	为发送一个文件描述符号，我们设置cmsg_len为cmsghdr结构的大小，加上一个整数（文件描述符）的大小。cmsg_level成员被设置成为SOL_SOCKET，cmsg_type被设置成为SCM_RIGHTS，以表明我们传递访问权限。(SCM代表套接字层次控制消息。)访问权限可以只通过unix域套接字来传递。文件描述符号存放在cmsg_type域后，通过使用宏CMSG_DATA来获得指向这个整数的指针。
	有三个宏可以被使用来访问控制数据，一个宏用来协助计算用于cmsg_len的值。
	#include <sys/socket.h>
	unsigned char *CMSG_DATA(struct cmsghdr *cp);
	返回：指向与cmsghdr结构相关联的指针。

	struct cmsghdr *CMSG_FIRSTHDR(struct msghdr *mp);
	返回：指向和msghdr结构关联的，第一个cmsghdr结构，或者如果不存在则返回NULL。

	struct cmsghdr *CMSG_NXTHDR(struct msghdr *mp, struct cmsghdr *cp);
	返回：在给定了当前的cmsghdr结构的前提下，获取指向和msghdr结构关联的，下一个cmsghdr结构，或者如果到达了最后一个则返回NULL。

	unsigned int CMSG_LEN(unsigned int nbytes);
	返回：用于分配nbytes大小的数据对象。

	Single UNIX Specification 定义了前面三个宏，但是忽略了CMSG_LEN。
	CMSG_LEN宏返回用来存放大小为nbytes的数据对象的字节数目，是加入了cmsghdr结构大小之后的，根据处理器结构调整了对齐的，以及向上取整的。(??????从下面代码看好象是容纳nbytes数据的cmsghdr的大小，但是翻译上确实整个msghdr大小)

	下面是用于UNIX域套接字的send_fd函数。
	UNIX域套接字的send_fd函数
	#include "apue.h"
	#include <sys/socket.h>
	/* size of control buffer to send/recv one file descriptor */
	#define CONTROLLEN  CMSG_LEN(sizeof(int))
	static struct cmsghdr   *cmptr = NULL;  /* malloc'ed first time */
	/*
	 * Pass a file descriptor to another process.
	 * If fd<0, then -fd is sent back instead as the error status.
	 */
	int send_fd(int fd, int fd_to_send)
	{
	    struct iovec    iov[1];
	    struct msghdr   msg;
	    char            buf[2]; /* send_fd()/recv_fd() 2-byte protocol */

	    iov[0].iov_base = buf;
	    iov[0].iov_len  = 2;
	    msg.msg_iov     = iov;
	    msg.msg_iovlen  = 1;
	    msg.msg_name    = NULL;
	    msg.msg_namelen = 0;
	    if (fd_to_send < 0) {
	        msg.msg_control    = NULL;
	        msg.msg_controllen = 0;
	        buf[1] = -fd_to_send;   /* nonzero status means error */
	        if (buf[1] == 0)
	            buf[1] = 1; /* -256, etc. would screw up protocol */
	    } else {
	        if (cmptr == NULL && (cmptr = malloc(CONTROLLEN)) == NULL)
	            return(-1);
	        cmptr->cmsg_level  = SOL_SOCKET;
	        cmptr->cmsg_type   = SCM_RIGHTS;
	        cmptr->cmsg_len    = CONTROLLEN;
	        msg.msg_control    = cmptr;
	        msg.msg_controllen = CONTROLLEN;
	        *(int *)CMSG_DATA(cmptr) = fd_to_send;     /* the fd to pass */
	        buf[1] = 0;          /* zero status means OK */
	    }
	    buf[0] = 0;              /* null byte flag to recv_fd() */
	    if (sendmsg(fd, &msg, 0) != 2)
	        return(-1);
	    return(0);
	}


	在sendmsg调用中，我们发送协议数据（null和状态字节）以及文件描述符号。
	为接收一个文件描述符号，我们需要分配足够的空间给cmsghdr结构以及文件描述符号，设置msg_control指向分配的区域，然后调用recvmsg。我们使用CMSG_LEN宏来计算需要的空间。
	我们从套接字读取，直到读取到状态字节之前的null字节。所有到达这个null字节的都是来自发送者的错误消息，请看如下代码：

	用于UNIX域套接字的recv_fd函数
	#include "apue.h"
	#include <sys/socket.h>     /* struct msghdr */

	/* size of control buffer to send/recv one file descriptor */
	#define CONTROLLEN  CMSG_LEN(sizeof(int))
	static struct cmsghdr   *cmptr = NULL;      /* malloc'ed first time */
	/*
	 * Receive a file descriptor from a server process.  Also, any data
	 * received is passed to (*userfunc)(STDERR_FILENO, buf, nbytes).
	 * We have a 2-byte protocol for receiving the fd from send_fd().
	 */
	int recv_fd(int fd, ssize_t (*userfunc)(int, const void *, size_t))
	{
	   int             newfd, nr, status;
	   char            *ptr;
	   char            buf[MAXLINE];
	   struct iovec    iov[1];
	   struct msghdr   msg;

	   status = -1;
	   for ( ; ; ) {
	       iov[0].iov_base = buf;
	       iov[0].iov_len  = sizeof(buf);
	       msg.msg_iov     = iov;
	       msg.msg_iovlen  = 1;
	       msg.msg_name    = NULL;
	       msg.msg_namelen = 0;
	       if (cmptr == NULL && (cmptr = malloc(CONTROLLEN)) == NULL)
	           return(-1);
	       msg.msg_control    = cmptr;
	       msg.msg_controllen = CONTROLLEN;
	       if ((nr = recvmsg(fd, &msg, 0)) < 0) {
	           err_sys("recvmsg error");
	       } else if (nr == 0) {
	           err_ret("connection closed by server");
	           return(-1);
	       }
	       /*
	        * See if this is the final data with null & status.  Null
	        * is next to last byte of buffer; status byte is last byte.
	        * Zero status means there is a file descriptor to receive.
	        */
	       for (ptr = buf; ptr < &buf[nr]; ) {
	           if (*ptr++ == 0) {
	               if (ptr != &buf[nr-1])
	                   err_dump("message format error");
	               status = *ptr & 0xFF;  /* prevent sign extension */
	               if (status == 0) {
	                   if (msg.msg_controllen != CONTROLLEN)
	                       err_dump("status = 0 but no fd");
	                   newfd = *(int *)CMSG_DATA(cmptr);
	               } else {
	                   newfd = -status;
	               }
	               nr -= 2;
	           }
	        }
	        if (nr > 0 && (*userfunc)(STDERR_FILENO, buf, nr) != nr)
	            return(-1);
	        if (status >= 0)    /* final data has arrived */
	            return(newfd);  /* descriptor, or -status */
	   }
	}
	注意，我们一直在准备接收一个文件描述符号（每次调用recvmsg之前，我们设置msg_control和msg_controllen），但是，只有msg_controllen返回为非0的时候，我们才接收一个文件描述符号。
	当传递文件描述符号的时候，一个UNIX域套接字和STREAMS pipes不同的地方就是，使用STREAMS pipes我们需要获取发送进程的进程标识。有些版本的UNIX域套接字提供类似的功能，但是接口却是不同的。
	FreeBSD 5.2.1和Linux 2.4.22提供通过UNIX域套接字发送凭证的支持，但是它们用不同的方式来做。Mac OS X 10.3有些部分继承自FreeBSD，但是不能传递凭证。Solaris 9不支持在UNIX域套接字上面发送凭证。

	通过使用FreeBSD，凭证通过cmsgcred结构来传送：
	#define CMGROUP_MAX 16
	struct cmsgcred {
		pid_t cmcred_pid;                   /* sender's process ID */
		uid_t cmcred_uid;                   /* sender's real UID */
		uid_t cmcred_euid;                  /* sender's effective UID */
		gid_t cmcred_gid;                   /* sender's real GID */
		short cmcred_ngroups;               /* number of groups */
		gid_t cmcred_groups[CMGROUP_MAX];   /* groups */
	};
	当我们传输凭证的时候，我们只需要为cmsgcred结构保留空间。内核将会帮助我们填充它以防止应用程序假装已经有了不同的标识。
	在Linux上面，凭证以ucred结构来传输：
	struct ucred {
		uint32_t pid;   /* sender's process ID */
		uint32_t uid;   /* sender's user ID */
		uint32_t gid;   /* sender's group ID */
	};
	和FreeBSD不同，Linux需要我们在传输这个结构之前初始化这个结构。内核将会保证应用程序要么使用与调用者相关的值要么有合适的权限使用其他的值。

	下面的代码展示了包含发送进程凭证的send_fd函数
	通过UNIX域套接字发送凭证
	#include "apue.h"
	#include <sys/socket.h>

	#if defined(SCM_CREDS)          /* BSD interface */
	#define CREDSTRUCT      cmsgcred
	#define SCM_CREDTYPE    SCM_CREDS
	#elif defined(SCM_CREDENTIALS)  /* Linux interface */
	#define CREDSTRUCT      ucred
	#define SCM_CREDTYPE    SCM_CREDENTIALS
	#else
	#error passing credentials is unsupported!
	#endif

	/* size of control buffer to send/recv one file descriptor */
	#define RIGHTSLEN   CMSG_LEN(sizeof(int))
	#define CREDSLEN    CMSG_LEN(sizeof(struct CREDSTRUCT))
	#define CONTROLLEN  (RIGHTSLEN + CREDSLEN)

	static struct cmsghdr   *cmptr = NULL;  /* malloc'ed first time */

	/*
	 * Pass a file descriptor to another process.
	 * If fd<0, then -fd is sent back instead as the error status.
	 */
	int send_fd(int fd, int fd_to_send)
	{
	    struct CREDSTRUCT   *credp;
	    struct cmsghdr      *cmp;
	    struct iovec        iov[1];
	    struct msghdr       msg;
	    char                buf[2]; /* send_fd/recv_ufd 2-byte protocol */

	    iov[0].iov_base = buf;
	    iov[0].iov_len =  2;
	    msg.msg_iov     = iov;
	    msg.msg_iovlen =  1;
	    msg.msg_name    = NULL;
	    msg.msg_namelen = 0;
	    msg.msg_flags = 0;
	    if (fd_to_send < 0) {
	        msg.msg_control    = NULL;
	        msg.msg_controllen = 0;
	        buf[1] = -fd_to_send;   /* nonzero status means error */
	        if (buf[1] == 0)
	            buf[1] = 1; /* -256, etc. would screw up protocol */
	    } else {
	        if (cmptr == NULL && (cmptr = malloc(CONTROLLEN)) == NULL)
	            return(-1);
	        msg.msg_control    = cmptr;
	        msg.msg_controllen = CONTROLLEN;
	        cmp = cmptr;
	        cmp->cmsg_level =  SOL_SOCKET;
	        cmp->cmsg_type   = SCM_RIGHTS;
	        cmp->cmsg_len    = RIGHTSLEN;
	        *(int *)CMSG_DATA(cmp) = fd_to_send;   /* the fd to pass */

	        cmp = CMSG_NXTHDR(&msg, cmp);
	        cmp->cmsg_level =  SOL_SOCKET;
	        cmp->cmsg_type   = SCM_CREDTYPE;
	        cmp->cmsg_len    = CREDSLEN;
	        credp = (struct CREDSTRUCT *)CMSG_DATA(cmp);
	#if defined(SCM_CREDENTIALS)
	        credp->uid = geteuid();
	        credp->gid = getegid();
	        credp->pid = getpid();
	#endif
	        buf[1] = 0;     /* zero status means OK */
	    }
	    buf[0] = 0;         /* null byte flag to recv_ufd() */
	    if (sendmsg(fd, &msg, 0) != 2)
	        return(-1);
	    return(0);
	}
	需要注意的是，我们只需要在Linux上面初始化凭证的数据结构。

	下面的recv_ufd函数改自recv_fd，通过引用参数返回发送者的用户ID。
	通过UNIX域套接字接收凭证
	#include "apue.h"
	#include <sys/socket.h>     /* struct msghdr */
	#include <sys/un.h>

	#if defined(SCM_CREDS)          /* BSD interface */
	#define CREDSTRUCT      cmsgcred
	#define CR_UID          cmcred_uid
	#define CREDOPT         LOCAL_PEERCRED
	#define SCM_CREDTYPE    SCM_CREDS
	#elif defined(SCM_CREDENTIALS)  /* Linux interface */
	#define CREDSTRUCT      ucred
	#define CR_UID          uid
	#define CREDOPT         SO_PASSCRED
	#define SCM_CREDTYPE    SCM_CREDENTIALS
	#else
	#error passing credentials is unsupported!
	#endif

	/* size of control buffer to send/recv one file descriptor */
	#define RIGHTSLEN   CMSG_LEN(sizeof(int))
	#define CREDSLEN    CMSG_LEN(sizeof(struct CREDSTRUCT))
	#define CONTROLLEN  (RIGHTSLEN + CREDSLEN)

	static struct cmsghdr   *cmptr = NULL;      /* malloc'ed first time */

	/*
	 * Receive a file descriptor from a server process.  Also, any data
	 * received is passed to (*userfunc)(STDERR_FILENO, buf, nbytes).
	 * We have a 2-byte protocol for receiving the fd from send_fd().
	 */
	int recv_ufd(int fd, uid_t *uidptr, ssize_t (*userfunc)(int, const void *, size_t))
	{
	    struct cmsghdr      *cmp;
	    struct CREDSTRUCT   *credp;
	    int                 newfd, nr, status;
	    char                *ptr;
	    char                buf[MAXLINE];
	    struct iovec        iov[1];
	    struct msghdr       msg;
	    const int           on = 1;

	    status = -1;
	    newfd = -1;
	    if (setsockopt(fd, SOL_SOCKET, CREDOPT, &on, sizeof(int)) < 0) {
	        err_ret("setsockopt failed");
	        return(-1);
	    }
	    for ( ; ; ) {
	        iov[0].iov_base = buf;
	        iov[0].iov_len  = sizeof(buf);
	        msg.msg_iov     = iov;
	        msg.msg_iovlen  = 1;
	        msg.msg_name    = NULL;
	        msg.msg_namelen = 0;
	        if (cmptr == NULL && (cmptr = malloc(CONTROLLEN)) == NULL)
	            return(-1);
	        msg.msg_control    = cmptr;
	        msg.msg_controllen = CONTROLLEN;
	        if ((nr = recvmsg(fd, &msg, 0)) < 0) {
	            err_sys("recvmsg error");
	        } else if (nr == 0) {
	            err_ret("connection closed by server");
	            return(-1);
	        }
	        /*
	         * See if this is the final data with null & status.  Null
	         * is next to last byte of buffer; status byte is last byte.
	         * Zero status means there is a file descriptor to receive.
	         */
	        for (ptr = buf; ptr < &buf[nr]; ) {
	            if (*ptr++ == 0) {
	                if (ptr != &buf[nr-1])
	                    err_dump("message format error");
	                status = *ptr & 0xFF;   /* prevent sign extension */
	                if (status == 0) {
	                    if (msg.msg_controllen != CONTROLLEN)
	                        err_dump("status = 0 but no fd");

	                    /* process the control data */
	                    for (cmp = CMSG_FIRSTHDR(&msg);
	                      cmp != NULL; cmp = CMSG_NXTHDR(&msg, cmp)) {
	                        if (cmp->cmsg_level != SOL_SOCKET)
	                            continue;
	                        switch (cmp->cmsg_type) {
	                        case SCM_RIGHTS:
	                            newfd = *(int *)CMSG_DATA(cmp);
	                            break;
	                        case SCM_CREDTYPE:
	                            credp = (struct CREDSTRUCT *)CMSG_DATA(cmp);
	                            *uidptr = credp->CR_UID;
	                        }
	                    }
	                } else {
	                    newfd = -status;
	                }
	                nr -= 2;
	             }
	         }
	         if (nr > 0 && (*userfunc)(STDERR_FILENO, buf, nr) != nr)
	             return(-1);
	         if (status >= 0)    /* final data has arrived */
	             return(newfd);  /* descriptor, or -status */
	    }
	}
	在FreeBSD上面，我们指定SCM_CREDS来传输凭证，在Linux上面，我们使用SCM_CREDENTIALS来传输凭证。

	5)一个用于打开的服务进程，版本1
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch17lev1sec5.html
	通过传递文件描述符号，我们开发一个用于打开的服务进程，这个程序被一个进程执行来打开一个或者多个文件。但是服务进程不会将文件内容发送给调用进程，而是将一个被打开的文件描述符号发送给调用进程。这样服务进程可以工作在任何文件类型上面（例如套接字文件，设备文件等）而不仅仅是普通文件类型。这样通过IPC传输的数据也会最少，从客户到服务传递文件名称和文件打开模式，从服务到客户传递返回的文件描述符号；而文件的内容并不通过IPC进行传递。
	将服务进程设计成为一个独立的可执行程序有许多的好处(像本节这样我们可以通过调用exec来进行执行，或者像下一节我们可以将它当做一个守护服务进程):
	a)服务进程可以很容易地被客户进程连接上，就像使用库函数那样。我们并不是将服务硬编码到一个应用程序中，而是将它设计成为一个可以被其它者重用的通用工具。
	b)如果我们想要修改服务进程，那么只会影响到一个程序。相反更新一个库函数可能会导致所有的调用这个库函数的应用程序更新(也就是通过连接编辑器重新连接)，当然动态连接共享库可以简化这个过程。
	c)服务程序可以做为一个set-user-id程序，这样可以给客户进程提供额外它不具备的权限。而库函数(或共享库函数)无法提供这样的功能。

	客户进程创建一个s-pipe(stream-based pipe或者UNIX域套接字对)然后调用fork和exec执行服务程序，客户通过s-pipe发送请求，服务通过s-pipe响应请求。
	我们在客户和服务之间定义如下应用程序协议：
	a)客户通过s-pipe给服务进程发送"open <pathname> <openmode>\0" 形式的请求。<openmode>是一个数值，ASCII十进制的，open函数的第二个参数，请求字符串以null字节结束。
	b)服务进程通过调用send_fd或者send_err将打开的文件描述符号或者错误返回。
	下面是一个发送给父进程打开的文件描述符号的例子。后面我们会使用一个单个的守护进程服务的例子来修改这个程序，那里服务进程发送文件描述符号给一个完全没有关系的进程。

	首先我们定义头文件，包含了一些标准头文件和函数的声明：
	open.h头文件
	#include "apue.h"
	#include <errno.h>
	#define CL_OPEN "open"        /* client's request for server */
	int     csopen(char *, int);

	main函数就是一个循环，从标准输入读取路径，然后将文件拷贝到标准输出。这个函数调用csopen来连接打开文件的服务进程，并且返回一个打开的文件描述符号。
	客户进程的main函数（版本1）
	#include    "open.h"
	#include    <fcntl.h>
	#define BUFFSIZE    8192
	int main(int argc, char *argv[])
	{
	    int     n, fd;
	    char    buf[BUFFSIZE], line[MAXLINE];

	    /* read filename to cat from stdin */
	    while (fgets(line, MAXLINE, stdin) != NULL) {
	        if (line[strlen(line) - 1] == '\n')
	            line[strlen(line) - 1] = 0; /* replace newline with null */

	        /* open the file */
	        if ((fd = csopen(line, O_RDONLY)) < 0)
	            continue;   /* csopen() prints error from server */

	        /* and cat to stdout */
	        while ((n = read(fd, buf, BUFFSIZE)) > 0)
	            if (write(STDOUT_FILENO, buf, n) != n)
	                err_sys("write error");
	        if (n < 0)
	            err_sys("read error");
	        close(fd);
	    }

	    exit(0);
	}

	创建了s-pipe管道之后，函数csopen调用fork和exec服务进程。
	csopen函数（版本1）
	#include    "open.h"
	#include    <sys/uio.h>     /* struct iovec */
	/*
	 * Open the file by sending the "name" and "oflag" to the
	 * connection server and reading a file descriptor back.
	 */
	int csopen(char *name, int oflag)
	{
	    pid_t           pid;
	    int             len;
	    char            buf[10];
	    struct iovec    iov[3];
	    static int      fd[2] = { -1, -1 };

	    if (fd[0] < 0) {    /* fork/exec our open server first time */
	        if (s_pipe(fd) < 0)
	            err_sys("s_pipe error");
	        if ((pid = fork()) < 0) {
	            err_sys("fork error");
	        } else if (pid == 0) {      /* child */
	            close(fd[0]);
	            if (fd[1] != STDIN_FILENO &&
	              dup2(fd[1], STDIN_FILENO) != STDIN_FILENO)
	                err_sys("dup2 error to stdin");
	            if (fd[1] != STDOUT_FILENO &&
	              dup2(fd[1], STDOUT_FILENO) != STDOUT_FILENO)
	                err_sys("dup2 error to stdout");
	            if (execl("./opend", "opend", (char *)0) < 0)
	                err_sys("execl error");
	        }
	        close(fd[1]);               /* parent */
	    }
	    sprintf(buf, " %d", oflag);     /* oflag to ascii */
	    iov[0].iov_base = CL_OPEN " ";      /* string concatenation */
	    iov[0].iov_len  = strlen(CL_OPEN) + 1;
	    iov[1].iov_base = name;
	    iov[1].iov_len  = strlen(name);
	    iov[2].iov_base = buf;
	    iov[2].iov_len  = strlen(buf) + 1;  /* +1 for null at end of buf */
	    len = iov[0].iov_len + iov[1].iov_len + iov[2].iov_len;
	    if (writev(fd[0], &iov[0], 3) != len)
	        err_sys("writev error");

	    /* read descriptor, returned errors handled by write() */
	    return(recv_fd(fd[0], write));
	}

	子进程关闭管道的一端，父进程关闭另外一端。exec服务进程之前，子进程首先将管道的没有关闭的那端dup到其标准输入和标准输出中。(另外一个可以选择的就是将文件描述符号fd[1]的ASCII表示作为一个参数传递给服务进程)
	父进程给服务进程发送包含路径和open模式的请求。最后，父进程调用recv_fd来返回文件描述符号或者错误。如果错误被服务进程返回，那么向标准错误输出写相关的信息。

	现在我们来查看一下打开的服务进程。下面就是客户进程exec的opend程序的代码。首先我们需要有一个opend.h头文件，这个头文件包含一些标准的头文件以及声明一些全局变量和函数。
	opend.h头文件，版本1
	#include "apue.h"
	#include <errno.h>
	#define CL_OPEN "open"         /* client's request for server */

	extern char  errmsg[];  /* error message string to return to client */
	extern int   oflag;     /* open() flag: O_xxx ... */
	extern char *pathname;  /* of file to open() for client */

	int      cli_args(int, char **);
	void     request(char *, int, int);

	main函数读取s-pipe上面的客户的请求（从它的标准输入），并且调用函数request。
	服务进程的main函数，版本1
	#include    "opend.h"
	char     errmsg[MAXLINE];
	int      oflag;
	char    *pathname;
	int main(void)
	{
	    int     nread;
	    char    buf[MAXLINE];

	    for ( ; ; ) {   /* read arg buffer from client, process request */
	        if ((nread = read(STDIN_FILENO, buf, MAXLINE)) < 0)
	            err_sys("read error on stream pipe");
	        else if (nread == 0)
	            break;      /* client has closed the stream pipe */
	        request(buf, nread, STDOUT_FILENO);
	    }
	    exit(0);
	}

	函数request进行所有的处理工作。它调用函数buf_args来将客户的请求变成标准的参数列表形式，然后调用cli_args处理客户进程的参数。如果所有的工作做好了，那么open会被调用来打开文件，然后send_fd通过s-pipe发送文件描述符号给客户进程( 它的标准输出)。如果遇到了一个错误，那么通过使用我们之前描述的客户服务协议，send_err会被调用来将一个错误消息发送回去。
	request函数，版本1
	#include    "opend.h"
	#include    <fcntl.h>
	void request(char *buf, int nread, int fd)
	{
	    int     newfd;

	    if (buf[nread-1] != 0) {
	        sprintf(errmsg, "request not null terminated: %*.*s\n",
	          nread, nread, buf);
	        send_err(fd, -1, errmsg);
	        return;
	    }
	    if (buf_args(buf, cli_args) < 0) {  /* parse args & set options */
	        send_err(fd, -1, errmsg);
	        return;
	    }
	    if ((newfd = open(pathname, oflag)) < 0) {
	        sprintf(errmsg, "can't open %s: %s\n", pathname,
	          strerror(errno));
	        send_err(fd, -1, errmsg);
	        return;
	    }
	    if (send_fd(fd, newfd) < 0)     /* send the descriptor */
	        err_sys("send_fd error");
	    close(newfd);       /* we're done with descriptor */
	}
	客户请求是一个以null结束的，空白分割的字符串。下面的函数buf_args会将这个字符串变成标准argv形式的参数列表，然后调用用户函数处理相应的参数。本章后面我们将要使用buf_args函数。我们使用ISO的标准C函数strtok来将字符串分割成各个参数。
	buf_args函数
	#include "apue.h"
	#define MAXARGC     50  /* max number of arguments in buf */
	#define WHITE   " \t\n" /* white space for tokenizing arguments */
	/*
	 * buf[] contains white-space-separated arguments.  We convert it to an
	 * argv-style array of pointers, and call the user's function (optfunc)
	 * to process the array.  We return -1 if there's a problem parsing buf,
	 * else we return whatever optfunc() returns.  Note that user's buf[]
	 * array is modified (nulls placed after each token).
	 */
	int buf_args(char *buf, int (*optfunc)(int, char **))
	{
	    char    *ptr, *argv[MAXARGC];
	    int     argc;

	    if (strtok(buf, WHITE) == NULL)    /* an argv[0] is required */
	        return(-1);
	    argv[argc = 0] = buf;
	    while ((ptr = strtok(NULL, WHITE)) != NULL) {
	        if (++argc >= MAXARGC-1)    /* -1 for room for NULL at end */
	            return(-1);
	        argv[argc] = ptr;
	    }
	    argv[++argc] = NULL;

	    /*
	     * Since argv[] pointers point into the user's buf[],
	     * user's function can just copy the pointers, even
	     * though argv[] array will disappear on return.
	     */
	    return((*optfunc)(argc, argv));
	}

	被buf_args调用的服务进程的函数是cli_args。它会检查客户进程发送了正确的促使数目，然后将其中的路径和打开模式存放在全局的变量中去。函数代码如下：
	cli_args函数
	#include    "opend.h"
	/*
	 * This function is called by buf_args(), which is called by
	 * request().  buf_args() has broken up the client's buffer
	 * into an argv[]-style array, which we now process.
	 */
	int cli_args(int argc, char **argv)
	{
	    if (argc != 3 || strcmp(argv[0], CL_OPEN) != 0) {
	        strcpy(errmsg, "usage: <pathname> <oflag>\n");
	        return(-1);
	    }
	    pathname = argv[1];     /* save ptr to pathname to open */
	    oflag = atoi(argv[2]);
	    return(0);
	}
	这样就完成了打开文件服务进程，这个进程使用客户进程的fork和exec运行。fork之前会创建一个单个的s-pipe，然后使用这个s-pipe来在客户进程和服务进程之间进行通信。通过这个架构，对与每个客户，我们都有一个服务。

	6)一个用于打开的服务进程，版本2
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch17lev1sec6.html
	在前面的章节中，我们开发了一个用于打开文件的服务进程，这个服务进程通过客户进程使用fork和exec被运行，用这个例子展示了我们如何将一个文件描述符号从一个子进程传递给父进程。本节我们开发一个守护进程形式的打开服务进程。一个服务进程处理所有的客户进程请求，由于不用fork和exec了，所以我们期望这样的效率可能会更高。我们还是使用s-pipe在客户和服务进程之间传递文件描述符号（两个没有关系的进程）。我们将要使用前面介绍的三个函数：serv_listen，serv_accept和cli_conn。这个服务进程也展示了通过前面的select和poll函数如何处理多个客户进程。
	客户进程和前面的客户进程是一样的。实际上，文件main.c是一样的，我们向open.h头文件中添加了如下的行：
	#define CS_OPEN "/home/sar/opend" /* server's well-known name */

	文件open.c相比前面的有所变化，因为我们现在使用cli_conn而不是使用fork和exec了。下面就是相关的代码：
	csopen函数，版本2
	#include    "open.h"
	#include    <sys/uio.h>     /* struct iovec */

	/*
	 * Open the file by sending the "name" and "oflag" to the
	 * connection server and reading a file descriptor back.
	 */
	int csopen(char *name, int oflag)
	{
	    int             len;
	    char            buf[10];
	    struct iovec    iov[3];
	    static int      csfd = -1;

	    if (csfd < 0) {     /* open connection to conn server */
	        if ((csfd = cli_conn(CS_OPEN)) < 0)
	            err_sys("cli_conn error");
	    }

	    sprintf(buf, " %d", oflag);     /* oflag to ascii */
	    iov[0].iov_base = CL_OPEN " ";  /* string concatenation */
	    iov[0].iov_len  = strlen(CL_OPEN) + 1;
	    iov[1].iov_base = name;
	    iov[1].iov_len  = strlen(name);
	    iov[2].iov_base = buf;
	    iov[2].iov_len  = strlen(buf) + 1;  /* null always sent */
	    len = iov[0].iov_len + iov[1].iov_len + iov[2].iov_len;
	    if (writev(csfd, &iov[0], 3) != len)
	        err_sys("writev error");

	    /* read back descriptor; returned errors handled by write() */
	    return(recv_fd(csfd, write));
	}

	客户到服务进程之间的协议保持不变。
	下面，我们将要看到服务进程。头文件opend.h包含一些标准的头文件以及一些全局变量和函数的声明。如下所示：
	头文件opend.h，版本2
	#include "apue.h"
	#include <errno.h>

	#define CS_OPEN "/home/sar/opend"   /* well-known name */
	#define CL_OPEN "open"              /* client's request for server */

	extern int   debug;     /* nonzero if interactive (not daemon) */
	extern char  errmsg[];  /* error message string to return to client */
	extern int   oflag;     /* open flag: O_xxx ... */
	extern char *pathname;  /* of file to open for client */

	typedef struct {    /* one Client struct per connected client */
	  int   fd;         /* fd, or -1 if available */
	  uid_t uid;
	} Client;

	extern Client   *client;        /* ptr to malloc'ed array */
	extern int       client_size;   /* # entries in client[] array */

	int      cli_args(int, char **);
	int      client_add(int, uid_t);
	void     client_del(int);
	void     loop(void);
	void     request(char *, int, int, uid_t);

	因为服务进程处理所有的客户进程请求，它必须维护每个客户连接的状态。这个通过一个opend.h中的Client数组来做到。下面代码就定义了操作这个数组的三个函数：
	用来操作客户进程数组的函数
	#include    "opend.h"
	#define NALLOC  10   /* # client structs to alloc/realloc for */
	static void client_alloc(void)   /* alloc more entries in the client[] array */
	{
	    int     i;

	    if (client == NULL)
	        client = malloc(NALLOC * sizeof(Client));
	    else
	        client = realloc(client, (client_size+NALLOC)*sizeof(Client));
	    if (client == NULL)
	        err_sys("can't alloc for client array");

	    /* initialize the new entries */
	    for (i = client_size; i < client_size + NALLOC; i++)
	        client[i].fd = -1;  /* fd of -1 means entry available */

	    client_size += NALLOC;
	}
	/*
	 * Called by loop() when connection request from a new client arrives.
	 */
	int client_add(int fd, uid_t uid)
	{
	    int     i;

	    if (client == NULL)     /* first time we're called */
	        client_alloc();
	again:
	    for (i = 0; i < client_size; i++) {
	        if (client[i].fd == -1) {   /* find an available entry */
	            client[i].fd = fd;
	            client[i].uid = uid;
	            return(i);  /* return index in client[] array */
	        }
	    }
	    /* client array full, time to realloc for more */
	    client_alloc();
	    goto again;     /* and search again (will work this time) */
	}
	/*
	 * Called by loop() when we're done with a client.
	 */
	void client_del(int fd)
	{
	    int     i;

	    for (i = 0; i < client_size; i++) {
	        if (client[i].fd == fd) {
	            client[i].fd = -1;
	            return;
	        }
	    }
	    log_quit("can't find client entry for fd %d", fd);
	}
	client_add第一次被调用时，会调用client_alloc给数组分配10个条目的空间。当这10个条目都被使用完了之后，后面对client_add的调用会导致realloc再次分配额外的空间。通过用这个方式动态分配额外的空间，我们不用在编译之前限制客户进程数组的数目。因为服务进程是一个守护进程，所以以上函数如果出现了错误，我们使用之前定义的log_函数来提示错误信息。
	下面的代码中，main函数定义了全局变量，处理了命令行选项，然后调用函数循环。如果我们使用-d选项启动服务进程，那么服务进程会以交互的方式运行而不是守护进程了。当测试服务进程的时候，这个会被使用。

	服务进程的main函数，版本2
	#include    "opend.h"
	#include    <syslog.h>

	int      debug, oflag, client_size, log_to_stderr;
	char     errmsg[MAXLINE];
	char    *pathname;
	Client  *client = NULL;

	int main(int argc, char *argv[])
	{
	    int     c;

	    log_open("open.serv", LOG_PID, LOG_USER);

	    opterr = 0;     /* don't want getopt() writing to stderr */
	    while ((c = getopt(argc, argv, "d")) != EOF) {
	        switch (c) {
	        case 'd':       /* debug */
	            debug = log_to_stderr = 1;
	            break;

	        case '?':
	            err_quit("unrecognized option: -%c", optopt);
	        }
	    }

	    if (debug == 0)
	        daemonize("opend");

	    loop();     /* never returns */
	}

	loop函数导致服务进程进入无限死循环。我们将会看到这个函数的两个版本。下面的代码显示了使用select的版本。后面的代码将会显示使用poll的版本。
	使用select实现的loop函数
	#include    "opend.h"
	#include    <sys/time.h>
	#include    <sys/select.h>

	void loop(void)
	{
	    int     i, n, maxfd, maxi, listenfd, clifd, nread;
	    char    buf[MAXLINE];
	    uid_t   uid;
	    fd_set  rset, allset;

	    FD_ZERO(&allset);

	    /* obtain fd to listen for client requests on */
	    if ((listenfd = serv_listen(CS_OPEN)) < 0)
	        log_sys("serv_listen error");
	    FD_SET(listenfd, &allset);
	    maxfd = listenfd;
	    maxi = -1;

	    for ( ; ; ) {
	        rset = allset;  /* rset gets modified each time around */
	        if ((n = select(maxfd + 1, &rset, NULL, NULL, NULL)) < 0)
	            log_sys("select error");

	        if (FD_ISSET(listenfd, &rset)) {
	            /* accept new client request */
	            if ((clifd = serv_accept(listenfd, &uid)) < 0)
	                log_sys("serv_accept error: %d", clifd);
	            i = client_add(clifd, uid);
	            FD_SET(clifd, &allset);
	            if (clifd > maxfd)
	                maxfd = clifd;  /* max fd for select() */
	            if (i > maxi)
	                maxi = i;   /* max index in client[] array */
	            log_msg("new connection: uid %d, fd %d", uid, clifd);
	            continue;
	        }
	        for (i = 0; i <= maxi; i++) {   /* go through client[] array */
	            if ((clifd = client[i].fd) < 0)
	                continue;
	            if (FD_ISSET(clifd, &rset)) {
	                /* read argument buffer from client */
	                if ((nread = read(clifd, buf, MAXLINE)) < 0) {
	                    log_sys("read error on fd %d", clifd);
	                } else if (nread == 0) {
	                    log_msg("closed: uid %d, fd %d",
	                      client[i].uid, clifd);
	                    client_del(clifd);  /* client has closed cxn */
	                    FD_CLR(clifd, &allset);
	                    close(clifd);
	                } else {    /* process client's request */
	                    request(buf, nread, clifd, client[i].uid);
	                }
	            }
	        }
	    }
	}
	这个函数调用serv_listen创建服务器端用于接收客户连接请求。剩下的部分就是一个循环，循环首先使用select调用。select返回的时候，可以确保两件事情：
	1.文件描述符号listenfd已经准备好了读取，也就是说，有某个新的客户进程调用了cli_conn。为了处理这个，我们调用serv_accept并且之后更新客户进程的数组以及相关的记录索引信息。（我们保存最大的文件描述符号号码以便传递select的第一个参数，我们也保存客户数组中被使用元素的最大索引）
	2.一个已经存在的客户连接准备好了被读取。这个意思是说，客户进程要么结束了，要么发送了一个新的请求。我们通过read返回0（文件结束符号）来确定客户进程已经终止。如果read返回正数，那么表明需要处理一个新的请求，这个请求通过我们调用request来进行处理。
	我们在allset文件描述符号集合中保存当前使用的文件描述符号。一个新的客户连接到服务器上的时候，会打开这个文件描述符号集合中的合适的位；当客户进程终止的时候，会关闭相应其中合适的位。
	无论客户进程的终止是自发的还是非自发的，当它终止的时候，我们经常能够知道，因为所有的客户的文件描述符号（包括连接到服务进程的）都会被内核自动地关闭。这一点和SXI的IPC机制有所不同。

	下面是使用poll实现的loop函数的代码
	使用poll的loop
	#include    "opend.h"
	#include    <poll.h>
	#if !defined(BSD) && !defined(MACOS)
	#include    <stropts.h>
	#endif

	void loop(void)
	{
	    int             i, maxi, listenfd, clifd, nread;
	    char            buf[MAXLINE];
	    uid_t           uid;
	    struct pollfd   *pollfd;

	    if ((pollfd = malloc(open_max() * sizeof(struct pollfd))) == NULL)
	        err_sys("malloc error");

	    /* obtain fd to listen for client requests on */
	    if ((listenfd = serv_listen(CS_OPEN)) < 0)
	        log_sys("serv_listen error");
	    client_add(listenfd, 0);    /* we use [0] for listenfd */
	    pollfd[0].fd = listenfd;
	    pollfd[0].events = POLLIN;
	    maxi = 0;

	    for ( ; ; ) {
	        if (poll(pollfd, maxi + 1, -1) < 0)
	            log_sys("poll error");

	        if (pollfd[0].revents & POLLIN) {
	            /* accept new client request */
	            if ((clifd = serv_accept(listenfd, &uid)) > 0)
	                log_sys("serv_accept error: %d", clifd);
	            i = client_add(clifd, uid);
	            pollfd[i].fd = clifd;
	            pollfd[i].events = POLLIN;
	            if (i > maxi)
	                maxi = i;
	            log_msg("new connection: uid %d, fd %d", uid, clifd);
	        }

	        for (i = 1; i <= maxi; i++) {
	            if ((clifd = client[i].fd) < 0)
	                continue;
	            if (pollfd[i].revents & POLLHUP) {
	                goto hungup;
	            } else if (pollfd[i].revents & POLLIN) {
	                /* read argument buffer from client */
	                if ((nread = read(clifd, buf, MAXLINE)) < 0) {
	                    log_sys("read error on fd %d", clifd);
	                } else if (nread == 0) {
	hungup:
	                    log_msg("closed: uid %d, fd %d",
	                      client[i].uid, clifd);
	                    client_del(clifd);  /* client has closed conn */
	                    pollfd[i].fd = -1;
	                    close(clifd);
	                } else {        /* process client's request */
	                    request(buf, nread, clifd, client[i].uid);
	                }
	            }
	        }
	    }
	}

	为了能够让客户进程和可能打开的的文件描述符号数量一样，我们动态分配pollfd结构数组的空间（前面我们定义过open_max函数）。
	我们使用客户数组的第一个项（下标为0）存放listenfd文件描述符号，这样，一个客户进程在客户数组上面的索引就和我们使用的pollfd数组上面的索引一样了。通过listenfd文件描述符号上面的POLLIN表示一个新的客户连接到达，如前类似，我们调用serv_accept来接收连接。
	对于一个已经存在的客户进程，我们处理用于poll的两个事件：客户进程的终止通过POLLHUP来进行表示，从一个已经存在的客户进程到来的新的请求通过POLLIN来表示。记得前面章节中的练习中说过,在仍旧存在数据可以从stream中被读取的时候，hang-up消息也可以到达stream的头。通过管道，我们想要在处理hangup之前读取所有的数据。但是这个服务进程中，当我们接收到来自客户进程的hangup的时候，我们就可以关闭到客户的连接（stream），这样会很高效地丢弃任何仍然存在在stream上面的数据，没有理由处理仍然在stream上面的请求，因为我们不会发送回任何的响应。

	和使用select实现的的loop函数一样，新的客户请求通过调用request函数被处理。这个函数和前面的版本类似，它也会调用buf_args,而这个buf_args再调用cli_args，但是因为这个服务进程是一个守护进程，它会将错误消息使用log方式登记而不是将它们打印到标准错误输出流中了。
	request函数，版本2
	#include    "opend.h"
	#include    <fcntl.h>

	void request(char *buf, int nread, int clifd, uid_t uid)
	{
	    int     newfd;

	    if (buf[nread-1] != 0) {
	        sprintf(errmsg,
	          "request from uid %d not null terminated: %*.*s\n",
	          uid, nread, nread, buf);
	        send_err(clifd, -1, errmsg);
	        return;
	    }
	    log_msg("request: %s, from uid %d", buf, uid);

	    /* parse the arguments, set options */
	    if (buf_args(buf, cli_args) < 0) {
	        send_err(clifd, -1, errmsg);
	        log_msg(errmsg);
	        return;
	    }

	    if ((newfd = open(pathname, oflag)) < 0) {
	        sprintf(errmsg, "can't open %s: %s\n",
	          pathname, strerror(errno));
	        send_err(clifd, -1, errmsg);
	        log_msg(errmsg);
	        return;
	    }

	    /* send the descriptor */
	    if (send_fd(clifd, newfd) < 0)
	        log_sys("send_fd error");
	    log_msg("sent fd %d over fd %d for %s", newfd, clifd, pathname);
	    close(newfd);       /* we're done with descriptor */
	}
	这就是第二个版本的打开服务进程，它做为一个守护进程处理所有的客户请求。

	7)总结
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch17lev1sec7.html
	这个章节的关键之处就是在进程之间传递文件描述符号，以及接收来自客户进程的单一连接的能力。我们已经看到了使用STREADM pipes和UNIX域套接字对此如何进行实现。尽管所有的平台都支持UNIX域套接字，但是实现都有所不同，所以增加了我们开发可移植的程序的难度。
	我们也开发了两个版本的打开文件服务程序，一个版本通过客户进程调用fork和exec来执行；另外一个是采用守护进程的方式来处理所有的用户请求。两个版本都使用了文件描述符号的传递和接收函数。后面的版本也使用了前面介绍的客户服务连接相关的函数，以及前面的多I/O函数。

*终端输入输出
==========================
1)简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec1.html
无论什么操作系统，对于终端输入输出的处理都是一个非常杂乱的领域。UNIX系统也是这样。一般在大多数编程手册中，终端输入输出是最长的部分。
对于UNIX系统，在1970s出现了一个分歧，System III开发了一套和version7不一样的终端函数集合。SystemIII形式的终端输入输出在System V中延续下来，而Version 7形式的成为基于BSD系统的标准。和信号处理一样，这两个不同的分歧在POSIX.1中不存在了。本章我们将要看到所有POSIX.1的终端相关函数以及一些平台特定的内容。
终端输入输出之所以很复杂，其一部分原因也是因为人们使用终端输入输出来做许多事情：终端，计算机之间的硬连接线，调制解调(modems)，打印机等等。

2)概要
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec2.html
终端输入输出有两种模式：
a)通常模式(后面使用canonical模式来表示)的输入处理。这种模式下，终端的输入被做为一行来进行处理。终端的驱动在每次read请求的时候返回至多一行。
b)非通常的模式(后面使用非canonical模式)输入处理。输入的字符并不会积攒为一行来进行处理。
如果我们不做任何的特殊处理，那么canonical模式就是默认的。例如shell将标准输入重新定向到终端，我们使用read和write将标准输入拷贝到标准输出，那么终端处于canonical模式，每次read会返回至多一行。而像vi编辑器这样处理整个屏幕的应用程序，一般都使用非canonical模式，因为其命令可能为单个字符而不以行结束符结尾。这个编辑器也不想系统处理一些特殊字符，因为这些字符可能会与它们本身的一些命令相互冲突，例如，Control-D在终端中一般表示文件的结尾，而它同时在vi中也是一个命令，表示滚动半个屏幕。
version7和原来bsd形式的终端驱动有三种终端输入模式：a)cooked模式（输入会被收集成行并且特殊符号会被处理）b)raw模式（输入不会被收集成行也不会处理特殊符号）c)cbreak模式（输入会被收集成行并且一些特殊符号会被处理）后面会给出一个函数tty_cbreak这个函数可以将终端设置成为cbreak或者raw模式。
POSIX.1定义了11个特殊的输入字符，我们可以修改其中的9个。本文中我们已经使用到了其中的一些，例如文件结束符号（一般都是Control-D），以及挂起字符(一般为Control-Z)，后面章节对应的参考资料中有相应的列表专门列出这些字符。
我们可以假设在内核中终端设备被终端驱动所控制。如下图所示，每个终端设备都有一个输入队列和输出队列。

终端设备输入队列和输出队列的逻辑图形
     next character written            next character read
          by process                         by process
               |                                  ^
               |                                  |
+--------------v-+ if echo enabled +--------------|-+- - - -
|  output queue  |<----------------|  input queue   |       |
+-|--------------+                 +-^--------------+- - - -
  |                                  |<------MAX_INPUT------>
  v                                  |
next character to                  next character
transmit to device                 read from device

对于上面的图形，有几点需要考虑：
a)如果如果echo被激活，那么在输入队列和输出队列之间有一个（隐含的）连接。
b)输入队列的大小，MAX_INPUT，是有限的。当某一个特定设备的输入队列被填满的时候，系统行为依赖于它的实现。大多数UNIX系统这个时候会响铃（也就是使用echo显示响铃字符）。
c)还有一个输入限制，MAX_CANON，我们这里不展示。这个限制表示通常输入的一行的最大字节数目。
d)虽然输出队列的大小是有限的，但是并没有可以让程序中可以访问到的对应常数来定义那个大小，因为当输出队列被填满的时候，内核只是简单地将写入进程设置为睡眠状态，直到有空间可以使用。
e)我们将会看到刷新函数tcflush是如何刷新输入和输出队列的。类似地，当我们描述tcsetattr函数的时候，我们将会看到（仅在输出队列空的情况下）我们如何让系统改变终端设备的属性。我们也可以在改变终端属性的时候告诉系统忽略输入队列中的所有内容。（如果我们正在改变输入属性或者在通常模式下进行切换，我们会想要这样做的，这样，之前输入的字符就不会在错误的模式下被解释了）
多数UNIX系统在一个被叫做"terminal line discipline"的模块下面执行通常模式处理。我们可以将这个模块想像成一个位于内核通用的read、write函数与实际设备驱动之间的盒子。参见下图。
           Terminal line discipline

              user process
                   ^
                   |
    +--------------|-------------+
    |              |             |
    |    +---------v--------+    |
    |    |  read and write  |    |
    |    |     functions    |    |
    |    +--------------^---+    |
    |          |        |        |
    |          |        |        |
    |          |        |        |
    |    +-----v------------+    |
    |    |     terminal     |    | kernel
    |    |  line discepline |    |
    |    +--------------^---+    |
    |          |        |        |
    |          |        |        |
    |          |        |        |
    |    +-----v------------+    |
    |    |     terminal     |    |
    |    |  device driver   |    |
    |    +---------^--------+    |
    |              |             |
    +--------------|-------------+
                   |
                   v
             actual device
注意这个图形和前面"A stream with a processing module"的类似之处。我们将会在后面我们讨论伪终端时回到这个图形。

我们能够检查以及改变的所有终端设备特性，都存放在一个termios结构中。这个结构定义在头文件<termios.h>里面，我们这一章都会使用这个结构。
struct termios {
	tcflag_t  c_iflag;    /* input flags */
	tcflag_t  c_oflag;    /* output flags */
	tcflag_t  c_cflag;    /* control flags */
	tcflag_t  c_lflag;    /* local flags */
	cc_t      c_cc[NCCS]; /* control characters */
};

大体来说，"input flags"控制终端设备驱动的输入字符（去掉输入的第8位，输入等值检测等）。"output flags"控制驱动输出（进行输出处理，将换行符号映射成CR/LF等等）。"control flags"影响RS-232串口（忽略modem状态行，每个字符有一或两个停止位等）。"local flags"影响驱动和用户之间的接口（echo与否，擦除字符，终端是否发起信号，用于后台输出的作业控制停止信号等）。

tcflag_t类型应该足够大，以容纳每个flag值，并且它经常被定义成unsigned int或者unsigned long。数组c_cc包含所有我们能够改变的特殊字符。NCCS是这个数组中的元素数目，大概为15到20之间（因为大多数UNIX系统的实现支持11个以上的POSIX定义的特殊字符）。cc_t类型有足够的空间可以容纳每个特殊字符，一般为unsigned char类型。
SystemV比POSIX标准要早，它已经有一个头文件，名字叫<termio.h>，以及一个结构termio。所以，POSIX.1给这个名字添加了一个s，用以区分。

这里，给出了几个表(在这个里面，限于篇幅就不列出来了)，用来列出所有我们可以改变的终端标记，通过修改这些标记，我们可以影响一个终端设备的特性。注意，尽管Single UNIX Specification定义了适用所有平台的公共子集，所有的实现也都有他们自己的额外的标记。所有这些额外的标记来自各自系统之间不同的历史。
列出的，表格包含了
	tcflag_t  c_iflag;    /* input flags */
	tcflag_t  c_oflag;    /* output flags */
	tcflag_t  c_cflag;    /* control flags */
	tcflag_t  c_lflag;    /* local flags */
这四个标记可能的取值以及对应的含义。本书在后面详细地对这些标记进行讨论。这里省略了。
假设上面所有的选项都是可用的，我们如何检查和改变终端设备的这些特性呢？下表中就列出了Single UNIX Specification定义的用于操作这些终端设备的不同的函数。(所有的函数都是基本的POSIX标准的一部分。tcgetsid函数除外，这个函数是一个XSI扩展标准，我们在前面章节中讨论过tcgetpgrp, tcgetsid, 和 tcsetpgrp这三个函数)
终端I/O函数
┌─────────────┬───────────────────────────────┐
│  Function   │         Description           │
├─────────────┼───────────────────────────────┤
│ tcgetattr   │ 获取属性 (termios 结构)       │
├─────────────┼───────────────────────────────┤
│ tcsetattr   │ 设置属性 (termios 结构)       │
├─────────────┼───────────────────────────────┤
│ cfgetispeed │ 获得输入速度                  │
├─────────────┼───────────────────────────────┤
│ cfgetospeed │ 获得输出速度                  │
├─────────────┼───────────────────────────────┤
│ cfsetispeed │ 设置输入速度                  │
├─────────────┼───────────────────────────────┤
│ cfsetospeed │ 设置输出速度                  │
├─────────────┼───────────────────────────────┤
│ tcdrain     │ 等待所有的输出被传输          │
├─────────────┼───────────────────────────────┤
│ tcflow      │ 挂起传输或者接收              │
├─────────────┼───────────────────────────────┤
│ tcflush     │ 刷新挂起的输入和／或输出      │
├─────────────┼───────────────────────────────┤
│ tcsendbreak │ 发送 BREAK 字符               │
├─────────────┼───────────────────────────────┤
│ tcgetpgrp   │ 获取前台进程组ID              │
├─────────────┼───────────────────────────────┤
│ tcsetpgrp   │ 设置前台进程组ID              │
├─────────────┼───────────────────────────────┤
│ tcgetsid    │ 获取用于控制TTY（XSI扩展）的  │
│             │ session leader的进程组ID      │
└─────────────┴───────────────────────────────┘
要注意的是，Single UNIX Specification没有使用ioctl来操作终端设备。相反，它使用以上的13个函数。原因是，用于终端设备的ioctl函数使用不同的数据结构用于它的最终参数，这取决于被执行的动作。这使得参数的类型检查，变得不太可能。
虽然只有13个函数用来操作终端设备，但是前面的两个函数(tcgetattr和tcsetattr)操作了几乎70多种不同的标记，处理终端设备的复杂之处在于终端设备中大量的可用选项以及确定对于一个特定的设备，哪个选项是需要的（是一个终端，还是modem，是打印机，还是别的什么）。
前面列出来的13个函数之间的关系，参见下面的图形。
                          终端设备相关函数之间的关系图
                      ^                ^
         cfsetispeed  |  cfsetospeed   |
             |   cfgetispeed  |   cfgetospeed
             |        |       |        |
        /+---v------------+---v------------+
struct / |input baud rate |output baud rate|
 termios +----------------+----------------+                                        foreground
       \ |                                 |                                    process group ID
        \+-------------------------^-------+      line control functions         ^      ^
                 |                 |             |      |       |      |         |      |      |
            tcsetattr              |      tcsendbreak   |   tcflush    |         |      |  tcsetpgrp
                 |                 |             |  tcdrain     |   tcflow       |  tcgetpgrp  |
                 |             tcgetattr         |      |       |      |     tcgetsid   |      |
                 |                 |             |      |       |      |         |      |      |
         +-------v-------------------------------v------v-------v------v-----------------------v----+
         |                  terminal line displine / terminal device driver                         |
         +------------------------------------------------------------------------------------------+

POSIX.1没有指定将波特率(baud rate)信息存放在termios结构中的哪里：因为这是一个实现的细节。有些系统，例如Linux和Solaris，会将这个信息存放在c_cflag域。基于BSD的系统，例如FreeBSD和Mac OS X在这个结构中有两个独立的域：一个用来存放输入速度，一个用来存放输出速度。

3)特殊输入字符
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec3.html
POSIX.1定义了输入时候需要处理的11个特殊字符，有些实现定义了额外的字符，请参考参考资料中的表，这里就不列举了。后面我们会对它们依次进行描述。
(这些特殊符号，例如回车，换行，退格等，通过在终端键入特殊按键来输入，例如^H，其实是[Control]H)
对于11个POSIX.1特殊字符，我们可以将其中的9个修改成我们喜欢的任何值。换行符号和回车符号是不能改变的（分别是\n和\r），并且可能STOP和START字符也可能不能改变（取决与具体实现）。我们通过修改termios结构中的c_cc数组成员中的特定元素来实现这个目的。这个数组成员中的元素通过一个名称被索引到，而这个名称以V开头，本书上节参考资料前面列出的表中的第三列中的元素就是。

POSIX.1允许我们禁止这些字符。如果我们设置c_cc数组中的一个元素值为_POSIX_VDISABLE，那么我们就相当与将相应的特殊符号给禁止了。
早期版本的Single UNIX Specification对_POSIX_VDISABLE的支持是可选的，而现在它已经变成了需要的了。
本文中的所有四种平台都支持这个特性。Linux 2.4.22和Solaris 9 将_POSIX_VDISABLE定义为0，FreeBSD 5.2.1和Mac OS X 10.3将它定义成0xff。
有些早期的UNIX系统会在相应的特殊输入字符为0的时候，禁止某个特性。

举例
在我们详细描述所有的特殊字符的时候，我们来看一下一个修改它们的小程序。下面代码中的程序禁止了中断字符，并且设置文件结束字符为Control-B。

禁止中断和改变文件结束符号的小程序
#include "apue.h"
#include <termios.h>
int main(void)
{
	struct termios term;
	long           vdisable;

	if (isatty(STDIN_FILENO) == 0)
		err_quit("standard input is not a terminal device");

	if ((vdisable = fpathconf(STDIN_FILENO, _PC_VDISABLE)) < 0)
		err_quit("fpathconf error or _POSIX_VDISABLE not in effect");

	if (tcgetattr(STDIN_FILENO, &term) < 0) /* fetch tty state */
		err_sys("tcgetattr error");

	term.c_cc[VINTR] = vdisable;    /* disable INTR character */
	term.c_cc[VEOF]  = 2;           /* EOF is Control-B */

	if (tcsetattr(STDIN_FILENO, TCSAFLUSH, &term) < 0)
		err_sys("tcsetattr error");

	exit(0);
}
对于这个程序，我们注意如下几点：
a)我们只有在标准输入是终端设备的时候，才会修改终端字符。我们调用isatty函数来对此进行检测。
b)我们使用fpathconf函数来获得_POSIX_VDISABLE值。
c)函数tcgetattr从内核获取一个termios结构。在我们修改了这个结构之后，我们调用tcsetattr函数来设置相应属性。所变化的属性只是我们特别修改的那些属性。
d)禁止中断键和忽略中断信号不一样。上面代码中的程序只是禁止了导致终端驱动产生SIGINT信号的特殊字符，我们还是可以通过kill函数来给进程发送这个SIGINT信号的。
下面我们具体讨论每个特殊的字符。我们把这些字符称作特殊输入字符，但是有两个字符，STOP和START（Control-S和Control-Q），也会在输出的时候被特殊处理。注意，当这些特殊字符被终端驱动认出并且进行特殊处理之后，这些字符然后就会被丢弃：也就是说，他们不会在read操作中返回给进程。对于这个的一个例外就是，换行符号(NL,EOL,EOL2)和回车符号(CR)不这样。

CR
回车(carriage return)字符。我们无法改变这个字符，这个字符在通常(canonical)输入模式中被识别。当ICANON(canonical模式)和ICRNL(将CR映射成NL)被设置，并且IGNCR(忽略CR)没有被设置的时候，(它们都是前面的c_iflag标记)CR字符就被转换成NL字符，并且和NL字符具有一样的功能。这个字符（可能被转换成NL之后）被返回给读取进程。

DISCARD
丢弃(discard)字符。这个字符，在extended(IEXTEN)输入模式中被识别，导致接下来的输出被丢弃，直到输入另外一个DISCARD字符或者清除了丢弃条件（参见FLUSHO选项）。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

DSUSP
延迟挂起(delayed-suspend)作业控制(job-control)字符。如果支持作业控制并且ISIG标记(前面的c_lflag)被设置，这个字符在extended(IEXTEN)输入模式中被识别。如同SUSP字符，这个延迟挂起字符产生SIGSTP信号，发送给所有前台的进程组。但是延迟挂起字符只有在进程从控制终端读取的时候才产生信号，而不是字符被打入的时候。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

EOF
文件结束(end-of-file)字符。这个字符在canonical输入模式(ICANON)中被识别。当我们键入这个字符的时候，所有等待被读取的字节都会被立即被传递给读取进程。如果没有其他字节等待被读取，那么会返回0。在一行的开始输入EOF字符是一个告诉程序到达文件结束的常用的方法。这个字符在canonical模式之中被处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

EOL
额外的行定界字符。类似NL，这个字符在canonical输入模式(ICANON)中被识别，并且会被返回给读取的进程；然而这个字符一般来说都不会使用。

EOL2
另外的行定界字符。类似NL，这个字符和EOL字符处理的方式一样。

ERASE
擦除字符（backspace）。这个字符在canonical输入模式(ICANON)中被识别，并且擦除本行中前面的字符，不会擦除本行开始以前的字符。这个字符在canonical模式中处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

ERASE2
一个可选的擦除字符(backspace)。这个字符的处理方式和ERASE字符的处理方式一样。

INTR
中断字符。这个字符在ISIG标记被设置的时候会在输入的时候被识别出来(前面的c_lflag)，并且产生SIGINT信号，发送给所有前台进程组的进程。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

KILL
kill字符。（名称kill已经被过度的使用了;记得前面我们发送信号给进程的时候就调用kill函数，而这里这个字符应该被称作行擦除字符，它和信号没有太大的关系）这个字符在canonical输入模式(ICANON)中被识别，它会擦除整行的字符，这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

LNEXT
literal-next字符。这个字符，在extended(IEXTEN)输入模式中被识别并且导致任何接下来的字符的特殊含义会忽略（我的理解是，输入这个字符之后，后面字符如果是特殊字符，那么它的特殊含义会被取消，当做正常字符了）。这个对于本节中我们所列出的所有的特殊字符都是管用的。我们使用这个字符就可以向应用程序键入任何字符。LNEXT字符会在处理之后被忽略，但是在它后面输入的特殊字符（包括LNEXT字符本身）会被传递给进程。

NL
新行(newline)字符，也被称作行定界符号。我们无法改变这个字符，这个字符在canonical输入模式(ICANON)中被识别，会被返回给读取的进程。

QUIT
退出(quit)字符。这个字符再ISIG标记被设置的时候会被识别。quit字符产生SIGQUIT信号，这个信号被发送给所有前台进程组的进程。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。
记得之前我们说过INTR和QUIT的不同在于QUIT字符不仅仅终止进程，而且还产生core文件(就是包含了进程运行时候内存状态信息的文件)。

REPRINT
reprint字符。这个字符，在extended输入模式中，以及canonical输入模式中（IEXTEN和ICANON标记都被设置）被识别，并且导致所有没有读取的输入被输出（reechoed）。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

START
start字符。这个字符会在IXON标记被设置的时候在输入的时候被识别，并且在设置了IXOFF标记(c_iflag)的时候会自动产生为输出。设置IXON之后接收到START字符会导致（之前由于输入STOP字符）被停止的输出被重新开始。在这情况下，这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。
当IXOFF被设置的时候，终端驱动自动产生一个START字符来重新开始之前被停止了的输入，当然，这是在新的输入不会覆盖输入缓存的时候。

STATUS
BSD的status-request字符。这个字符，在extended输入模式中，以及canonical输入模式中（IEXTEN和ICANON标记都被设置）被识别，并且产生SIGINFO信号，这个信号会被发送给所有前台的进程组的进程。另外，如果NOKERNINFO标记(c_lflag)没有被设置的时候，前台进程组的状态信息也会被显示到终端上面。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

STOP
stop字符。这个字符会在IXON标记被设置的时候在输入的时候被识别，并且在设置了IXOFF标记(c_iflag)的时候会自动产生为输出。在IXON被设置的时候，接收到STOP字符会停止输出。这个时候，这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。被停止的输出会在START字符被键入的时候重新开始。
当IXOFF被设置的时候，终端驱动会自动产生STOP阻止输入缓存被溢出。

SUSP
作业控制(job-control)挂起字符。如果支持作业控制，并且ISIG标记被设置的时候，那么这个字符回在输入的时候被识别出来。这个挂起字符会产生SIGTSTP信号，这个信号被发送给前台进程组中的所有进程。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

WERASE
word-erase字符。这个字符，在extended输入模式中，以及canonical输入模式中（IEXTEN和ICANON标记都被设置）被识别，并且导致前面的单词被删除。首先它向后跳过任何空白（空格或者tab键），然后向后跳过前面的token，导致光标停止在前面token所在的第一个字符。一般来说，token会在遇到一个空白的时候结束（其实就是一直向前删除，直至遇到空白）。我们可以修改这个特性。然而得通过设置ALTWERASE标记。这个标记导致当遇到第一个非字母和数字的字符的时候，之前的token结束。这个字符处理之后就会被丢弃（也就是说，它不会被传递给相应的进程）。

另外一个我们需要为终端设备定义的字符是BREAK字符。BREAK其实并不真正是一个字符，但是它表示一个在串口数据异步传输的时候发生的一个条件。一个BREAK条件会根据串行接口，以各种不同方式发送信号给设备驱动。
大多数原来的串行终端有一个按键上面标记着BREAK，这个按键可以产生BREAK条件，所以大多数人才以为BREAK是一个字符。有些新的终端键盘没有BREAK按键了，在PC机上面，break可能会被用作其他目的。例如，windows命令解释器可能会通过键入Control-BREAK的时候被中断。
对于异步串行数据传输，一个BREAK就是一系列的0比特，这些0持续的时间比发送一个字节的时间要长。整个0比特序列被当做一个单个的BREAK。在后面，我们将会看到，如何通过函数tcsendbreak函数发送一个BREAK。

4)获取和设置终端属性
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec4.html
为了获取以及设置一个termios 结构，我们分别调用tcgetattr 和 tcsetattr函数，这也是按照我们想要终端操作什么的时候，检查和修改各种选项标记以及特殊字符的基本方法。
#include <termios.h>
int tcgetattr(int filedes, struct termios *termptr);
int tcsetattr(int filedes, int opt, const struct termios *termptr);
两个函数返回：如果成功都返回0，如果错误，返回1。
这两个函数都使用一个指向termios结构的指针，并且都返回当前终端属性状态或者设置终端的属性。因为这两个函数只操作终端设备，所以如果filedes如果没有引用一个终端设备的时候，它们会返回1并且设置errno为ENOTTY。

函数tcsetattr的opt参数的作用是，当我们想要新的终端属性起作用的时候，我们可以通过指定这个参数来实现。这个参数可以被指定的常数为如下这些：
TCSANOW 改变立即生效。
TCSADRAIN 改变在所有输出被传输完的时候发生。这个选项应该在我们改变输出参数的时候被使用。
TCSAFLUSH 改变在所有输出被传输完的时候发生。另外，如果发生变化的话，那么所有没有被读取的输入数据会被忽略（flushed）。
函数tcsetattr很让人困扰。这个函数在如果能够执行所要求的动作的时候会返回OK，甚至它并没有执行这些动作的时候也会返回OK。所以，如果这个函数返回了OK，我们还需要查看一下所请求的动作是否被执行了。也就是说，在我们调用完了tcsetattr函数设置了相应的属性之后，我们需要调用tcgetattr并且比较实际的终端属性和我们想要的属性，通过它们是否相同来确定是否真的执行了我们所请求的动作。

5)终端选项标记
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec5.html
这一节中，我们列出了各种终端选项标记，扩展了前面我们所省略的列表中的相应描述。列表以字母次序列出它们并且标记了这些选项是属于四个终端标记域中的哪一个。（控制选项的域，一般来说并不是像选项名字那样的明显）我们也会看见，每个选项通过Single UNIX Specification来定义，并且列出了支持它们的平台。

所有列出来的标记(flags)指定了一个或者多个我们需要打开或者清除的位，除非我们把flag叫做mask。一个mask定义了多个位，这些位组合在一起定义了一系列值的集合。我们对于mask和每个value都有一个定义好了的名字。例如，为了设置字符的大小，我们首先使用字符大小的mask也就是CSIZE将一些位清零，然后设置一个CS5, CS6, CS7, 或 CS8中之一的某个值。

有六个延迟值被Linux和Solaris支持，它们也是masks，它们分别是：BSDLY, CRDLY, FFDLY, NLDLY, TABDLY, 和 VtdLY。无论如何，延迟mask为0表示没有延迟，如果一个延迟被指定了，那么OFILL 和 OFDEL标记可以决定驱动是否做实际的延迟，或者是否来传输填充字符以取代之。

例子
下面的代码列出了使用这些mask来获取一个值或者设置一个值的例子
使用tcgetattr和tcsetattr函数的例子
#include "apue.h"
#include <termios.h>
int main(void)
{
    struct termios term;

    if (tcgetattr(STDIN_FILENO, &term) < 0)
        err_sys("tcgetattr error");

    switch (term.c_cflag & CSIZE) {
    case CS5:
        printf("5 bits/byte\n");
        break;
    case CS6:
        printf("6 bits/byte\n");
        break;
    case CS7:
        printf("7 bits/byte\n");
        break;
    case CS8:
        printf("8 bits/byte\n");
        break;
    default:
        printf("unknown bits/byte\n");
    }

    term.c_cflag &= ~CSIZE;     /* zero out the bits */
    term.c_cflag |= CS8;        /* set 8 bits/byte */
    if (tcsetattr(STDIN_FILENO, TCSANOW, &term) < 0)
        err_sys("tcsetattr error");

    exit(0);
}

我们现在对每个标记进行描述。
ALTWERASE (c_lflag, FreeBSD, Mac OS X)如果设置了这个，那么会在输入WERASE字符的时候使用一个可选的word-erase算法。不是向前移动直到遇到空白字符了，这个标记会导致WERASE字符向前移动，直到遇到第一个非字母和数字的字符。

BRKINT (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris)如果这个标记被设置，并且IGNBRK没有被设置，那么当接收到一个BREAK的时候会将输入和输出队列刷新，并且产生SIGINT信号。如果中断设备是一个控制终端，那么信号用于前台进程组。如果IGNBRK或者BRKINT都没有被设置，那么BREAK被做为一个单个的字符'\0'被读取，除非PARMRK被设置的时候，这样BREAK会被做为一个三个字节的序列\377, \0, \0。

BSDLY (c_oflag, XSI, Linux, Solaris)Backspace延迟mask，值为BSO或者BSI。

CBAUDEXT (c_cflag, Solaris)扩展波特率。用来使能大于B38400的波特率。（后面讨论波特率）

CCAR_OFLOW (c_cflag, FreeBSD, Mac OS X)通过使用RS-232 modem carrier signal(DCD, 被认为是 Data- Carrier-Detect)使能输出的硬件流控制。这个和MDMBUF标记一样。

CCTS_OFLOW (c_cflag, FreeBSD, Mac OS X, Solaris)通过使用Clear-To-Send(CTS)RS-232 signal使能输出的硬件流控制。

CDSR_OFLOW (c_cflag, FreeBSD, Mac OS X)根据Data-Set-Ready (DSR) RS-232 signal进行输出的流控制。

CDTR_IFLOW (c_cflag, FreeBSD, Mac OS X)根据Data-Terminal-Ready (DTR) RS-232 signal进行输入的流控制。

CIBAUDEXT (c_cflag, Solaris)扩展输入波特率。用来使能大于B38400的输入波特率。

CIGNORE (c_cflag, FreeBSD, Mac OS X)忽略控制标记。

CLOCAL (c_cflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris)如果设置了那么modem status lines会被忽略。这一般意味着设备被直接连接了。当这个标记没有被设置的时候，对于一个终端设备的打开经常会被阻塞，直至例如modem相应一个call以及建立一个连接。

CMSPAR (c_oflag, Linux) 选择标记或者空白一致(space parity)。如果PARODD被设置了，那么相应的parity位会被设置为始终为1。否则，parity位始终为0（space parity）。

CRDLY (c_oflag, XSI, Linux, Solaris) 回车返回延迟掩码。掩码值为 CR0, CR1, CR2, or CR3.

CREAD (c_cflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置，那么接收者被激活，并且字符可以被接收。

CRTSCTS (c_cflag, FreeBSD, Linux, Mac OS X, Solaris) 其动作取决于平台。对于Solaris中，会在设置的时候激活带外硬件流控制。在其他的三个平台上面，会激活带外和带内的硬件流控制。(等价 CCTS_OFLOW|CRTS_IFLOW).

CRTS_IFLOW (c_cflag, FreeBSD, Mac OS X, Solaris) 输入的Request-To-Send (RTS) 流控制。

CRTSXOFF (c_cflag, Solaris) 如果设置，那么带内硬件流控制会被激活。Request-To-Send RS-232信号的状态控制流控制。

CSIZE (c_cflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 这个成员是一个掩码，指定了用于传输和接收的每个字节的位的数目，大小不包含parity位，如果有的话，值可以是：CS5, CS6, CS7, and CS8, for 5, 6, 7, 每个字节分别 8 位.

CSTOPB (c_cflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置，那么会使用两个停止位；否则使用一个停止位。

ECHO (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置，那么输入字符会被回显给终端设备。输入的字符在canonical或者noncanonical模式中都可以显示。

ECHOCTL 如果被设置，并且如果ECHO被设置，那么除了TAB,NL,和START，STOP的ASCII控制字符（字符的范围在0-37之间）会被显示为^X，这里X代表控制字符+100之后形成的字符。也就是说，Control-A字符（ASCII码为10进制的1），会被显示成^A。类似，DELETE字符会被显示成^?。如果这个标记没有被设置，那么ASCII控制字符就以它们自己的形式被显示出来。也就是说，通过ECHO标记，这个标记可以影响canonical和noncanonical模式下面的控制字符的显示。
需要注意的是，有些系统显示的EOF字符有所不同，因为它的常用值为Control-D(Control-D是EOT字符的ASCII，导致终端挂起)，具体请参见你的手册。

ECHOE (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置了，并且如果ICANON被设置了，那么ERASE字符会从显示中擦除当前行的上一个字符。这个一般在终端驱动中写入三个字符序列来做到：backspace,space,backspace。
如果WERASE字符被支持，那么ECHOE导致使用一个或者多个这样的三个字符序列，将之前的单词被擦除。
如果支持ECHOPRT标记，那么这里叙述的ECHOE的动作是假设ECHOPRT没有被设置的情况下的。

ECHOK (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置，并且如果ICANON被设置，那么KILL字符会从显示器中擦除当前行，或者输出一个NL字符（为了强调表征整行被擦除）。
如果支持ECHOKE标记，那么这里对ECHOK的描述是假设ECHOKE没有被设置。

ECHOKE (c_lflag, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置，并且如果ICANON被设置，那么KILL字符通过删除一行中的每一个字符被显示。每一个字符被擦除的方式通过ECHOE和ECHOPRT标记被选择。

ECHONL (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置并且如果ICANON被设置，那么甚至在ECHO没有被设置的时候，NL字符也会被显示。

ECHOPRT (c_lflag, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置，并且ICANON和ECHO两者也被设置了，那么ERASE字符（如果支持的话,WERASE字符也是）会导致所有的被擦除的字符以它们被擦处的方式打印出来。这在硬拷贝终端以便查看具体什么字符被删除的时候，会非常有用（估计应该类似抓取log的时候）。

EXTPROC (c_lflag, FreeBSD, Mac OS X) 如果被设置了，那么canonical字符处理会在操作系统以外进行。可以出现这个情况的可以是：当串口通信设备可以通过处理一些行处理动作来脱离主机处理器。或者当使用伪终端的时候。

FFDLY (c_oflag, XSI, Linux, Solaris) 形成提供延迟掩码。这个掩码的值可以是FFO或者FF1。

FLUSHO (c_lflag, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置了，那么输出会被flushed。这个标记当我们键入DISCARD字符的时候被设置;这个标记在我们键入另外一个DISCARD字符的时候会被清除。我们可以通过设置或者清楚这个终端标记来设置或者清除相应的条件。

HUPCL (c_cflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置了，那么当最后一个进程关闭设备的时候modem 控制行会被lowered（也就是modem连接被断开）。

ICANON (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置了，那么canonical模式就会起作用。这将会激活如下字符：EOF, EOL, EOL2, ERASE, KILL, REPRINT, STATUS, 以及 WERASE.输入的字符会被汇集成行。
如果canonical模式没有被激活，那么read请求直接从输入对列中被满足。一个read不会返回，直到最小字节数目(MIN)字节数据被接收，或者到达超时（TIME），具体参见后面。

ICRNL (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置并且如果IGNCR没有被设置，那么会将接收到的CR字符转换成NL字符。

IEXTEN (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置，那么扩展的实现定义的特殊字符会被识别并且被处理。

IGNBRK (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置，那么会忽略输入的BREAK条件。可以查看BRKINT来寻找一种方法，通过这个方法来让BREAK条件既产生SIGINT信号或者也被做为数据读取。

IGNCR (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置了，那么接收到的CR字符会被忽略。如果这个标记没有被设置，那么就会在ICRNL被设置的时候将接收到的CR转换成NL字符。

IGNPAR (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 当被设置的时候，具有framing错误的输入字节（除了BREAK）或者一个具有parity错误的输入字节将会被忽略。

IMAXBEL (c_iflag, FreeBSD, Linux, Mac OS X, Solaris) 当输入队列满的时候，会响铃。

INLCR (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置了，那么接收到的NL字符会被转换成CR字符。

INPCK (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 当被设置了，那么input parity检测会被激活，如果INPCK没有被设置，那么input parity检测不会被激活。
Parity(应该是奇偶校验码之类的东西) "generation and detection" 和 "input parity checking" 是两个不同的东西。"generation and detection"的奇偶校验检测使用PARENB标记进行控制，设置这个标记经常导致特定串口的设备驱动为出去的字符产生parity并且检测收到的字符的parity(等值,或者校验码之类的东西)。标记PARODD决定parity是奇数还是偶数。如果一个输入字符到达，但是parity（等值）是错误的，那么会检测INPCK标记的状态，如果这个标记被设置，那么会检测IGNPAR标记（以查看是否忽略产生parity错误的输入字节）；如果字节不被忽略，那么PARMRK标记会被检测，来确定应该传递给读取进程的字符。

ISIG (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置，那么输入字符会和特定的字符进行比较，而这个特定的字符是导致产生终端发起的信号（INTR,QUIT,SUSP,和DSUSP）的字符；如果相等，那么会产生相应的信号。

ISTRIP (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris)当设置的时候，合法的输入字节会被strip成7个比特；当这个标记没有被设置的时候，所有的8比特都被处理。

IUCLC (c_iflag, Linux, Solaris) 将输入的大写字符映射成相知相惜字符。

IXANY (c_iflag, XSI, FreeBSD, Linux, Mac OS X, Solaris) 激活任何字符，以重新开始输出。

IXOFF (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置，那么会激活startstop输入控制。当输入队列满的时候，终端驱动输出一个STOP字符。这个字符应当被发送数据和导致设备停止的设备识别。然后，当输入队列上面的字符被处理的时候，终端驱动将会输出一个START字符。这会导致设备重新开始发送数据。

IXON (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置了，那么startstop输出控制会被激活。当终端驱动接收到STOP字符的时候，输出会停止。当输出停止的时候，下一个START字符将会导致重新开始输出。如果这个标记没有被设置，那么START和STOP字符会被读取，并且被进程当做普通字符来进行处理。

MDMBUF (c_cflag, FreeBSD, Mac OS X) 根据modem carrier的标记，对output进行流控制。这是CCAR_OFLOW标记的旧名字。

NLDLY (c_oflag, XSI, Linux, Solaris) 新行延迟码。其值可以是NL0或者NL1。

NOFLSH (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 默认来说，当终端驱动产生SIGINT和SIGQUIT信号的时候，输入和输出队列都会被刷新。并且，当产生SIGSUSP信号的时候，输入队列也会被刷新。如果NOFLSH标记被设置了，那么产生相应的信号的时候，这些队列通常就不会被刷新了。

NOKERNINFO (c_lflag, FreeBSD, Mac OS X) 当被设置的时候，这个标记会阻止STATUS字符向前台进程组打印字符。然而如果忽略这个标记，STATUS字符始终会导致SIGINFO信号被发送到前台进程组。

OCRNL (c_oflag, XSI, FreeBSD, Linux, Solaris) 如果设置，会在输出上面将CR映射成NL。

OFDEL (c_oflag, XSI, Linux, Solaris) 如果被设置，那么输出填充字符将会是ASCII的DEL；否则将会是ASCII的NUL。需要查看OFILL标记。

OFILL (c_oflag, XSI, Linux, Solaris) 如果被设置，那么填充字符 ( ASCII DEL 或 ASCII NUL; 请查看 OFDEL 标记)会在需要延迟的时候被作为延迟被发送，而不是延迟一个指定的时间。具体需要查看六个延迟掩码：BSDLY, CRDLY, FFDLY, NLDLY, TABDLY, 以及 VtdLY.

OLCUC (c_oflag, Linux, Solaris) 如果被设置了，那么将输出的小写字符映射成大写字符。

ONLCR (c_oflag, XSI, FreeBSD, Linux, Mac OS X, Solaris)如果设置了，那么会将输出的NL映射成CR-NL。

ONLRET (c_oflag, XSI, FreeBSD, Linux, Solaris) 如果设置了，那么会假设输出上面的NL字符和回车字符一样。

ONOCR (c_oflag, XSI, FreeBSD, Linux, Solaris) 如果设置了，那么不会在第0列输出CR。

ONOEOT (c_oflag, FreeBSD, Mac OS X) 如果设置了，那么忽略输出的EOT(^D)字符。这在一些可能会对Control-D解释成挂起的终端中，很有必要。

OPOST (c_oflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置了，那么会进行实现所定义的输出处理。根据前面参考资料中各个标记的表格所列出的对于c_oflag标记的不同的系统实现定义而处理。

OXTABS (c_oflag, FreeBSD, Mac OS X) 如果被设置了，那么输出上面的tabs被扩展成为space。这与设置水平制表延迟(TABDLY)为XTABS或者TAB3的效果一样。

PARENB (c_cflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置，那么会对之后的字符进行校验。如果PARODD设置了那么就进行奇数校验，否则偶数校验。可以查看INPCK，IGNPAR，以及PARMRK标记。

PAREXT (c_cflag, Solaris) 选择标记或者空白校验。如果设置了PARODD，那么校验位始终为1（标记校验），否则校验为始终为0（空白校验）。

PARMRK (c_iflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 当设置了，并且IGNPAR没有被设置的时候，一个错误帧的字节（除了BREAK）或者一个具有校验错误的字节会被进程读取为三个字符序列：\377, \0, X，这里X就是接收到的出错的字节。如果ISTRIP没有被设置，那么合法的的\377传递给进程为\377,\377。如果IGNPAR或者PARMRK都没有被设置，那么一个错误帧的字节（除了BREAK）或者一个具有校验错误的字节会被读取为\0。

PARODD (c_cflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果设置了，那么对接下来的字符进行奇数校验。否则，进行偶数校验。注意：PARENB标记会控制是否进行校验。
当CMSPAR或者PAREXT标记被设置的时候，PARODD标记也控制是否进行mark或者space校验。

PENDIN (c_lflag, FreeBSD, Linux, Mac OS X, Solaris)当被设置的时候，任何没有被读取的输入会在下一个字符输入的时候通过系统被重新打印出来。这个动作和我们键入REPRINT字符的时候类似。

TABDLY (c_oflag, XSI, Linux, Solaris) 水平制表延迟码，掩码的值为TAB0，TAB1，TAB2或者TAB3。
XTABS的值等于TAB3。这个值导致系统将tabs扩展成空格。系统假设一个tab会在8个空格之后stop一下，这个假定不能被改变。

TOSTOP (c_lflag, POSIX.1, FreeBSD, Linux, Mac OS X, Solaris) 如果被设置了，并且如果实现支持作业控制，那么SIGTTOU信号会发送给尝试写控制终端的后台进程的进程组。默认来说，这个信号会将进程组中所有的进程停止。这个信号在尝试写控制终端的后台进程忽略或者阻塞信号的时候不会由终端驱动发起。

VTDLY (c_oflag, XSI, Linux, Solaris) 垂直制表延迟码。延迟码的值可以为VT0或者VT1。

XCASE (c_lflag, Linux, Solaris) 如果设置了，并且如果ICANON也被设置了，那么会假设终端只是大写的，并且所有的输入都会被转换成小写的。如果想要输入一个大写的字符，那么将反斜线做为其前缀。类似，一个大写的字符会被系统通过使用反斜线前缀的方式来输出（目前，这个选项被淘汰了，因为几乎不存在只有大写的终端了）。

6)stty命令
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec6.html
前面小节中所说的所有选项都可以被检查和修改，可以在一个程序中通过函数tcgetattr函数和tcsetattr函数，或者在shell脚本中通过命令stty(1)。这个stty命令只是一个前面列出的"终端I/O函数"表中的六个函数的接口，如果我们使用-a选项执行这个命令，那么它会显示所有的终端选项：
$ stty -a
speed 9600 baud; 25 rows; 80 columns;
lflags: icanon isig iexten echo echoe -echok echoke -echonl echoctl
        -echoprt -altwerase -noflsh -tostop -flusho pendin -nokerninfo
        -extproc
iflags: -istrip icrnl -inlcr -igncr ixon -ixoff ixany imaxbel -ignbrk
        brkint -inpck -ignpar -parmrk
oflags: opost onlcr -ocrnl -oxtabs -onocr -onlret
cflags: cread cs8 -parenb -parodd hupcl -clocal -cstopb -crtscts
        -dsrflow -dtrflow -mdmbuf
cchars: discard = ^O; dsusp = ^Y; eof = ^D; eol = <undef>;
        eol2 = <undef>; erase = ^H; erase2 = ^?; intr = ^C; kill = ^U;
        lnext = ^V; min = 1; quit = ^; reprint = ^R; start = ^Q;
        status = ^T; stop = ^S; susp = ^Z; time = 0; werase = ^W;
通过连字符号选项名称表示这个选项被处于未激活状态。最后四行显示了当前设定的每个终端特殊字符。第一行显示了当前终端窗口的行和列，我们后面会讨论。
stty命令使用它的标准输入来获取和设置终端选项标记。尽管有些旧的实现使用标准输出，POSIX.1要求使用标准输入。本书中的四个系统实现提供了在标准输入上面进行操作的stty命令，也就是说，假设我们对tty1a终端的设置感兴趣，我们可以通过键入：
stty -a </dev/tty1a

7)波特率函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec7.html
波特率是一个历史名字，实际它就是“每秒的比特数目”。尽管多数终端设备使用同样的波特率用于输入和输出，但是如果硬件允许的化，也可以设置它们两个为不同的值。
#include <termios.h>
speed_t cfgetispeed(const struct termios *termptr);
speed_t cfgetospeed(const struct termios *termptr);
两者返回：波特率值

int cfsetispeed(struct termios *termptr, speed_t speed);
int cfsetospeed(struct termios *termptr, speed_t speed);
两者返回：如果成功返回0，如果错误返回1。

两个cfget函数的返回值，以及 两个cfset函数的speed参数可以是如下的常数：B50, B75, B110, B134, B150, B200, B300, B600, B1200, B1800, B2400, B4800, B9600, B19200, or B38400。常数"B0"表示"hang up."当调用tcsetattr的时候B0被指定为输出的波特率的时候，modem control lines不会被生效了(???)。
多数系统定义了额外的波特率值，例如B57600，和B115200。
为了使用这些函数，我们必须知道，输入和输出的波特率都存放在终端设备的termios结构中，如前面的"终端设备相关函数之间的关系图"图所示。调用任何的cfget函数之前，我们首先需要使用tcgetattr函数获取设备的termios结构。类似地，调用完了任意两个cfset函数之一之后，我们所做的就只是修改了termios结构中的波特率，如果想要这个改变影响到设备，我们需要调用tcsetattr。如果之前我们设置的波特率有错误的时候，直到我们调用tcsetattr之前，我们都可能不会发现我们设置的错误。

这四个波特率函数屏蔽了应用程序在termios结构中存放波特率的表示方式导致的不同。基于BSD的系统平台倾向将它存为和波特率一样的数值（也就是说，9,600的波特率会被存放成值9,600），然而Linux以及基于System V的平台倾向于将波特率编码成一个bitmask。我们从cfget函数获取的速度值以及传递给cfset函数的速度值都是没有转换成它们存放在termios结构中的形式的。

8)行控制函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec8.html
下面的四个函数提供了终端设备的行控制能力，所有的四个函数要求filedes引用一个终端设备，否则会返回错误并且设置错误号码errno为ENOTTY.
#include <termios.h>
int tcdrain(int filedes);
int tcflow(int filedes, int action);
int tcflush(int filedes, int queue);
int tcsendbreak(int filedes, int duration);
所有的四个函数返回：如果成功返回0，如果错误返回1。
函数tcdrain等待所有输出被传输。tcflow函数让我们可以控制输入和输出控制流。action参数必须是如下的四个值之一：
TCOOFF 输出被挂起。
TCOON 之前被挂起的输出被重启。
TCIOFF 系统传输STOP字符，这会导致终端设备停止发送数据。
TCION 系统传输START字符，这会导致终端设备重新开始发送数据。

tcflush函数允许我们flush（丢弃）输入缓存（这里的数据是已经被终端驱动接收了但是我们还没有读取）或者输出缓存（这里的数据是我们已经写入了，但是还没有传输）。queue参数必须是如下三个常数之中的一个：
TCIFLUSH 输入队列被flush。
TCOFLUSH 输出对列被flush。
TCIOFLUSH 输入和输出队列都被flush。

tcsendbreak函数会传输连续的0比特流以用于特定的延迟。如果duration参数是0，那么传输会持续大约0.25-0.5秒之间。POSIX.1指定，如果duration非0，那么传输的时间根据具体实现有所不同。

9)终端标识
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec9.html
根据以前，大多数版本的UNIX 系统上面的控制终端的名称都是/dev/tty。POSIX.1提供了一个运行时的函数，我们可以通过调用这个函数来确定控制终端的名字。
#include <stdio.h>
char *ctermid(char *ptr);
返回：如果成功，返回指向控制终端名字的指针；如果错误返回空的字符串。
如果ptr非空，那么会假定它指向一个至少有L_ctermid字节的数组，而进程的控制终端的名字就存放在那个数组中。常数L_ctermid定义在<stdio.h>中。如果ptr是一个空指针，那么函数会为这个数组分配一个空间（这个空间通常都是一个静态变量）。同样地，进程的控制终端的名字会存放在这个数组中。
对于这两种情况，数组的起始地址都会被做为函数的返回值返回。由于大多数的UNIX系统使用/dev/tty作为控制终端的名字，所以这个函数只是为了便于在其它操作系统可移植的一种手段。
本书描述的所有四个平台，都会在我们调用ctermid的时候返回"dev/tty"的。

ctermid函数的例子
下面的代码展示了POSIX.1的ctermid函数的实现
需要注意的是我们不会保护调用者的缓存越界，因为我们无法确定它的大小。
POSIX.1中的ctermid函数的实现
#include     <stdio.h>
#include     <string.h>
static char ctermid_name[L_ctermid];
char * ctermid(char *str)
{
    if (str == NULL)
        str = ctermid_name;
    return(strcpy(str, "/dev/tty"));    /* strcpy() returns str */
}

对于UNIX系统有两个值得知道的函数：一个是isatty，这个函数在如果一个文件描述符号引用的是终端设备的时候返回true；一个是ttyname，这个函数返回打开的文件描述符号的终端设备路径名称。
#include <unistd.h>
int isatty(int filedes);
返回：如果是终端设备返回1，如果不是就返回0。

char *ttyname(int filedes);
返回：指向终端的路径名称，如果错误返回NULL。

isatty函数的例子
函数isatty的时间非常简单，如下面代码所示。我们只是简单地执行了一个终端特定的函数（这个函数如果成功执行的时候并不会改变任何东西），然后通过查看返回值来确定。
函数isatty的POSIX.1实现
#include    <termios.h>
int isatty(int fd)
{
    struct termios ts;
    return(tcgetattr(fd, &ts) != -1); /* true if no error (is a tty) */
}

我们通过如下的代码来测试我们上面写的isatty函数，
测试isatty函数
#include "apue.h"
int main(void)
{
    printf("fd 0: %s\n", isatty(0) ? "tty" : "not a tty");
    printf("fd 1: %s\n", isatty(1) ? "tty" : "not a tty");
    printf("fd 2: %s\n", isatty(2) ? "tty" : "not a tty");
    exit(0);
}
当我们运行上面代码对应的程序的时候，我们会得到如下的输出：
   $ ./a.out
   fd 0: tty
   fd 1: tty
   fd 2: tty
   $ ./a.out </etc/passwd 2>/dev/null
   fd 0: not a tty
   fd 1: tty
   fd 2: not a tty

函数ttyname的例子
如下面代码所示的，其实ttyname函数很长，因为我们需要搜索所有的设备节点，来查找一个匹配的。
POSIX.1的ttyname函数的实现
#include    <sys/stat.h>
#include    <dirent.h>
#include    <limits.h>
#include    <string.h>
#include    <termios.h>
#include    <unistd.h>
#include    <stdlib.h>

struct devdir {
    struct devdir    *d_next;
    char             *d_name;
};

static struct devdir    *head;
static struct devdir    *tail;
static char             pathname[_POSIX_PATH_MAX + 1];

static void add(char *dirname)
{
    struct devdir    *ddp;
    int              len;

    len = strlen(dirname);

    /*
     * Skip ., .., and /dev/fd.
     */
    if ((dirname[len-1] == '.') && (dirname[len-2] == '/' ||
      (dirname[len-2] == '.' && dirname[len-3] == '/')))
        return;
    if (strcmp(dirname, "/dev/fd") == 0)
        return;
    ddp = malloc(sizeof(struct devdir));
    if (ddp == NULL)
        return;

    ddp->d_name = strdup(dirname);
    if (ddp->d_name == NULL) {
        free(ddp);
        return;
    }
    ddp->d_next = NULL;
    if (tail == NULL) {
        head = ddp;
        tail = ddp;
    } else {
        tail->d_next = ddp;
        tail = ddp;
    }
}

static void cleanup(void)
{
    struct devdir *ddp, *nddp;

    ddp = head;
    while (ddp != NULL) {
        nddp = ddp->d_next;
        free(ddp->d_name);
        free(ddp);
        ddp = nddp;
    }
    head = NULL;
    tail = NULL;
}

static char * searchdir(char *dirname, struct stat *fdstatp)
{
    struct stat     devstat;
    DIR             *dp;
    int             devlen;
    struct dirent   *dirp;

    strcpy(pathname, dirname);
    if ((dp = opendir(dirname)) == NULL)
        return(NULL);
    strcat(pathname, "/");
    devlen = strlen(pathname);
    while ((dirp = readdir(dp)) != NULL) {
        strncpy(pathname + devlen, dirp->d_name,
          _POSIX_PATH_MAX - devlen);
        /*
         * Skip aliases.
         */
        if (strcmp(pathname, "/dev/stdin") == 0 ||
          strcmp(pathname, "/dev/stdout") == 0 ||
          strcmp(pathname, "/dev/stderr") == 0)
            continue;
        if (stat(pathname, &devstat) < 0)
            continue;
        if (S_ISDIR(devstat.st_mode)) {
            add(pathname);
            continue;
        }
        if (devstat.st_ino == fdstatp->st_ino &&
          devstat.st_dev == fdstatp->st_dev) { /* found a match */
            closedir(dp);
            return(pathname);
        }
    }
    closedir(dp);
    return(NULL);
}

char * ttyname(int fd)
{
    struct stat     fdstat;
    struct devdir   *ddp;
    char            *rval;

    if (isatty(fd) == 0)
        return(NULL);
    if (fstat(fd, &fdstat) < 0)
        return(NULL);
    if (S_ISCHR(fdstat.st_mode) == 0)
        return(NULL);

    rval = searchdir("/dev", &fdstat);
    if (rval == NULL) {
        for (ddp = head; ddp != NULL; ddp = ddp->d_next)
            if ((rval = searchdir(ddp->d_name, &fdstat)) != NULL)
                break;
    }

    cleanup();
    return(rval);
}
主要的技术是读取/dev目录，查找一个具有同样设备号码以及i-node号码的文件。前面说过，每个文件系统都有一个唯一的设备号码（stat结构的st_dev成员），每个文件系统的目录项都有一个唯一的i-node号（stat结构的st_ino成员）。我们假定在这个函数中，我们遇到一个匹配的设备号码以及i-node号码的时候，我们定位到了想要的目录项。我们也会检查两者的st_rdev成员是否匹配（也就是终端设备的主、次设备号码）以及目录项是不是一个字符设备文件。但是，因为我们已经确定了文件描述符号参数是一个终端设备和字符设备文件，并且设备号码和i-node号码在UNIX系统中是唯一的，所以，没有必要进行额外的检查。
我们的终端可能在子目录/dev下面，所以我们搜索其中的所有文件。我们会跳过一些目录，因为它门会产生不正确地输出，这些目录是：/dev/.,/dev/..,/dev/fd。我们也会跳过/dev/stdin,/dev/stdout,和/dev/stderr,因为它们是指向/dev/fd中的一个目录项的链接。

我们可以通过如下的代码来检查上面实现的函数：
测试ttyname函数的代码
#include "apue.h"
int main(void)
{
    char *name;

    if (isatty(0)) {
        name = ttyname(0);
        if (name == NULL)
            name = "undefined";
    } else {
        name = "not a tty";
    }
    printf("fd 0: %s\n", name);
    if (isatty(1)) {
        name = ttyname(1);
        if (name == NULL)
            name = "undefined";
    } else {
        name = "not a tty";
    }
    printf("fd 1: %s\n", name);
    if (isatty(2)) {
        name = ttyname(2);
        if (name == NULL)
            name = "undefined";
    } else {
        name = "not a tty";
    }
    printf("fd 2: %s\n", name);
    exit(0);
}
运行上面的程序，我们得到如下的输出：
   $ ./a.out < /dev/console 2> /dev/null
   fd 0: /dev/console
   fd 1: /dev/ttyp3
   fd 2: not a tty

10)canonical模式
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec10.html
Canonical模式非常简单：我们调用一个read，然后终端驱动程序会在输入完一行之后返回。导致read返回的有以下几种情况。
* 当所请求的字节数目被读取完成之后read会返回。我们不用读取一个整行，如果我们读取一行中的一个部分，那么不会丢失任何信息；下一次读取的位置就是上次停止的位置。
* read会在遇到一个行定界符号的时候返回。前面我们说过，被解释成为canonical模式的行结束符号有：NL, EOL, EOL2, 和 EOF。前面也说过，如果ICRNL被设置并且IGNCR没有被设置，那么CR字符也会终止一个行，就像NL字符一样。
我们需要注意的是，对于所有这5个行定界符号，有一个字符(即EOF)会在被处理之后被终端驱动程序丢弃。剩下的4个字符会返回给调用者，作为一行的最后一个字符。
* read在捕获到一个信号并且这个函数不是自动重新启动的时候返回。

getpass函数的例子
我们现在看看getpass函数。这个函数会从用户终端读取某种密码，login和crypt程序就会调用这个函数。为了读取密码，函数必须关闭字符的显示，但是它也必须让终端处于canonical模式，把我们输入的组成一行的密码读取。下面代码就列举了unix系统上面一个典型的这个函数的实现。

getpass函数的实现
#include <signal.h>
#include <stdio.h>
#include <termios.h>

#define MAX_PASS_LEN    8      /* max #chars for user to enter */

char * getpass(const char *prompt)
{
    static char     buf[MAX_PASS_LEN + 1]; /* null byte at end */
    char            *ptr;
    sigset_t        sig, osig;
    struct termios  ts, ots;
    FILE            *fp;
    int             c;

    if ((fp = fopen(ctermid(NULL), "r+")) == NULL)
        return(NULL);
    setbuf(fp, NULL);

    sigemptyset(&sig);
    sigaddset(&sig, SIGINT);        /* block SIGINT */
    sigaddset(&sig, SIGTSTP);       /* block SIGTSTP */
    sigprocmask(SIG_BLOCK, &sig, &osig);    /* and save mask */

    tcgetattr(fileno(fp), &ts);     /* save tty state */
    ots = ts;                       /* structure copy */
    ts.c_lflag &= ~(ECHO | ECHOE | ECHOK | ECHONL);
    tcsetattr(fileno(fp), TCSAFLUSH, &ts);
    fputs(prompt, fp);

    ptr = buf;
    while ((c = getc(fp)) != EOF && c != '\n')
        if (ptr < &buf[MAX_PASS_LEN])
            *ptr++ = c;
    *ptr = 0;                  /* null terminate */
    putc('\n', fp);            /* we echo a newline */

    tcsetattr(fileno(fp), TCSAFLUSH, &ots); /* restore TTY state */
    sigprocmask(SIG_SETMASK, &osig, NULL);  /* restore mask */
    fclose(fp);         /* done with /dev/tty */
    return(buf);
}

这个例子中有几个需要注意的地方。
* 我们不是直接在程序中使用"/dev/tty"，而是调用函数ctermid来打开控制终端。
* 我们只从控制终端读写，并且如果我们无法打开设备进行读写的时候我们会返回错误。也有其他的情况，BSD版本的getpass从标准输入读取，并且如果控制终端无法被打开用于读写的时候会写到标准错误输出。SystemV版本的系统会一直向标准错误输出写，但是只从控制终端读取。
* 我们会阻塞信号SIGINT以及SIGSTP。如果我们没有做这些，那么输入INTR字符的时候将会导致程序被abort（异常终止）并且留下一个被取消了显示字符的终端。类似地，如果输入SUSP字符将会停止程序，并且返回一个被取消了显示字符的shell。我们在我们取消显示的时候选择阻塞这些信号。如果在我们读取密码的时候产生了这些信号，那么它们会被保留，直到我们返回。也有一些其他处理这些信号的方式。有些版本会仅仅再getpass的时候忽略SIGINT（当然保存之前的动作），然后当返回的时候恢复之前的动作，但是这样也意味着在这个信号被忽略的期间（就是执行getpass的期间），任何产生的这个信号将会丢失。另外一个版本处理的方式是如果发现产生信号则捕捉SIGINT信号（也会保存之前的动作），如果产生了信号，那么在重置终端的状态和信号动作的时候将这些信号通过kill函数发送。没有任何版本的getpass函数会阻塞、捕获、或者忽略信号SIGQUIT，所以键入QUIT字符会导致程序终止同时可能会留下一个不能显示的终端。
* 需要注意的是，有一些shell，尤其是Korn shell，会再它们读取交互命令的时候将回显打开。这些shell一般是那些提供命令行编辑功能的shell，因此每当我们输入交互命令的时候会操作终端的状态。因此，如果我们在这些shell下面发起应用程序，并且使用QUIT字符退出应用程序的时候，这个shell将会重新为我们开启回显功能。其他的没有提供提供命令行编辑功能的shell，例如Bourne shell，将会在取消应用程序的时候留下一个没有回显的shell。如果这样，我们可以使用stty命令来重新开启回显。
* 我们使用标准输入输出来读写控制终端。我们特别地设置了stream为非缓冲的，否则可能会有一些交互出现在读和写这个流之间（我们需要使用一些调用来进行fflush）。我们可能会使用非缓冲的I/O，但是我们使用读取的时候需要模仿getc函数。
* 我们只存放了8个字符作为密码。任何其他的字符都将会被忽略。

下面的代码调用getpass并且打印我们所输入的，以便我们可以验证ERASE和KILL字符是可以工作的（因为它们需要在canonical模式）。

调用getpass函数
#include "apue.h"
char    *getpass(const char *);
int main(void)
{
    char   *ptr;

    if ((ptr = getpass("Enter password:")) == NULL)
        err_sys("getpass error");
    printf("password: %s\n", ptr);

    /* now use password (probably encrypt it) ... */

    while (*ptr != 0)
        *ptr++ = 0;      /* zero it out when we're done with it */
    exit(0);
}

当一个调用getpass的应用程序使用明文密码的时候，应用程序应该在内存中将它尽早清除以杜绝安全隐患。如果应用程序会产生core文件，其它程序可能会读取到相应信息；或者如果有些应用程序可以读取我们内存的时候；这都会导致我们的明文密码被读取到。（这里的明文"cleartext",意思是我们在输入提示处输入的并且通过getpass被打印出来的密码。大多数UNIX系统程序会接着将这个明文的密码变成一个"加密的密码"。例如，password的pw_passwd成员就包含了加密的密码而不是明文的密码）。

11)noncanonical模式
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec11.html
Noncanonical模式通过关闭termios结构中的c_lflag域中的ICANON标记来指定。在noncanonical模式，输入的数据不会被收集成行，并且这些字符不会被处理：ERASE, KILL, EOF, NL, EOL, EOL2, CR, REPRINT, STATUS,  WERASE。
如我们所说，canonical模式比较简单，系统每次返回一行。但是noncanonical模式中，系统如何知道什么时候给我们返回数据？如果每次返回一个字节，那么开销就会很大。（前面给出过我们一次read一个字节的开销，每次我们将返回的数据量增倍，相应的系统调用的开销就会减半）。系统不能总是每次返回多个字节，因为有时候我们直到我们开始读取之前，我们都无法知道需要读取多少数据。
有一个解决的方法就是，当已经读取了指定数目的数据或者过了一个指定的时间之后，告诉系统返回。这个技术使用两个变量，它们存放在termios结构中的c_cc数组中：MIN和TIME。这两个数组的元素通过名称VMIN和VTIME被索引到。

MIN指定了一个read返回之前的最小字节数目。TIME指定了等待数据到达的每个10分之一秒的数目。主要有4种情况：
Case A: MIN > 0, TIME > 0
TIME指定了一个交互字节计时器，这个计时器只有在第一个字节被接收到的时候会被启动。如果在计时器超时之前，MIN字节的数据被读取到了，那么read会返回MIN字节。如果计时器在接收到MIN个字节之前超时了，那么read会返回当前已经读取的字节数目。（如果超时了，那至少会返回1个字节，因为计时器在接收到一个字节的时候才会被启动）这个情况下，调用者会阻塞，直到收到第一个字节，如果调用read的时候数据已经可用，那么就好象read之后数据立即被接收到了。

Case B: MIN > 0, TIME == 0
read不会返回，直到MIN字节被接收到。这会导致read处于一种永远阻塞的状态。

Case C: MIN == 0, TIME > 0
TIME指定了一个读取计时器，这个计时器会在read被调用的时候启动。(和case A进行比较会发现，case A中的非零TIME表示一个交互字节计时器，这个计时器只有接收到第一个字节的时候才会被启动)，read会在接收到一个单个字节的时候返回，或者计时器超时的时候返回。如果计时器超时了，那么read返回0。

Case D: MIN == 0, TIME == 0
如果一些数据是可用的，那么read返回请求的字节的数目。如果没有数据可用，那么read会立即返回0。

需要注意的是，对于以上这些情况，MIN只是一个最小值。如果应用程序请求的数据大于MIN字节，那么会可能接收到所有可能请求的数据。这也是C和D中的情况，即C和D中的MIN都是0。

下面的图表列出了noncanonical输入下的四种情况。这个图中，nbytes就是read的第3个参数（也就是返回的最大字节数目）。
noncanonical输入模式中的四种情况
                     MIN > 0                           MIN == 0
           +------------------------------------+------------------------------+
           | A:read returns [MIN,nbytes]        | C:read returns [1,nbytes]    |
           |    before timer expires;           |       before timer expires;  |
 TIME > 0  |   read returns [1,MIN)             |   read returns 0             |
           |    if timer expires.               |       if timer expires.      |
           | (TIME= interbyte timer             | (TIME= read timer.)          |
           |  Caller can block indefinitely.)   |                              |
           +------------------------------------+------------------------------+
           | B:read returns [MIN,nbytes]        | D:read returns [0,nbytes]    |
 TIME == 0 |      when available.               |       immediately.           |
           | (Caller can block indefinitely.)   |                              |
           +------------------------------------+------------------------------+
我们需要注意的是POSIX.1允许下标VMIN和VTIME分别和VEOF与VEOL的值一样。其实，Solaris为了兼容以前的老版本的System V，就是这样做的。这导致了一个移植的问题。当从noncanonical转换到canonical模式的时候，我们现在必须也恢复VEOF和VEOL，如果VMIN和VEOF一样，并且我们没有恢复它们的值，那么当我们设置VMIN为经常使用的1的时候，end-of-file字符就变成了Control-A。回避这个问题的最简单的方法就是当进入到noncanonical模式的时候保存整个termios结构，回到canonical模式的时候恢复它。
例子
下面的程序定义了tty_cbreak和tty_raw函数，这函数设置终端为cbreak模式和raw模式（cbreak和raw来自终端驱动的版本7)。我们可以调用函数tty_reset来重新设置终端为它的原始模式（也就是调用这些函数之前的状态）。

设置终端模式为cbreak或者raw
#include "apue.h"
#include <termios.h>
#include <errno.h>

static struct termios       save_termios;
static int                  ttysavefd = -1;
static enum { RESET, RAW, CBREAK } ttystate = RESET;

int tty_cbreak(int fd) /* put terminal into a cbreak mode */
{
    int              err;
    struct termios   buf;

    if (ttystate != RESET) {
        errno = EINVAL;
        return(-1);
    }
    if (tcgetattr(fd, &buf) < 0)
        return(-1);
    save_termios = buf; /* structure copy */

    /*
     * Echo off, canonical mode off.
     */
    buf.c_lflag &= ~(ECHO | ICANON);

    /*
     * Case B: 1 byte at a time, no timer.
     */
    buf.c_cc[VMIN] = 1;
    buf.c_cc[VTIME] = 0;
    if (tcsetattr(fd, TCSAFLUSH, &buf) < 0)
        return(-1);

    /*
     * Verify that the changes stuck. tcsetattr can return 0 on
     * partial success.
     */
    if (tcgetattr(fd, &buf) < 0) {
        err = errno;
        tcsetattr(fd, TCSAFLUSH, &save_termios);
        errno = err;
        return(-1);
    }
    if ((buf.c_lflag & (ECHO | ICANON)) || buf.c_cc[VMIN] != 1 ||
      buf.c_cc[VTIME] != 0) {
        /*
         * Only some of the changes were made. Restore the
         * original settings.
         */
        tcsetattr(fd, TCSAFLUSH, &save_termios);
        errno = EINVAL;
        return(-1);
    }

    ttystate = CBREAK;
    ttysavefd = fd;
    return(0);
}

int tty_raw(int fd)     /* put terminal into a raw mode */
{
    int             err;
    struct termios  buf;

    if (ttystate != RESET) {
        errno = EINVAL;
        return(-1);
    }
    if (tcgetattr(fd, &buf) < 0)
        return(-1);
    save_termios = buf; /* structure copy */

    /*
     * Echo off, canonical mode off, extended input
     * processing off, signal chars off.
     */
    buf.c_lflag &= ~(ECHO | ICANON | IEXTEN | ISIG);

    /*
     * No SIGINT on BREAK, CR-to-NL off, input parity
     * check off, don't strip 8th bit on input, output
     * flow control off.
     */
    buf.c_iflag &= ~(BRKINT | ICRNL | INPCK | ISTRIP | IXON);

    /*
     * Clear size bits, parity checking off.
     */
    buf.c_cflag &= ~(CSIZE | PARENB);

    /*
     * Set 8 bits/char.
     */
    buf.c_cflag |= CS8;

    /*
     * Output processing off.
     */
    buf.c_oflag &= ~(OPOST);

    /*
     * Case B: 1 byte at a time, no timer.
     */
    buf.c_cc[VMIN] = 1;
    buf.c_cc[VTIME] = 0;
    if (tcsetattr(fd, TCSAFLUSH, &buf) < 0)
        return(-1);

    /*
     * Verify that the changes stuck. tcsetattr can return 0 on
     * partial success.
     */
    if (tcgetattr(fd, &buf) < 0) {
        err = errno;
        tcsetattr(fd, TCSAFLUSH, &save_termios);
        errno = err;
        return(-1);
    }
    if ((buf.c_lflag & (ECHO | ICANON | IEXTEN | ISIG)) ||
      (buf.c_iflag & (BRKINT | ICRNL | INPCK | ISTRIP | IXON)) ||
      (buf.c_cflag & (CSIZE | PARENB | CS8)) != CS8 ||
      (buf.c_oflag & OPOST) || buf.c_cc[VMIN] != 1 ||
      buf.c_cc[VTIME] != 0) {
        /*
         * Only some of the changes were made. Restore the
         * original settings.
         */
        tcsetattr(fd, TCSAFLUSH, &save_termios);
        errno = EINVAL;
        return(-1);
    }

    ttystate = RAW;
    ttysavefd = fd;
    return(0);
}

int tty_reset(int fd)      /* restore terminal's mode */
{
    if (ttystate == RESET)
        return(0);
    if (tcsetattr(fd, TCSAFLUSH, &save_termios) < 0)
        return(-1);
    ttystate = RESET;
    return(0);
}
void tty_atexit(void)        /* can be set up by atexit(tty_atexit) */
{
    if (ttysavefd >= 0)
        tty_reset(ttysavefd);
}

struct termios * tty_termios(void)       /* let caller see original tty state */
{
    return(&save_termios);
}

如果我们已经调用了tty_cbreak，我们需要在调用tty_raw之前调用tty_reset。调用tty_cbreak之后、再调用tty_raw的时候也是如此（即先调用tty_reset再tty_raw）。这样可以确保在出现错误的时候，终端不会处于不稳定的状态。

还有两个函数：tty_atexit可以被建立成一个exit处理函数，保证在exit的时候终端的模式被重置，tty_termios返回一个指向原始的canonical模式的termios结构。
我们对cbreak模式的定义如下：
* Noncanonical模式。正如我们这一节开始所述，这个模式会关闭一些输入字符的处理。它不会关闭信号处理，所以用户始终可以键入任何一个终端信号产生函数。需要注意的是，调用者应该获取这些信号，否则信号可能会终止终端程序导致终端可能处于一种cbreak模式。
做为一个通用的规则，当我们写一个改变终端模式的程序的时候，我们应该捕获尽可能多的信号，这样我们可以在程序终止的时候重新设置终端。
* 关闭回显。
* 一次输入一个字节。为了实现这个，我们设置MIN为1，TIME为0。这样和前面表中列出的case B一样了。read不会返回，直到至少有一个字节可用。

我们对raw模式的定义如下：
* Noncanonical模式。我们也会关闭对信号生成字符（ISIG）以及扩展输入字符(IEXTEN)的处理。另外，我们通过关闭BRKINT来不让BREAK字符产生信号。
* 关闭回显。
* 我们禁止输入上面CR和NL之间的映射(ICRNL)、等值输入检查(INPCK)、以及输入的第8位的strip(ISTRIP)，以及输出流控制（IXON）。
* 8位字符(CS8)，和等值检查(PARENB)被禁止。
* 所有输出的处理(OPOST)被禁止。
* 每次输入一个字节(MIN=1,TIME=0)。

下面的程序测试了raw和cbreak模式。

运行下面的程序，我们可以看到终端的模式发生了什么现象。
测试raw和cbreak终端模式
#include "apue.h"
static void sig_catch(int signo)
{
    printf("signal caught\n");
    tty_reset(STDIN_FILENO);
    exit(0);
}

int main(void)
{
    int    i;
    char   c;

    if (signal(SIGINT, sig_catch) == SIG_ERR)   /* catch signals */
        err_sys("signal(SIGINT) error");
    if (signal(SIGQUIT, sig_catch) == SIG_ERR)
        err_sys("signal(SIGQUIT) error");
    if (signal(SIGTERM, sig_catch) == SIG_ERR)
        err_sys("signal(SIGTERM) error");

    if (tty_raw(STDIN_FILENO) < 0)
        err_sys("tty_raw error");
    printf("Enter raw mode characters, terminate with DELETE\n");
    while ((i = read(STDIN_FILENO, &c, 1)) == 1) {
        if ((c &= 255) == 0177)     /* 0177 = ASCII DELETE */
            break;
        printf("%o\n", c);
    }
    if (tty_reset(STDIN_FILENO) < 0)
        err_sys("tty_reset error");
    if (i <= 0)
        err_sys("read error");
    if (tty_cbreak(STDIN_FILENO) < 0)
        err_sys("tty_cbreak error");
    printf("\nEnter cbreak mode characters, terminate with SIGINT\n");
    while ((i = read(STDIN_FILENO, &c, 1)) == 1) {
        c &= 255;
        printf("%o\n", c);
    }
    if (tty_reset(STDIN_FILENO) < 0)
        err_sys("tty_reset error");
    if (i <= 0)
        err_sys("read error");
    exit(0);
}
运行与输出如下：
$ ./a.out
Enter raw mode characters, terminate with DELETE
                                                 4
                                                   33
                                                     133
                                                        61
                                                          70
                                                            176
                          type DELETE
Enter cbreak mode characters, terminate with SIGINT
1                         type Control-A
10                        type backspace
signal caught             type interrupt key

在raw模式中，输入的字符是Control-D(04)和特殊功能键F7。在使用的终端上面，这个功能键会产生如下5个字符：ESC(033), [ (0133), 1 (061), 8 (070), 和 ~ (0176)。需要注意的是，raw模式中的输出处理被关闭的情况下(~OPOST)，我们在每个字符后面无法获得返回的回车。我们也需要注意，特殊字符的处理在cbreak模式中是被禁止的（所以，像Control-D, end-of-file字符, 以及 backspace没有被特别地处理），然而终端产生的信号还是始终被处理的。

12)终端窗口大小
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec12.html
大多数UNIX系统提供一种方式，可以跟踪当前终端窗口大小，以便内核在大小改变的时候通知前台进程组。内核对每一个终端和伪终端维护一个窗口大小的结构。
struct winsize
{
	unsigned short ws_row;       /* rows, in characters */
	unsigned short ws_col;       /* columns, in characters */
	unsigned short ws_xpixel;    /* horizontal size, pixels (unused) */
	unsigned short ws_ypixel;    /* vertical size, pixels (unused) */
};

结构的规则如下：
* 我们可以通过使用TIOCGWINSZ的ioctl来获取当前结构的值。
* 我们可以通过TIOCSWINSZ的ioctl向内核存储一个新的这个结构的值。如果新的值和当前内核存放的值不同，那么会给前台进程组发送一个SIGWINCH信号。（需要注意的是前面说过，这个信号的默认情况是被忽略）
* 除了存放当前的结构值以及当值变化的时候发送信号之外，内核不会对这个结构做任何事情。对于这个结构的解释，完全交给应用程序来做。
提供这个特性的原因是为了在窗口大小改变的时候通知应用程序（例如vi编辑器）。当收到这个信号的时候，应用程序可以获取新的大小，然后重新绘制屏幕。

例子
下面代码中的程序，会打印当前窗口的大小。每次窗口大小改变的时候，程序会接收到一个SIGWINCH信号，然后打印新的大小。我们需要通过一个信号来终止这个应用程序。
打印窗口大小
#include "apue.h"
#include <termios.h>
#ifndef TIOCGWINSZ
#include <sys/ioctl.h>
#endif

static void pr_winsize(int fd)
{
    struct winsize size;

    if (ioctl(fd, TIOCGWINSZ, (char *) &size) < 0)
        err_sys("TIOCGWINSZ error");
    printf("%d rows, %d columns\n", size.ws_row, size.ws_col);
}

static void sig_winch(int signo)
{
    printf("SIGWINCH received\n");
    pr_winsize(STDIN_FILENO);
}

int main(void)
{
    if (isatty(STDIN_FILENO) == 0)
        exit(1);
    if (signal(SIGWINCH, sig_winch) == SIG_ERR)
        err_sys("signal error");
    pr_winsize(STDIN_FILENO);   /* print initial size */
    for ( ; ; )                 /* and sleep forever */
        pause();
}

在一个终端窗口中运行这个应用程序，我们会得到如下的输出：
$ ./a.out
35 rows, 80 columns       initial size
SIGWINCH received         change window size: signal is caught
40 rows, 123 columns
SIGWINCH received         and again
42 rows, 33 columns
^? $                      type the interrupt key to terminate


13)termcap, terminfo, 和 curses
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec13.html
termcap表示"终端能力(terminal capability)"，它引用文本文件/etc/termcap并且使用一系列的函数来读取这个文件。termcap机制是在 Berkeley开发的，用来支持vi编辑器。termcap文件包含各种终端文件描述：终端支持什么特性（多少行列，是否支持backspace等等）以及如何让终端执行特定的操作（清除屏幕，将光标移动到一个指定的位置等等）。将这个信息从编译的程序中提取出来，然后将它放在一个方便编辑的文本文件中，就可以允许vi编辑器运行在各种终端上面了。

支持termcap文件的函数之后就从vi编辑器中导出来，被放在一个独立的库curses中了。有许多特性被添加到这个库中，使得任何应用程序都可以使用它来操作屏幕。

termcap机制并不是完美的。随着越来越多的终端被添加到这个数据文件中，当查找一个特定的终端的时候，扫描文件的时间就会增多了。数据文件也使用两个字符的名字来标识终端的各种不同的属性。这些缺点导致terminfo机制的产生以及其相关的curses库的开发。terminfo中的终端描述符号是文本描述符号的一个基本编译版本，可以在运行的时候被很快地定位。terminfo出现在SVR2并且在那之后所有的System V发布都包含了。
历史上，基于System V的系统使用terminfo，基于BSD的系统使用termcap，但是现在的系统同时支持两者已经是很平常的现象了，然而Mac OS X只支持terminfo。

关于terminfo和curses库等信息，可以参见原文中列出的一些参考资料。有一个ncurses库，是自由版本，和SVR4的curses接口兼容，可以在"http://invisible-island.net/ncurses/ncurses.html"中找到。

termcap或者terminfo本身并不处理我们本章所见到的一些问题：改变终端模式，改变终端特殊字符，处理窗口大小，等等。它们所提供的，只是一种典型的操作（清屏幕，移动光标），使这些操作可以在许多终端上实现。另外，curses可以用来处理我们本章所遇到的一些问题的细节。curses提供了设置raw模式，设置cbread模式，打开和关闭回显等类似操作的函数。但是curses库用于基于字符的哑终端，而这些哑终端现在大多已经被基于像素的图形终端所替代了。

14)总结
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch18lev1sec14.html
终端有许多的特性和选项，我们可以修改它们中的大多数，来适应我们的需求。在本章，我们叙述了大量的可以改变终端操作的功能：特殊输入字符和选项标记。我们也看到了所有的终端特殊滋是以及许多可以设置或者重置终端设备的选项。
终端的输入有两种模式：canonical（每次一行）模式和noncanonical模式。我们展示了两种模式下面的例子，也提供了一些函数可以在POSIX.1终端选项以及原来的BSD的cbreak和raw模式之间映射。我们也描述了如何获取和改变终端窗口的大小。

*伪终端
==========================
1）简介
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19.html
在前面，我们看到了终端的登陆通过一个终端设备, 并且自动提供终端的语义。在终端和我们运行的程序之间有一个终端行规范，所以我们可以设置终端特殊字符 (backspace, line erase, interrupt, 等.)和类似的内容。然而，当一个来自网络连接的登陆请求到达的时候，在网络连接和登陆的shell之间并不会自动地提供终端行规范。前面的图形(第9章第3节)中，给出使用伪终端设备驱动来提供终端的规范。
除了网络登陆之外，我们将会看到伪终端还会有其他的应用之处。我们开始对如何使用伪终端进行了一个展示，然后讨论特定的应用。我们之后会提供在各种平台上面建立伪终端的函数，并且使用这些函数写一个叫做pty的程序。我们将会展示这个程序的多个用途：创建一个对终端上面所有输入输出字符的转换脚本（script程序），然后运行协作处理进程来防止出现我们在进程通信时候遇到的那个缓存问题。

2)总体概述
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19lev1sec2.html
伪终端的意思是，这个终端对于应用程序来说表现像是一个终端，但是实际上它并不是一个真正的终端。下面的图就展示了一个典型的进程使用伪终端的组织结构。
                         进程使用伪终端的典型结构

                     +----------+         +----------+
                     |    user  |  fork   |   user   |
                     |  process |-------->|  process |
                     +-----^----+  exec   +-----^----+
                           |                    |stdin,stdout,stderr
            +- - - - - - - - - - - - - - - - - - - - - - - - -+
            |              |                    |             |
                 +---------v-------+   +--------v-------+
            |    | read and write  |   | read and write |     |
                 |    functions    |   |    functions   |
            |    +-----|-----^-----+   +----|------^----+     |
                       |     |              |      |
            |          |     |         +----v------|----+     |
                       |     |         |    terminal    |       Kernel
            |          |     |         | line dscipline |     |
                       |     |         +----|------^----+
            |          |     |              |      |          |
                 +-----v-----|-----+   +----v------|----+
            |    | pseudo-terminal |   | pseudo-terminal|     |
                 |     master      |   |     slave      |
            |    +-----|-----^-----+   +----|------^----+     |
                       |     |              v      |
            |          |     +<-------------+      |          |
                       v                           |
            |          +-------------------------->+          |
            +- - - - - - - - - - - - - - - - - - - - - - - - -+

*一般来说，进程打开伪终端主控端(后面用pseudo-terminal master表示)，然后调用fork。子进程建立新的会话，打开相应的伪终端从控端（后面用pseudo-terminal slave表示），复制文件描述符号到标准输入、标准输出、标准错误输出，然后调用exec。pseudo-terminal变成子进程的控制终端。
* 对于slave端的用户进程来说，它的标准输入，标准输出，以及标准错误输出是一个终端设备。进程可以对这些文件描述符号调用所有前面描述的终端I/O相关的函数。但是，因为在slave下面没有真正的终端设备，所以不会起作用的那些函数（改变波特率，发送break字符，设置oddparity等），会被忽略。
* 任何写入到master端的内容都会被视作slave端的输入，反之亦然。实际上，所有到达slave端的输入来自pseudo-terminal master上面的用户进程。这个行为看起来就像是一个双向的管道。但是通过slave上面的终端行规范模块，我们可以有除了管道之外更多的能力。
上面的图中的伪终端表现是FreeBSD,Mac OS X, 或者 Linux系统上面的大致情况。后面，我们将要展示如何打开这些设备。

在Solaris下，伪终端通过使用STREAMS子系统构建。下面的图形列出了Solaris下面的伪终端STREAMS模块的组织结构。两个用虚线框起来的STREAMS模块(ttcompat和pckt)是可选的。pckt和ptem模块用来提供伪终端的语义规范。另外两个模块(ldterm和ttcompat)提供行处理规范。
                         Solaris下面伪终端的结构

                     +----------+         +----------+
                     |    user  |  fork   |   user   |
                     |  process |-------->|  process |
                     +-----^----+  exec   +-----^----+
                           |                    |stdin,stdout,stderr
            +- - - - - - - - - - - - - - - - - - - - - - - - -+
            |              |                    |             |
                 +---------v-------+   +--------v-------+
            |    |  stream head    |   |   stream head  |     |
                 +-----|-----^-----+   +----|------^----+
            |          |     |              |      |          |
                       |     |         +- - v- - - |- - +
            |          |     |         .    ttcompat    .     |
                       |     |         . STREAMS module .
            |          |     |         + - -| - - -^ - -+     |
                       |     |              |      |
            |          |     |         +----v------|----+     |
                       |     |         |     ldterm     |
            |          |     |         | STREAMS module |     | kernel
                       |     |         +----|------^----+
            |          |     |              |      |          |
                 +- - -v- - -|- - -+   +----v------|----+
            |    .      pckt       .   |      ptem      |     |
                 .  STREAMS module .   | STREAMS module |
            |    +- - -|- - -^- - -+   +----|------^----+     |
            |          |     |              |      |          |
                 +-----v-----|-----+   +----v------|----+
            |    | pseudo-terminal |   | pseudo-terminal|     |
                 |     master      |   |     slave      |
            |    +-----|-----^-----+   +----|------^----+     |
                       |     |              v      |
            |          |     +<-------------+      |          |
                       v                           |
            |          +-------------------------->+          |
            +- - - - - - - - - - - - - - - - - - - - - - - - -+

需要注意的是slave上面的三个STREAMS模块和以前"高级输入输出"中的一个名为"列出stream上的模块名称"的用于网络登陆的代码中的输出是一样。后面我们将会展示如何构建这个结构的STREAMS模块。

现在开始，我们将要通过去掉"read and write functions"来简化前面的"进程使用伪终端的典型结构"图形，或者通过去掉"stream head"简化前面的"Solaris下面伪终端的结构"图形。我们将会使用PTY表示伪终端的简写，把前面"Solaris下面伪终端的结构"的slave PTY之上所有的STREAMS模块放到"terminal line discipline"盒子中。
我们现在将会看看一些伪终端的典型使用。

网络登录服务
伪终端被编译成支持网络登录的服务。典型的例子就是telnetd和rlogind服务。第15章给出了rlogin服务的具体步骤。当登录shell运行在远程主机上面的时候，我们会有下面图形的结构。使用telnetd服务也会有类似的结构。

                        rlogind服务进程的组织结构

            +--------------------+   fork     +-----------+
            |      rlongind      +------------>   login   |
            |       server       | exec,exec  |   shell   |
            +----/-----^---\---^-+            +---|----^--+
                /     /     \   \          stdout |    |stdin
               /     /       |   \         stderr |    |
     +......../...../........|...|................|....|.........+
     .   +---v-----/----+    |   |           +----v----|-----+   .
     .   |    TCP/IP    |    |   |           |    terminal   |   .
     .   +---|-----^----+    |   |           |line discipline|   .
     .       |     |         \    \          +----|----^-----+   .
     .       |     |          \    \              |    |         .
     .   +---v-----|----+    +-v----\---+       +-v----|--+      .kernel
     .   |    network   |    |   PTY    |       |   PTY   |      .
     .   | device driver|    |  master  |       |  slave  |      .
     .   +------^-------+    +-|----^---+       +-|----^--+      .
     .          |              |    |             v    |         .
     .          |              v    +<------------+    |         .
     .          |              +---------------------->+         .
     +..........|................................................+
                v
       ...................
             network

我们在rlogind服务和loginshell之间两次调用exec，因为login程序会在两者之间，用来用户验证。
上面这个图形中的一个比较关键的地方就是驱动PTY master的进程一般同时都会也读取另外一个I/O stream。在这个途中，另外的I/O stream就是 TCP/IP box。这也意味着进程必须使用一些多I/O的形式，例如select或者poll，或者必须被分割成两个进程或者线程。

script 程序
script程序由大多数的UNIX系统提供，它会将终端会话过程中的任何输入输出拷贝到一个文件中去。这个程序通过将它自身放置在终端和我们新启动的一个登陆shell之间来做到这个。下面的图详细列出了script程序的交互。这里我们特别指出script程序一般从一个登陆的shell中运行，然后这个登陆的shell等待script终止。

                                   script程序

                         +-----------+
                         |script file|
                         +-----^-----+
                               |
 +-----------+ fork +----------|---------+   fork     +-----------+
 |login shell+------>  script process    +------------>   shell   |
 +-----------+ exec +----/-----^---\---^-+   exec     +---|----^--+
  (sleeping)            /     /     \   \          stdout |    |stdin
                       /     /       |   \         stderr |    |
             +......../...../........|...|................|....|.........+
             .   +---v-----/-----+   |   |           +----v----|-----+   .
             .   |    terminal   |   |   |           |    terminal   |   .
             .   |line discipline|   |   |           |line discipline|   .
             .   +---|-----^-----+   \    \          +----|----^-----+   .
             .       |     |          \    \              |    |         .
             .   +---v-----|-----+   +-v----\---+       +-v----|--+      .kernel
             .   |    terminal   |   |   PTY    |       |   PTY   |      .
             .   | device driver |   |  master  |       |  slave  |      .
             .   +------^--------+   +-|----^---+       +-|----^--+      .
             .          |              |    |             v    |         .
             .          |              v    +<------------+    |         .
             .          |              +---------------------->+         .
             +..........|................................................+
                        v
                    - - - - --
                   / user at a\
                   \ terminal /
                    - - - - --

当script运行的时候，任何经过PTY slave上面的终端行规则的输出都会被拷贝到script file(一个script的文件)中去(一般被称作typescript)。因为我们的键盘键入一般通过那个行规则模块来显示，所以script file也会包含我们的输入。然而由于密码不会被显示出来，所以script file不会包含我们输入的任何密码。
当写这本书的第一个版本的时候，作者Rich Stevens使用script程序来捕获例子程序的输出。这个避免了相比较他自己手动来拷贝这些程序的输出，导致的印刷上面可能遇到的错误。然而，script程序的缺点就是，需要处理出现在script file中的控制字符。
在后面写的pty程序的时候，我们将会看到一个简单的shell脚本将这个程序变成一个script程序。

expect 程序
伪终端可以用来以非交互的模式来运行交互的程序。大量的程序需要一个终端来运行。有一个例子就是passwd命令，这个程序需要用户键入一个密码来相应提示符号。
除了可以修改所有的交互程序，让它们本身可以支持批量处理模式的操作，一个更好的解决方法就是，提供一个方式，可以让所有的交互程序能够从一个脚本中运行。expect程序就提供了这样的功能。它使用伪终端来运行其他的程序，这和我们后面讲述的pty程序类似，但是expect可以提供一种程序语言来检查运行的应用程序的输出，然后确定再将给应用程序发送什么作为应用程序的输入。当一个交互的程序从一个脚本中运行的时候，我们无法从脚本中只拷贝所有内容到应用程序，以及反之。所以，我们需要给应用程序发送一些输入，查看它的输出，然后决定之后给应用程序发送什么。

运行协作处理进程
在前面协作处理进程(协作处理进程参见前面，简之即被协作者输入给协作者，协作者处理之后再送回给被协作者)的例子中，我们无法启动一个使用标准输入输出库作为输入输出的协作处理程序，因为当我们通过一个管道和协作处理程序交互的时候，标准输入输出库是将标准输入输出设成满缓冲形式的，这样会导致死锁。如果我们没有那个编译好了的协作处理程序的源代码，那么我们无法使用fflush来解决这个问题。15章第4节中"通过写它的标准输入以及读取它的标准输出来运行写作处理程序"这个图，展示的就是一个进程来驱动协作处理程序。我们需要做的只是将一个伪终端放置在两个进程之间。这样使得协作处理程序以为，它运行在一个终端上面，而不是另外一个进程驱动它运行。如下图所示。

                     使用伪终端来驱动一个协作处理进程

                                                            coprocess
      +-----------+  pipe1    +-------------+            +-------------+
      |  driving  |---------->|   pseudo    |----------->| stdin       |
      |  program  |<----------|  terminal   |<-----------| stdout      |
      +-----------+  pipe2    +-------------+            +-------------+

现在协作处理进程的标准输入和标准输出看起来就像是一个终端设备，所以标准输入输出库会设置这两个流为行缓冲的方式。

父进程可以以两种方式获得在它本身和协作处理进程之间的伪终端。(这里父进程可以是前面使用两个管道和协作处理进程通信的程序，也可以是使用一个单一的STREAMS管道的程序)。一个方法就是，父进程直接调用pty_fork函数（后面有这个函数相关的内容）而不是调用fork。另一个方法就是使用exec执行pty程序（后面有这个程序的实现），并且将协作处理进程作为它的参数。我们将在介绍完了pty程序之后，看看这两个解决的方法。

查看长时间运行的程序的输出
如果我们有一个程序，那个程序运行很长的时间，我们可以在任何一种标准的shell下面将这个程序简单地放到后台运行。但是，如果我们将这个程序的标准输出重新定向到一个文件中的时候，或者它并不产生许多输出的时候，我们无法方便地检测这个进程，因为标准输入输出库对它的标准输出设置成为了满缓存(标准输出被重新定向成了一个文件，而根据前面，一个文件被标准输入输出库读写的时候会被首先设置成满缓冲的形式)。 我们所能够看到的只是标准输入输出库将成块的输出写到文件中去，可能每块数据的大小达到8,192字节。
如果我们有源代码，我们可以插入fflush调用。另外，我们可以通过pty程序运行这个程序，这样让标准输入输出库以为它的标准输出是一个终端（这样就不会成为满缓冲了）。下面的图形就展示了这个结构，我们将它称为慢输出程序。fork/exec箭头从login shell指向pty进程，箭头是虚线的，用来强调pty进程运行在后台作业当中。

                          通过伪终端运行慢输出程序

                               +-------------+
                               | output file |
                               +------^------+
                                      |
        +----------+           +------|------+           +----------+
        |  login   |  fork     |     pty     |   fork    | slow out |
        |  shell   |- - - - - ->   process   |---------->|          |
        +--|----^--+  exec     +--|-----^----+   exec    +--|-----^-+
           |    |                 |     |             stdout|     |stdin
           |    |                 |     |             stderr|     |
   +- - - -|- - |- - - - - - - - -|- - -|- - - - - - - - - -|- - -|- - - -+
   |   +---v----|------+          |     |              +----v-----|----+  |
       |   terminal    |          |     |              |   terminal    |
   |   |line discipline|          |     |              |line discipline|  |
       +---|----^------+          |     |              +----|-----^----+
   |       |    |                 |     |                   |     |       |
           |    |                 |     |                   |     |         kernel
   |   +---v----|------+       +--v-----|----+           +--v-----|--+    |
       |   terminal    |       |    PTY      |           |   PTY     |
   |   | device driver |       |   master    |           |   slave   |    |
       +------^--------+       +--|-----^----+           +--|-----^--+
   |          |                   |     |                   v     |       |
              |                   v     +<------------------+     |
   |          |                   +------------------------------>+       |
   + - - - - -|- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -+
              v
         /---------\
        | user at a |
        |  terminal |
         \---------/

3)打开伪终端设备
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19lev1sec3.html
我们打开伪终端设备的方式随平台有所不同。Single UNIX Specification将一些函数作为XSI扩展，尝试统一这些方法。这些扩展基于一些函数，这些函数原来是用来为System V4提供基于流的伪终端管理。
posix_openpt函数提供了一个可移植的方法，以打开一个可用的伪终端主设备。
#include <stdlib.h>
#include <fcntl.h>
int posix_openpt(int oflag);
返回：如果成功返回下一个可用的PTY master的文件描述符号，如果错误返回1。
oflag参数是一个位掩码，指定主设备如何被打开，它和open函数的参数类似，但是也不是支持所有的open标记。通过使用posix_openpt，我们可以指定O_RDWR打开主设备用于读和写，我们也可以指定O_NOCTTY来阻止主设备变成调用者的控制终端，其他的open标记的行为都是不可知的。

在一个slave伪终端可以被使用之前，需要设置它的权限，以便应用程序能够访问它。grantpt函数就做了这样的事情，它设置从设备节点的user ID为调用者的real user ID，并设置节点的group ID为一个未指定的值，一般来说，是一些具有访问终端设备权限的组。可以设置权限允许特定的属主进行读写访问以及特定的组属主进行写访问（即0620）。
#include <stdlib.h>
int grantpt(int filedes);
int unlockpt(int filedes);
两者返回：如果成功返回0，如果错误返回1。
为了修改从设备节点的权限，grantpt可能需要调用fork和exec一个set-user-ID程序（例如Solaris上面的/usr/lib/pt_chmod）。因此，如果调用者捕获了SIGCHLD信号，那么行为就是不确定的了(捕获了说明子进程停止或者终止了，但是为什么???)。
unlockpt函数用于给slave伪终端设备赋予访问权限，从而允许应用程序打开设备。通过阻止其他的应用程序打开从(slave)设备，设置设备的应用程序可以有机会在主从设备可以被使用之前，对它们进行合适的初始化。
注意，对于grantpt和unlockpt函数，文件描述符号参数(filedes)是和master(主)伪终端设备关联的文件描述符号。

ptsname函数可以通过给定的主设备的文件描述符号，获取slave伪终端设备的路径名称。这允许应用程序可以独立于特定平台导致的一些特性，来辨别slave。注意，返回的name可能会被存放在静态内存当中，这样它会被后来的调用覆盖。
#include <stdlib.h>
char *ptsname(int filedes);
返回：如果成功返回一个指向PTY slave的指针，如果错误返回NULL。

下表列出了Single UNIX Specification所支持的伪终端函数，并且标识了哪些函数在本书所讨论的平台中是被支持的。

						   XSI的伪终端函数
┌──────────────┬─────────────────────────────────┬─────┬───────────┬────────┬─────────┬────────┐
│   Function   │             Description         │ XSI │   FreeBSD │  Linux │ Mac OS X│ Solaris│
│              │                                 │     │    5.2.1  │ 2.4.22 │   10.3  │    9   │
├──────────────┼─────────────────────────────────┼─────┼───────────┼────────┼─────────┼────────┤
│ grantpt      │ Change permissions of slave PTY │  •  │      •    │    •   │         │    •   │
│              │ device.                         │     │           │        │         │        │
├──────────────┼─────────────────────────────────┼─────┼───────────┼────────┼─────────┼────────┤
│ posix_openpt │ Open a master PTY device.       │  •  │      •    │        │         │        │
├──────────────┼─────────────────────────────────┼─────┼───────────┼────────┼─────────┼────────┤
│ ptsname      │ Return name of slave PTY device.│  •  │      •    │    •   │         │    •   │
├──────────────┼─────────────────────────────────┼─────┼───────────┼────────┼─────────┼────────┤
│ unlockpt     │ Allow slave PTY device to be    │  •  │      •    │    •   │         │    •   │
│              │ opened.                         │     │           │        │         │        │
└──────────────┴─────────────────────────────────┴─────┴───────────┴────────┴─────────┴────────┘
在FreeBSD中，unlockpt什么也不做，O_NOCTTY标记只是为了兼容调用posix_openpt函数的应用程序。FreeBSD在打开一个终端设备的时候，并不会为它分配一个控制终端，所以O_NOCTTY标记没有任何作用。

尽管Single UNIX Specification尝试在这里提高移植特性，但是正如上表所示实现上还是有些问题。因此，我们提供了两个函数处理所有的细节：ptym_open函数打开下一个可用的PTY master设备，ptys_open打开相应的slave设备。
#include "apue.h"
int ptym_open(char *pts_name, int pts_namesz);
返回：如果成功返回PTY master的文件描述符号，如果错误返回1。
int ptys_open(char *pts_name);
返回：如果成功返回PTY slave的文件描述符号，如果错误返回1。
一般，我们不会直接调用这两个函数；函数pty_fork会调用他们，也会fork子进程。
ptym_open函数确定下一个可用的PTY master并且打开这个设备。调用者必须分配一个数组来存储master或者slave的名称；如果调用成功，那么相应的slave会通过pts_name返回。这个名字然后被传递给ptys_open，它会打开slave设备。缓存的字节长度会被通过pts_namesz参数传递，这样ptym_open函数就不会拷贝一个比缓存长度还长的字符串了。
提供这两个函数来打开两个设备的原因，在我们展示pty_fork函数的时候会很明显的。一般，一个进程调用ptym_open来打开master并且获得slave的名称。进程然后进行fork，然后子进程调用setsid建立一个新的会话之后将调用ptys_open来打开slave。slave就是这样成为子进程的控制终端的。

*基于流的伪终端
下一个可用的PTY master设备通过一个STREAMS的克隆设备来进行访问。克隆设备就是一个特殊的设备，这个设备在被打开的时候会返回一个没有使用的设备。

基于STREAMS的PTY master克隆设备是/dev/ptmx。当我们打开它的时候，这个克隆打开函数会自动确认第一个没有使用的PTY master设备，然后打开那个没有使用的设备(后面我们将会看到，在基于BSD的系统中，我们需要自己寻找第一个没有使用的PTY master设备)。

基于流的伪终端打开函数
#include "apue.h"
#include <errno.h>
#include <fcntl.h>
#include <stropts.h>
int ptym_open(char *pts_name, int pts_namesz)
{
    char    *ptr;
    int     fdm;

    /*
     * Return the name of the master device so that on failure
     * the caller can print an error message.  Null terminate
     * to handle case where strlen("/dev/ptmx") > pts_namesz.
     */
    strncpy(pts_name, "/dev/ptmx", pts_namesz);
    pts_name[pts_namesz - 1] = '\0';
    if ((fdm = open(pts_name, O_RDWR)) < 0)
        return(-1);
    if (grantpt(fdm) < 0) {     /* grant access to slave */
        close(fdm);
        return(-2);
    }
    if (unlockpt(fdm) < 0) {    /* clear slave's lock flag */
        close(fdm);
        return(-3);
    }
    if ((ptr = ptsname(fdm)) == NULL) { /* get slave's name */
        close(fdm);
        return(-4);
    }

    /*
     * Return name of slave.  Null terminate to handle
     * case where strlen(ptr) > pts_namesz.
     */
    strncpy(pts_name, ptr, pts_namesz);
    pts_name[pts_namesz - 1] = '\0';
    return(fdm);            /* return fd of master */
}

int ptys_open(char *pts_name)
{
    int     fds, setup;

    /*
     * The following open should allocate a controlling terminal.
     */
    if ((fds = open(pts_name, O_RDWR)) < 0)
        return(-5);

    /*
     * Check if stream is already set up by autopush facility.
     */
    if ((setup = ioctl(fds, I_FIND, "ldterm")) < 0) {
        close(fds);
        return(-6);
    }
    if (setup == 0) {
        if (ioctl(fds, I_PUSH, "ptem") < 0) {
            close(fds);
            return(-7);
        }
        if (ioctl(fds, I_PUSH, "ldterm") < 0) {
            close(fds);
            return(-8);
        }
        if (ioctl(fds, I_PUSH, "ttcompat") < 0) {
            close(fds);
            return(-9);
        }
    }
    return(fds);
}

我们首先打开克隆设备/dev/ptmx来获取PTY master的文件描述符号。打开这个master 设备会自动锁住相应的slave 设备。
然后我们调用grantpt来改变slave设备的权限。在Solaris上面，会将slave设备的属主改变成real user ID，并且改变其组属主为tty组，以及将其许可权限修改成允许用户读、写，以及组写。将组属主修改成tty以及打开组写的权限的原因就是程序wall和write是被set-group-ID为tty组的。调用grantpt会执行/usr/lib/pt_chmod程序，这个程序是被set-user-ID为root的这样它能够修改slave的属主。
函数unlockpt被调用以清理slave设备的内部锁状态。我们需要在打开slave之前做这一步。我们必须调用ptsname来获取slave设备的名字，这个名字的形式一般为/dev/pts/NNN。
下一个函数是ptys_open。这个函数会实际打开slave设备。Solaris遵从以前的System V的动作：如果调用者是一个没有控制终端的session leader，那么这个open会将PTY slave分配成为一个控制终端。如果我们不想这么做，那么我们需要在open的时候指定O_NOCTTY标记。
打开slave设备之后，我们可能需要将三个STREAMS模块推送到slave流上面。伪终端模拟模块(ptem)和终端行规则模块(ldterm)一起，使得其行为如同一个终端。ttcompat模块提供了对原来的V7系统、4BSD系统以及Xenix ioctl调用的兼容，它是一个可选的模块，但是因为它在终端登陆以及网络登陆的时候会被自动推送，我们也会将它推送到slave流上面。
如果这三个模块已经存在，那么我们不需要推送它们。STREAMS系统提供了一个叫做autopush的工具，这个工具允许管理者配置一个模块的列表，这些模块会在特定的终端设备打开的时候被推送到一个流上面。我们使用ioctl的I_FIND命令来查看ldterm是否已经被推送到流上面，如果已经推送上去了，那么我们会假定流已经被autopush机制配置好了，就不用再次推送这个模块了。
调用ptym_open和ptys_open的结果就是给调用进程打开了两个文件描述符号：一个用于master，另外一个用于slave。

*基于BSD的伪终端
在基于BSD的系统中，和基于Linux的系统中，我们提供了自己的XSI函数版本。
在我们自己写的posix_openpt函数中，我们需要确定第一个可用的PTY master设备。为了做到这个，我们从/dev/ptyp0开始，并且一直尝试直至我们成功打开了一个PTY master或者直到我们的设备没有了。我们可以从open中得到两个不同的错误：EIO表示设备已经被使用；ENOENT表示设备不存在。在后一种情况中，因为所有的伪终端设备在使用中，我们可以停止搜索。当我们可以打开一个PTY master的时候，也就是/dev/ptyMN，那么相应的的slave名字就是/dev/ttyMN。在Linux上面，如果PTY master名字是/dev/pty/mXX，那么相应的PTY slave名字应该是/dev/pty/sXX。

在我们定义的grantpt中，我们调用chown和chmod但是需要注意的是，这两个函数必须有超级用户的权限才能正常工作。如果改变用户属主以及保护权限是非常重要的，那么这两个函数调用应该被放到set-user-ID为root的可执行文件中去，就像Solaris系统实现它的那样。

下面代码中的函数ptys_open只是打开slave设备，没有其他必要的初始化动作。在基于BSD的系统中对slave PTY的打开，并没有自动将该设备分配为控制终端的效果。在后面我们将会看到如何在基于BSD的系统中分配控制终端。

BSD和Linux的伪终端打开函数
#include "apue.h"
#include <errno.h>
#include <fcntl.h>
#include <grp.h>

#ifndef _HAS_OPENPT
int posix_openpt(int oflag)
{
    int     fdm;
    char    *ptr1, *ptr2;
    char    ptm_name[16];

    strcpy(ptm_name, "/dev/ptyXY");
    /* array index:   0123456789   (for references in following code) */
    for (ptr1 = "pqrstuvwxyzPQRST"; *ptr1 != 0; ptr1++) {
        ptm_name[8] = *ptr1;
        for (ptr2 = "0123456789abcdef"; *ptr2 != 0; ptr2++) {
            ptm_name[9] = *ptr2;

            /*
             * Try to open the master.
             */
            if ((fdm = open(ptm_name, oflag)) < 0) {
                if (errno == ENOENT)    /* different from EIO */
                    return(-1);         /* out of pty devices */
                else
                    continue;           /* try next pty device */
            }
            return(fdm);        /* got it, return fd of master */
            }
    }
    errno = EAGAIN;
    return(-1);     /* out of pty devices */
}
#endif

#ifndef _HAS_PTSNAME
char * ptsname(int fdm)
{
    static char pts_name[16];
    char        *ptm_name;

    ptm_name = ttyname(fdm);
    if (ptm_name == NULL)
        return(NULL);
    strncpy(pts_name, ptm_name, sizeof(pts_name));
    pts_name[sizeof(pts_name) - 1] = '\0';
    if (strncmp(pts_name, "/dev/pty/", 9) == 0)
		pts_name[9] = 's';  /* change /dev/pty/mXX to /dev/pty/sXX */
    else
        pts_name[5] = 't';  /* change "pty" to "tty" */
    return(pts_name);
}
#endif

#ifndef _HAS_GRANTPT
int grantpt(int fdm)
{
    struct group    *grptr;
    int             gid;
    char            *pts_name;

    pts_name = ptsname(fdm);
    if ((grptr = getgrnam("tty")) != NULL)
        gid = grptr->gr_gid;
    else
        gid = -1;       /* group tty is not in the group file */

    /*
     * The following two calls won't work unless we're the superuser.
     */
    if (chown(pts_name, getuid(), gid) < 0)
        return(-1);
    return(chmod(pts_name, S_IRUSR | S_IWUSR | S_IWGRP));
}
#endif

#ifndef _HAS_UNLOCKPT
int unlockpt(int fdm)
{

    return(0); /* nothing to do */
}
#endif

int ptym_open(char *pts_name, int pts_namesz)
{
    char    *ptr;
    int     fdm;

    /*
     * Return the name of the master device so that on failure
     * the caller can print an error message.  Null terminate
     * to handle case where string length > pts_namesz.
     */
    strncpy(pts_name, "/dev/ptyXX", pts_namesz);
    pts_name[pts_namesz - 1] = '\0';
    if ((fdm = posix_openpt(O_RDWR)) < 0)
        return(-1);
    if (grantpt(fdm) < 0) {     /* grant access to slave */
        close(fdm);
        return(-2);
    }
    if (unlockpt(fdm) < 0) {    /* clear slave's lock flag */
        close(fdm);
        return(-3);
    }
    if ((ptr = ptsname(fdm)) == NULL) { /* get slave's name */
        close(fdm);
        return(-4);
    }

    /*
     * Return name of slave.  Null terminate to handle
     * case where strlen(ptr) > pts_namesz.
     */
    strncpy(pts_name, ptr, pts_namesz);
    pts_name[pts_namesz - 1] = '\0';
    return(fdm);            /* return fd of master */
}

int ptys_open(char *pts_name)
{
    int fds;

    if ((fds = open(pts_name, O_RDWR)) < 0)
        return(-5);
    return(fds);
}
我们定义的posix_openpt尝试16个PTY master的16个不同的组：/dev/ptyp0 到/dev/ptyTf。实际的可用PTY设备数目取决于两个因素：a)配置到内核中的数目。b)/dev目录下面建立的特殊设备文件的数目。可用的数目就是两者之间最小者。

*基于Linux的伪终端
Linux提供访问伪终端的BSD方法，所以可以使用上面代码中同样的函数在Linux上面进行工作。然而，Linux也支持使用/dev/ptmx的伪终端克隆接口(这不是STREAMS设备)。克隆接口要求额外的步骤来辨别和解锁一个slave设备。在Linux上面我们可以使用访问伪终端设备的函数参见下面的代码。

用于Linux的伪终端打开函数
#include "apue.h"
#include <fcntl.h>
#ifndef _HAS_OPENPT
int posix_openpt(int oflag)
{
    int     fdm;

    fdm = open("/dev/ptmx", oflag);
    return(fdm);
}
#endif

#ifndef _HAS_PTSNAME
char * ptsname(int fdm)
{
    int         sminor;
    static char pts_name[16];

    if (ioctl(fdm, TIOCGPTN, &sminor) < 0)
        return(NULL);
    snprintf(pts_name, sizeof(pts_name), "/dev/pts/%d", sminor);
    return(pts_name);
}
#endif

#ifndef _HAS_GRANTPT
int grantpt(int fdm)
{
    char            *pts_name;

    pts_name = ptsname(fdm);
    return(chmod(pts_name, S_IRUSR | S_IWUSR | S_IWGRP));
}
#endif

#ifndef _HAS_UNLOCKPT
int unlockpt(int fdm)
{
    int lock = 0;

    return(ioctl(fdm, TIOCSPTLCK, &lock));
}
#endif

int ptym_open(char *pts_name, int pts_namesz)
{
    char    *ptr;
    int     fdm;

    /*
     * Return the name of the master device so that on failure
     * the caller can print an error message.  Null terminate
     * to handle case where string length > pts_namesz.
     */
    strncpy(pts_name, "/dev/ptmx", pts_namesz);
    pts_name[pts_namesz - 1] = '\0';

    fdm = posix_openpt(O_RDWR);
    if (fdm < 0)
        return(-1);
    if (grantpt(fdm) < 0) {     /* grant access to slave */
        close(fdm);
        return(-2);
    }
    if (unlockpt(fdm) < 0) {    /* clear slave's lock flag */
        close(fdm);
        return(-3);
    }
    if ((ptr = ptsname(fdm)) == NULL) { /* get slave's name */
        close(fdm);
        return(-4);
    }
    /*
     * Return name of slave.  Null terminate to handle case
     * where strlen(ptr) > pts_namesz.
     */
    strncpy(pts_name, ptr, pts_namesz);
    pts_name[pts_namesz - 1] = '\0';
    return(fdm);            /* return fd of master */
}

int ptys_open(char *pts_name)
{
    int fds;

    if ((fds = open(pts_name, O_RDWR)) < 0)
        return(-5);
    return(fds);
}

在Linux上面PTY slave设备已经被tty组拥有，所以我们grantpt中需要做的只是保证权限的正确。


4)pty_fork函数
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19lev1sec4.html
我们现在使用前面的两个函数，ptym_open和ptys_open，来写一个新的函数，名字叫pty_fork。这个新的函数将在fork的时候同时打开master和slave，并且为子进程建立一个具有控制终端的session leader。
#include "apue.h"
#include <termios.h>
#include <sys/ioctl.h>   /* find struct winsize on BSD systems */

pid_t pty_fork(int *ptrfdm, char *slave_name, int slave_namesz,
               const struct termios *slave_termios, const struct winsize *slave_winsize);
返回：子进程中返回0，父进程中返回子进程的进程ID，如果错误返回1。
(这里描述似乎不准确，因为通过代码看错误的时候返回的是-1???)

PTY master的文件描述符号通过ptrfdm指针返回。如果slave_name非空，那么slave设备的名称会被存放在其中，调用者需要为这个参数指向的指针分配空间。
如果指针slave_termios非空，那么系统使用这个引用的结构来初始化slave的终端行规则。如果这个指针为空，那么系统设置slave的termios结构为系统定义的初始状态。类似，如果slave_winsize指针非空的时候，就用其引用的结构来初始化slave的窗口大小，如果这个指针为空，那么一般会将窗口大小的结构初始化为0。
下面代码给出了这个函数的实现，它运行在本文所描述的平台之下，会调用合适的ptym_open和ptys_open函数。

pty_fork函数
#include "apue.h"
#include <termios.h>
#ifndef TIOCGWINSZ
#include <sys/ioctl.h>
#endif

pid_t pty_fork(int *ptrfdm, char *slave_name, int slave_namesz,
         const struct termios *slave_termios, const struct winsize *slave_winsize)
{
    int     fdm, fds;
    pid_t   pid;
    char    pts_name[20];

    if ((fdm = ptym_open(pts_name, sizeof(pts_name))) < 0)
        err_sys("can't open master pty: %s, error %d", pts_name, fdm);

    if (slave_name != NULL) {
        /*
         * Return name of slave.  Null terminate to handle case
         * where strlen(pts_name) > slave_namesz.
         */
        strncpy(slave_name, pts_name, slave_namesz);
        slave_name[slave_namesz - 1] = '\0';
    }

    if ((pid = fork()) < 0) {
        return(-1);
    } else if (pid == 0) {      /* child */
        if (setsid() < 0)
            err_sys("setsid error");

        /*
         * System V acquires controlling terminal on open().
         */
        if ((fds = ptys_open(pts_name)) < 0)
            err_sys("can't open slave pty");
        close(fdm);     /* all done with master in child */

#if defined(TIOCSCTTY)
        /*
         * TIOCSCTTY is the BSD way to acquire a controlling terminal.
         */
        if (ioctl(fds, TIOCSCTTY, (char *)0) < 0)
            err_sys("TIOCSCTTY error");
#endif

        /*
         * Set slave's termios and window size.
         */
        if (slave_termios != NULL) {
            if (tcsetattr(fds, TCSANOW, slave_termios) < 0)
                err_sys("tcsetattr error on slave pty");
        }
        if (slave_winsize != NULL) {
            if (ioctl(fds, TIOCSWINSZ, slave_winsize) < 0)
                err_sys("TIOCSWINSZ error on slave pty");
        }
        /*
         * Slave becomes stdin/stdout/stderr of child.
         */
        if (dup2(fds, STDIN_FILENO) != STDIN_FILENO)
            err_sys("dup2 error to stdin");
        if (dup2(fds, STDOUT_FILENO) != STDOUT_FILENO)
            err_sys("dup2 error to stdout");
        if (dup2(fds, STDERR_FILENO) != STDERR_FILENO)
            err_sys("dup2 error to stderr");
        if (fds != STDIN_FILENO && fds != STDOUT_FILENO &&
          fds != STDERR_FILENO)
            close(fds);
        return(0);      /* child returns 0 just like fork() */
    } else {                    /* parent */
        *ptrfdm = fdm;  /* return fd of master */
        return(pid);    /* parent returns pid of child */
    }
}

打开PTY master之后，调用fork。如我们前面所述，我们等待子进程调用ptys_open和setsid建立一个新的会话。当子进程调用setsid的时候，子进程不是一个进程组leader，所以会发生如第9章节5节所述的步骤：a)会创建一个新的会话，新的session leader为子进程。b)会为子进程创建一个新的进程组。c)子进程失去原有的控制终端的所有联系。在Linux和Solaris，slave会在调用ptys_open的时候变成新session控制终端。在FreeBSD和Mac OS X中，我们需要调用ioctl，参数为TIOCSCTTY来分配一个控制终端。（Linux也支持TIOCSCTTY的ioctl命令）。termios和winsize两个结构然后会在子进程中被初始化。最后，slave文件描述符号会被克隆到子进程的标准输入，标准输出，以及标准错误上。这意思是说，无论子进程exec什么程序，都将会和相应的slave PTY（控制终端）有所关联了。
调用fork之后，父进程返回PTY master描述符号，以及子进程的进程ID。在后面的章节中，我们在pty程序中使用pty_fork函数。

5)pty程序
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19lev1sec5.html
写pty程序是因为这样就可以用"pty prog arg1 arg2"方式的键入取代"prog arg1 arg2"方式的键入。
当我们使用pty来执行另外一个程序的时候，那个程序会在它自己的session中被执行，并且连接到一个伪终端上面。下面，我们来看一下pty程序的源代码。
首先是包含main函数的文件，这个文件会调用前面章节中定义的pty_fork函数。

pty程序的main函数
#include "apue.h"
#include <termios.h>
#ifndef TIOCGWINSZ
#include <sys/ioctl.h>  /* for struct winsize */
#endif

#ifdef LINUX
#define OPTSTR "+d:einv"
#else
#define OPTSTR "d:einv"
#endif

static void set_noecho(int);    /* at the end of this file */
void        do_driver(char *);  /* in the file driver.c */
void        loop(int, int);     /* in the file loop.c */

int main(int argc, char *argv[])
{
    int             fdm, c, ignoreeof, interactive, noecho, verbose;
    pid_t           pid;
    char            *driver;
    char            slave_name[20];
    struct termios  orig_termios;
    struct winsize  size;

    interactive = isatty(STDIN_FILENO);
    ignoreeof = 0;
    noecho = 0;
    verbose = 0;
    driver = NULL;

    opterr = 0;     /* don't want getopt() writing to stderr */
    while ((c = getopt(argc, argv, OPTSTR)) != EOF) {
        switch (c) {
        case 'd':        /* driver for stdin/stdout */
            driver = optarg;
            break;
        case 'e':        /* noecho for slave pty's line discipline */
            noecho = 1;
            break;

        case 'i':       /* ignore EOF on standard input */
            ignoreeof = 1;
            break;

        case 'n':       /* not interactive */
            interactive = 0;
            break;

        case 'v':       /* verbose */
            verbose = 1;
            break;

        case '?':
            err_quit("unrecognized option: -%c", optopt);
        }
    }
    if (optind >= argc)
        err_quit("usage: pty [ -d driver -einv ] program [ arg ... ]");

    if (interactive) {  /* fetch current termios and window size */
        if (tcgetattr(STDIN_FILENO, &orig_termios) < 0)
            err_sys("tcgetattr error on stdin");
        if (ioctl(STDIN_FILENO, TIOCGWINSZ, (char *) &size) < 0)
            err_sys("TIOCGWINSZ error");
        pid = pty_fork(&fdm, slave_name, sizeof(slave_name),
          &orig_termios, &size);
    } else {
        pid = pty_fork(&fdm, slave_name, sizeof(slave_name),
          NULL, NULL);
    }

    if (pid < 0) {
        err_sys("fork error");
    } else if (pid == 0) {      /* child */
        if (noecho)
            set_noecho(STDIN_FILENO);   /* stdin is slave pty */

        if (execvp(argv[optind], &argv[optind]) < 0)
            err_sys("can't execute: %s", argv[optind]);
    }

    if (verbose) {
        fprintf(stderr, "slave name = %s\n", slave_name);
        if (driver != NULL)
            fprintf(stderr, "driver = %s\n", driver);
    }

    if (interactive && driver == NULL) {
        if (tty_raw(STDIN_FILENO) < 0)  /* user's tty to raw mode */
        err_sys("tty_raw error");
    if (atexit(tty_atexit) < 0)         /* reset user's tty on exit */
        err_sys("atexit error");
    }

    if (driver)
        do_driver(driver);   /* changes our stdin/stdout */

    loop(fdm, ignoreeof);    /* copies stdin -> ptym, ptym -> stdout */

    exit(0);
}

static void set_noecho(int fd)     /* turn off echo (for slave pty) */
{
    struct termios stermios;

    if (tcgetattr(fd, &stermios) < 0)
        err_sys("tcgetattr error");

    stermios.c_lflag &= ~(ECHO | ECHOE | ECHOK | ECHONL);

    /*
     * Also turn off NL to CR/NL mapping on output.
     */
    stermios.c_oflag &= ~(ONLCR);

    if (tcsetattr(fd, TCSANOW, &stermios) < 0)
        err_sys("tcsetattr error");
}
在下一节，我们将要看到使用pty程序的各种不同的命令行选项。getopt函数帮助我们将命令参数以一个比较一致的方式包装起来，本书21章对getopt函数进行了更详细的解说。
在调用pty_fork之前，我们获得当前termios和winsize结构的值，并且将它们作为pty_fork的参数进行传递。采用这个方法，PTY slave假设具有和当前终端同样的初始状态。
从pty_fork返回之后，子进程可以关闭slave PTY的显示，然后调用execvp来执行命令行中指定的程序。所有剩下的命令行的参数都会被作为参数传递给这个程序。
父进程可以设置用户终端为raw模式。在这个情况下，父进程也设置exit处理函数以便调用exit的时候重置终端状态。我们后面会对do_driver函数进行描述。
父进程然后调用loop函数，这个函数会将从标准输入上面接收到的所有数据拷贝到PTY master上面，并且将拷贝PTY master上面的所有内容到标准输出。为了表示多样性，我们这里在两个进程中对它进行拷贝。当然，在一个进程中使用select,pool或者多线程的方式也可以做到这个效果。

补充：鉴于以后可能不会再对像20，21章这样只是开发一个程序的过程描述、这样的章节进行详细的翻译，这里给出一个经过实践的使用和解说getopt的例子。实践的系统为ubuntu 8.04，具体如下：
对于getopt函数的解说以及例子：
/**@mainpage 程序功能：测试getopt选项以及选项的参数的处理函数的使用方法
 *
 *#include <unistd.h>
 *int getopt(int argc, const * const argv[], const
 * char *options);
 *extern int optind, opterr, optopt;
 *extern char *optarg;
 *
 *参数argc和argv和main函数的一样，它们就是main函数传进来的；
 *参数options是一个字符串，这个字符串包含命令支持的所有选项字符;
 *
 *如果选项是非法的，或者选项缺少参数，那么getopt会返回一个'?'.
 *如果一个选项字符后面跟着一个冒号(即':')，那么说明这个选项需要一个参数。例如有一个命令如下：
 *	command [-i] [-u username] [-z] filename
 *那么这里的options应该赋值为："iu:z".
 *另外，getopt会忽略"--"后面的选项，例如:rm -- -bar,将删除-bar文件。
 *
 *getopt支持的四个外部变量:
 *optarg:
 *如果一个选项需要参数，那么getopt在处理一个选项的时候把optarg设置成为指向选项参数字符串的指针。
 *opterr:
 *如果出现选项错误，getopt会打印一个错误消息。如果去掉这个特性，那么在程序中将opterr设置成0.
 *optind:
 *下一个要处理的参数在argv数组中的索引。它从1开始，在每次用getopt处理参数的时候会增1。
 *optopt:
 *如果在处理选项的时候遇到了一个错误，getopt将会设置optopt， 让它指向导致错误的选项字符串。
 * */
#include <unistd.h>
//#include <fcntl.h>//只用这个也行
//#include <getopt.h>//只用这个也行

#include <stdio.h>
extern char *optarg;
extern int optind;
int main(int argc, char *argv[])
{
	if(argc == 1)
	{//没有参数
		printf("Introduction:\n");
		printf("Syntax is:\n%s [-i] [-u username] [-z] filename\n",argv[0]);
	}
	else
	{
		printf("Begin to process...\n");
		char c;
		char *optStr = "iu:z";
		while((c = getopt(argc, argv, optStr)) != -1)
		{//不要忘了加"()","="的优先级小于"!=".
			switch(c)
			{//处理每一个选项
				case 'i':
					printf("The argument \'i\' is used. \n");
					break;
				case 'u':
					printf("The argument \'u\' is used,and ");
					printf("the parameter of \'u\' is:%s \n", optarg);//选项的参数
					break;
				case 'z':
					printf("The argument \'z\' is used. \n");
					break;
				case '?':
					printf("Invalid option!\n");
					break;

			}
		}

		//选项处理完毕之后，处理输入的真正参数
		printf("option ok, and the main parameter is \"%s\"\n", argv[optind]);
		printf("Processed complete!\n");
	}
	return 0;
}

言归正转（早上上班的时候在公交车上学到的，用英语应该是"Let's get down to business."^_^），这里给出前面用到的loop函数。

loop函数
#include "apue.h"
#define BUFFSIZE    512
static void sig_term(int);
static volatile sig_atomic_t    sigcaught; /* set by signal handler */

void loop(int ptym, int ignoreeof)
{
    pid_t   child;
    int     nread;
    char    buf[BUFFSIZE];

    if ((child = fork()) < 0) {
        err_sys("fork error");
    } else if (child == 0) {    /* child copies stdin to ptym */
        for ( ; ; ) {
            if ((nread = read(STDIN_FILENO, buf, BUFFSIZE)) < 0)
                err_sys("read error from stdin");
            else if (nread == 0)
                break;      /* EOF on stdin means we're done */
            if (writen(ptym, buf, nread) != nread)
                err_sys("writen error to master pty");
        }

        /*
         * We always terminate when we encounter an EOF on stdin,
         * but we notify the parent only if ignoreeof is 0.
         */
        if (ignoreeof == 0)
            kill(getppid(), SIGTERM);   /* notify parent */
        exit(0);    /* and terminate; child can't return */
    }

    /*
     * Parent copies ptym to stdout.
     */
    if (signal_intr(SIGTERM, sig_term) == SIG_ERR)
        err_sys("signal_intr error for SIGTERM");

    for ( ; ; ) {
        if ((nread = read(ptym, buf, BUFFSIZE)) <= 0)
            break;      /* signal caught, error, or EOF */
        if (writen(STDOUT_FILENO, buf, nread) != nread)
            err_sys("writen error to stdout");
    }

    /*
     * There are three ways to get here: sig_term() below caught the
     * SIGTERM from the child, we read an EOF on the pty master (which
     * means we have to signal the child to stop), or an error.
     */
    if (sigcaught == 0) /* tell child if it didn't send us the signal */
        kill(child, SIGTERM);
    /*
     * Parent returns to caller.
     */
}

/*
 * The child sends us SIGTERM when it gets EOF on the pty slave or
 * when read() fails.  We probably interrupted the read() of ptym.
 */
static void sig_term(int signo)
{
    sigcaught = 1;      /* just set flag and return */
}

注意，通过两个进程，当一个进程终止的时候，它应该通知另外一个进程。我们使用SIGTERM信号进行通知。

6)使用pty程序
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19lev1sec6.html
我们现在，通过命令行选项，来看看使用pty程序的各种不同的例子。
如果我们的shell是Korn shell，我们可以执行：
pty ksh
启动一个新的shell，这个shell运行在伪终端之下。
如果文件ttyname就是我们在18章的那个程序，我们可以如下运行pty程序：
   $ who
   sar  :0      Oct  5 18:07
   sar  pts/0   Oct  5 18:07
   sar  pts/1   Oct  5 18:07
   sar  pts/2   Oct  5 18:07
   sar  pts/3   Oct  5 18:07
   sar  pts/4   Oct  5 18:07        pts/4 is the highest PTY currently in use
   $ pty ttyname                    run program in Figure 18.16 from PTY
   fd 0: /dev/pts/5                 pts/5 is the next available PTY
   fd 1: /dev/pts/5
   fd 2: /dev/pts/5


utmp文件
在第6章，我们叙述了utmp文件，这个文件记录了所有当前登陆到一个UNIX系统上面的用户。问题是，一个在伪终端上面运行程序的用户，是否被当做登陆的用户？在远程登陆中，telnetd和rlogind，显然会为在伪终端上面登陆的用户创建一个utmp文件中的条目。然而，如果用户从窗口系统或者某个程序（例如script）中运行shell于伪终端上，是否应当在utmp文件中有对应的条目，却有许多争议。有些系统会记录这些，有些却不会。如果一个系统没有在utmp文件中记录这些，那么who程序就通常不会显示相应的、被使用的伪终端。
如果utmp文件没有将other用户的写权限打开（这通常被认为是一种安全漏洞），那么任意使用伪终端的应用程序并不能写这个文件。

作业控制交互
如果我们在pty下面运行一个作业控制shell，那么它会正常地工作。例如：
    pty ksh
在pty下面运行Korn shell，我们可以在这个新的shell下面运行这个程序，并且像我们使用登陆shell那样使用作业控制。但是，如果我们如果在pty下面运行一个不是作业控制的交互程序，例如：
    pty cat
那么所有的东西会直到我们键入作业控制挂起字符的时候才会正常。在那个时候，作业控制字符被显示成^Z并且被忽略。在早期基于BSD的系统中，cat进程终止，pty进程也终止，然后我们回到原来的shell中去。为了了解究竟发生了什么事情，我们需要对所有的进程，它们的进程组，以及会话进行检查。下面的图就展示了运行pty cat的时候的情况。

                              对于pty cat的进程组和会话

                           session                                      session
    +- - - - - - - - - - - - - - - - - - - - - - - - - - - - - +   +- - - - - - - -+
    |  process group                process group              |   | process group |
    | +- - - - - - -+    +- - - - - - - - - - - - - - - - - +  |   |  +- - - - -+  |
    | | +---------+ |    | +------------+       +---------+ |  |   |  | +-----+ |  |
    | | |  login  | |    | |     pty    |       |   pty   | |  |   |  | | cat | |  |
    | | |  shell  | |    | |    parent  |       |  child  | |  |   |  | |     | |  |
    | | +---------+ |    | +--|-------^-+       +--|---^--+ |  |   |  | +-|-^-+ |  |
    | +- - - - - - -+    +- - | - - - -\- - - - - -|- / - - +  |   |  +- -|-|- -+  |
    +- - - - - - - - - - - - -|- - - - -\- - - - - | / - - - - +   +- - - | | - - -+
                              |      /---+---------+/                     | |
                         +----v-----/----+\        |               +------v-|------+
                         |    terminal   | \       |               |    terminal   |
                         |line discipline|  \      |               |line discipline|
                         +----|-----^----+   \     |               +------|-^------+
                              |     |         \----+---                   | |
                              |     |              |   \                  | |
                         +----v-----|----+      +--v----\-+           +---v-|---+
                         |    terminal   |      |   PTY   |           |   PTY   |
                         | device driver |      |  master |           |  slave  |
                         +-------^-------+      +--|----^-+           +---|-^---+
                                 |                 |    |                 v |
                                 |                 v    +<----------------+ |
                                 |                 +----------------------->+
                            /----v---\
                           |user at a |
                           | terminal |
                            \--------/

当我们键入挂起字符(Control-z)的时候，从pty将终端（在pty父进程之下）切入raw模式起，这个字符会被cat下面的行规则模块识别。但是由于它本身是孤儿进程组，所以内核不会停止这个cat进程(具体需要参见第9章10节)。cat的父进程是pty父进程，但是却属于另外一个会话。
以前，各种实现对这个情况的处理有所不同。POSIX.1只是说SIGTSTP信号不能发送给进程。从4.3BSD继承过来的系统却发送了SIGKILL信号，这个信号进程甚至不能捕获。4.4BSD中，这个行为改变了，它遵从POSIX.1，4.4BSD不是发送SIGKILL，它会静静地忽略SIGTSTP信号（如果这个信号是默认的行为并且要发送给另外一个孤儿进程组中的进程）。
当我们使用pty运行一个作业控制shell的时候，通过这个新的shell发起的作业不会是一个孤儿进程组中的成员，因为作业控制shell本身属于同一个会话。这个时候，Control-Z的键入，就会通过shell发送给这个被shell发起的进程，而不是发送给shell本身。
有一个方法可以避免被pty发起的进程无法处理作业控制信号：为pty添加另外一个命令行标记，告诉它让它自己识别作业控制挂起字符（在pty子进程中），而不是任由这个字符通过其他的行规则。

查看长时间运行的程序的输出
另外一个通过pty程序进行作业控制交互的例子就是本章第2节的"通过伪终端运行慢输出程序"图所示的例子。如果我们如下运行的程序输出很慢：
   pty slowout > file.out &
pty进程会在子进程尝试读取它的标准输入（终端）的时候立即停止。原因就是，这个作业是一个后台作业，当它尝试访问终端的时候会导致作业控制停止。如果我们将标准输入重新定向，一边pty不会尝试从终端进行读取，如下：
   pty slowout < /dev/null > file.out &
pty程序会立即停止，因为它在它的标准输入上面读取到一个文件结束符号并且终止。解决这个问题的方法就是使用-i选项，这个选项表示会忽略标准输入的文件结束符号:
   pty -i slowout < /dev/null > file.out &
这个标记导致当遇到文件结束符号的时候，pty子进程(前面代码中的loop函数)exit，但是子进程不会告诉父进程它终止了。相反，父进程还是继续将PTY slave的输出拷贝到标准输出（这个例子中的file.out文件）。

script程序
使用pty程序，我们可以如下通过shell脚本执行script程序:
    #!/bin/sh
    pty "${SHELL:-/bin/sh}" | tee typescript
当我们运行这个shell脚本的时候，我们可以执行ps命令来查看所有进程的关系，下面的途中就详细地列出了这些关系。

                        script的shell脚本的进程组织结构图

                           typescript
                             file                  -------------
                              ^                   /             \
  +-----------+   +----+   +--|--+   +----------+/   +---------+ \    +-----+    +----+
  |login shell|-->| sh |-->| tee |-->|pty parent|--->|pty child|  --->| ksh |--->| ps |
  +-----------+   +----+   +-|-^-+   +--|---^---+    +--|---^--+      +-----+    +|--^+
                             | |  pipe  v    \          /  /                      |  |
                             | +<-------+     \        /  /                       |  |
                             |    /------------+------+---                    +---v--|---+
                         +---v----|-+           \     |                       |  line    |
                         |   line   |            \   /                        |discipline|
                         |discipline|             \ /                         +---|--^---+
                         +---|-^----+              X                              |  |
                             | |                  / \                             |  |
                             | |               +-v---\-+                        +-v--|-+
                           +-v-|-+             |  PTY  |                        | PTY  |
                           | TTY |             | master|                        |master|
                           +--^--+             +-|---^-+                        +-|--^-+
                              |                  |   |                            v  |
                              |                  v   +<---------------------------+  |
                              |                  +---------------------------------->+
                           /--v--\
                          |  user |
                           \-----/

在这个例子里面，我们假设SHELL变量是Korn shell(一般来说导致使用/bin/ksh)。如我们前面所提到的那样，script只是拷贝这个新shell(以及它所发起的进程)所输出的内容。但是，当PTY slave上面的行规则模块一般来说打开回显的时候，大多数我们输入的也会写入到typescript文件中去。

运行协作处理进程
在15章2节中"使用两个管道用于父子进程同步"这个图中，协作处理进程不能使用标准输入输出函数，因为标准输入输出不会引用终端，所以标准输入输出函数将它们看作是全缓冲的。如果我们在pty下面如下代码运行写作处理进程：
    if (execl("./add2", "add2", (char *)0) < 0)
而不是：
    if (execl("./pty", "pty", "-e", "add2", (char *)0) < 0)
那么程序即使在写作处理进程使用标准输入输出的时候，也会正常工作。

下图展示我们使用伪终端作为协作处理进程的输入输出的时候进程的运行情况。它实际上是对本章第2节的图"使用伪终端来驱动一个协作处理进程"的一个扩展,(为方便起见，我将它也贴在下面了，其实它和前面的图一样)它展示了所有的进程连接和数据流。标记了"driving program"的部分是来自在15章2节中"使用两个管道用于父子进程同步"图的程序，其中的execl如前面所说的进行了修改。

                     使用伪终端来驱动一个协作处理进程(扩展之前)
                                                            coprocess
      +-----------+  pipe1    +-------------+            +-------------+
      |  driving  |---------->|   pseudo    |----------->| stdin       |
      |  program  |<----------|  terminal   |<-----------| stdout      |
      +-----------+  pipe2    +-------------+            +-------------+


            将伪终端作为协作处理进程的输入输出来运行写作处理进程(扩展后)
                                                        fork,exec
                                                 ---------------------\
     +-------------------+  fork    +---------+ /       +--------+     \    +-----------+
     |   driving         |--------->|  pty    |/  fork  |  pty   |      \   |   add2    |
     |       program     |  exec    | parent  |-------->| child  |       -->|(coprocess)|
     +--|----^----|---^--+          +--|---^--+         +--/---^-+          +---|----^--+
        |    |    |   |     pipe2      v    \             /    |                |    |
        |    |    v   +<---------------+     \           /     |                |    |
        |    |    +---------------------------\---------/----->+                |    |
        |    |              pipe1              \       /                        |    |
     +--v----|-------+                          \     /                   +-----v----|----+
     |    terminal   |                           \   /                    |    terminal   |
     |line discipline|                            \ /                     |line discipline|
     +--|----^-------+                             X                      +-----|----^----+
        |    |                                    / \                           |    |
        |    |                                   /   \                          |    |
     +--v----|-------+                       +--v-----\-+                    +--v----|-+
     |   terminal    |                       |   PTY    |                    |   PTY   |
     | device driver |                       |  master  |                    |  slave  |
     +------^--------+                       +--|-----^-+                    +--|----^-+
            |                                   |     |                         v    |
       /----v----\                              v     +<------------------------+    |
      | user at a |                             +----------------------------------->+
      | terminal  |
       \---------/

这个例子，展示了pty程序-e选项的需要。pty程序并不是交互运行的，因为它的标准输入没有连接到终端上面。因为对isatty返回为false，前面"pty程序的main函数"里面，交互的标记默认设置为false。也就是说，实际终端上面的行规则部分保持一个回显被打开的canonical模式。通过指定-e选项，我们关闭了PTY slave上面的行规则模块的回显。如果我们没有做这个步骤，我们所键入的就会被两个行规则模块显示两次。
我们指定-e选项也会关闭termios结构中的ONLCR标记，以组织所有来自协作处理进程的输出被回车或者新行终止。
在不同的系统上面测试这个例子，也显示了另外一个我们在14章8节中描述readn和writen函数时候暗示的问题。即当文件描述符号引用一个不是普通磁盘文件的时候，通过read返回的数据的数量，会根据实现有所不同。这个使用pty的协作处理进程的例子在还是15章2节中的那个程序里，由于其程序管道中的read函数返回少于一行，所以对read函数跟踪得到的数据结果是无法预料的。解决的方法就是不使用那个程序，但是使用本书中15章练习题第5题中的修改过的程序，这个程序使用了标准输入输出库，并且为两个管道的标准输入输出流设置了行缓冲。通过这样做，fgets函数读取的次数如同请求获取一整个行。15章2节的那个程序中的while循环假设每次向协作处理程序发送一行会导致一行被返回。

通过非交互的方式驱动交互程序
尽管我们觉得pty可以运行任何协作处理进程（甚至一个协作处理进程是交互的进程），它并不会正常工作。问题是，pty只是仅仅将它的标准输入的内容拷贝到PTY，以及将PTY的所有内容拷贝到它的标准输出，却不会检查它究竟发送了什么以及获取了什么。
作为一个例子，我们可以在pty下面运行telnet命令直接与远程主机交互：
    pty telnet 192.168.1.3
这样做，并不比直接键入telnet 192.168.1.3好多少，但是我们可能想要telnet程序从一个脚本中运行，并且可能会检测远程主机上面的一些条件。如果文件telnet.cmd包含这四行：
    sar
    passwd
    uptime
    exit
其中第一行远程登陆的用户名称，第二行是密码，第三行是我们想要运行的命令，第四行是终止会话的行。但是如果我们如下运行这个脚本：
    pty -i < telnet.cmd telnet 192.168.1.3
它并没有如我们所想的方式工作。所发生的事情应就是，文件telnet.cmd中的内容在开始提示我们输入用户名称和密码之前就被发送到远程主机上面。当关闭回显读取密码的时候，login程序使用tcsetattr选项，导致所有已经被排队的数据被丢弃。因此，我们发送的数据被丢弃了。
当我们交互运行telnet程序的时候，我们等待远程主机提示密码，然后我们才开始输入。但是pty程序不知道需要这样做，所以导致前面所说的那个现象。因此，需要一个更复杂的程序来实现这个功能，例如expect程序，通过这个程序才能正常地从一个脚本中以非交互的方式来运行一个交互的程序。

即使运行前面我们展示的"使用伪终端来驱动一个协作处理进程(扩展之前)"对应的程序，也没有什么作用。因为，程序假设每向一个管道写一行，也会在另外一个管道产生同样的一行。在交互处理程序中，一行输入可能会产生许多行输出，并且，前面途中的程序经常会在读取之前向协作处理进程发送一行数据。这样，当我们想要在发送之前从协作处理进程中读取一些数据的时候，就不能正常地工作了。
这里，有一些方法可以从一个脚本来启动交互处理程序。我们可以添加一个命令语言，以及给pty程序添加一个解释器，但是这样的话那个语言本身可能就比pty程序复杂多了。另外一个方法就是，采用一个命令行语言，然后使用pty_fork函数来发起交互程序。这也是expect程序所做的事情。
我们会采用不同的路径，并且添加一个-d选项，允许pty程序连接到驱动的进程的输入和输出。进程的标准输出是pty的标准输入，反之同样。这和协作处理进程类似，但是在pty的"另外一端"，结构和"将伪终端作为协作处理进程的输入输出来运行写作处理进程(扩展后)"是几乎一样的。但是在当前的情况中，pty对驱动的进程做了一步fork和exec的操作。并且，不是使用两个半双工的管道，我们将要在pty和驱动的进程之间，使用一个全双工的管道。
下面的代码展示了do_driver函数的源代码，这个函数会在指定-d选项的时候，被pty的main函数调用(参见前面"pty程序的main函数")。

pty程序的do_driver函数
#include "apue.h"
void do_driver(char *driver)
{
    pid_t   child;
    int     pipe[2];

    /*
     * Create a stream pipe to communicate with the driver.
     */
    if (s_pipe(pipe) < 0)
        err_sys("can't create stream pipe");

    if ((child = fork()) < 0) {
        err_sys("fork error");
    } else if (child == 0) {        /* child */
        close(pipe[1]);

        /* stdin for driver */
        if (dup2(pipe[0], STDIN_FILENO) != STDIN_FILENO)
            err_sys("dup2 error to stdin");

        /* stdout for driver */
        if (dup2(pipe[0], STDOUT_FILENO) != STDOUT_FILENO)
            err_sys("dup2 error to stdout");
        if (pipe[0] != STDIN_FILENO && pipe[0] != STDOUT_FILENO)
            close(pipe[0]);

        /* leave stderr for driver alone */
        execlp(driver, driver, (char *)0);
        err_sys("execlp error for: %s", driver);
    }
    close(pipe[0]);     /* parent */
    if (dup2(pipe[1], STDIN_FILENO) != STDIN_FILENO)
        err_sys("dup2 error to stdin");
    if (dup2(pipe[1], STDOUT_FILENO) != STDOUT_FILENO)
        err_sys("dup2 error to stdout");
    if (pipe[1] != STDIN_FILENO && pipe[1] != STDOUT_FILENO)
        close(pipe[1]);

    /*
     * Parent returns, but with stdin and stdout connected
     * to the driver.
     */
}

通过我们自己写的被pty调用的driver程序，我们可以以任何需要的方式来驱动交互程序。即使它的标准输入和标准输出连接到pty上面，driver进程也还是可以通过读写/dev/tty来和用户进行交互。这个方案还是不如expect程序通用，但是它只通过不到50行的代码，就为pty程序添加了一个有用的选项。

7)高级特性
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19lev1sec7.html
伪终端还有一些额外的特性，我们这里简单对它们列出。这些特性在Sun Microsystems和BSD的pty的man手册第4节中描述了。

包模式
包模式可以让PTY master获知PTY slave的状态变化。在Solaris上面，这个模式通过向PTY master端推送pckt的STREAMS模块来实现。我们在前面第2节中的"Solaris下面伪终端的结构"图中，对其进行了展示。在FreeBSD, Linux, 和 Mac OS X中，这个模式通过ioctl的TIOCPKT命令来激活。
Solaris和其他平台的包模式细节有一些不同。Solaris下面，由于pckt模块将特定的事件转化成非数据的STREAMS消息，所以从PTY master读取的进程需要调用getmsg来获得来自stream头的消息。在其他平台下面，每次从PTY master读取都会返回一个状态字节接着一个可选的数据。
除去这些实现上面的细节，包模式的目的就是在PTY slave上面的行规则模块发生如下事件的时候，通知读取PTY master的进程：当读取队列被flushed，当写队列被flushed，当输出停止的时候（例如Control-S导致其停止），当输出重新启动的时候，当XON/XOFF流控制在被禁止之后再次被使能的时候，在XON/XOFF流控制在被使能之后又被禁止的时候。这些事件，在诸如rlogin客户和rlogind服务进程中可能会被用到。

远程模式
通过使用ioctl的TIOCREMOTE命令，PTY master可以设置PTY slave为远程模式。尽管FreeBSD 5.2.1, Mac OS X 10.3, 和 Solaris 9使用同样的命令来使能这个特性，在Solaris中ioctl的第3各参数是一个整数，而FreeBSD 和 Mac OS X的相应参数是一个指向整数的指针(Linux 2.4.22 不支持这个命令)。
当设置成这个模式的时候，PTY master告诉PTY slave行规则模块，不要对从PTY master接收到的任何数据进行处理，要忽略slave的termios结构中的canonical/noncanonical标记。Remote模式用于一些类似窗口管理的应用程序，这些应用程序进行它们自己的行编辑。

窗口大小的改变
PTY master上面的进程可以通过ioctl的TIOCSWINSZ命令来设置slave的窗口大小。如果新的大小和当前的大小不一样，那么会给PTY slave的前台进程组发出一个SIGWINCH信号。

信号产生
读写PTY master的进程可以给PTY slave的进程组发送信号。在Solaris 9中，这个通过ioctl的TIOCSIGNAL命令来实现，其第三个参数就是信号的号码。FreeBSD 5.2.1 和 Mac OS X 10.3中，相应的ioctl命令是TIOCSIG，并且第三个参数是一个指向表示信号号码的整数的指针(Linux 2.4.22 也不支持这个ioctl命令)。

8)总结
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch19lev1sec8.html
我们通过大致展示如何使用伪终端以及查看一些使用用例来开始本章。我们然后检查在本章4个平台上面打开伪终端的代码，来继续。然后我们使用这些代码给出了一个pty_fork函数，这个函数可以被许多应用程序使用。我们使用这个函数作为后面的pty程序的基础，然后我们通过这个pty程序，展示了伪终端的许多特性。
一般我们在大多数UNIX系统中使用伪终端来提供网络登陆。我们也通过一个用批处理脚本启动交互程序的脚本程序，看到了其他使用伪终端的使用。


*其他不太确定的
==========================
*一个用于操作数据库的库
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch20.html
简介
在20实际80年代早期，UNIX系统非常不适合运行多用户的数据库系统。早期的系统，例如Version 7，确实在这个方面有较大的困难。因为这些系统不提供任何形式的IPC(当然除了半双工管道)并且不提供任何形式的字节范围内的锁。后来这些缺陷都被克服了。在20世纪晚期，UNIX体统可以提供一个可靠的，用于多用户数据库系统的环境了。然后，大量的商业公司，开始提供这样的数据库系统。
在本章中，我们开发了一个简单的多用户的数据库c函数库，任何程序都可以调用其中函数向一个数据库中存取或者从中获取记录。这些C函数库只是一个完整的数据库系统的一小部分，我们并没有开发诸如请求语言等其他方面的内容，这些可以参见相关的书籍。我们只关注一个数据库函数库到底需要UNIX系统提供哪些接口，以及那些接口如何与我们前面提到的内容相关联（例如14章3节中字节范围的记录锁）。

*历史背景
有一个在UNIX系统下面比较流行的数据库库函数，叫做dbm(3)库。这个库由Ken Thompson开发，使用动态哈希策略实现。这个库原来由Version 7提供，并且出现在所有的BSD发行版当中。它也被SVR4的BSD兼容库提供。BSD开发者将这个dbm库进行了扩展，然后将它称做ndbm。ndbm库被BSD以及SVR4包含。ndbm的函数在SUS的XSI扩展中被标准化。
Seltzer 和 Yigit曾经详细叙述了dbm以及其它库所使用的动态哈希算法。这些库也包括gdbm（dbm库的GNU版本）。然而，所有这些库的实现，都无法支持多进程之间同时进行数据更新，因为它们没有提供同步控制（例如记录锁）。
4.4BSD提供了一个新的db(3)库，这个库支持三种形式的访问：(a)面向记录。(b)哈希。(c)B-tree。但是它也没有提供同步机制（这也被db(3)用户手册作为其BUGS列出）。
Sleepycat Software提供了db库版本，可以支持同步访问，锁，以及事务处理。
多数数据库库提供同步控制，用于多进程同时进行数据库的更新。这些系统一般使用建议锁（如我们14.3所述）。但是他们一般一般实现自己的锁元素，以避免系统调用的开销，以请求一个没有争议的锁。这些商业系统一般通过B+树来实现他们自己的数据库，有些也使用动态哈希技术（例如线性哈希，或者扩展的哈希）。
下表列出了本书中四个系统经常看到的数据库库。需要注意的是，在Linux上面，gdbm库同时提供了dbm和ndbm函数的支持。

各种平台对数据库库的支持情况
┌─────────┬─────────┬───────────────┬──────────────┬───────────────┬───────────┐
│ Library │ POSIX.1 │ FreeBSD 5.2.1 │ Linux 2.4.22 │ Mac OS X 10.3 │ Solaris 9 │
├─────────┼─────────┼───────────────┼──────────────┼───────────────┼───────────┤
│ dbm     │         │               │     gdbm     │               │     •     │
├─────────┼─────────┼───────────────┼──────────────┼───────────────┼───────────┤
│ ndbm    │   XSI   │       •       │     gdbm     │       •       │     •     │
├─────────┼─────────┼───────────────┼──────────────┼───────────────┼───────────┤
│ db      │         │       •       │      •       │       •       │     •     │
└─────────┴─────────┴───────────────┴──────────────┴───────────────┴───────────┘

本章具体内容，讲述一个类似ndbm库的设计和实现，属于应用开发的范围了，这里不再进行详细讲述，具体参见参考资料。

总结
本章首先对这个数据库函数库进行了设计。虽然见谅保持其简洁，但是它也包含了记录锁的功能，可以让多个进程进行访问。
我们也通过使用没有锁，建议锁（细粒度和粗粒度），和强制锁来对比，看到了这个函数库的执行情况，我们可以看到，建议锁相对没有锁的情况，只增加了不到10%的始终时间，强制锁却相对建议锁增加了33%到66的时间。

*和网络打印机通信
参考：http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/ch21.html
简介
这里，我们开发了一个可以和网络打印机通信的程序。这些打印机可以通过以太网连接到多台计算机上面，提供明文文件或者附笔(PostScript)文件。应用程序通常使用因特网打印协议(IPP)和这些打印机进行交，当然也有一些可选的通信协议。
我们将要讲述两个程序：一个是print spooler 守护进程，它给printer发送作业和提交打印作业的命令给spooler守护进程。print spooler需要用到许多功能（例如和提交作业的客户进程进行通信，和printer进行通信，读取文件，扫描目录等等），所以我们需要用到前面讲述的很多函数。例如，我们使用线程（11章和12章）来简化print spooler的设计，使用sockets(16章)进行调度打印文件的程序与print spooler之间的交互，以及print spooler和网络printer之间的交互。

本章具体内容，属于应用开发的范围了，这里不再进行讲述。具体参见参考资料。这里只给出一个简单的图形，描述这里开发的程序：
                             Printer spooling 的组成

             +---------+              +------------+
             |  print  |<------------>|   printd   |
             | command |              |  printer   |
             +^------^-+              |   spooler  |<---- 
             /        \               +^-----^-----+     \   queue of files to be printed
            /          \        ------/      |            \
           /            \      /             |           +-v-----+    +-------+    +-------+
 +---------+           +--------+            |           | file1 |--->| file2 |--->| file3 |
 | file to |           | config |            |           +-------+    +-------+    +-------+
 |  print  |           |  file  |            |
 +---------+           +--------+            |
                                       +-----v----+
                                       |  printer |
                                       +----------+


总结
这章对两个完整的程序进行了详细的讲述：print spooler守护进程，用于给网络printer发送打印作业；以及一个可以用来提交被打印的作业到spooling守护进程的命令。这样，我们可以看到之前章节中讲到的许多的内容的应用（例如线程，多I/O，文件I/O，套接字I/O，信号等）。

高级输入输出课后练习中，
14.2参考网址在：
http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/app03lev1sec14.html#ch14qa1q2a1
说了一个技巧，就是两个数组之间不能直接通过赋值语句赋值（得循环），但是可以将它们嵌入到一个结构中，通过结构变量之间的赋值达到数组的赋值，这样就不用循环了。
14.8参考网址在：
http://book.chinaunix.net/special/ebook/addisonWesley/APUE2/0201433079/app03lev1sec14.html#ch14qa1q8a1
这里说明了一个问题，就是管道的容量和PIPE_BUF不是一回事情，前者是管道可以容纳的数据，后者是每次"原子性"写入管道的最大字节数目。
