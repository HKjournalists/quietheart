这里说了在EB K1下搜索Wikipedia中的相关总结。

一个参考网站：http://hi.baidu.com/wtnzone/blog/item/39f159daa67de9d1b6fd4892.html

wikipedia访问接口官方文档：
=========================
	http://www.mediawiki.org/wiki/API
其中有各种语言下api的列表。
例如：
　　中文维基API：http://zh.wikipedia.org/w/api.php
　　英文维基API：http://en.wikipedia.org/w/api.php


通过官方文档介绍，访问wikipedia的api有如下几种语言的库接口：
http://www.mediawiki.org/wiki/API:Client_Code
 Python
 Java
 Javascript
 .NET
 Perl
 Ruby
 PHP

常见问题：
参考：http://www.mediawiki.org/wiki/API:FAQ#call_the_API.3F
如何调用api？通过发送http请求给api.php。后面有几个例子可以参考。

如何控制输出的格式？在请求中指定参数字符串"&format=someformat"。

如何获得页面的内容？(txt)
如果你只是想要获取wikitext文件，不要其他的任何信息，那么最好使用"index.php"的"action=raw"模式，来替代api。如：http://en.wikipedia.org/w/index.php?action=raw&title=Main_Page。可以参考文档" action=raw documentation".
prop=revisions 模块可以获得页面的信息.
You can retrieve 50 pages per API request: http://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&titles=Main_Page|Articles This also work with generators.

显示页面的内容?（html）
类似如下的请求来替代api:http://en.wikipedia.org/w/index.php?action=render&title=Main_Page

一些可能有用的信息：
每个自建的mediawiki中都有api的使用帮助，例如我的：
http://192.168.0.118/mediawiki/api.php
其中看似有用的api有：
* list=search (sr) *
* action=opensearch *

*mediawiki的index也有其接口，参考文档：
http://www.mediawiki.org/wiki/Manual:Parameters_to_index.php



实践例子：
=========================
1）在wiki上面全名搜索
http://192.168.0.118/mediawiki/api.php?action=query&list=search&srsearch=测试分类的文章1
这里，wiki网站就是http://192.168.0.118/mediawiki/,
搜索的文章是：测试分类的文章1.这样会列出所有这个名字的文件到一个文件中（默认xml格式）

*用txt显示：
http://192.168.0.118/mediawiki/api.php?action=query&list=search&srsearch=mytest1&format=txt
这里，具体格式参见http://zh.wikipedia.org/w/api.php，这样显示的结果类似如下：
Array
(
    [query] => Array
        (
            [search] => Array
                (
                    [0] => Array
                        (
                            [ns] => 0
                            [title] => Mytest1
                        )

                )

        )

)

*之请求指定页面的内容，不要任何的其他信息：
http://192.168.0.118/mediawiki/index.php?action=raw&title=mytest1

*用txt格式获取页面的版本和作者等信息：
http://192.168.0.118/mediawiki/api.php?action=query&prop=revisions&titles=mytest1&format=txt
这里，如果是txtfm就直接在浏览器中显示出来这个内容了。
内容如下：
Array
(
    [query] => Array
        (
            [normalized] => Array
                (
                    [0] => Array
                        (
                            [from] => mytest1
                            [to] => Mytest1
                        )

                )

            [pages] => Array
                (
                    [15] => Array
                        (
                            [pageid] => 15
                            [ns] => 0
                            [title] => Mytest1
                            [revisions] => Array
                                (
                                    [0] => Array
                                        (
                                            [revid] => 42
                                            [user] => Administrator
                                            [timestamp] => 2010-03-17T08:54:35Z
                                        )

                                )

                        )

                )

        )

)

*获得页面的内容
http://192.168.0.118/mediawiki/api.php?action=query&prop=revisions&titles=mytest1&rvprop=timestamp|user|comment|content

*获得的内容以一定的格式来返回：
http://192.168.0.118/mediawiki/api.php?action=query&prop=revisions&titles=mytest1&rvprop=content&format=xmlfm
这里，如果不用xmlfm用xml就是将文件下载下来。

*根据指定的标题导出页面的txt文本:
http://192.168.0.118/mediawiki/index.php?action=raw&title=mytest1
这里，导出来之后，页面的格式标记也作为txt的内容导出来了,这里使用的是index的接口。

*查看页面的内容，显示到浏览器上面：
http://192.168.0.118/mediawiki/index.php?action=view&title=mytest1
这里使用的是index的接口,显示的内容是源代码，包含页面框架。

*查看页面内容，只显示请求的页面，并且没有格式：
http://192.168.0.118/mediawiki/index.php?action=render&title=mytest1

目前通过wikimedia提供的php接口，返回的内容里面都包含标记，还没有办法把这些标记去掉。

目前打算使用Pywikipediabot工具来请求wikipedia内容：
=========================
这里是python库，好像是访问wikipedia的api接口的一些python脚本集合。
而wikipedia的api接口是php的，利用这些接口可以操作wikipedia上的内容，例如添加删除文章等。
下载地址：http://toolserver.org/~valhallasw/pywiki/
项目地址：https://sourceforge.net/projects/pywikipediabot/
检出地址：svn co http://svn.wikimedia.org/svnroot/pywikipedia/trunk/pywikipedia pywikipedia
文档地址：http://meta.wikimedia.org/wiki/Using_the_python_wikipediabot

1,使用方法：
pywikipediabot机器人程序，利用python脚本，发送http请求，调用mediawiki系统网站提供的php接口，来操作相关的网站，其中它已经支持了wikipedia网站，
这里更一步说明如何利用pywikipediabot机器人程序来操作自己搭建的mediawiki网站。
1）搭建mediawiki
具体步骤不多说了,网上也有,自己也做过类似的总结。

2)运行之前的配置。
在运行其中的模块之前，首先需要配置,大致过程如下：
2.1)安装python2.4或更新版本的python.
2.2)下载pywikipedia机器人程序。
2.3)在解压之后的pywikipedia/families目录里建立你自己的网站描述信息。
2.4)运行generate_user_files.py脚本，生成user-config.py配置文件和user-fixes.py配置文件。
2.5)运login.py登录user-config.py中指定网站的指定用户帐号。
2.6)开始运行其他脚本进行操作。例如category.py来管理分类，template.py来管理模板等等。

下面就关键的地方进行详细说明：
(1)下载pywikipedia机器人程序。
下载地址：http://toolserver.org/~valhallasw/pywiki/
项目地址：https://sourceforge.net/projects/pywikipediabot/
(2)在解压之后的pywikipedia/families目录里建立你自己的网站描述信息:
这里，我将mediawiki的内容搭建在/var/www/mediawiki了。
(2.1)查看自己的网站信息
根据文档说明：http://meta.wikimedia.org/wiki/Pywikipediabot/Use_on_non-WMF_wikis
用如下的php api请求：
http://192.168.0.118/mediawiki/api.php?action=query&meta=siteinfo&siprop=general|namespaces|namespacealiases|statistics
这里，我的网站名称是QuietHeart,机器地址是192.168.0.118,还有mediawiki的版本,以及api的帮助等。
(2.2)建立pywikipedia/families/quietheart_family.py
创建的方法参考：README-family.txt.
关键的地方是含有REQUIRED的地方：
#...前面省略...
self.name = 'quietheart'        # REQUIRED; replace with actual name
self.langs = {                # REQUIRED
	'en': '192.168.0.118/mediawiki',  # Include one line for each wiki in family
		'zh-hans': '192.168.0.118/mediawiki',   # in the format 'code': 'hostname',
}
#...省略...
self.namespaces[4] = {
	'_default': [u'quietheart', self.namespaces[4]['_default']], # REQUIRED
		'de': 'Name des wiki',
	'es': 'Nombre del wiki',
	'zh-hans': 'Nom du wiki',
# ETC.
}
#...省略...
	def scriptpath(self, code):
	#这里，一定注意不要写成return '/'
	return ''
#...省略...
    def version(self, code):
        return '1.15.2'
#...省略...
(2.3)根据你的网站信息，生成用户配置文件：
$python generate_user_files.py
这样按照提示去做，会生成一个user-config.py.文件。

如果想要指定的用户登录，修改其中如下语句：
usernames['quietheart']['zh-hans'] = u'administrator'
这样会在quietheart站点上面用administrator登录。

user-config.py编辑完了之后要去掉写权限,否则登录的时候会被忽略。
(3)登录
$python login.py
这样就登录到你自己的站点上面了。
你就可以使用其他的脚本工具了。

根据文档http://meta.wikimedia.org/wiki/Pywikipediabot/Basic_use
工具中的每个功能脚本的运行方式如下格式：
$python <脚本名>.py
对于所有脚本程序，一些通用的参数:
-help
打印帮助信息列表。

-lang:xx
设置你运行时候的语言码为xx.这个设置会覆盖user-config.py中的设置。

-family:xyz
设置你想要运行的wiki的family.例如:wikipedia,wiktionary等。这里会覆盖user-config.py中的设置。

-log
使用logfile,日志信息会存储在logs子目录。

-log:xyz
使用logfile,使用xyz作为文件名。

-nolog
不使用logfile(前提是默认使用log了).

-putthrottle:nn
设置机器人程序在存储页面的时候的最小等待时间为nn秒。默认的值是10秒。

例如，
python scriptname.py -family:wiktionary
这个命令会运行"scriptname"机器人脚本，取代user-config的family而处理指定的wiktionary上的文章.


2,使用举例:
1)使用query来请求php的api接口：
*调用 action=opensearch 接口，
搜索标题以mytest开始的标题,最多返回2个结果
(1)编写python脚本如下：
#!/usr/bin/python
#Search "mytest" maximum count is 2.
import query
params = {
	'action'    :'opensearch',
	'search'    :'mytest',
	'limit'     :'5',
	'rvlimit'   :'2',
	'rvprop'    :'user|timestamp|content',
}
print query.GetData(params, encodeTitle = False)
(2)运行脚本：
$python mytest_opensearch.py
这里假设python脚本保存的文件名是:mytest_opensearch.py.具体的opensearch,其api参考相关文档。

*调用 list=search (sr) 接口。
在页的标题中搜索含mytest,最大返回数目是5.
(1)编写脚本如下：
#!/usr/bin/python
#Search "mytest" in the title/text,maximum return count is 5.
import query
params = {
	'action'    :'query',
	'list'      :'search',
	'srwhat'    :'title',
#'srwhat'    :'text',
	'srsearch'  :'*mytest*',
	'srlimit'   :'5',
}
print query.GetData(params, encodeTitle = False)
(2)运行脚本：
$python mytest_search.py
这里假设python脚本保存的文件名是:mytest_search.py.具体的search,其api参考相关文档。

*获取指定标题的页面的内容:
$python get.py mytest1
这里，get.py脚本是自带的，mytest1就是要获取的页面的标题。执行之后会把页面的内容用txt的形式打印到标准输出中。



目前的问题：
mediawiki的phpapi提供的访问页面的接口，无论txt还是xml格式，返回的数据都是页面的源代码，而不是解析之后显示给用户的数据。
mediawiki的index接口提供的raw也是这样,好像只要是下载的东西，返回的都是源代码。
